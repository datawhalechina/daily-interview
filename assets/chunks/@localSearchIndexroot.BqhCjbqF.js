const t='{"documentCount":851,"nextId":851,"documentIds":{"0":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#动态规-dp","1":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_1-最长上升子序列","2":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_2-最长公共子序列","3":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_3-最长整除子","4":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_4-背包问题","5":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_5-编辑距离","6":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_6-矩阵链乘","7":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_7-回文划分","8":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_8-丑数","9":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_9-最小花费路","10":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_10-最大矩阵和","11":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_11-最大正方形面积","12":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_12-二进制串个数","13":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_13-交叉字符","14":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_14-乘积最大子序列","15":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#_15-k个数之和","16":"/daily-interview/01-algorithm-basics/algorithm-concepts/dynamic-programming.html#参","17":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#贪心算法","18":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_1-最大连续子序列","19":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_2-删除数字","20":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_3-无重叠区","21":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_4-合并数字","22":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_5-最小支撑树","23":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_6-补齐数组","24":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_7-买卖股票的最佳时","25":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_8-买卖股票的最佳时机ii","26":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_9-买卖股票的最佳时机含手续","27":"/daily-interview/01-algorithm-basics/algorithm-concepts/greedy-algorithms.html#_10-最后的","28":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#search","29":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_1-全排","30":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_2-子集","31":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_3-word-break-problem","32":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_4-k-similar-strings","33":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_5-无向图的联通块","34":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_6-k个数的和","35":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_7-单词接龙","36":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_8-单词搜索","37":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_9-分割字符","38":"/daily-interview/01-algorithm-basics/algorithm-concepts/search-algorithms.html#_10-划分回文","39":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#数组-array�","40":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_1-two-sum","41":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_2-查找旋转数组","42":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_3-主元�","43":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_4-落单的数","44":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_5-中位�","45":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_6-二维数组中的查找","46":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_7-构建乘积数组","47":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_8-滑动窗口的最大�","48":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_9-第k�-�-的数","49":"/daily-interview/01-algorithm-basics/data-structures/arrays-and-strings.html#_10-奇偶排序","50":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#排序-sort","51":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#_1-快速排序","52":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#_2-堆排序","53":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#_3-归并排序","54":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#_4-实现多路归并排序","55":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#_5-单链表插入排序","56":"/daily-interview/01-algorithm-basics/algorithm-concepts/sorting-algorithms.html#_6-单链表归并排序","57":"/daily-interview/01-algorithm-basics/data-structures/graph.html#graph-图","58":"/daily-interview/01-algorithm-basics/data-structures/graph.html#_1-最短路径","59":"/daily-interview/01-algorithm-basics/data-structures/graph.html#_2-最小支撑树","60":"/daily-interview/01-algorithm-basics/data-structures/graph.html#_3-拓扑排序","61":"/daily-interview/01-algorithm-basics/data-structures/graph.html#_4-有向图判环","62":"/daily-interview/01-algorithm-basics/data-structures/graph.html#参考","63":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#linklist","64":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_1-回文链表-234","65":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_2-求单链表的中间节点","66":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_3-删除无序链表中的重复项","67":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_4-给定一个排序链表-删除所有含有重复数字的节点","68":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_5-环形链表-41","69":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_6-反转链表-06","70":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_7-在双向链表中删除指定元素-微软","71":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_8-两个链表合并为一个升序链表-微软","72":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_9-倒数第k个节","73":"/daily-interview/01-algorithm-basics/data-structures/linked-lists.html#_10-等概率返回链表中的一个元","74":"/daily-interview/01-algorithm-basics/data-structures/string.html#_1-最长公共前缀","75":"/daily-interview/01-algorithm-basics/data-structures/string.html#_2-有效的括","76":"/daily-interview/01-algorithm-basics/data-structures/string.html#_3-验证回文","77":"/daily-interview/01-algorithm-basics/data-structures/string.html#_4-反转字符串中的单词iii","78":"/daily-interview/01-algorithm-basics/data-structures/string.html#_5-无重复字符的最长子","79":"/daily-interview/01-algorithm-basics/data-structures/string.html#_6-最长回文子","80":"/daily-interview/01-algorithm-basics/data-structures/string.html#_7-括号生成","81":"/daily-interview/01-algorithm-basics/data-structures/string.html#_8-压缩字符","82":"/daily-interview/01-algorithm-basics/data-structures/string.html#_9-字符串中的第一个唯一字符","83":"/daily-interview/01-algorithm-basics/data-structures/string.html#_10-字符串相","84":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#二叉树-binary-tree","85":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_1-二叉树的遍历","86":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_2-二叉树的z型遍","87":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_3-平衡二叉","88":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_4-前序遍历的第k个结","89":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_5-二叉树的对角线遍","90":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_6-构造二叉树","91":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_7-对称二叉","92":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_8-最近公共祖","93":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_9-寻找树中最左下结点的","94":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_10-二叉树的最长连续子序列","95":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#_11-左边看到的二叉树结点","96":"/daily-interview/01-algorithm-basics/data-structures/trees-and-graphs.html#参","97":"/daily-interview/01-algorithm-basics/#算法基础","98":"/daily-interview/01-algorithm-basics/#📚-内容导航","99":"/daily-interview/01-algorithm-basics/#🔢-数据结构","100":"/daily-interview/01-algorithm-basics/#🧠-算法思想","101":"/daily-interview/01-algorithm-basics/#📊-复杂度分析","102":"/daily-interview/01-algorithm-basics/#🎯-学习重点","103":"/daily-interview/01-algorithm-basics/#数据结构重点","104":"/daily-interview/01-algorithm-basics/#算法思想重点","105":"/daily-interview/01-algorithm-basics/#💡-面试准备建议","106":"/daily-interview/01-algorithm-basics/#🔗-学习路径","107":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#校招前端面试常见问题�-】——nodejs","108":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#nodejs","109":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#q-nodejs-�-io-模型特点是什么-与多线程同步-io-有什么不同","110":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#q-v8-引擎垃圾回收机制是什么样的","111":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#q-实现一�-eventemitter�","112":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#q-es6-模块化、commonjs-模块化的区别�","113":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#nodejs-相关框架","114":"/daily-interview/02-programming-languages/JavaScript/NodeJS.html#q-请简述一�-koa-的洋葱模型","115":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#java-基础","116":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#知识体系","117":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#questions","118":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-hashmap-1-8�-7的区�","119":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-扩容因子默认为什么是0-75","120":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-为什么链表长度为8要转化为红黑�","121":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-string-、stringbuffer-、stringbuilder-的区�","122":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_3-强引用、软引用、弱引用、虚引用的区�","123":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_4-�-equals-区别","124":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_5-object-类的-hashcode-方法的作�","125":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#java并发","126":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#知识体系-1","127":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#questions-1","128":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-线性池了解吗-参数有哪些-任务到达线程池的过程-线程池的大小如何设置","129":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#线程池参�","130":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#线程处理任务过程","131":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#线程池的大小设置","132":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-java乐观锁机制-cas思想-缺点-是否原子性","133":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#java乐观锁机�","134":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#cas思想","135":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#原子�","136":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_3-reentrantlock-使用方法-底层实现-�-synchronized-区别�","137":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#使用方法","138":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#底层实现","139":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#reentrantlock和synchronized-的区�","140":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_4-介绍一�-java-的内存模�","141":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_5-volatile-作用-底层实现-单例模式�-volatile-的作用","142":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#作用","143":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#底层实现-1","144":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#单例模式�-volatile-的作�","145":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_6-threadlocal-原理","146":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_7-cas-�-aba-问题","147":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_8-原子类的实现原理","148":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_9-说一�-currenthashmap-如何实现线程安全�","149":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#jvm","150":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#知识体系-2","151":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#questions-2","152":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-jvm-内存划分","153":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-gc-垃圾收集�","154":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_3-垃圾收集算法-为什么新生代用标�-复制老年代用标记-整理","155":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_4-类加载流�","156":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_5-双亲委派机制-怎么样会打破双亲委派模型","157":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_6-jvm-1-7-�-1-8-的区�","158":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#数据�","159":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#知识体系-3","160":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#questions-3","161":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-mysql的引擎了解吗-默认的是哪个-innodb-�-myisam-的区别","162":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-介绍-mvcc","163":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_3-mysql-中一�-sql-语句的执行过�","164":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_4-如何查看-sql-语句的执行计划-用哪个关键字-使用这个关键字可以得到哪些信息�","165":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_5-聚簇索引和非聚簇索引的区别-非聚簇索引是如何查询的","166":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_6-mysql�-acid-分别解释一�","167":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_7-数据库索引的实现原理","168":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_8-联合索引-最左前缀匹配规则","169":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_9-索引怎么优化","170":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_10-事物隔离级别","171":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_11-binlog、redo-log、undo-log","172":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#binlog","173":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#redo-log","174":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#undo-log","175":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#spring","176":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#知识体系-4","177":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#questions-4","178":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-sping-ioc-aop-的实现原�","179":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-spring-事务的实现原�","180":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_3-bean-的生命周�","181":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#redis","182":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#知识体系-5","183":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#questions-5","184":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_1-基于-redis-的分布式锁是如何实现�","185":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#redisson-实现-redis-分布式锁","186":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_2-跳表数据结构-redis-中哪里用到了跳表","187":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_3-出现缓存雪崩、击穿、穿透的情况及解决方�","188":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#缓存雪崩","189":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#缓存穿�","190":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#缓存击穿","191":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_4-持久化策�","192":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#rdb","193":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#aof","194":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_5-主从复制原理","195":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_6-数据库缓存一致�","196":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#先更新数据库-再更新缓存","197":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#先删除缓存-再更新数据库","198":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#先更新数据库-再删除缓存","199":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#延时双删","200":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_7-redis-的内存淘汰策�","201":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_8-redis-�-key-的过期策�","202":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#_9-redis-是单线程的吗-为什么这么快","203":"/daily-interview/02-programming-languages/Java/java-fundamentals.html#参�","204":"/daily-interview/02-programming-languages/#编程语言","205":"/daily-interview/02-programming-languages/#📂-分类目录","206":"/daily-interview/02-programming-languages/#☕-java","207":"/daily-interview/02-programming-languages/#🌐-javascript","208":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#前端开发校招面试问题整理�-】——javascript","209":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#_1、javascript-基础","210":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-介�-js-的基本数据类型","211":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-js-中如何判断一个对象是什么类型","212":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-js-的原型链你是如何理解的","213":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-js-�-function-call-�-function-apply-的区别","214":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-js-中作用域你是如何理解的","215":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-js-中什么是闭包�","216":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#_2、javascript-流控�","217":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-介绍一�-js-�-promise-的用法","218":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-介绍一�-js-�-async-�-await-的用法-�-promise-的区别","219":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#_3、javascript-常用数据结构","220":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-说几个常用�-array-�-api�","221":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-for-in-�-for-of-遍历数组-对象的区别","222":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-代码实现一下展平数组","223":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-代码实现一下深拷贝对象�","224":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q�-test-�-new-string-test-有什么区别-�-new-object-有什么区别","225":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#_4、dom-bom-api","226":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-addeventlistener-用法-和-onxxx-的区别是什么","227":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-事件代理指的是什么","228":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-如何使�-js-访问-cookie-如果想要禁止用-js-访问-cookie-该怎么做","229":"/daily-interview/02-programming-languages/JavaScript/javascript-fundamentals.html#q-如何使�-js-计算浏览器可视区域","230":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#计算机网络","231":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#知识体系","232":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#questions","233":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_1-计算机网络分层的优点和缺点","234":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_2-计算机体系结构","235":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_3-从输入网址到获得页面的过程","236":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_4-三次握手","237":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#为什么需要三次握手","238":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_5-四次挥手","239":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#为什么需要四次挥手","240":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_6-tcp和udp的区别","241":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_7-tcp如何保证可靠传输","242":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_8-tcp流量控制","243":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_9-tcp拥塞控制","244":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_10-session与cookie","245":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_11-http状态码","246":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_12-http报文","247":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_13-http与https的区别","248":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#面试真题","249":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_1-dns的具体过程","250":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_2-arp协议的工作原理和流程-路由器是如何转发的-路由表的工作原理","251":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_3-ipv4和ipv6的区别","252":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#_4-对称加密和非对称加密在https的应用","253":"/daily-interview/03-computer-basics/computer-network/network-protocols.html#参考链接","254":"/daily-interview/03-computer-basics/database/sql-fundamentals.html#数据库","255":"/daily-interview/03-computer-basics/database/sql-fundamentals.html#_1-事务四大特性","256":"/daily-interview/03-computer-basics/database/sql-fundamentals.html#_2-数据库模型编辑","257":"/daily-interview/03-computer-basics/database/sql-fundamentals.html#_3-数据库三范式","258":"/daily-interview/03-computer-basics/database/sql-fundamentals.html#_4-关系型数据库和非关系型数据库","259":"/daily-interview/03-computer-basics/database/sql-fundamentals.html#参考","260":"/daily-interview/03-computer-basics/#计算机基础","261":"/daily-interview/03-computer-basics/#📂-分类目录","262":"/daily-interview/03-computer-basics/#💻-操作系统","263":"/daily-interview/03-computer-basics/#🌐-计算机网络","264":"/daily-interview/03-computer-basics/#🗄️-数据库","265":"/daily-interview/03-computer-basics/#📊-数学基础","266":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#逻辑题目","267":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#_1-猜数字","268":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#_2-握手","269":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#_3-找出毒药","270":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#_4-坏鸡蛋","271":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#_5-测半径","272":"/daily-interview/03-computer-basics/mathematics/discrete-mathematics.html#参考-copy","273":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#概率题目","274":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_1-三角形问题","275":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_2-排列组合","276":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_3-男女比例","277":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_4-取球问题","278":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_5-等概率器","279":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_6-再谈等概率器","280":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_7-吃苹果","281":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_8-蚂蚁爬三角形","282":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_9-正确的概率","283":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#_10-和超过1的个数","284":"/daily-interview/03-computer-basics/mathematics/probability-statistics.html#参考","285":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#操作系统","286":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#知识体系","287":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#questions","288":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_1-进程和线程的区别","289":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_2-协程","290":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_3-进程的状态","291":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#三态模型","292":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#五态模型","293":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_4-进程间通信方式","294":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_5-僵尸进程和孤儿进程","295":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_6-死锁","296":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#死锁产生的必要条件","297":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#死锁预防","298":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#死锁避免","299":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_7-页面置换算法","300":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_8-分页和分段的区别","301":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_9-硬中断和软中断","302":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#_10-io模型","303":"/daily-interview/03-computer-basics/operating-system/processes-and-threads.html#参考链接","304":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#cv基础知识","305":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_1-为什么需要做特征归一化、标准化","306":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_2-常用常用的归一化和标准化的方法有哪些","307":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_4-怎么判断模型是否过拟合-有哪些防止过拟合的策略","308":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_5-除了sgd和adam之外-你还知道哪些优化算法","309":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_6-阐述一下感受野的概念-并说一下在cnn中如何计算","310":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_7-训练神经网络有哪些调参技巧","311":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_8-神经网络的深度和宽度分别指的是什么","312":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_9-上采样的原理和常用方式","313":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_10-下采样的作用是什么-通常有哪些方式","314":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_11-模型的参数量指的是什么-怎么计算","315":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_12-模型的flops-计算量-指的是什么-怎么计算","316":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_13-有哪些经典的卷积类型","317":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_14-深度可分离卷积的概念和作用","318":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_15-神经网络中addition-concatenate区别是什么","319":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_16-激活函数是什么-你知道哪些常用的激活函数","320":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_17-神经网络中1×1卷积有什么作用","321":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_18-随机梯度下降相比全局梯度下降好处是什么","322":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_19-如果在网络初始化时给网络赋予0的权重-这个网络能正常训练嘛","323":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_20-为什么要对网络进行初始化-有哪些初始化的方法","324":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_21-增大感受野的方法","325":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_22-神经网络的正则化方法-过拟合的解决方法","326":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_23-梯度消失和梯度爆炸的原因是什么","327":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_24-深度学习为什么在计算机视觉领域这么好","328":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_25-为什么神经网络种常用relu作为激活函数","329":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_26-卷积层和全连接层的区别是什么","330":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_27-什么是正则化-l1正则化和l2正则化有什么区别","331":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_28-常见的损失函数有哪些-你用过哪些","332":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_29-dropout为什么能解决过拟合","333":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_30-深度学习中的batch的大小对学习效果有何影响","334":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_31-pytorch和tensorflow的特点分别是什么","335":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_32-pytorch-多卡并行的时候怎么实现参数共享-通信梯度是指平均梯度-还是最大梯度-还是梯度总和","336":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_33-数据不平衡的解决方法","337":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_34-relu函数在0处不可导-为什么还能用","338":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_35-pooling层的作用以及如何进行反向传播","339":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_36-为什么max-pooling-要更常用-什么场景下-average-pooling-比-max-pooling-更合适","340":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_37-为什么要反向传播-手推反向传播公式展示一下","341":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_38-cv中的卷积操作和数学上的严格定义的卷积的关系","342":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_39-简述cnn分类网络的演变脉络及各自的贡献与特点","343":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_40-神经网络的优缺点","344":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_41-softmax-cross-entropy如何反向求导","345":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_42-有什么数据增强的方式","346":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_43-为什么在模型训练开始会有warm-up","347":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_44-vgg使用3-3卷积核的优势是什么","348":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_45-什么是group-convolution","349":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_46-训练过程中-若一个模型不收敛-那么是否说明这个模型无效-导致模型不收敛的原因有哪些","350":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_47-relu比sigmoid的效果好在哪里","351":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_48-batch-normalization的作用","352":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_49-gan网络的思想","353":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_50-attention机制的作用","354":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_51-怎么提升网络的泛化能力","355":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_52-cnn为什么比dnn在图像识别上更好","356":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_53-dnn的梯度是如何更新的","357":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#_54-depthwise-卷积实际速度与理论速度差距较大-解释原因。","358":"/daily-interview/04-ai-algorithms/computer-vision/cv-fundamentals.html#主要的参考文献","359":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#目标检测部分","360":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#一、目标检测背景知识","361":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#传统目标检测算法","362":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#基于深度学习目标检测算法","363":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#二、questions","364":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_1、faster-rcnn网络","365":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_1-请介绍一下faster-r-cnn网络的原理-注-需要能够详细画出网络结构图-顺丰-一面-2018-、腾讯-一面-2018-、旷视-三面-2018","366":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2-请简要叙述一下-r-cnn——faster-r-cnn","367":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-faster-r-cnn是经典的two-stage-检测器-请简单说明其中two-stage的含义。","368":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_5-说一下roi-pooling是怎么做的-有什么缺陷-有什么作用-顺丰-一面-2018","369":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_6-roi-pooling与roi-align-mask-r-cnn-的区别-字节跳动-二面-2019","370":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_7-faster-r-cnn是如何解决正负样本不平衡的问题","371":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_8-faster-rcnn怎么筛选正负anchor","372":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_9-faster-rcnn中bbox回归用的是什么公式-说一下该网络是怎么回归bbox的","373":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_10-简述faster-rcnn的前向计算过程并简述faster-rcnn训练步骤","374":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_11-介绍faster-rcnn这个流程-faster-rcnn有哪些缺点-如何改进-商汤-一面-2019","375":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_12-阐述一下mask-rcnn网络-这个网络相比于faster-rcnn网络有哪些改进的地方","376":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_13-比较fasterrcnn在rcnn系列中的改进点","377":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2、yolo系列网络","378":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_1-yolov1、yolov2、yolov3复述一遍-yolov1到v3的发展历程以及解决的问题。-云从科技-一面-2020-、旷视-三面-2018","379":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2-yolo的预测框是什么值","380":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-yolov2中如何通过k-means得到anchor-boxes","381":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_4-请叙述一下yolov3中k-means聚类获得anchor-boxes过程详解","382":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_5-yolo系列anchor的设计原理-kmeans的原理-anchor距离如何度量-如何改进k-means原理","383":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_6-yolov3框是怎么得到的-yolov3有什么致命问题-长虹ai-lab-一面-2020-、阿里实习-一面-2018-、中兴-一面-2019","384":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-其他检测网络","385":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_1-简要阐述一下ssd网络-有哪些优点缺点-商汤-一面-2019-、蘑菇街-一面-2018","386":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2-简述ssd网络前向是如何计算的","387":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-简要阐述一下retinanet","388":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_4-简单叙述一下retinanet中的fpn代码运行流程-p6、p7的作用是什么","389":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_5-简单介绍下cascade-rcnn-字节跳动-三面-2019","390":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_6-简要介绍一下fpn-百度实习-一面-2019-、字节跳动-二面-2019-、云从科技-二面-2019","391":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2-anchor设置的意义","392":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-如何理解concat和add这两种常见的feature-map特征融合方式","393":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_4-介绍一下目标检测的主要评测指标","394":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_5-flops计算","395":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_6-参数量paras计算-参数与flops中一致","396":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_7-简单介绍一下kmeans算法-小米-一面-2020-、腾讯-一面-2018","397":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_8-说一下非极大值抑制-nms-non-maximum-suppression-nms实现细节-手撕nms-小米-二面-2020-、-百度实习-一面-2019-、商汤-一面-2019-、腾讯-一面-2018","398":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_7、延伸问题","399":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_1-讲一下目标检测优化的方向-百度实习-一面-2019","400":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2-如果只能修改rpn网络的话-怎么修改可以提升网络小目标检出率","401":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-阐述一下如何检测小物体","402":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_4-阐述一下目标检测任务中的多尺度","403":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_5-如果有很长-很小-或者很宽的目标-应该如何处理目标检测中如何解决目标尺度大小不一的情况-小目标不好检测-有试过其他的方法吗-比如裁剪图像进行重叠","404":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_6-检测的框角度偏移了45度-这种情况怎么处理-海康-一面-2020","405":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_8、思考一下","406":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_1-讲一下two-stage和one-stage的异同-百度实习-一面-2019","407":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_2-讲一下faster-rcnn的两阶段训练和end-to-end训练的不一样-百度实习-一面-2019","408":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_3-讲一下你所知道的插值方式-百度实习-一面-2019","409":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_4-一阶段ssd-yolo之间的区别是什么-tencent-ai-lab-一面-2020","410":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_5-r-cnn系列和ssd本质有啥不一样吗-tencent-ai-lab-一面-2020","411":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_6-讲一下目标检测的发展历程-从传统到深度-百度实习-一面-2019","412":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_7-近年来-一些新的目标检测的backbone有哪些-各有什么特点-小米-一面-2020","413":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#_8-为选择用yolov3-这个网络真的好吗-长虹ai-lab-一面-2020","414":"/daily-interview/04-ai-algorithms/computer-vision/object-detection.html#三、参考链接","415":"/daily-interview/04-ai-algorithms/#ai算法","416":"/daily-interview/04-ai-algorithms/#📂-分类目录","417":"/daily-interview/04-ai-algorithms/#🤖-机器学习","418":"/daily-interview/04-ai-algorithms/#👁️-计算机视觉","419":"/daily-interview/04-ai-algorithms/#🗣️-自然语言处理","420":"/daily-interview/04-ai-algorithms/#📊-推荐系统","421":"/daily-interview/04-ai-algorithms/#🧠-大语言模型","422":"/daily-interview/04-ai-algorithms/llm/llm-interview-questions.html#大模型的一些面试题小结","423":"/daily-interview/04-ai-algorithms/llm/llm-interview-questions.html#英语学习应用中如何限制词汇范围","424":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#adaboost-算法介绍","425":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_1-集成学习","426":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_2-adaboost-算法详解","427":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_2-1-adaboost-步骤概览","428":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_2-2-adaboost-算法流程","429":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-算法面试题","430":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-1-adaboost分类模型的学习器的权重系数怎么计算的","431":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-2-adaboost能否做回归问题","432":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-3-boosting和bagging之间的区别-从偏差-方差的角度解释adaboost","433":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-4-为什么adaboost方式能够提高整体模型的学习精度","434":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-5-adaboost算法如何加入正则项","435":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-6-adaboost使用m个基学习器和加权平均使用m个学习器之间有什么不同","436":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-7-adaboost和gbdt之间的区别","437":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-8-adaboost的迭代次数-基学习器的个数-如何控制","438":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-9-adaboost算法中基学习器是否很重要-应该怎么选择基学习器","439":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-10-multiboosting算法将adaboost作为bagging的基学习器-iterative-bagging将bagging作为adaboost的基学习器。比较两者的优缺点","440":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-11-训练过程中-每轮训练一直存在分类错误的问题-整个adaboost却能快速收敛-为何","441":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#_3-12-adaboost-的优缺点","442":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Adaboost.html#参考资料","443":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#catboost面试","444":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_1-简单介绍catboost","445":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_2-相比于xgboost、lightgbm-catboost的创新点有哪些","446":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_3-catboost是如何处理类别特征的","447":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_4-catboost如何避免梯度偏差","448":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_5-catboost如何避免预测偏移","449":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_6-解释一下排序提","450":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_7-catboost为什么要使用对称树","451":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/Catboost.html#_8-catboost的优缺点","452":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#集成学习面试题","453":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_1-什么是集成学习算法","454":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_2-集成学习主要有哪几种框架","455":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_3-简单介绍一下bagging-常用bagging算法有哪些","456":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_4-简单介绍一下boosting-常用boosting算法有哪些","457":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_5-boosting思想的数学表达式是什么","458":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_6-简单介绍一下stacking","459":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_7-你意识到你的模型受到低偏差和高方差问题的困扰-应该使用哪种算法来解决问题呢-为什么","460":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_8-常用的基分类器是什么","461":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_9-可否将随机森林中的基分类器-由决策树替换为线性分类器或k-近邻-请解释为什么","462":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/EnsembleLearning.html#_10-gbdt和rf如何计算特征重要性","463":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#lightgbm面试题","464":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_1-简单介绍一下lightgbm","465":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_2-介绍一下直方图算法","466":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_3-介绍一下leaf-wise和-level-wise","467":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_4-介绍一下单边梯度采样算法-goss","468":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_5-介绍互斥特征捆绑算法-efb","469":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_6-特征之间如何捆绑","470":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_7-lightgbm是怎么支持类别特征","471":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_8-lightgbm的优缺点","472":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#_9-gbdt是如何做回归和分类的","473":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/LightGBM.html#参考资料","474":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#随机森林面试题","475":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_1-简单介绍随机森林","476":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_2-随机森林的随机性体现在哪里","477":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_3-随机森林为什么不容易过拟合","478":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_4-为什么不用全样本训练","479":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_5-为什么要随机特征","480":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_6-rf与-gbdt-的区别","481":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_7-rf为什么比bagging效率高","482":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_8-你已经建了一个有10000棵树的随机森林模型。在得到0-00的训练误差后-你非常高兴。但是-验证错误是34-23。到底是怎么回事-你还没有训练好你的模型吗","483":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_9-如何使用随机森林对特征重要性进行评估","484":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_10-随机森林算法训练时主要需要调整哪些参数","485":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_11-随机森林的优缺点","486":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_12-简述一下adaboost原理","487":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_13-adaboost的优点和缺点","488":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_14-adaboost对噪声敏感吗","489":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/RandomForest.html#_15-adaboost和随机森林算法的异同点","490":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#树模型集成学","491":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#概要介绍","492":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#randomforest","493":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#gbdt","494":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#xgboost","495":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#lightgbm","496":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#核心公式","497":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#算法十问","498":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#面试真题","499":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/TreeEmbedding.html#参","500":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#xgboost面试","501":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_1-rf和gbdt的区","502":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_2-比较lr和gbdt-说说什么情景下gbdt不如lr","503":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_3-简单介绍一下xgboost","504":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_4-xgboost与gbdt有什么不","505":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_5-xgboost为什么可以并行训","506":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_6-xgboost为什么快","507":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_7-xgboost中如何处理过拟合的情况","508":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_8-xgboost如何处理缺失值","509":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_9-xgboost如何处理不平衡数据","510":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_10-xgboost如何选择最佳分裂点","511":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_11-xgboost的scalable性如何体现","512":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_12-xgboost如何评价特征的重要性","513":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_14-xgboost的优缺","514":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_15-xgboost和lightgbm的区别","515":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_16-gbdt的拟合值残差为什么用负梯度代替-而不是直接拟合残","516":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#_17-xgboost使用二阶泰勒展开的目的和优势","517":"/daily-interview/04-ai-algorithms/machine-learning/ensemble-learning/XGBoost.html#参","518":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/CRF.html#条件随机场面试题","519":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/CRF.html#_1-简单介绍条件随机场","520":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/CRF.html#_4-hmm、memm和crf模型的比","521":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/CRF.html#_5-注意要点","522":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/CRF.html#参","523":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#hmm","524":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#author-李文-email-cocoleyy-outlook-com","525":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#直观理解","526":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#核心公式","527":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#注意要点","528":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#面试真题","529":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/HMM.html#参","530":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#prophet面试","531":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_1-简要介绍prophet","532":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_2-趋势项模","533":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_3-变点的选择","534":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_4-对未来的预估","535":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_5-季节性趋","536":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_6-节假日效应-holidays-and-events","537":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#_7-参数","538":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/Prophet.html#参考资","539":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#梯度下降法面试题","540":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_1-机器学习中为什么需要梯度下降","541":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_2-梯度下降法缺点","542":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_3-梯度下降法直观理解","543":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_4-梯度下降核心思想归纳","544":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_5-如何对梯度下降法进行调优","545":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_6-随机梯度和批量梯度区别","546":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_7-各种梯度下降法性能比较","547":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_8-推导多元函数梯度下降法的迭代公式。","548":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_9-梯度下降法如何判断是否收敛","549":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_10-梯度下降法为什么要在迭代公式中使用步长系数","550":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_11-梯度下降法和牛顿法能保证找到函数的极小值点吗-为什么","551":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_12-解释一元函数极值判别法则。","552":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_13-解释多元函数极值判别法则。","553":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_14-什么是鞍点","554":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_15-解释什么是局部极小值-什么是全局极小值。","555":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#_16-推导多元函数牛顿法的迭代公式。","556":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/gradient-descent.html#参考资料","557":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#过拟合欠拟合面试题","558":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_1-如何理解高方差与低偏差","559":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_2-什么是过拟合和欠拟合-为什么会出现这个现象","560":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_3-怎么解决欠拟合","561":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_4-怎么解决过拟合-重点","562":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_5-为什么参数越小代表模型越简单","563":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_6-为什么l1比l2更容易获得稀疏解-重点","564":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_7-dropout为什么有助于防止过拟合-重点","565":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_8-dropout在训练和测试时都需要吗","566":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_9-dropout如何平衡训练和测试时的差异呢","567":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_10-bn和dropout共同使用时会出现的问题","568":"/daily-interview/04-ai-algorithms/machine-learning/fundamentals/overfitting-underfitting.html#_11-l1-和-l2-正则先验分别服从什么分布","569":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#ab测试面试题","570":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_1-介绍一下abtest的步骤","571":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_2-abtest背后的理论支撑是什么","572":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_3-如何分组才能更好地避免混淆呢","573":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_4-样本量大小如何","574":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_5-两类错误是什么","575":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_6-埋点-暗中观察","576":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#_7-如果一个人有多个账号-分别做不同用途-abtest的时候怎么分组才最合理呢","577":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/ABTest.html#参考资料","578":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#评测指标面试","579":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#回归-regression","580":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#平均绝对误差-mae","581":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#均方误差-mse","582":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#均方根误-rmse","583":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#r2-score","584":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#分类-classification","585":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#准确率和错误","586":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#混淆矩阵","587":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#精确率-查准率-precision","588":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#召回率-查全率-recall","589":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#f1-score","590":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#roc","591":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#auc","592":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#ks-kolmogorov-smirnov","593":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#ctr-click-through-rate","594":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#cvr-conversion-rate","595":"/daily-interview/04-ai-algorithms/machine-learning/model-evaluation/metrics.html#参","596":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#决策树面试题","597":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_1-简单介绍决策树算法","598":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_2-决策树和条件概率分布的关系","599":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_3-信息增益比相对信息增益有什么好处","600":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_4-id3算法-c4-5算法-cart算法","601":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_5-决策树的缺失值是怎么处理的","602":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_6-决策树的目标函数是什么","603":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_7-决策树怎么处理连续性特征","604":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_8-决策树对离散值的处理","605":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_9-决策树怎么防止过拟合","606":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_10-如果特征很多-决策树中最后没有用到的特征一定是无用吗","607":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_11-决策树的优缺点","608":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_12-树形结构为什么不需要归一化","609":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#_13-如果特征很多-决策树中最后没有用到的特征一定是无用吗","610":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/DecisionTree.html#参考资料","611":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#贝叶斯面试题","612":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_1-简述朴素贝叶斯算法原理和工作流","613":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_2-条件概率、先验概率、后验概率、联合概率、贝叶斯公式的概","614":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_3-为什么朴素贝叶斯如此朴素","615":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_4-什么是贝叶斯决策理论","616":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_5-朴素贝叶斯算法的前提假设是什么","617":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_6-为什么属性独立性假设在实际情况中很难成立-但朴素贝叶斯仍能取得较好的效","618":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_7-什么是朴素贝叶斯中的零概率问题-如何解决","619":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_8-朴素贝叶斯中概率计算的下溢问题如何解决","620":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_9-当数据的属性是连续型变量时-朴素贝叶斯算法如何处理","621":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_10-朴素贝叶斯有哪几种常用的分类模型","622":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_11-为什么说朴素贝叶斯是高偏差低方差","623":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_12-朴素贝叶斯为什么适合增量计算","624":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_13-高度相关的特征对朴素贝叶斯有什么影响","625":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_14-朴素贝叶斯的应用场景有哪些","626":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_15-朴素贝叶斯有什么优缺点","627":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_16-朴素贝叶斯与-lr-区别","628":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_17-贝叶斯优化算-参数调优","629":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_18-朴素贝叶斯分类器对异常值敏感吗","630":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_19-朴素贝叶斯算法对缺失值敏感吗","631":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_20-一句话总结贝叶斯算","632":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/NaiveBayes.html#_21-朴素贝叶斯与lr的区别-经典问题","633":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#svm面试题","634":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_1-svm直观解释","635":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_2-核心公式","636":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_3-svm-为什么采用间隔最大化","637":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_4-为什么要将求-svm-的原始问题转换为其对偶问","638":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_5-为什-svm-要引入核函数","639":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_6-为什么svm对缺失数据敏","640":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_7-svm-核函数之间的区别","641":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_8-lr和svm的联系与区别","642":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_9-svm的原理是什么","643":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#_10-svm如何处理多分类问题","644":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/SVM.html#参考文","645":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#knn面试","646":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#_1-简述一下knn算法的原","647":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#_2-如何理解knn中的k的取值","648":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#_3-在knn的样本搜索中-如何进行高效的匹配查找","649":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#_4-knn算法有哪些优点和缺点","650":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#_5-不平衡的样本可以给knn的预测结果造成哪些问题-有没有什么好的解决方式","651":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#_6-为了解决knn算法计算量过大的问题-可以使用分组的方式进行计算-简述一下该方式的原理","652":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/kNN.html#参","653":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#线性回归于逻辑回归面试题","654":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_1-简单介绍一下线性回归。","655":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_2-线性回归的假设函数是什么形式","656":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_3-线性回归的损失函数是什么形式","657":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_4-简述岭回归与lasso回归以及使用场景。","658":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_5-线性回归要求因变量服从正态分布吗","659":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_6-简单介绍一下逻辑回归","660":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_7-简单介绍一下sigmoid函数","661":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_8-逻辑回归的损失函数是什么","662":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_9-逻辑回归如何进行多分类","663":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_10-逻辑回归的优缺点","664":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_11-逻辑斯特回归为什么要对特征进行离散化。","665":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_12-线性回归与逻辑回归的区别","666":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_13-为什么逻辑回归比线性回归要好","667":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_14-逻辑回归有哪些应用","668":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_15-如果label-1-1-给出lr的损失函数","669":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_16-逻辑回归在训练的过程当中-如果有很多的特征高度相关或者说有一个特征重复了100遍-会造成怎样的影响","670":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_17-lr为什么使用sigmoid函数","671":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_18-lr如何进行并行计算","672":"/daily-interview/04-ai-algorithms/machine-learning/supervised-learning/linear-logistic-regression.html#_19-lr和svm有什么不同吗","673":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#k-means面试题","674":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_1-聚类算法-clustering-algorithms-介绍","675":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_2-kmeans原理详解","676":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_3-优缺点及改进算法","677":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_4-k值的选取","678":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_5-k-means算法中初始点的选择对最终结果的影响","679":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_6-为什么在计算k-means之前要将数据点在各维度上归一化","680":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_7-k-means不适用哪些数据","681":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_8-k-means-中常用的距离度量","682":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_9-k-means是否会一直陷入选择质心的循环停不下来-为什么迭代次数后会收敛","683":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_10-聚类和分类区别","684":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_11-如何对k-means聚类效果进行评估","685":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#_12-k-means中空聚类的处理","686":"/daily-interview/04-ai-algorithms/machine-learning/unsupervised-learning/kmeans.html#参考资料","687":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#基于深度学习的模型","688":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#知识体系","689":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#cnn","690":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#rnn","691":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#questions","692":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#cnn相关","693":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#cnn-有什么好处","694":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#cnn-有什么不足","695":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#卷积层输出-size","696":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#rnn-1","697":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#lstm-网络结构","698":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#如何解决-rnn-中的梯度消失或梯度爆炸问题","699":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#假设输入维度为-m-输出为-n-求-gru-参数","700":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#lstm-和-gru-的区别","701":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#attention","702":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#attention-机制","703":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#自注意力中为何要缩放","704":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#transformer","705":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#transformer-中为什么用-add-而不是-concat","706":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#elmo","707":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#简单介绍下elmo","708":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#elmo的缺点","709":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#gpt","710":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#简单介绍下gpt","711":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#gpt的缺点","712":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#bert","713":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#简单介绍下bert","714":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#bert缺点","715":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#ernie","716":"/daily-interview/04-ai-algorithms/nlp/deep-learning-models.html#ernie对bert进行了哪些优化","717":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-模型介绍","718":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-1-模型概述","719":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-2-cbow模型","720":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-2-1-hierarchical-softmax","721":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-2-2-negative-sampling","722":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-3-skip-gram模型","723":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-3-1-hierarchical-softmax","724":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_1-3-2-negative-sampling","725":"/daily-interview/04-ai-algorithms/nlp/text-representation.html#_2-常见面试问题","726":"/daily-interview/04-ai-algorithms/recommendation/collaborative_filtering.html#协同过滤-collaborative-filtering","727":"/daily-interview/04-ai-algorithms/recommendation/collaborative_filtering.html#直观解释","728":"/daily-interview/04-ai-algorithms/recommendation/collaborative_filtering.html#导图","729":"/daily-interview/04-ai-algorithms/recommendation/collaborative_filtering.html#核心公式","730":"/daily-interview/04-ai-algorithms/recommendation/collaborative_filtering.html#注意要点","731":"/daily-interview/04-ai-algorithms/recommendation/collaborative_filtering.html#面试真题","732":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#deepfm","733":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#模型结构","734":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#input与embedding层","735":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#wide部分-fm","736":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#deep部分","737":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#output层","738":"/daily-interview/04-ai-algorithms/recommendation/deepfm.html#面试相关","739":"/daily-interview/04-ai-algorithms/recommendation/gbdt_lr.html#gbdt-lr","740":"/daily-interview/04-ai-algorithms/recommendation/gbdt_lr.html#核心思想","741":"/daily-interview/04-ai-algorithms/recommendation/gbdt_lr.html#面试十问","742":"/daily-interview/04-ai-algorithms/recommendation/gbdt_lr.html#面试真题","743":"/daily-interview/04-ai-algorithms/recommendation/gbdt_lr.html#参考","744":"/daily-interview/05-system-design/#系统设计","745":"/daily-interview/05-system-design/#📂-分类目录","746":"/daily-interview/06-development-tech/big-data/big-data-interview.html#面试题目","747":"/daily-interview/06-development-tech/big-data/big-data-interview.html#_1-相同url","748":"/daily-interview/06-development-tech/big-data/big-data-interview.html#_2-query排序","749":"/daily-interview/06-development-tech/big-data/big-data-interview.html#_3-top-k-单词","750":"/daily-interview/06-development-tech/big-data/big-data-interview.html#_4-ip统计","751":"/daily-interview/06-development-tech/big-data/big-data-interview.html#_5-不重复的整数","752":"/daily-interview/06-development-tech/big-data/big-data-interview.html#_6-top-k","753":"/daily-interview/06-development-tech/big-data/big-data-interview.html#参考","754":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#相关技","755":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#排序","756":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#堆排","757":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#快速排","758":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#桶排","759":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#位图排序","760":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#归并排序","761":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#倒排索引","762":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#字典","763":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#面试问题","764":"/daily-interview/06-development-tech/big-data/hadoop-ecosystem.html#参","765":"/daily-interview/06-development-tech/big-data/#背景","766":"/daily-interview/06-development-tech/big-data/#笔者联系方�","767":"/daily-interview/06-development-tech/big-data/#大数据技术框�","768":"/daily-interview/06-development-tech/big-data/mapreduce.html#海量数据处理常用技术概述","769":"/daily-interview/06-development-tech/big-data/mapreduce.html#海量数据处理-从分而治之到mapreduce","770":"/daily-interview/06-development-tech/big-data/mapreduce.html#浅谈技术细节","771":"/daily-interview/06-development-tech/big-data/mapreduce.html#参考","772":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#前端开发校招面试问题整理�-】——html","773":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#_1、html-元素-element�","774":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#q-简单介绍下常用�-html-元素�","775":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#q-语义化元素是指�","776":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#q-html5-新增了哪些元素","777":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#_2、html-事件","778":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#q-描述一�-html-的事件模型-事件捕获-事件冒泡指的是","779":"/daily-interview/06-development-tech/frontend/HTML_CSS.html#q-如何阻止事件冒泡-如何阻止元素默认行为�","780":"/daily-interview/06-development-tech/frontend/css-advanced.html#校招前端面试常见问题【3】——css","781":"/daily-interview/06-development-tech/frontend/css-advanced.html#_1、盒模型","782":"/daily-interview/06-development-tech/frontend/css-advanced.html#q-请简述一下-css-盒模型","783":"/daily-interview/06-development-tech/frontend/css-advanced.html#_4、常见概念","784":"/daily-interview/06-development-tech/frontend/css-advanced.html#q-fc-是什么-bfc-和-ifc-是什么","785":"/daily-interview/06-development-tech/frontend/css-advanced.html#q-如何清除浮动","786":"/daily-interview/06-development-tech/frontend/css-advanced.html#q-什么是回流-什么是重绘","787":"/daily-interview/06-development-tech/frontend/css-advanced.html#q-如何开启-gpu-加速-其优缺点是什么","788":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#校招前端面试常见问题�-】——前端框架及常用工具","789":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#react","790":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-请简述一下虚�-dom-的概念","791":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-请简述一�-react-的生命周期","792":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-请简述一�-react-fiber-的概念","793":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-react-setstate-的时机","794":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#vue","795":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-什么是-mvvm-模式�","796":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-请简述一�-vue-响应式数据的原理�","797":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-请简述一�-vue-的生命周期","798":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-请简述一�-vue-router-的原理","799":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#打包工具","800":"/daily-interview/06-development-tech/frontend/frontend-frameworks.html#q-介绍一�-webpack�","801":"/daily-interview/06-development-tech/#开发技�","802":"/daily-interview/06-development-tech/#📂-分类目录","803":"/daily-interview/06-development-tech/#🌐-前端开发","804":"/daily-interview/06-development-tech/#📊-大数据","805":"/daily-interview/07-project-experience/#项目经验","806":"/daily-interview/07-project-experience/#📂-分类目录","807":"/daily-interview/08-behavioral-interview/#行为面试","808":"/daily-interview/08-behavioral-interview/#📚-内容导航","809":"/daily-interview/08-behavioral-interview/#🎯-自我介绍","810":"/daily-interview/08-behavioral-interview/#🚀-职业规划","811":"/daily-interview/08-behavioral-interview/#💪-压力面试","812":"/daily-interview/08-behavioral-interview/#💰-薪资谈判","813":"/daily-interview/08-behavioral-interview/#🎯-行为面试核心评估维度","814":"/daily-interview/08-behavioral-interview/#🧠-认知能力","815":"/daily-interview/08-behavioral-interview/#学习能力","816":"/daily-interview/08-behavioral-interview/#问题解决","817":"/daily-interview/08-behavioral-interview/#🤝-人际能力","818":"/daily-interview/08-behavioral-interview/#沟通协�-表达能力-清晰准确地表达想法和观�-倾听能力-理解他人观点和需�-团队合作-与不同背景的人有效协作","819":"/daily-interview/08-behavioral-interview/#领导�-影响�-影响和说服他人的能�-责任�-承担责任和推动结果的意�-团队建设-激励和发展团队成员","820":"/daily-interview/08-behavioral-interview/#💪-个人品质","821":"/daily-interview/08-behavioral-interview/#工作态度","822":"/daily-interview/08-behavioral-interview/#价值观","823":"/daily-interview/08-behavioral-interview/#💡-常见行为面试问题","824":"/daily-interview/08-behavioral-interview/#自我认知�-请简单介绍一下自�","825":"/daily-interview/08-behavioral-interview/#经历回顾�-请介绍一个你最有成就感的项�","826":"/daily-interview/08-behavioral-interview/#情景假设�-如果你的上级给你安排了一个不合理的任务-你会怎么办","827":"/daily-interview/08-behavioral-interview/#公司文化�-你了解我们公司吗-为什么想加入我们�","828":"/daily-interview/08-behavioral-interview/#🔍-回答技巧和策略","829":"/daily-interview/08-behavioral-interview/#star法则","830":"/daily-interview/08-behavioral-interview/#回答原则","831":"/daily-interview/08-behavioral-interview/#表达技�-1-结构清晰-有逻辑的组织语言","832":"/daily-interview/08-behavioral-interview/#📖-面试准备建议","833":"/daily-interview/08-behavioral-interview/#前期准备","834":"/daily-interview/08-behavioral-interview/#心理准备","835":"/daily-interview/08-behavioral-interview/#实战练习","836":"/daily-interview/08-behavioral-interview/#面试当天","837":"/daily-interview/08-behavioral-interview/#🚀-不同岗位的行为面试重�","838":"/daily-interview/08-behavioral-interview/#技术岗�-技术热�-对技术的兴趣和追�-学习能力-快速学习新技术的能力","839":"/daily-interview/08-behavioral-interview/#管理岗位","840":"/daily-interview/08-behavioral-interview/#销售岗�-客户导向-理解客户需求和价值创�-沟通说�-影响和说服客户的能�-抗压能力-面对拒绝和挫折的韧�-结果导向-关注业绩和目标达成","841":"/daily-interview/09-interview-tips/#面试技巧","842":"/daily-interview/09-interview-tips/#📂-分类目录","843":"/daily-interview/09-interview-tips/#🎭-模拟面试","844":"/daily-interview/#🎯-按岗位快速导航","845":"/daily-interview/#🤖-算法工程师","846":"/daily-interview/#💻-后端开发工程师","847":"/daily-interview/#🌐-前端开发工程师","848":"/daily-interview/#📊-数据分析师","849":"/daily-interview/#🤝-贡献指南","850":"/daily-interview/#📞-联系我们"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[3,1,5],"1":[2,3,45],"2":[2,3,39],"3":[3,3,49],"4":[2,3,42],"5":[2,3,44],"6":[2,3,68],"7":[2,3,64],"8":[2,3,51],"9":[3,3,36],"10":[2,3,68],"11":[2,3,52],"12":[2,3,30],"13":[3,3,37],"14":[2,3,35],"15":[2,3,41],"16":[2,1,11],"17":[1,1,10],"18":[2,1,58],"19":[2,1,37],"20":[3,1,44],"21":[2,1,48],"22":[2,1,67],"23":[2,1,51],"24":[3,1,33],"25":[2,1,42],"26":[3,1,84],"27":[3,1,57],"28":[1,1,3],"29":[3,1,34],"30":[2,1,40],"31":[4,1,67],"32":[4,1,64],"33":[2,1,50],"34":[2,1,54],"35":[2,1,75],"36":[2,1,66],"37":[3,1,38],"38":[3,1,50],"39":[3,1,16],"40":[3,3,70],"41":[2,3,47],"42":[3,3,44],"43":[2,3,73],"44":[3,3,42],"45":[2,3,48],"46":[2,3,36],"47":[3,3,38],"48":[4,3,48],"49":[2,3,30],"50":[3,1,20],"51":[2,3,50],"52":[2,3,38],"53":[2,3,46],"54":[2,3,62],"55":[2,3,36],"56":[2,3,46],"57":[3,1,18],"58":[2,3,92],"59":[2,3,119],"60":[2,3,84],"61":[2,3,63],"62":[1,1,17],"63":[1,1,6],"64":[4,1,26],"65":[2,1,19],"66":[2,1,35],"67":[3,1,41],"68":[4,1,35],"69":[4,1,45],"70":[4,1,34],"71":[4,1,26],"72":[3,1,39],"73":[3,1,36],"74":[2,1,76],"75":[3,1,48],"76":[3,1,60],"77":[2,1,74],"78":[3,1,70],"79":[3,1,57],"80":[2,1,47],"81":[3,1,87],"82":[2,1,80],"83":[3,1,85],"84":[4,1,17],"85":[2,4,72],"86":[3,4,57],"87":[3,4,31],"88":[3,4,28],"89":[3,4,72],"90":[2,4,65],"91":[3,4,36],"92":[3,4,62],"93":[3,4,38],"94":[2,4,77],"95":[2,4,48],"96":[2,4,21],"97":[1,1,6],"98":[2,1,1],"99":[1,3,13],"100":[1,3,11],"101":[1,3,4],"102":[2,1,1],"103":[1,3,17],"104":[1,3,14],"105":[2,1,11],"106":[2,1,17],"107":[2,1,1],"108":[1,2,1],"109":[8,2,45],"110":[4,2,121],"111":[4,2,57],"112":[6,2,73],"113":[2,2,1],"114":[5,3,45],"115":[2,1,1],"116":[1,2,1],"117":[1,2,1],"118":[5,3,21],"119":[4,8,10],"120":[3,8,31],"121":[6,3,13],"122":[6,3,23],"123":[4,3,16],"124":[6,3,10],"125":[1,1,1],"126":[1,1,1],"127":[1,1,1],"128":[6,2,1],"129":[2,8,26],"130":[1,8,26],"131":[1,8,26],"132":[6,2,1],"133":[2,8,40],"134":[1,8,42],"135":[2,8,18],"136":[8,2,42],"137":[1,10,12],"138":[1,10,8],"139":[3,10,86],"140":[5,2,57],"141":[7,2,1],"142":[1,9,10],"143":[1,9,23],"144":[4,9,23],"145":[3,2,1],"146":[5,2,1],"147":[2,2,1],"148":[5,2,1],"149":[1,1,1],"150":[1,1,1],"151":[1,1,1],"152":[3,2,1],"153":[4,2,1],"154":[5,2,1],"155":[3,2,1],"156":[3,2,1],"157":[8,2,1],"158":[2,1,1],"159":[1,2,1],"160":[1,2,1],"161":[8,2,17],"162":[3,2,28],"163":[6,2,64],"164":[7,2,4],"165":[4,2,43],"166":[5,2,18],"167":[2,2,38],"168":[3,2,33],"169":[2,2,17],"170":[2,2,32],"171":[5,2,1],"172":[1,7,15],"173":[2,7,43],"174":[2,7,34],"175":[1,1,1],"176":[1,1,1],"177":[1,1,1],"178":[6,2,1],"179":[4,2,1],"180":[4,2,1],"181":[1,1,1],"182":[1,1,1],"183":[1,1,1],"184":[5,2,46],"185":[4,7,82],"186":[4,2,48],"187":[5,2,1],"188":[1,7,32],"189":[2,7,32],"190":[1,7,27],"191":[3,2,1],"192":[1,5,66],"193":[1,5,47],"194":[2,2,51],"195":[3,2,1],"196":[2,5,30],"197":[2,5,11],"198":[2,5,22],"199":[1,5,52],"200":[4,2,22],"201":[6,2,24],"202":[4,2,52],"203":[2,2,59],"204":[1,1,1],"205":[2,1,1],"206":[1,3,2],"207":[1,3,3],"208":[2,1,1],"209":[3,2,1],"210":[5,4,51],"211":[4,4,59],"212":[4,4,25],"213":[8,4,27],"214":[4,4,39],"215":[4,4,36],"216":[4,2,1],"217":[7,5,82],"218":[10,5,79],"219":[3,2,1],"220":[6,4,70],"221":[8,4,14],"222":[3,4,39],"223":[3,4,30],"224":[9,4,28],"225":[4,2,1],"226":[7,6,30],"227":[3,6,10],"228":[8,6,16],"229":[5,6,15],"230":[1,1,1],"231":[1,1,1],"232":[1,1,1],"233":[2,2,11],"234":[2,2,1],"235":[2,2,36],"236":[2,2,7],"237":[1,4,23],"238":[2,2,1],"239":[1,4,20],"240":[2,2,30],"241":[2,2,37],"242":[2,2,17],"243":[2,2,48],"244":[2,2,49],"245":[2,2,26],"246":[2,2,40],"247":[2,2,45],"248":[1,1,1],"249":[2,2,16],"250":[5,2,36],"251":[2,2,28],"252":[2,2,52],"253":[1,1,46],"254":[1,1,1],"255":[2,1,16],"256":[2,1,20],"257":[2,1,12],"258":[2,1,59],"259":[1,1,25],"260":[1,1,1],"261":[2,1,1],"262":[1,3,2],"263":[1,3,3],"264":[1,3,2],"265":[1,3,3],"266":[1,1,16],"267":[2,1,59],"268":[2,1,49],"269":[2,1,52],"270":[2,1,100],"271":[2,1,13],"272":[3,1,22],"273":[1,1,4],"274":[2,1,61],"275":[2,1,23],"276":[2,1,33],"277":[2,1,35],"278":[2,1,30],"279":[2,1,95],"280":[2,1,24],"281":[2,1,17],"282":[2,1,53],"283":[2,1,8],"284":[1,1,30],"285":[1,1,1],"286":[1,1,1],"287":[1,1,1],"288":[2,2,23],"289":[2,2,12],"290":[2,2,1],"291":[1,4,29],"292":[1,4,8],"293":[2,2,44],"294":[2,2,15],"295":[2,2,6],"296":[1,4,12],"297":[1,4,20],"298":[1,4,3],"299":[2,2,26],"300":[2,2,15],"301":[2,2,59],"302":[2,2,64],"303":[1,1,31],"304":[1,1,1],"305":[4,1,15],"306":[3,1,57],"307":[4,1,54],"308":[4,1,21],"309":[3,1,13],"310":[2,1,3],"311":[3,1,25],"312":[2,1,43],"313":[4,1,23],"314":[4,1,22],"315":[6,1,45],"316":[3,1,2],"317":[2,1,23],"318":[4,1,32],"319":[4,1,27],"320":[3,1,33],"321":[3,1,9],"322":[4,1,5],"323":[4,1,19],"324":[3,1,4],"325":[4,1,20],"326":[3,1,15],"327":[3,1,10],"328":[3,1,14],"329":[3,1,7],"330":[4,1,35],"331":[4,1,11],"332":[3,1,4],"333":[3,1,19],"334":[3,1,26],"335":[7,1,5],"336":[2,1,22],"337":[4,1,13],"338":[2,1,17],"339":[10,1,46],"340":[3,1,10],"341":[3,1,3],"342":[2,1,5],"343":[3,1,12],"344":[4,1,1],"345":[3,1,15],"346":[4,1,25],"347":[4,1,9],"348":[3,1,10],"349":[6,1,8],"350":[3,1,12],"351":[3,1,10],"352":[2,1,10],"353":[2,1,7],"354":[2,1,17],"355":[2,1,11],"356":[3,1,3],"357":[5,1,70],"358":[2,1,26],"359":[1,1,1],"360":[2,1,16],"361":[1,3,40],"362":[1,3,15],"363":[2,1,1],"364":[3,3,1],"365":[15,6,27],"366":[7,6,52],"367":[9,6,129],"368":[11,6,66],"369":[14,6,94],"370":[5,6,14],"371":[4,6,13],"372":[5,6,69],"373":[5,6,57],"374":[12,6,12],"375":[6,6,23],"376":[3,6,13],"377":[2,3,1],"378":[14,5,126],"379":[3,5,5],"380":[5,5,7],"381":[5,5,62],"382":[7,5,20],"383":[14,5,9],"384":[2,3,1],"385":[11,5,58],"386":[3,5,24],"387":[3,5,24],"388":[5,5,70],"389":[9,5,17],"390":[11,5,59],"391":[3,5,2],"392":[4,5,25],"393":[3,5,45],"394":[3,5,101],"395":[4,5,31],"396":[10,5,37],"397":[20,5,113],"398":[2,3,1],"399":[8,5,22],"400":[4,5,7],"401":[3,5,39],"402":[3,5,34],"403":[9,5,28],"404":[9,5,16],"405":[2,3,1],"406":[10,5,1],"407":[11,5,1],"408":[8,5,1],"409":[11,5,1],"410":[11,5,1],"411":[9,5,1],"412":[10,5,1],"413":[10,5,1],"414":[2,1,71],"415":[1,1,1],"416":[2,1,1],"417":[1,3,1],"418":[1,3,3],"419":[1,3,3],"420":[1,3,6],"421":[1,3,2],"422":[1,1,685],"423":[2,1,1025],"424":[2,1,1],"425":[2,2,22],"426":[3,2,1],"427":[4,4,15],"428":[3,4,79],"429":[2,2,1],"430":[4,4,51],"431":[4,4,50],"432":[5,4,9],"433":[4,4,6],"434":[4,4,5],"435":[4,4,10],"436":[4,4,12],"437":[6,4,2],"438":[5,4,6],"439":[7,4,17],"440":[7,4,12],"441":[5,4,8],"442":[2,2,14],"443":[2,1,1],"444":[3,2,9],"445":[5,2,11],"446":[3,2,41],"447":[2,2,9],"448":[3,2,10],"449":[3,2,12],"450":[3,2,8],"451":[2,2,17],"452":[1,1,1],"453":[3,1,8],"454":[3,1,4],"455":[4,1,36],"456":[4,1,24],"457":[3,1,7],"458":[2,1,16],"459":[5,1,32],"460":[3,1,15],"461":[6,1,12],"462":[2,1,33],"463":[1,1,1],"464":[3,1,39],"465":[3,1,22],"466":[6,1,33],"467":[4,1,12],"468":[4,1,18],"469":[3,1,12],"470":[3,1,53],"471":[2,1,20],"472":[2,1,61],"473":[1,1,32],"474":[1,1,1],"475":[2,1,38],"476":[3,1,3],"477":[3,1,8],"478":[3,1,5],"479":[3,1,5],"480":[5,1,8],"481":[3,1,5],"482":[11,1,3],"483":[3,1,24],"484":[3,1,59],"485":[2,1,23],"486":[2,1,23],"487":[2,1,29],"488":[3,1,5],"489":[2,1,21],"490":[2,1,10],"491":[1,1,1],"492":[1,1,17],"493":[1,1,19],"494":[1,1,6],"495":[1,1,32],"496":[1,1,132],"497":[1,1,303],"498":[1,1,8],"499":[2,1,22],"500":[2,1,1],"501":[3,2,33],"502":[3,2,60],"503":[3,2,26],"504":[3,2,44],"505":[3,2,31],"506":[3,2,18],"507":[3,2,48],"508":[3,2,25],"509":[3,2,18],"510":[3,2,13],"511":[3,2,20],"512":[3,2,30],"513":[3,2,90],"514":[2,2,91],"515":[4,2,30],"516":[2,2,14],"517":[2,2,29],"518":[1,1,7],"519":[2,1,106],"520":[4,1,16],"521":[2,1,102],"522":[2,1,30],"523":[1,1,1],"524":[4,1,1],"525":[1,1,23],"526":[1,1,3],"527":[1,1,95],"528":[1,1,4],"529":[2,1,10],"530":[2,1,1],"531":[2,1,15],"532":[3,1,68],"533":[2,1,25],"534":[2,1,5],"535":[3,1,18],"536":[6,1,40],"537":[2,1,30],"538":[2,1,7],"539":[1,1,1],"540":[2,1,10],"541":[2,1,10],"542":[2,1,27],"543":[2,1,12],"544":[2,1,43],"545":[2,1,105],"546":[2,1,47],"547":[3,1,54],"548":[3,1,8],"549":[3,1,8],"550":[4,1,4],"551":[3,1,14],"552":[3,1,21],"553":[3,1,4],"554":[4,1,17],"555":[3,1,58],"556":[2,1,17],"557":[1,1,1],"558":[3,1,34],"559":[3,1,19],"560":[2,1,21],"561":[4,1,13],"562":[3,1,12],"563":[4,1,10],"564":[4,1,44],"565":[3,1,8],"566":[3,1,19],"567":[2,1,15],"568":[5,1,36],"569":[1,1,1],"570":[2,1,27],"571":[3,1,18],"572":[3,1,19],"573":[3,1,26],"574":[3,1,29],"575":[4,1,21],"576":[5,1,9],"577":[1,1,7],"578":[2,1,8],"579":[3,2,1],"580":[3,4,13],"581":[3,4,13],"582":[3,4,5],"583":[2,4,30],"584":[3,2,1],"585":[2,4,17],"586":[1,4,28],"587":[3,4,10],"588":[3,4,10],"589":[2,4,22],"590":[1,4,65],"591":[1,4,56],"592":[3,4,31],"593":[5,4,19],"594":[4,4,7],"595":[2,2,21],"596":[1,1,1],"597":[2,1,37],"598":[3,1,7],"599":[3,1,6],"600":[6,1,29],"601":[2,1,66],"602":[3,1,15],"603":[3,1,51],"604":[2,1,28],"605":[3,1,39],"606":[4,1,12],"607":[3,1,39],"608":[3,1,7],"609":[4,1,12],"610":[1,1,3],"611":[1,1,1],"612":[3,1,49],"613":[7,1,45],"614":[3,1,29],"615":[3,1,13],"616":[3,1,3],"617":[4,1,7],"618":[4,1,47],"619":[3,1,19],"620":[4,1,36],"621":[3,1,40],"622":[3,1,27],"623":[3,1,6],"624":[3,1,8],"625":[3,1,27],"626":[3,1,17],"627":[5,1,21],"628":[4,1,23],"629":[3,1,8],"630":[3,1,13],"631":[3,1,33],"632":[4,1,35],"633":[1,1,1],"634":[2,1,52],"635":[2,1,290],"636":[3,1,14],"637":[5,1,11],"638":[4,1,22],"639":[3,1,5],"640":[3,1,24],"641":[2,1,31],"642":[3,1,11],"643":[3,1,23],"644":[2,1,20],"645":[2,1,1],"646":[3,2,8],"647":[3,2,4],"648":[4,2,12],"649":[3,2,16],"650":[4,2,8],"651":[5,2,148],"652":[2,2,29],"653":[1,1,1],"654":[3,1,44],"655":[3,1,13],"656":[3,1,27],"657":[3,1,59],"658":[3,1,17],"659":[2,1,15],"660":[2,1,34],"661":[2,1,26],"662":[3,1,27],"663":[2,1,25],"664":[3,1,45],"665":[2,1,19],"666":[3,1,24],"667":[2,1,11],"668":[6,1,36],"669":[5,1,16],"670":[3,1,28],"671":[3,1,10],"672":[2,1,37],"673":[2,1,1],"674":[5,2,22],"675":[2,2,15],"676":[2,2,23],"677":[2,2,12],"678":[3,2,5],"679":[3,2,20],"680":[3,2,12],"681":[4,2,3],"682":[5,2,17],"683":[2,2,5],"684":[3,2,67],"685":[3,2,15],"686":[1,2,32],"687":[1,1,1],"688":[1,1,6],"689":[1,2,58],"690":[1,2,77],"691":[1,1,1],"692":[1,2,1],"693":[3,3,13],"694":[3,3,5],"695":[3,3,13],"696":[1,2,1],"697":[3,3,31],"698":[4,3,12],"699":[8,3,17],"700":[5,3,11],"701":[1,2,1],"702":[2,3,31],"703":[2,3,34],"704":[1,2,1],"705":[6,3,12],"706":[1,2,1],"707":[1,3,14],"708":[1,2,13],"709":[1,2,1],"710":[1,3,13],"711":[1,3,6],"712":[1,2,1],"713":[1,3,16],"714":[1,3,6],"715":[1,2,1],"716":[2,3,11],"717":[2,1,1],"718":[2,2,89],"719":[3,2,48],"720":[4,4,1],"721":[4,4,75],"722":[4,2,30],"723":[4,5,1],"724":[5,5,1],"725":[2,1,146],"726":[4,1,1],"727":[1,4,27],"728":[1,4,1],"729":[1,4,52],"730":[1,4,248],"731":[1,4,12],"732":[1,1,27],"733":[1,1,9],"734":[1,2,28],"735":[2,3,67],"736":[1,3,3],"737":[1,2,5],"738":[1,1,19],"739":[2,1,58],"740":[1,1,55],"741":[1,1,107],"742":[1,1,2],"743":[1,1,22],"744":[1,1,1],"745":[2,1,2],"746":[1,1,1],"747":[2,1,57],"748":[2,1,44],"749":[4,1,33],"750":[2,1,20],"751":[2,1,35],"752":[3,1,8],"753":[1,1,12],"754":[2,1,25],"755":[1,2,43],"756":[2,2,153],"757":[2,2,49],"758":[2,2,29],"759":[1,2,53],"760":[1,2,54],"761":[1,2,35],"762":[2,2,42],"763":[1,2,158],"764":[2,1,8],"765":[1,1,17],"766":[2,1,6],"767":[2,1,10],"768":[1,1,38],"769":[2,1,177],"770":[1,1,77],"771":[1,1,4],"772":[2,1,1],"773":[5,2,1],"774":[5,6,40],"775":[3,6,24],"776":[4,6,36],"777":[3,2,1],"778":[7,4,16],"779":[4,4,8],"780":[3,1,1],"781":[2,3,1],"782":[5,5,56],"783":[2,3,1],"784":[7,5,70],"785":[3,5,30],"786":[4,5,46],"787":[6,5,39],"788":[2,1,1],"789":[1,2,1],"790":[5,3,28],"791":[5,3,1],"792":[6,3,90],"793":[5,3,31],"794":[1,2,1],"795":[5,3,21],"796":[5,3,94],"797":[5,3,1],"798":[6,3,77],"799":[1,2,1],"800":[4,3,96],"801":[2,1,1],"802":[2,2,1],"803":[1,3,5],"804":[1,3,5],"805":[1,1,1],"806":[2,1,2],"807":[1,1,4],"808":[2,1,1],"809":[2,3,11],"810":[2,3,9],"811":[2,3,9],"812":[2,3,11],"813":[2,1,1],"814":[2,3,1],"815":[1,5,9],"816":[1,5,9],"817":[2,3,1],"818":[7,5,3],"819":[7,5,3],"820":[2,3,1],"821":[1,5,9],"822":[1,5,9],"823":[2,1,1],"824":[4,3,6],"825":[4,3,6],"826":[5,3,8],"827":[5,3,5],"828":[2,1,1],"829":[1,3,13],"830":[1,3,11],"831":[4,3,8],"832":[2,1,1],"833":[1,3,13],"834":[1,3,12],"835":[1,3,12],"836":[1,3,11],"837":[3,1,1],"838":[5,4,6],"839":[1,4,9],"840":[9,4,8],"841":[1,1,1],"842":[2,1,1],"843":[1,3,2],"844":[2,1,1],"845":[2,2,14],"846":[2,2,14],"847":[2,2,14],"848":[2,2,15],"849":[2,1,12],"850":[2,1,12]},"averageFieldLength":[2.9588719153936536,2.251468860164513,28.2761457109283],"storedFields":{"0":{"title":"动态规?DP)","titles":[]},"1":{"title":"1. 最长上升子序列","titles":["动态规?DP)"]},"2":{"title":"2. 最长公共子序列","titles":["动态规?DP)"]},"3":{"title":"3. 最长整除子?","titles":["动态规?DP)"]},"4":{"title":"4. 背包问题","titles":["动态规?DP)"]},"5":{"title":"5. 编辑距离","titles":["动态规?DP)"]},"6":{"title":"6. 矩阵链乘","titles":["动态规?DP)"]},"7":{"title":"7. 回文划分","titles":["动态规?DP)"]},"8":{"title":"8. 丑数","titles":["动态规?DP)"]},"9":{"title":"9. 最小花费路?","titles":["动态规?DP)"]},"10":{"title":"10. 最大矩阵和","titles":["动态规?DP)"]},"11":{"title":"11. 最大正方形面积","titles":["动态规?DP)"]},"12":{"title":"12. 二进制串个数","titles":["动态规?DP)"]},"13":{"title":"13. 交叉字符?","titles":["动态规?DP)"]},"14":{"title":"14. 乘积最大子序列","titles":["动态规?DP)"]},"15":{"title":"15. k个数之和","titles":["动态规?DP)"]},"16":{"title":"参?","titles":[]},"17":{"title":"贪心算法","titles":[]},"18":{"title":"1. 最大连续子序列","titles":["贪心算法"]},"19":{"title":"2. 删除数字","titles":["贪心算法"]},"20":{"title":"3. 无重叠区?","titles":["贪心算法"]},"21":{"title":"4. 合并数字","titles":["贪心算法"]},"22":{"title":"5. 最小支撑树","titles":["贪心算法"]},"23":{"title":"6. 补齐数组","titles":["贪心算法"]},"24":{"title":"7. 买卖股票的最佳时?","titles":["贪心算法"]},"25":{"title":"8. 买卖股票的最佳时机II","titles":["贪心算法"]},"26":{"title":"9. 买卖股票的最佳时机含手续?","titles":["贪心算法"]},"27":{"title":"10. 最后的?","titles":["贪心算法"]},"28":{"title":"search","titles":[]},"29":{"title":"1. 全排?","titles":["search"]},"30":{"title":"2. 子集","titles":["search"]},"31":{"title":"3. Word Break Problem","titles":["search"]},"32":{"title":"4. K-Similar Strings","titles":["search"]},"33":{"title":"5. 无向图的联通块","titles":["search"]},"34":{"title":"6. k个数的和","titles":["search"]},"35":{"title":"7. 单词接龙","titles":["search"]},"36":{"title":"8. 单词搜索","titles":["search"]},"37":{"title":"9. 分割字符?","titles":["search"]},"38":{"title":"10. 划分回文?","titles":["search"]},"39":{"title":"数组（Array�?","titles":[]},"40":{"title":"1. two sum","titles":["数组（Array�?"]},"41":{"title":"2. 查找旋转数组","titles":["数组（Array�?"]},"42":{"title":"3 主元�?","titles":["数组（Array�?"]},"43":{"title":"4. 落单的数","titles":["数组（Array�?"]},"44":{"title":"5. 中位�?","titles":["数组（Array�?"]},"45":{"title":"6. 二维数组中的查找","titles":["数组（Array�?"]},"46":{"title":"7. 构建乘积数组","titles":["数组（Array�?"]},"47":{"title":"8. 滑动窗口的最大�?","titles":["数组（Array�?"]},"48":{"title":"9. 第k�?�?的数","titles":["数组（Array�?"]},"49":{"title":"10. 奇偶排序","titles":["数组（Array�?"]},"50":{"title":"排序（sort）","titles":[]},"51":{"title":"1. 快速排序","titles":["排序（sort）"]},"52":{"title":"2. 堆排序","titles":["排序（sort）"]},"53":{"title":"3. 归并排序","titles":["排序（sort）"]},"54":{"title":"4. 实现多路归并排序","titles":["排序（sort）"]},"55":{"title":"5. 单链表插入排序","titles":["排序（sort）"]},"56":{"title":"6. 单链表归并排序","titles":["排序（sort）"]},"57":{"title":"Graph(图)","titles":[]},"58":{"title":"1. 最短路径","titles":["Graph(图)"]},"59":{"title":"2. 最小支撑树","titles":["Graph(图)"]},"60":{"title":"3. 拓扑排序","titles":["Graph(图)"]},"61":{"title":"4. 有向图判环","titles":["Graph(图)"]},"62":{"title":"参考","titles":[]},"63":{"title":"linklist","titles":[]},"64":{"title":"1.回文链表(234)","titles":["linklist"]},"65":{"title":"2.求单链表的中间节点","titles":["linklist"]},"66":{"title":"3.删除无序链表中的重复项","titles":["linklist"]},"67":{"title":"4.给定一个排序链表，删除所有含有重复数字的节点","titles":["linklist"]},"68":{"title":"5.环形链表?41?","titles":["linklist"]},"69":{"title":"6.反转链表?06?","titles":["linklist"]},"70":{"title":"7.在双向链表中删除指定元素（微软）","titles":["linklist"]},"71":{"title":"8.两个链表合并为一个升序链表（微软?","titles":["linklist"]},"72":{"title":"9. 倒数第k个节?","titles":["linklist"]},"73":{"title":"10. 等概率返回链表中的一个元?","titles":["linklist"]},"74":{"title":"1.最长公共前缀","titles":[]},"75":{"title":"2.有效的括?","titles":[]},"76":{"title":"3.验证回文?","titles":[]},"77":{"title":"4.反转字符串中的单词III","titles":[]},"78":{"title":"5.无重复字符的最长子?","titles":[]},"79":{"title":"6. 最长回文子?","titles":[]},"80":{"title":"7.括号生成","titles":[]},"81":{"title":"8.压缩字符?","titles":[]},"82":{"title":"9.字符串中的第一个唯一字符","titles":[]},"83":{"title":"10.字符串相?","titles":[]},"84":{"title":"二叉树(Binary Tree)","titles":[]},"85":{"title":"1. 二叉树的遍历","titles":["二叉树(Binary Tree)"]},"86":{"title":"2. 二叉树的Z型遍?","titles":["二叉树(Binary Tree)"]},"87":{"title":"3. 平衡二叉?","titles":["二叉树(Binary Tree)"]},"88":{"title":"4. 前序遍历的第k个结?","titles":["二叉树(Binary Tree)"]},"89":{"title":"5. 二叉树的对角线遍?","titles":["二叉树(Binary Tree)"]},"90":{"title":"6. 构造二叉树","titles":["二叉树(Binary Tree)"]},"91":{"title":"7. 对称二叉?","titles":["二叉树(Binary Tree)"]},"92":{"title":"8. 最近公共祖?","titles":["二叉树(Binary Tree)"]},"93":{"title":"9. 寻找树中最左下结点的?","titles":["二叉树(Binary Tree)"]},"94":{"title":"10. 二叉树的最长连续子序列","titles":["二叉树(Binary Tree)"]},"95":{"title":"11. 左边看到的二叉树结点","titles":["二叉树(Binary Tree)"]},"96":{"title":"参?","titles":["二叉树(Binary Tree)"]},"97":{"title":"算法基础","titles":[]},"98":{"title":"📚 内容导航","titles":["算法基础"]},"99":{"title":"🔢","titles":["算法基础","📚 内容导航"]},"100":{"title":"🧠","titles":["算法基础","📚 内容导航"]},"101":{"title":"📊","titles":["算法基础","📚 内容导航"]},"102":{"title":"🎯 学习重点","titles":["算法基础"]},"103":{"title":"数据结构重点","titles":["算法基础","🎯 学习重点"]},"104":{"title":"算法思想重点","titles":["算法基础","🎯 学习重点"]},"105":{"title":"💡 面试准备建议","titles":["算法基础"]},"106":{"title":"🔗 学习路径","titles":["算法基础"]},"107":{"title":"校招前端面试常见问题�?】——NodeJS","titles":[]},"108":{"title":"NodeJS","titles":["校招前端面试常见问题�?】——NodeJS"]},"109":{"title":"Q：NodeJS �?IO 模型特点是什么？与多线程同步 IO 有什么不同？","titles":["校招前端面试常见问题�?】——NodeJS","NodeJS"]},"110":{"title":"Q：V8 引擎垃圾回收机制是什么样的？","titles":["校招前端面试常见问题�?】——NodeJS","NodeJS"]},"111":{"title":"Q：实现一�?EventEmitter�?","titles":["校招前端面试常见问题�?】——NodeJS","NodeJS"]},"112":{"title":"Q：es6 模块化、commonjs 模块化的区别�?","titles":["校招前端面试常见问题�?】——NodeJS","NodeJS"]},"113":{"title":"NodeJS 相关框架","titles":["校招前端面试常见问题�?】——NodeJS"]},"114":{"title":"Q：请简述一�?Koa 的洋葱模型？","titles":["校招前端面试常见问题�?】——NodeJS","NodeJS 相关框架"]},"115":{"title":"Java 基础","titles":[]},"116":{"title":"知识体系","titles":["Java 基础"]},"117":{"title":"Questions","titles":["Java 基础"]},"118":{"title":"1. HashMap 1.8�?.7的区�?","titles":["Java 基础","Questions"]},"119":{"title":"(1) 扩容因子默认为什么是0.75","titles":["Java 基础","Questions","1. HashMap 1.8�?.7的区�?"]},"120":{"title":"(2)为什么链表长度为8要转化为红黑�?","titles":["Java 基础","Questions","1. HashMap 1.8�?.7的区�?"]},"121":{"title":"2. String 、StringBuffer 、StringBuilder 的区�?","titles":["Java 基础","Questions"]},"122":{"title":"3.强引用、软引用、弱引用、虚引用的区�?","titles":["Java 基础","Questions"]},"123":{"title":"4.==�?equals 区别","titles":["Java 基础","Questions"]},"124":{"title":"5.Object 类的 hashCode 方法的作�?","titles":["Java 基础","Questions"]},"125":{"title":"Java并发","titles":[]},"126":{"title":"知识体系","titles":["Java并发"]},"127":{"title":"Questions","titles":["Java并发"]},"128":{"title":"1.线性池了解吗？参数有哪些？任务到达线程池的过程？线程池的大小如何设置？","titles":["Java并发","Questions"]},"129":{"title":"线程池参�?","titles":["Java并发","Questions","1.线性池了解吗？参数有哪些？任务到达线程池的过程？线程池的大小如何设置？"]},"130":{"title":"线程处理任务过程","titles":["Java并发","Questions","1.线性池了解吗？参数有哪些？任务到达线程池的过程？线程池的大小如何设置？"]},"131":{"title":"线程池的大小设置","titles":["Java并发","Questions","1.线性池了解吗？参数有哪些？任务到达线程池的过程？线程池的大小如何设置？"]},"132":{"title":"2.Java乐观锁机制，CAS思想？缺点？是否原子性？","titles":["Java并发","Questions"]},"133":{"title":"Java乐观锁机�?","titles":["Java并发","Questions","2.Java乐观锁机制，CAS思想？缺点？是否原子性？"]},"134":{"title":"CAS思想","titles":["Java并发","Questions","2.Java乐观锁机制，CAS思想？缺点？是否原子性？"]},"135":{"title":"原子�?","titles":["Java并发","Questions","2.Java乐观锁机制，CAS思想？缺点？是否原子性？"]},"136":{"title":"3.ReenTrantLock 使用方法？底层实现？�?synchronized 区别�?","titles":["Java并发","Questions"]},"137":{"title":"使用方法","titles":["Java并发","Questions","3.ReenTrantLock 使用方法？底层实现？�?synchronized 区别�?"]},"138":{"title":"底层实现","titles":["Java并发","Questions","3.ReenTrantLock 使用方法？底层实现？�?synchronized 区别�?"]},"139":{"title":"ReenTrantLock和synchronized 的区�?","titles":["Java并发","Questions","3.ReenTrantLock 使用方法？底层实现？�?synchronized 区别�?"]},"140":{"title":"4.介绍一�?Java 的内存模�?","titles":["Java并发","Questions"]},"141":{"title":"5.volatile 作用？底层实现？单例模式�?volatile 的作用？","titles":["Java并发","Questions"]},"142":{"title":"作用","titles":["Java并发","Questions","5.volatile 作用？底层实现？单例模式�?volatile 的作用？"]},"143":{"title":"底层实现","titles":["Java并发","Questions","5.volatile 作用？底层实现？单例模式�?volatile 的作用？"]},"144":{"title":"单例模式�?volatile 的作�?","titles":["Java并发","Questions","5.volatile 作用？底层实现？单例模式�?volatile 的作用？"]},"145":{"title":"6.ThreadLocal 原理","titles":["Java并发","Questions"]},"146":{"title":"7.CAS �?ABA 问题","titles":["Java并发","Questions"]},"147":{"title":"8.原子类的实现原理","titles":["Java并发","Questions"]},"148":{"title":"9.说一�?CurrentHashMap 如何实现线程安全�?","titles":["Java并发","Questions"]},"149":{"title":"JVM","titles":[]},"150":{"title":"知识体系","titles":["JVM"]},"151":{"title":"Questions","titles":["JVM"]},"152":{"title":"1.JVM 内存划分","titles":["JVM","Questions"]},"153":{"title":"2.GC 垃圾收集�?","titles":["JVM","Questions"]},"154":{"title":"3.垃圾收集算法，为什么新生代用标�?复制老年代用标记-整理","titles":["JVM","Questions"]},"155":{"title":"4.类加载流�?","titles":["JVM","Questions"]},"156":{"title":"5.双亲委派机制，怎么样会打破双亲委派模型","titles":["JVM","Questions"]},"157":{"title":"6.JVM 1.7 �?1.8 的区�?","titles":["JVM","Questions"]},"158":{"title":"数据�?","titles":[]},"159":{"title":"知识体系","titles":["数据�?"]},"160":{"title":"Questions","titles":["数据�?"]},"161":{"title":"1.MySQL的引擎了解吗？默认的是哪个？InnoDB �?myISAM 的区别？","titles":["数据�?","Questions"]},"162":{"title":"2.介绍 MVCC","titles":["数据�?","Questions"]},"163":{"title":"3.MySQL 中一�?SQL 语句的执行过�?","titles":["数据�?","Questions"]},"164":{"title":"4.如何查看 sql 语句的执行计划？用哪个关键字？使用这个关键字可以得到哪些信息�?","titles":["数据�?","Questions"]},"165":{"title":"5.聚簇索引和非聚簇索引的区别，非聚簇索引是如何查询的？","titles":["数据�?","Questions"]},"166":{"title":"6.MySQL�?ACID，分别解释一�?","titles":["数据�?","Questions"]},"167":{"title":"7.数据库索引的实现原理","titles":["数据�?","Questions"]},"168":{"title":"8.联合索引，最左前缀匹配规则","titles":["数据�?","Questions"]},"169":{"title":"9.索引怎么优化","titles":["数据�?","Questions"]},"170":{"title":"10.事物隔离级别","titles":["数据�?","Questions"]},"171":{"title":"11.binlog、redo log、undo log","titles":["数据�?","Questions"]},"172":{"title":"binlog","titles":["数据�?","Questions","11.binlog、redo log、undo log"]},"173":{"title":"redo log","titles":["数据�?","Questions","11.binlog、redo log、undo log"]},"174":{"title":"undo log","titles":["数据�?","Questions","11.binlog、redo log、undo log"]},"175":{"title":"Spring","titles":[]},"176":{"title":"知识体系","titles":["Spring"]},"177":{"title":"Questions","titles":["Spring"]},"178":{"title":"1.Sping IOC AOP 的实现原�?","titles":["Spring","Questions"]},"179":{"title":"2.Spring 事务的实现原�?","titles":["Spring","Questions"]},"180":{"title":"3.bean 的生命周�?","titles":["Spring","Questions"]},"181":{"title":"Redis","titles":[]},"182":{"title":"知识体系","titles":["Redis"]},"183":{"title":"Questions","titles":["Redis"]},"184":{"title":"1.基于 redis 的分布式锁是如何实现�?","titles":["Redis","Questions"]},"185":{"title":"Redisson 实现 Redis 分布式锁","titles":["Redis","Questions","1.基于 redis 的分布式锁是如何实现�?"]},"186":{"title":"2.跳表数据结构，redis 中哪里用到了跳表","titles":["Redis","Questions"]},"187":{"title":"3.出现缓存雪崩、击穿、穿透的情况及解决方�?","titles":["Redis","Questions"]},"188":{"title":"缓存雪崩","titles":["Redis","Questions","3.出现缓存雪崩、击穿、穿透的情况及解决方�?"]},"189":{"title":"*缓存穿�?","titles":["Redis","Questions","3.出现缓存雪崩、击穿、穿透的情况及解决方�?"]},"190":{"title":"缓存击穿","titles":["Redis","Questions","3.出现缓存雪崩、击穿、穿透的情况及解决方�?"]},"191":{"title":"4.持久化策�?","titles":["Redis","Questions"]},"192":{"title":"RDB","titles":["Redis","Questions","4.持久化策�?"]},"193":{"title":"AOF","titles":["Redis","Questions","4.持久化策�?"]},"194":{"title":"5.主从复制原理","titles":["Redis","Questions"]},"195":{"title":"6.数据库缓存一致�?","titles":["Redis","Questions"]},"196":{"title":"先更新数据库，再更新缓存","titles":["Redis","Questions","6.数据库缓存一致�?"]},"197":{"title":"先删除缓存，再更新数据库","titles":["Redis","Questions","6.数据库缓存一致�?"]},"198":{"title":"先更新数据库，再删除缓存","titles":["Redis","Questions","6.数据库缓存一致�?"]},"199":{"title":"延时双删","titles":["Redis","Questions","6.数据库缓存一致�?"]},"200":{"title":"7.redis 的内存淘汰策�?","titles":["Redis","Questions"]},"201":{"title":"8.redis �?key 的过期策�?","titles":["Redis","Questions"]},"202":{"title":"9.redis 是单线程的吗，为什么这么快","titles":["Redis","Questions"]},"203":{"title":"参�?","titles":["Redis","Questions"]},"204":{"title":"编程语言","titles":[]},"205":{"title":"📂 分类目录","titles":["编程语言"]},"206":{"title":"☕","titles":["编程语言","📂 分类目录"]},"207":{"title":"🌐","titles":["编程语言","📂 分类目录"]},"208":{"title":"前端开发校招面试问题整理�?】——JavaScript","titles":[]},"209":{"title":"1、JavaScript 基础","titles":["前端开发校招面试问题整理�?】——JavaScript"]},"210":{"title":"Q：介�?js 的基本数据类型？","titles":["前端开发校招面试问题整理�?】——JavaScript","1、JavaScript 基础"]},"211":{"title":"Q：js 中如何判断一个对象是什么类型？","titles":["前端开发校招面试问题整理�?】——JavaScript","1、JavaScript 基础"]},"212":{"title":"Q：js 的原型链你是如何理解的？","titles":["前端开发校招面试问题整理�?】——JavaScript","1、JavaScript 基础"]},"213":{"title":"Q：js �?function.call �?function.apply 的区别？","titles":["前端开发校招面试问题整理�?】——JavaScript","1、JavaScript 基础"]},"214":{"title":"Q：js 中作用域你是如何理解的？","titles":["前端开发校招面试问题整理�?】——JavaScript","1、JavaScript 基础"]},"215":{"title":"Q：js 中什么是闭包�?","titles":["前端开发校招面试问题整理�?】——JavaScript","1、JavaScript 基础"]},"216":{"title":"2、JavaScript 流控�?","titles":["前端开发校招面试问题整理�?】——JavaScript"]},"217":{"title":"Q：介绍一�?js �?Promise 的用法？","titles":["前端开发校招面试问题整理�?】——JavaScript","2、JavaScript 流控�?"]},"218":{"title":"Q：介绍一�?js �?async �?await 的用法？�?Promise 的区别？","titles":["前端开发校招面试问题整理�?】——JavaScript","2、JavaScript 流控�?"]},"219":{"title":"3、JavaScript 常用数据结构","titles":["前端开发校招面试问题整理�?】——JavaScript"]},"220":{"title":"Q：说几个常用�?Array �?api�?","titles":["前端开发校招面试问题整理�?】——JavaScript","3、JavaScript 常用数据结构"]},"221":{"title":"Q：for in �?for of 遍历数组/对象的区别？","titles":["前端开发校招面试问题整理�?】——JavaScript","3、JavaScript 常用数据结构"]},"222":{"title":"Q：代码实现一下展平数组？","titles":["前端开发校招面试问题整理�?】——JavaScript","3、JavaScript 常用数据结构"]},"223":{"title":"Q：代码实现一下深拷贝对象�?","titles":["前端开发校招面试问题整理�?】——JavaScript","3、JavaScript 常用数据结构"]},"224":{"title":"Q�?test&quot; �?new String(&quot;test&quot;)有什么区别，{}�?new Object()有什么区别？","titles":["前端开发校招面试问题整理�?】——JavaScript","3、JavaScript 常用数据结构"]},"225":{"title":"4、DOM/BOM api","titles":["前端开发校招面试问题整理�?】——JavaScript"]},"226":{"title":"Q：addEventListener 用法？和 onxxx 的区别是什么？","titles":["前端开发校招面试问题整理�?】——JavaScript","4、DOM/BOM api"]},"227":{"title":"Q：事件代理指的是什么？","titles":["前端开发校招面试问题整理�?】——JavaScript","4、DOM/BOM api"]},"228":{"title":"Q：如何使�?js 访问 cookie？如果想要禁止用 js 访问 cookie，该怎么做？","titles":["前端开发校招面试问题整理�?】——JavaScript","4、DOM/BOM api"]},"229":{"title":"Q：如何使�?js 计算浏览器可视区域？","titles":["前端开发校招面试问题整理�?】——JavaScript","4、DOM/BOM api"]},"230":{"title":"计算机网络","titles":[]},"231":{"title":"知识体系","titles":["计算机网络"]},"232":{"title":"Questions","titles":["计算机网络"]},"233":{"title":"1.计算机网络分层的优点和缺点","titles":["计算机网络","Questions"]},"234":{"title":"2.计算机体系结构","titles":["计算机网络","Questions"]},"235":{"title":"3.从输入网址到获得页面的过程","titles":["计算机网络","Questions"]},"236":{"title":"4.三次握手","titles":["计算机网络","Questions"]},"237":{"title":"为什么需要三次握手","titles":["计算机网络","Questions","4.三次握手"]},"238":{"title":"5.四次挥手","titles":["计算机网络","Questions"]},"239":{"title":"为什么需要四次挥手","titles":["计算机网络","Questions","5.四次挥手"]},"240":{"title":"6.TCP和UDP的区别","titles":["计算机网络","Questions"]},"241":{"title":"7.TCP如何保证可靠传输","titles":["计算机网络","Questions"]},"242":{"title":"8.TCP流量控制","titles":["计算机网络","Questions"]},"243":{"title":"9.TCP拥塞控制","titles":["计算机网络","Questions"]},"244":{"title":"10.Session与Cookie","titles":["计算机网络","Questions"]},"245":{"title":"11.HTTP状态码","titles":["计算机网络","Questions"]},"246":{"title":"12.HTTP报文","titles":["计算机网络","Questions"]},"247":{"title":"13.HTTP与HTTPS的区别","titles":["计算机网络","Questions"]},"248":{"title":"面试真题","titles":["计算机网络"]},"249":{"title":"1.DNS的具体过程","titles":["计算机网络","面试真题"]},"250":{"title":"2.ARP协议的工作原理和流程，路由器是如何转发的？(路由表的工作原理)","titles":["计算机网络","面试真题"]},"251":{"title":"3.IPv4和IPv6的区别","titles":["计算机网络","面试真题"]},"252":{"title":"4.对称加密和非对称加密在HTTPS的应用","titles":["计算机网络","面试真题"]},"253":{"title":"参考链接","titles":["计算机网络"]},"254":{"title":"数据库","titles":[]},"255":{"title":"1. 事务四大特性","titles":["数据库"]},"256":{"title":"2. 数据库模型编辑","titles":["数据库"]},"257":{"title":"3. 数据库三范式","titles":["数据库"]},"258":{"title":"4. 关系型数据库和非关系型数据库","titles":["数据库"]},"259":{"title":"参考","titles":[]},"260":{"title":"计算机基础","titles":[]},"261":{"title":"📂 分类目录","titles":["计算机基础"]},"262":{"title":"💻","titles":["计算机基础","📂 分类目录"]},"263":{"title":"🌐","titles":["计算机基础","📂 分类目录"]},"264":{"title":"🗄️","titles":["计算机基础","📂 分类目录"]},"265":{"title":"📊","titles":["计算机基础","📂 分类目录"]},"266":{"title":"逻辑题目","titles":[]},"267":{"title":"1. 猜数字","titles":["逻辑题目"]},"268":{"title":"2. 握手","titles":["逻辑题目"]},"269":{"title":"3. 找出毒药","titles":["逻辑题目"]},"270":{"title":"4. 坏鸡蛋","titles":["逻辑题目"]},"271":{"title":"5. 测半径","titles":["逻辑题目"]},"272":{"title":"参考(copy)","titles":[]},"273":{"title":"概率题目","titles":[]},"274":{"title":"1. 三角形问题","titles":["概率题目"]},"275":{"title":"2. 排列组合","titles":["概率题目"]},"276":{"title":"3. 男女比例","titles":["概率题目"]},"277":{"title":"4. 取球问题","titles":["概率题目"]},"278":{"title":"5. 等概率器","titles":["概率题目"]},"279":{"title":"6. 再谈等概率器","titles":["概率题目"]},"280":{"title":"7. 吃苹果","titles":["概率题目"]},"281":{"title":"8. 蚂蚁爬三角形","titles":["概率题目"]},"282":{"title":"9. 正确的概率","titles":["概率题目"]},"283":{"title":"10. 和超过1的个数","titles":["概率题目"]},"284":{"title":"参考","titles":[]},"285":{"title":"操作系统","titles":[]},"286":{"title":"知识体系","titles":["操作系统"]},"287":{"title":"Questions","titles":["操作系统"]},"288":{"title":"1.进程和线程的区别","titles":["操作系统","Questions"]},"289":{"title":"2.协程","titles":["操作系统","Questions"]},"290":{"title":"3.进程的状态","titles":["操作系统","Questions"]},"291":{"title":"三态模型","titles":["操作系统","Questions","3.进程的状态"]},"292":{"title":"五态模型","titles":["操作系统","Questions","3.进程的状态"]},"293":{"title":"4.进程间通信方式","titles":["操作系统","Questions"]},"294":{"title":"5.僵尸进程和孤儿进程","titles":["操作系统","Questions"]},"295":{"title":"6.死锁","titles":["操作系统","Questions"]},"296":{"title":"死锁产生的必要条件","titles":["操作系统","Questions","6.死锁"]},"297":{"title":"死锁预防","titles":["操作系统","Questions","6.死锁"]},"298":{"title":"死锁避免","titles":["操作系统","Questions","6.死锁"]},"299":{"title":"7.页面置换算法","titles":["操作系统","Questions"]},"300":{"title":"8.分页和分段的区别","titles":["操作系统","Questions"]},"301":{"title":"9.硬中断和软中断","titles":["操作系统","Questions"]},"302":{"title":"10.IO模型","titles":["操作系统","Questions"]},"303":{"title":"参考链接","titles":["操作系统"]},"304":{"title":"CV基础知识","titles":[]},"305":{"title":"1. 为什么需要做特征归一化、标准化？","titles":["CV基础知识"]},"306":{"title":"2. 常用常用的归一化和标准化的方法有哪些？","titles":["CV基础知识"]},"307":{"title":"4. 怎么判断模型是否过拟合，有哪些防止过拟合的策略？","titles":["CV基础知识"]},"308":{"title":"5. 除了SGD和Adam之外，你还知道哪些优化算法？","titles":["CV基础知识"]},"309":{"title":"6. 阐述一下感受野的概念，并说一下在CNN中如何计算","titles":["CV基础知识"]},"310":{"title":"7. 训练神经网络有哪些调参技巧","titles":["CV基础知识"]},"311":{"title":"8. 神经网络的深度和宽度分别指的是什么？","titles":["CV基础知识"]},"312":{"title":"9. 上采样的原理和常用方式","titles":["CV基础知识"]},"313":{"title":"10. 下采样的作用是什么？通常有哪些方式？","titles":["CV基础知识"]},"314":{"title":"11.  模型的参数量指的是什么？怎么计算？","titles":["CV基础知识"]},"315":{"title":"12. 模型的FLOPs（计算量）指的是什么？怎么计算？","titles":["CV基础知识"]},"316":{"title":"13. 有哪些经典的卷积类型？","titles":["CV基础知识"]},"317":{"title":"14. 深度可分离卷积的概念和作用","titles":["CV基础知识"]},"318":{"title":"15. 神经网络中Addition / Concatenate区别是什么？","titles":["CV基础知识"]},"319":{"title":"16. 激活函数是什么？你知道哪些常用的激活函数？","titles":["CV基础知识"]},"320":{"title":"17. 神经网络中1×1卷积有什么作用？","titles":["CV基础知识"]},"321":{"title":"18. 随机梯度下降相比全局梯度下降好处是什么？","titles":["CV基础知识"]},"322":{"title":"19. 如果在网络初始化时给网络赋予0的权重，这个网络能正常训练嘛？","titles":["CV基础知识"]},"323":{"title":"20. 为什么要对网络进行初始化，有哪些初始化的方法？","titles":["CV基础知识"]},"324":{"title":"21. 增大感受野的方法？","titles":["CV基础知识"]},"325":{"title":"22. 神经网络的正则化方法？过拟合的解决方法？","titles":["CV基础知识"]},"326":{"title":"23. 梯度消失和梯度爆炸的原因是什么？","titles":["CV基础知识"]},"327":{"title":"24. 深度学习为什么在计算机视觉领域这么好？","titles":["CV基础知识"]},"328":{"title":"25. 为什么神经网络种常用relu作为激活函数？","titles":["CV基础知识"]},"329":{"title":"26. 卷积层和全连接层的区别是什么？","titles":["CV基础知识"]},"330":{"title":"27. 什么是正则化？L1正则化和L2正则化有什么区别？","titles":["CV基础知识"]},"331":{"title":"28. 常见的损失函数有哪些？你用过哪些？","titles":["CV基础知识"]},"332":{"title":"29. dropout为什么能解决过拟合？","titles":["CV基础知识"]},"333":{"title":"30. 深度学习中的batch的大小对学习效果有何影响？","titles":["CV基础知识"]},"334":{"title":"31. PyTorch和TensorFlow的特点分别是什么？","titles":["CV基础知识"]},"335":{"title":"32. Pytorch 多卡并行的时候怎么实现参数共享，通信梯度是指平均梯度，还是最大梯度，还是梯度总和？","titles":["CV基础知识"]},"336":{"title":"33. 数据不平衡的解决方法","titles":["CV基础知识"]},"337":{"title":"34. ReLU函数在0处不可导，为什么还能用？","titles":["CV基础知识"]},"338":{"title":"35. Pooling层的作用以及如何进行反向传播","titles":["CV基础知识"]},"339":{"title":"36. 为什么max pooling 要更常用？什么场景下 average pooling 比 max pooling 更合适？","titles":["CV基础知识"]},"340":{"title":"37. 为什么要反向传播？手推反向传播公式展示一下","titles":["CV基础知识"]},"341":{"title":"38. CV中的卷积操作和数学上的严格定义的卷积的关系？","titles":["CV基础知识"]},"342":{"title":"39. 简述CNN分类网络的演变脉络及各自的贡献与特点","titles":["CV基础知识"]},"343":{"title":"40. 神经网络的优缺点？","titles":["CV基础知识"]},"344":{"title":"41. Softmax+Cross Entropy如何反向求导？","titles":["CV基础知识"]},"345":{"title":"42. 有什么数据增强的方式？","titles":["CV基础知识"]},"346":{"title":"43. 为什么在模型训练开始会有warm up？","titles":["CV基础知识"]},"347":{"title":"44. VGG使用3*3卷积核的优势是什么?","titles":["CV基础知识"]},"348":{"title":"45. 什么是Group Convolution","titles":["CV基础知识"]},"349":{"title":"46. 训练过程中,若一个模型不收敛,那么是否说明这个模型无效?导致模型不收敛的原因有哪些?","titles":["CV基础知识"]},"350":{"title":"47. Relu比Sigmoid的效果好在哪里?","titles":["CV基础知识"]},"351":{"title":"48. Batch Normalization的作用","titles":["CV基础知识"]},"352":{"title":"49. GAN网络的思想","titles":["CV基础知识"]},"353":{"title":"50. Attention机制的作用","titles":["CV基础知识"]},"354":{"title":"51. 怎么提升网络的泛化能力","titles":["CV基础知识"]},"355":{"title":"52. CNN为什么比DNN在图像识别上更好","titles":["CV基础知识"]},"356":{"title":"53. DNN的梯度是如何更新的？","titles":["CV基础知识"]},"357":{"title":"54. Depthwise 卷积实际速度与理论速度差距较大，解释原因。","titles":["CV基础知识"]},"358":{"title":"主要的参考文献：","titles":["CV基础知识"]},"359":{"title":"目标检测部分","titles":[]},"360":{"title":"一、目标检测背景知识","titles":["目标检测部分"]},"361":{"title":"传统目标检测算法","titles":["目标检测部分","一、目标检测背景知识"]},"362":{"title":"基于深度学习目标检测算法","titles":["目标检测部分","一、目标检测背景知识"]},"363":{"title":"二、Questions","titles":["目标检测部分"]},"364":{"title":"1、Faster-Rcnn网络","titles":["目标检测部分","二、Questions"]},"365":{"title":"（1）请介绍一下faster R-CNN网络的原理（注: 需要能够详细画出网络结构图）&lt;顺丰-一面(2018)、腾讯-一面(2018)、旷视-三面（2018）&gt;","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"366":{"title":"（2）请简要叙述一下&quot;R-CNN——faster R-CNN&quot;","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"367":{"title":"（3）faster R-CNN是经典的two-stage 检测器，请简单说明其中two-stage的含义。","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"368":{"title":"（5）说一下RoI Pooling是怎么做的？有什么缺陷？有什么作用&lt;顺丰-一面(2018)&gt;","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"369":{"title":"（6)ROI Pooling与ROI Align(Mask R-CNN)的区别 &lt;字节跳动-二面（2019）&gt;","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"370":{"title":"（7）Faster R-CNN是如何解决正负样本不平衡的问题？","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"371":{"title":"（8）Faster RCNN怎么筛选正负anchor","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"372":{"title":"（9）faster-rcnn中bbox回归用的是什么公式，说一下该网络是怎么回归bbox的？","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"373":{"title":"（10）简述faster rcnn的前向计算过程并简述faster rcnn训练步骤","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"374":{"title":"（11）介绍faster rcnn这个流程，faster rcnn有哪些缺点？如何改进？&lt;商汤-一面（2019）&gt;","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"375":{"title":"（12）阐述一下Mask RCNN网络，这个网络相比于Faster RCNN网络有哪些改进的地方","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"376":{"title":"（13） 比较FasterRCNN在RCNN系列中的改进点","titles":["目标检测部分","二、Questions","1、Faster-Rcnn网络"]},"377":{"title":"2、YOLO系列网络","titles":["目标检测部分","二、Questions"]},"378":{"title":"（1）YOLOV1、YOLOV2、YOLOV3复述一遍  YOLOv1到v3的发展历程以及解决的问题。&lt;云从科技-一面（2020）、旷视-三面（2018）&gt;","titles":["目标检测部分","二、Questions","2、YOLO系列网络"]},"379":{"title":"（2）yolo的预测框是什么值:","titles":["目标检测部分","二、Questions","2、YOLO系列网络"]},"380":{"title":"（3）YOLOv2中如何通过K-Means得到anchor boxes？","titles":["目标检测部分","二、Questions","2、YOLO系列网络"]},"381":{"title":"（4）请叙述一下YOLOv3中k-means聚类获得anchor boxes过程详解","titles":["目标检测部分","二、Questions","2、YOLO系列网络"]},"382":{"title":"（5）YOLO系列anchor的设计原理，kmeans的原理，anchor距离如何度量，如何改进k-means原理？","titles":["目标检测部分","二、Questions","2、YOLO系列网络"]},"383":{"title":"（6）YOLOv3框是怎么得到的？ YOLOv3有什么致命问题？&lt;长虹AI lab-一面（2020）、阿里实习-一面（2018）、中兴-一面（2019）&gt;","titles":["目标检测部分","二、Questions","2、YOLO系列网络"]},"384":{"title":"3. 其他检测网络","titles":["目标检测部分","二、Questions"]},"385":{"title":"（1）简要阐述一下SSD网络，有哪些优点缺点？&lt;商汤-一面（2019）、蘑菇街-一面（2018）&gt;","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"386":{"title":"（2）简述SSD网络前向是如何计算的","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"387":{"title":"（3）简要阐述一下RetinaNet","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"388":{"title":"（4）简单叙述一下RetinaNet中的FPN代码运行流程，P6、P7的作用是什么？","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"389":{"title":"（5） 简单介绍下cascade rcnn&lt;字节跳动-三面（2019）&gt;","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"390":{"title":"（6）简要介绍一下FPN&lt;百度实习-一面（2019）、字节跳动-二面（2019）、云从科技-二面(2019)&gt;","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"391":{"title":"（2）anchor设置的意义","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"392":{"title":"（3）如何理解concat和add这两种常见的feature map特征融合方式","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"393":{"title":"（4）介绍一下目标检测的主要评测指标","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"394":{"title":"（5） FLOPs计算","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"395":{"title":"（6） 参数量paras计算 （参数与FLOPs中一致）","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"396":{"title":"（7）简单介绍一下kmeans算法&lt;小米-一面（2020）、腾讯-一面(2018)&gt;","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"397":{"title":"（8）说一下非极大值抑制（NMS）（non maximum suppression） NMS实现细节，手撕NMS&lt;小米-二面（2020）、&lt;百度实习-一面（2019）、商汤-一面（2019）、腾讯-一面(2018)&gt;","titles":["目标检测部分","二、Questions","3. 其他检测网络"]},"398":{"title":"7、延伸问题","titles":["目标检测部分","二、Questions"]},"399":{"title":"（1）讲一下目标检测优化的方向&lt;百度实习-一面（2019）&gt;","titles":["目标检测部分","二、Questions","7、延伸问题"]},"400":{"title":"（2）如果只能修改RPN网络的话，怎么修改可以提升网络小目标检出率","titles":["目标检测部分","二、Questions","7、延伸问题"]},"401":{"title":"（3）阐述一下如何检测小物体","titles":["目标检测部分","二、Questions","7、延伸问题"]},"402":{"title":"（4）阐述一下目标检测任务中的多尺度","titles":["目标检测部分","二、Questions","7、延伸问题"]},"403":{"title":"（5）如果有很长，很小，或者很宽的目标，应该如何处理目标检测中如何解决目标尺度大小不一的情况  小目标不好检测，有试过其他的方法吗？比如裁剪图像进行重叠","titles":["目标检测部分","二、Questions","7、延伸问题"]},"404":{"title":"（6）检测的框角度偏移了45度，这种情况怎么处理?&lt;海康-一面（2020）&gt;","titles":["目标检测部分","二、Questions","7、延伸问题"]},"405":{"title":"8、思考一下","titles":["目标检测部分","二、Questions"]},"406":{"title":"（1）讲一下two-stage和one-stage的异同&lt;百度实习-一面（2019）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"407":{"title":"（2）讲一下Faster RCNN的两阶段训练和END TO END训练的不一样？&lt;百度实习-一面（2019）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"408":{"title":"（3）讲一下你所知道的插值方式&lt;百度实习-一面（2019）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"409":{"title":"（4）一阶段SSD，YOLO之间的区别是什么？&lt;Tencent AI lab-一面（2020）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"410":{"title":"（5）R-CNN系列和SSD本质有啥不一样吗？&lt;Tencent AI lab-一面（2020）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"411":{"title":"（6）讲一下目标检测的发展历程，从传统到深度&lt;百度实习-一面（2019）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"412":{"title":"（7）近年来，一些新的目标检测的backbone有哪些，各有什么特点？&lt;小米-一面（2020）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"413":{"title":"（8） 为选择用YOLOv3，这个网络真的好吗？&lt;长虹AI lab-一面（2020）&gt;","titles":["目标检测部分","二、Questions","8、思考一下"]},"414":{"title":"三、参考链接","titles":["目标检测部分"]},"415":{"title":"AI算法","titles":[]},"416":{"title":"📂 分类目录","titles":["AI算法"]},"417":{"title":"🤖","titles":["AI算法","📂 分类目录"]},"418":{"title":"👁️","titles":["AI算法","📂 分类目录"]},"419":{"title":"🗣️","titles":["AI算法","📂 分类目录"]},"420":{"title":"📊","titles":["AI算法","📂 分类目录"]},"421":{"title":"🧠","titles":["AI算法","📂 分类目录"]},"422":{"title":"大模型的一些面试题小结","titles":[]},"423":{"title":"英语学习应用中如何限制词汇范围？","titles":["大模型的一些面试题小结"]},"424":{"title":"Adaboost 算法介绍","titles":[]},"425":{"title":"1. 集成学习","titles":["Adaboost 算法介绍"]},"426":{"title":"2. Adaboost 算法详解","titles":["Adaboost 算法介绍"]},"427":{"title":"2.1 Adaboost 步骤概览","titles":["Adaboost 算法介绍","2. Adaboost 算法详解"]},"428":{"title":"2.2 Adaboost 算法流程","titles":["Adaboost 算法介绍","2. Adaboost 算法详解"]},"429":{"title":"3. 算法面试题","titles":["Adaboost 算法介绍"]},"430":{"title":"3.1 Adaboost分类模型的学习器的权重系数α怎么计算的？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"431":{"title":"3.2 Adaboost能否做回归问题？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"432":{"title":"3.3 boosting和bagging之间的区别,从偏差-方差的角度解释Adaboost？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"433":{"title":"3.4 为什么Adaboost方式能够提高整体模型的学习精度？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"434":{"title":"3.5 Adaboost算法如何加入正则项?","titles":["Adaboost 算法介绍","3. 算法面试题"]},"435":{"title":"3.6 Adaboost使用m个基学习器和加权平均使用m个学习器之间有什么不同？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"436":{"title":"3.7 Adaboost和GBDT之间的区别？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"437":{"title":"3.8 Adaboost的迭代次数(基学习器的个数)如何控制？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"438":{"title":"3.9 Adaboost算法中基学习器是否很重要，应该怎么选择基学习器？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"439":{"title":"3.10 MultiBoosting算法将Adaboost作为Bagging的基学习器，Iterative Bagging将Bagging作为Adaboost的基学习器。比较两者的优缺点？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"440":{"title":"3.11 训练过程中，每轮训练一直存在分类错误的问题，整个Adaboost却能快速收敛，为何？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"441":{"title":"3.12 Adaboost 的优缺点？","titles":["Adaboost 算法介绍","3. 算法面试题"]},"442":{"title":"参考资料：","titles":["Adaboost 算法介绍"]},"443":{"title":"Catboost面试?","titles":[]},"444":{"title":"1. 简单介绍Catboost?","titles":["Catboost面试?"]},"445":{"title":"2. 相比于XGBoost、LightGBM，CatBoost的创新点有哪些？","titles":["Catboost面试?"]},"446":{"title":"3. Catboost是如何处理类别特征的?","titles":["Catboost面试?"]},"447":{"title":"4. Catboost如何避免梯度偏差","titles":["Catboost面试?"]},"448":{"title":"5. Catboost如何避免预测偏移?","titles":["Catboost面试?"]},"449":{"title":"6. 解释一下排序提?","titles":["Catboost面试?"]},"450":{"title":"7. Catboost为什么要使用对称树？","titles":["Catboost面试?"]},"451":{"title":"8. CatBoost的优缺点","titles":["Catboost面试?"]},"452":{"title":"集成学习面试题","titles":[]},"453":{"title":"1. 什么是集成学习算法？","titles":["集成学习面试题"]},"454":{"title":"2. 集成学习主要有哪几种框架？","titles":["集成学习面试题"]},"455":{"title":"3. 简单介绍一下bagging，常用bagging算法有哪些？","titles":["集成学习面试题"]},"456":{"title":"4. 简单介绍一下boosting，常用boosting算法有哪些？","titles":["集成学习面试题"]},"457":{"title":"5. boosting思想的数学表达式是什么？","titles":["集成学习面试题"]},"458":{"title":"6. 简单介绍一下stacking","titles":["集成学习面试题"]},"459":{"title":"7. 你意识到你的模型受到低偏差和高方差问题的困扰，应该使用哪种算法来解决问题呢？为什么？","titles":["集成学习面试题"]},"460":{"title":"8. 常用的基分类器是什么？","titles":["集成学习面试题"]},"461":{"title":"9. 可否将随机森林中的基分类器，由决策树替换为线性分类器或K-近邻？请解释为什么？","titles":["集成学习面试题"]},"462":{"title":"10. GBDT和RF如何计算特征重要性","titles":["集成学习面试题"]},"463":{"title":"LightGBM面试题","titles":[]},"464":{"title":"1. 简单介绍一下LightGBM？","titles":["LightGBM面试题"]},"465":{"title":"2. 介绍一下直方图算法？","titles":["LightGBM面试题"]},"466":{"title":"3. 介绍一下Leaf-wise和 Level-wise？","titles":["LightGBM面试题"]},"467":{"title":"4. 介绍一下单边梯度采样算法(GOSS)？","titles":["LightGBM面试题"]},"468":{"title":"5. 介绍互斥特征捆绑算法(EFB)？","titles":["LightGBM面试题"]},"469":{"title":"6. 特征之间如何捆绑？","titles":["LightGBM面试题"]},"470":{"title":"7. LightGBM是怎么支持类别特征？","titles":["LightGBM面试题"]},"471":{"title":"8. LightGBM的优缺点","titles":["LightGBM面试题"]},"472":{"title":"9. GBDT是如何做回归和分类的","titles":["LightGBM面试题"]},"473":{"title":"参考资料","titles":["LightGBM面试题"]},"474":{"title":"随机森林面试题","titles":[]},"475":{"title":"1. 简单介绍随机森林","titles":["随机森林面试题"]},"476":{"title":"2. 随机森林的随机性体现在哪里？","titles":["随机森林面试题"]},"477":{"title":"3. 随机森林为什么不容易过拟合？","titles":["随机森林面试题"]},"478":{"title":"4. 为什么不用全样本训练？","titles":["随机森林面试题"]},"479":{"title":"5. 为什么要随机特征？","titles":["随机森林面试题"]},"480":{"title":"6. RF与 GBDT 的区别？","titles":["随机森林面试题"]},"481":{"title":"7. RF为什么比Bagging效率高？","titles":["随机森林面试题"]},"482":{"title":"8. 你已经建了一个有10000棵树的随机森林模型。在得到0.00的训练误差后，你非常高兴。但是，验证错误是34.23。到底是怎么回事？你还没有训练好你的模型吗？","titles":["随机森林面试题"]},"483":{"title":"9. 如何使用随机森林对特征重要性进行评估？","titles":["随机森林面试题"]},"484":{"title":"10. 随机森林算法训练时主要需要调整哪些参数？","titles":["随机森林面试题"]},"485":{"title":"11. 随机森林的优缺点","titles":["随机森林面试题"]},"486":{"title":"12. 简述一下Adaboost原理","titles":["随机森林面试题"]},"487":{"title":"13. AdaBoost的优点和缺点","titles":["随机森林面试题"]},"488":{"title":"14. Adaboost对噪声敏感吗？","titles":["随机森林面试题"]},"489":{"title":"15. Adaboost和随机森林算法的异同点","titles":["随机森林面试题"]},"490":{"title":"树模型集成学?","titles":[]},"491":{"title":"概要介绍","titles":[]},"492":{"title":"RandomForest","titles":["概要介绍"]},"493":{"title":"GBDT","titles":["概要介绍"]},"494":{"title":"Xgboost","titles":["概要介绍"]},"495":{"title":"Lightgbm","titles":["概要介绍"]},"496":{"title":"核心公式","titles":[]},"497":{"title":"算法十问","titles":[]},"498":{"title":"面试真题","titles":[]},"499":{"title":"参?","titles":[]},"500":{"title":"XGBoost面试?","titles":[]},"501":{"title":"1. RF和GBDT的区?","titles":["XGBoost面试?"]},"502":{"title":"2. 比较LR和GBDT，说说什么情景下GBDT不如LR","titles":["XGBoost面试?"]},"503":{"title":"3. 简单介绍一下XGBoost?","titles":["XGBoost面试?"]},"504":{"title":"4. XGBoost与GBDT有什么不?","titles":["XGBoost面试?"]},"505":{"title":"5. XGBoost为什么可以并行训?","titles":["XGBoost面试?"]},"506":{"title":"6. XGBoost为什么快?","titles":["XGBoost面试?"]},"507":{"title":"7. XGBoost中如何处理过拟合的情况?","titles":["XGBoost面试?"]},"508":{"title":"8. XGBoost如何处理缺失值？","titles":["XGBoost面试?"]},"509":{"title":"9. XGBoost如何处理不平衡数据?","titles":["XGBoost面试?"]},"510":{"title":"10. XGBoost如何选择最佳分裂点?","titles":["XGBoost面试?"]},"511":{"title":"11. XGBoost的Scalable性如何体现？","titles":["XGBoost面试?"]},"512":{"title":"12. XGBoost如何评价特征的重要性？","titles":["XGBoost面试?"]},"513":{"title":"14. XGBoost的优缺?","titles":["XGBoost面试?"]},"514":{"title":"15. XGBoost和LightGBM的区别","titles":["XGBoost面试?"]},"515":{"title":"16. GBDT的拟合值残差为什么用负梯度代替，而不是直接拟合残?","titles":["XGBoost面试?"]},"516":{"title":"17. XGBoost使用二阶泰勒展开的目的和优势","titles":["XGBoost面试?"]},"517":{"title":"参?","titles":["XGBoost面试?"]},"518":{"title":"条件随机场面试题","titles":[]},"519":{"title":"1. 简单介绍条件随机场","titles":["条件随机场面试题"]},"520":{"title":"4. HMM、MEMM和CRF模型的比?","titles":["条件随机场面试题"]},"521":{"title":"5. 注意要点","titles":["条件随机场面试题"]},"522":{"title":"参?","titles":["条件随机场面试题"]},"523":{"title":"HMM","titles":[]},"524":{"title":"Author: 李文? Email:","titles":["HMM"]},"525":{"title":"直观理解","titles":["HMM"]},"526":{"title":"核心公式","titles":["HMM"]},"527":{"title":"注意要点","titles":["HMM"]},"528":{"title":"面试真题","titles":["HMM"]},"529":{"title":"参?##","titles":["HMM"]},"530":{"title":"Prophet面试?","titles":[]},"531":{"title":"1. 简要介绍Prophet","titles":[]},"532":{"title":"2. 趋势项模?","titles":[]},"533":{"title":"3. 变点的选择","titles":[]},"534":{"title":"4. 对未来的预估","titles":[]},"535":{"title":"5. 季节性趋?","titles":[]},"536":{"title":"6. 节假日效应（holidays and events?","titles":[]},"537":{"title":"7. 参数","titles":[]},"538":{"title":"参考资?","titles":[]},"539":{"title":"梯度下降法面试题","titles":[]},"540":{"title":"1. 机器学习中为什么需要梯度下降","titles":["梯度下降法面试题"]},"541":{"title":"2. 梯度下降法缺点","titles":["梯度下降法面试题"]},"542":{"title":"3. 梯度下降法直观理解","titles":["梯度下降法面试题"]},"543":{"title":"4. 梯度下降核心思想归纳","titles":["梯度下降法面试题"]},"544":{"title":"5. 如何对梯度下降法进行调优","titles":["梯度下降法面试题"]},"545":{"title":"6. 随机梯度和批量梯度区别","titles":["梯度下降法面试题"]},"546":{"title":"7.  各种梯度下降法性能比较","titles":["梯度下降法面试题"]},"547":{"title":"8. 推导多元函数梯度下降法的迭代公式。","titles":["梯度下降法面试题"]},"548":{"title":"9.  梯度下降法如何判断是否收敛？","titles":["梯度下降法面试题"]},"549":{"title":"10. 梯度下降法为什么要在迭代公式中使用步长系数？","titles":["梯度下降法面试题"]},"550":{"title":"11. 梯度下降法和牛顿法能保证找到函数的极小值点吗，为什么？","titles":["梯度下降法面试题"]},"551":{"title":"12. 解释一元函数极值判别法则。","titles":["梯度下降法面试题"]},"552":{"title":"13. 解释多元函数极值判别法则。","titles":["梯度下降法面试题"]},"553":{"title":"14. 什么是鞍点？","titles":["梯度下降法面试题"]},"554":{"title":"15. 解释什么是局部极小值，什么是全局极小值。","titles":["梯度下降法面试题"]},"555":{"title":"16. 推导多元函数牛顿法的迭代公式。","titles":["梯度下降法面试题"]},"556":{"title":"参考资料：","titles":["梯度下降法面试题"]},"557":{"title":"过拟合欠拟合面试题","titles":[]},"558":{"title":"1. 如何理解高方差与低偏差?","titles":["过拟合欠拟合面试题"]},"559":{"title":"2. 什么是过拟合和欠拟合，为什么会出现这个现象","titles":["过拟合欠拟合面试题"]},"560":{"title":"3. 怎么解决欠拟合","titles":["过拟合欠拟合面试题"]},"561":{"title":"4. 怎么解决过拟合（重点）","titles":["过拟合欠拟合面试题"]},"562":{"title":"5. 为什么参数越小代表模型越简单？","titles":["过拟合欠拟合面试题"]},"563":{"title":"6. 为什么L1比L2更容易获得稀疏解？（重点）","titles":["过拟合欠拟合面试题"]},"564":{"title":"7. Dropout为什么有助于防止过拟合？（重点）","titles":["过拟合欠拟合面试题"]},"565":{"title":"8. Dropout在训练和测试时都需要吗？","titles":["过拟合欠拟合面试题"]},"566":{"title":"9. Dropout如何平衡训练和测试时的差异呢？","titles":["过拟合欠拟合面试题"]},"567":{"title":"10. BN和Dropout共同使用时会出现的问题","titles":["过拟合欠拟合面试题"]},"568":{"title":"11. L1 和 L2 正则先验分别服从什么分布","titles":["过拟合欠拟合面试题"]},"569":{"title":"AB测试面试题","titles":[]},"570":{"title":"1. 介绍一下ABTest的步骤","titles":["AB测试面试题"]},"571":{"title":"2. ABtest背后的理论支撑是什么？","titles":["AB测试面试题"]},"572":{"title":"3. 如何分组才能更好地避免混淆呢?","titles":["AB测试面试题"]},"573":{"title":"4. 样本量大小如何？","titles":["AB测试面试题"]},"574":{"title":"5. 两类错误是什么？","titles":["AB测试面试题"]},"575":{"title":"6. 埋点&amp;暗中观察","titles":["AB测试面试题"]},"576":{"title":"7. 如果一个人有多个账号，分别做不同用途，abtest的时候怎么分组才最合理呢？","titles":["AB测试面试题"]},"577":{"title":"参考资料","titles":["AB测试面试题"]},"578":{"title":"评测指标面试?","titles":[]},"579":{"title":"回归(Regression)","titles":["评测指标面试?"]},"580":{"title":"平均绝对误差(MAE)","titles":["评测指标面试?","回归(Regression)"]},"581":{"title":"均方误差(MSE)","titles":["评测指标面试?","回归(Regression)"]},"582":{"title":"均方根误?RMSE)","titles":["评测指标面试?","回归(Regression)"]},"583":{"title":"R2_score","titles":["评测指标面试?","回归(Regression)"]},"584":{"title":"分类(Classification)","titles":["评测指标面试?"]},"585":{"title":"准确率和错误?","titles":["评测指标面试?","分类(Classification)"]},"586":{"title":"混淆矩阵","titles":["评测指标面试?","分类(Classification)"]},"587":{"title":"精确率（查准率） Precision","titles":["评测指标面试?","分类(Classification)"]},"588":{"title":"召回率（查全率）Recall","titles":["评测指标面试?","分类(Classification)"]},"589":{"title":"F1 Score","titles":["评测指标面试?","分类(Classification)"]},"590":{"title":"ROC","titles":["评测指标面试?","分类(Classification)"]},"591":{"title":"AUC","titles":["评测指标面试?","分类(Classification)"]},"592":{"title":"KS Kolmogorov-Smirnov","titles":["评测指标面试?","分类(Classification)"]},"593":{"title":"CTR（Click-Through-Rate?","titles":["评测指标面试?","分类(Classification)"]},"594":{"title":"CVR    (Conversion Rate)","titles":["评测指标面试?","分类(Classification)"]},"595":{"title":"参?","titles":["评测指标面试?"]},"596":{"title":"决策树面试题","titles":[]},"597":{"title":"1. 简单介绍决策树算法","titles":["决策树面试题"]},"598":{"title":"2. 决策树和条件概率分布的关系？","titles":["决策树面试题"]},"599":{"title":"3. 信息增益比相对信息增益有什么好处？","titles":["决策树面试题"]},"600":{"title":"4. ID3算法&gt;C4.5算法&gt; CART算法","titles":["决策树面试题"]},"601":{"title":"5. 决策树的缺失值是怎么处理的","titles":["决策树面试题"]},"602":{"title":"6. 决策树的目标函数是什么？","titles":["决策树面试题"]},"603":{"title":"7. 决策树怎么处理连续性特征？","titles":["决策树面试题"]},"604":{"title":"8. 决策树对离散值的处理","titles":["决策树面试题"]},"605":{"title":"9. 决策树怎么防止过拟合？","titles":["决策树面试题"]},"606":{"title":"10. 如果特征很多，决策树中最后没有用到的特征一定是无用吗？","titles":["决策树面试题"]},"607":{"title":"11.决策树的优缺点？","titles":["决策树面试题"]},"608":{"title":"12. 树形结构为什么不需要归一化?","titles":["决策树面试题"]},"609":{"title":"13. 如果特征很多，决策树中最后没有用到的特征一定是无用吗？","titles":["决策树面试题"]},"610":{"title":"参考资料","titles":["决策树面试题"]},"611":{"title":"贝叶斯面试题","titles":[]},"612":{"title":"1.简述朴素贝叶斯算法原理和工作流?","titles":["贝叶斯面试题"]},"613":{"title":"2. 条件概率、先验概率、后验概率、联合概率、贝叶斯公式的概?","titles":["贝叶斯面试题"]},"614":{"title":"3.为什么朴素贝叶斯如此朴素？","titles":["贝叶斯面试题"]},"615":{"title":"4.什么是贝叶斯决策理论？","titles":["贝叶斯面试题"]},"616":{"title":"5.朴素贝叶斯算法的前提假设是什么？","titles":["贝叶斯面试题"]},"617":{"title":"6.为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效?","titles":["贝叶斯面试题"]},"618":{"title":"7.什么是朴素贝叶斯中的零概率问题？如何解决？","titles":["贝叶斯面试题"]},"619":{"title":"8.朴素贝叶斯中概率计算的下溢问题如何解决？","titles":["贝叶斯面试题"]},"620":{"title":"9.当数据的属性是连续型变量时，朴素贝叶斯算法如何处理?","titles":["贝叶斯面试题"]},"621":{"title":"10.朴素贝叶斯有哪几种常用的分类模型?","titles":["贝叶斯面试题"]},"622":{"title":"11.为什么说朴素贝叶斯是高偏差低方差?","titles":["贝叶斯面试题"]},"623":{"title":"12.朴素贝叶斯为什么适合增量计算?","titles":["贝叶斯面试题"]},"624":{"title":"13.高度相关的特征对朴素贝叶斯有什么影响？","titles":["贝叶斯面试题"]},"625":{"title":"14.朴素贝叶斯的应用场景有哪些？","titles":["贝叶斯面试题"]},"626":{"title":"15.朴素贝叶斯有什么优缺点?","titles":["贝叶斯面试题"]},"627":{"title":"16.朴素贝叶斯与 LR 区别?","titles":["贝叶斯面试题"]},"628":{"title":"17. 贝叶斯优化算?参数调优)","titles":["贝叶斯面试题"]},"629":{"title":"18.朴素贝叶斯分类器对异常值敏感吗?","titles":["贝叶斯面试题"]},"630":{"title":"19.朴素贝叶斯算法对缺失值敏感吗?","titles":["贝叶斯面试题"]},"631":{"title":"20. 一句话总结贝叶斯算?","titles":["贝叶斯面试题"]},"632":{"title":"21.朴素贝叶斯与LR的区别？（经典问题）","titles":["贝叶斯面试题"]},"633":{"title":"SVM面试题","titles":[]},"634":{"title":"1. SVM直观解释","titles":["SVM面试题"]},"635":{"title":"2. 核心公式","titles":["SVM面试题"]},"636":{"title":"3. SVM 为什么采用间隔最大化","titles":["SVM面试题"]},"637":{"title":"4. 为什么要将求?SVM 的原始问题转换为其对偶问?","titles":["SVM面试题"]},"638":{"title":"5. 为什?SVM 要引入核函数","titles":["SVM面试题"]},"639":{"title":"6. 为什么SVM对缺失数据敏?","titles":["SVM面试题"]},"640":{"title":"7. SVM 核函数之间的区别","titles":["SVM面试题"]},"641":{"title":"8. LR和SVM的联系与区别","titles":["SVM面试题"]},"642":{"title":"9. SVM的原理是什么？","titles":["SVM面试题"]},"643":{"title":"10. SVM如何处理多分类问题？","titles":["SVM面试题"]},"644":{"title":"参考文?","titles":["SVM面试题"]},"645":{"title":"KNN面试?","titles":[]},"646":{"title":"1.简述一下KNN算法的原?","titles":["KNN面试?"]},"647":{"title":"2. 如何理解kNN中的k的取值？","titles":["KNN面试?"]},"648":{"title":"3. 在kNN的样本搜索中，如何进行高效的匹配查找?","titles":["KNN面试?"]},"649":{"title":"4. KNN算法有哪些优点和缺点?","titles":["KNN面试?"]},"650":{"title":"5. 不平衡的样本可以给KNN的预测结果造成哪些问题，有没有什么好的解决方式？","titles":["KNN面试?"]},"651":{"title":"6. 为了解决KNN算法计算量过大的问题，可以使用分组的方式进行计算，简述一下该方式的原理?","titles":["KNN面试?"]},"652":{"title":"参?","titles":["KNN面试?"]},"653":{"title":"线性回归于逻辑回归面试题","titles":[]},"654":{"title":"1. 简单介绍一下线性回归。","titles":["线性回归于逻辑回归面试题"]},"655":{"title":"2. 线性回归的假设函数是什么形式？","titles":["线性回归于逻辑回归面试题"]},"656":{"title":"3. 线性回归的损失函数是什么形式？","titles":["线性回归于逻辑回归面试题"]},"657":{"title":"4. 简述岭回归与Lasso回归以及使用场景。","titles":["线性回归于逻辑回归面试题"]},"658":{"title":"5. 线性回归要求因变量服从正态分布吗？","titles":["线性回归于逻辑回归面试题"]},"659":{"title":"6. 简单介绍一下逻辑回归","titles":["线性回归于逻辑回归面试题"]},"660":{"title":"7. 简单介绍一下Sigmoid函数","titles":["线性回归于逻辑回归面试题"]},"661":{"title":"8. 逻辑回归的损失函数是什么","titles":["线性回归于逻辑回归面试题"]},"662":{"title":"9.逻辑回归如何进行多分类？","titles":["线性回归于逻辑回归面试题"]},"663":{"title":"10.逻辑回归的优缺点","titles":["线性回归于逻辑回归面试题"]},"664":{"title":"11. 逻辑斯特回归为什么要对特征进行离散化。","titles":["线性回归于逻辑回归面试题"]},"665":{"title":"12.  线性回归与逻辑回归的区别","titles":["线性回归于逻辑回归面试题"]},"666":{"title":"13. 为什么逻辑回归比线性回归要好？","titles":["线性回归于逻辑回归面试题"]},"667":{"title":"14. 逻辑回归有哪些应用","titles":["线性回归于逻辑回归面试题"]},"668":{"title":"15. 如果label={-1, +1}，给出LR的损失函数？","titles":["线性回归于逻辑回归面试题"]},"669":{"title":"16. 逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？","titles":["线性回归于逻辑回归面试题"]},"670":{"title":"17. LR为什么使用sigmoid函数？","titles":["线性回归于逻辑回归面试题"]},"671":{"title":"18. LR如何进行并行计算？","titles":["线性回归于逻辑回归面试题"]},"672":{"title":"19.LR和SVM有什么不同吗","titles":["线性回归于逻辑回归面试题"]},"673":{"title":"K-means面试题","titles":[]},"674":{"title":"1. 聚类算法（clustering Algorithms）介绍","titles":["K-means面试题"]},"675":{"title":"2. kmeans原理详解","titles":["K-means面试题"]},"676":{"title":"3.  优缺点及改进算法","titles":["K-means面试题"]},"677":{"title":"4. k值的选取","titles":["K-means面试题"]},"678":{"title":"5. K-means算法中初始点的选择对最终结果的影响","titles":["K-means面试题"]},"679":{"title":"6. 为什么在计算K-means之前要将数据点在各维度上归一化","titles":["K-means面试题"]},"680":{"title":"7.  K-means不适用哪些数据","titles":["K-means面试题"]},"681":{"title":"8.  K-means 中常用的距离度量","titles":["K-means面试题"]},"682":{"title":"9. K-means是否会一直陷入选择质心的循环停不下来（为什么迭代次数后会收敛）？","titles":["K-means面试题"]},"683":{"title":"10. 聚类和分类区别","titles":["K-means面试题"]},"684":{"title":"11. 如何对K-means聚类效果进行评估","titles":["K-means面试题"]},"685":{"title":"12. K-means中空聚类的处理","titles":["K-means面试题"]},"686":{"title":"参考资料","titles":["K-means面试题"]},"687":{"title":"基于深度学习的模型","titles":[]},"688":{"title":"知识体系","titles":["基于深度学习的模型"]},"689":{"title":"CNN","titles":["基于深度学习的模型","知识体系"]},"690":{"title":"RNN","titles":["基于深度学习的模型","知识体系"]},"691":{"title":"Questions","titles":["基于深度学习的模型"]},"692":{"title":"CNN相关","titles":["基于深度学习的模型","Questions"]},"693":{"title":"CNN 有什么好处？","titles":["基于深度学习的模型","Questions","CNN相关"]},"694":{"title":"CNN 有什么不足？","titles":["基于深度学习的模型","Questions","CNN相关"]},"695":{"title":"卷积层输出 size？","titles":["基于深度学习的模型","Questions","CNN相关"]},"696":{"title":"RNN","titles":["基于深度学习的模型","Questions"]},"697":{"title":"LSTM 网络结构？","titles":["基于深度学习的模型","Questions","RNN"]},"698":{"title":"如何解决 RNN 中的梯度消失或梯度爆炸问题？","titles":["基于深度学习的模型","Questions","RNN"]},"699":{"title":"假设输入维度为 m，输出为 n，求 GRU 参数？","titles":["基于深度学习的模型","Questions","RNN"]},"700":{"title":"LSTM 和 GRU 的区别？","titles":["基于深度学习的模型","Questions","RNN"]},"701":{"title":"Attention","titles":["基于深度学习的模型","Questions"]},"702":{"title":"Attention 机制","titles":["基于深度学习的模型","Questions","Attention"]},"703":{"title":"自注意力中为何要缩放？","titles":["基于深度学习的模型","Questions","Attention"]},"704":{"title":"Transformer","titles":["基于深度学习的模型","Questions"]},"705":{"title":"Transformer 中为什么用 Add 而不是 Concat？","titles":["基于深度学习的模型","Questions","Transformer"]},"706":{"title":"ELMO","titles":["基于深度学习的模型","Questions"]},"707":{"title":"简单介绍下ELMO","titles":["基于深度学习的模型","Questions","ELMO"]},"708":{"title":"ELMO的缺点","titles":["基于深度学习的模型","Questions"]},"709":{"title":"GPT","titles":["基于深度学习的模型","Questions"]},"710":{"title":"简单介绍下GPT","titles":["基于深度学习的模型","Questions","GPT"]},"711":{"title":"GPT的缺点","titles":["基于深度学习的模型","Questions","GPT"]},"712":{"title":"BERT","titles":["基于深度学习的模型","Questions"]},"713":{"title":"简单介绍下BERT","titles":["基于深度学习的模型","Questions","BERT"]},"714":{"title":"BERT缺点","titles":["基于深度学习的模型","Questions","BERT"]},"715":{"title":"ERNIE","titles":["基于深度学习的模型","Questions"]},"716":{"title":"ERNIE对BERT进行了哪些优化？","titles":["基于深度学习的模型","Questions","ERNIE"]},"717":{"title":"1 模型介绍","titles":[]},"718":{"title":"1.1 模型概述","titles":["1 模型介绍"]},"719":{"title":"1.2 CBOW模型","titles":["1 模型介绍"]},"720":{"title":"1.2.1 Hierarchical Softmax","titles":["1 模型介绍","1.2 CBOW模型"]},"721":{"title":"1.2.2 Negative Sampling","titles":["1 模型介绍","1.2 CBOW模型"]},"722":{"title":"1.3 Skip-Gram模型","titles":["1 模型介绍"]},"723":{"title":"1.3.1 Hierarchical Softmax","titles":["1 模型介绍","1.3 Skip-Gram模型"]},"724":{"title":"1.3.2 Negative Sampling","titles":["1 模型介绍","1.3 Skip-Gram模型"]},"725":{"title":"2 常见面试问题","titles":[]},"726":{"title":"协同过滤(collaborative filtering)","titles":[]},"727":{"title":"直观解释","titles":["协同过滤(collaborative filtering)"]},"728":{"title":"导图","titles":["协同过滤(collaborative filtering)"]},"729":{"title":"核心公式","titles":["协同过滤(collaborative filtering)"]},"730":{"title":"注意要点","titles":["协同过滤(collaborative filtering)"]},"731":{"title":"面试真题","titles":["协同过滤(collaborative filtering)"]},"732":{"title":"DeepFM","titles":[]},"733":{"title":"模型结构","titles":["DeepFM"]},"734":{"title":"Input与Embedding层","titles":["DeepFM","模型结构"]},"735":{"title":"Wide部分---FM","titles":["DeepFM","模型结构","Input与Embedding层"]},"736":{"title":"Deep部分","titles":["DeepFM","模型结构","Input与Embedding层"]},"737":{"title":"Output层","titles":["DeepFM","模型结构"]},"738":{"title":"面试相关","titles":["DeepFM"]},"739":{"title":"gbdt lr","titles":[]},"740":{"title":"核心思想","titles":[]},"741":{"title":"面试十问","titles":[]},"742":{"title":"面试真题","titles":[]},"743":{"title":"参考","titles":[]},"744":{"title":"系统设计","titles":[]},"745":{"title":"📂 分类目录","titles":["系统设计"]},"746":{"title":"面试题目","titles":[]},"747":{"title":"1. 相同URL","titles":["面试题目"]},"748":{"title":"2. Query排序","titles":["面试题目"]},"749":{"title":"3. Top k 单词","titles":["面试题目"]},"750":{"title":"4. IP统计","titles":["面试题目"]},"751":{"title":"5. 不重复的整数","titles":["面试题目"]},"752":{"title":"6. Top K","titles":["面试题目"]},"753":{"title":"参考","titles":[]},"754":{"title":"相关技?","titles":[]},"755":{"title":"排序","titles":["相关技?"]},"756":{"title":"堆排?","titles":["相关技?"]},"757":{"title":"快速排?","titles":["相关技?"]},"758":{"title":"桶排?","titles":["相关技?"]},"759":{"title":"位图排序","titles":["相关技?"]},"760":{"title":"归并排序","titles":["相关技?"]},"761":{"title":"倒排索引","titles":["相关技?"]},"762":{"title":"字典?","titles":["相关技?"]},"763":{"title":"面试问题","titles":["相关技?"]},"764":{"title":"参?","titles":[]},"765":{"title":"背景","titles":[]},"766":{"title":"笔者联系方�?","titles":[]},"767":{"title":"大数据技术框�?","titles":[]},"768":{"title":"海量数据处理常用技术概述","titles":[]},"769":{"title":"海量数据处理－－从分而治之到Mapreduce","titles":["海量数据处理常用技术概述"]},"770":{"title":"浅谈技术细节","titles":["海量数据处理常用技术概述"]},"771":{"title":"参考","titles":["海量数据处理常用技术概述"]},"772":{"title":"前端开发校招面试问题整理�?】——HTML","titles":[]},"773":{"title":"1、HTML 元素（element�?","titles":["前端开发校招面试问题整理�?】——HTML"]},"774":{"title":"Q：简单介绍下常用�?HTML 元素�?","titles":["前端开发校招面试问题整理�?】——HTML","1、HTML 元素（element�?"]},"775":{"title":"Q：语义化元素是指�?","titles":["前端开发校招面试问题整理�?】——HTML","1、HTML 元素（element�?"]},"776":{"title":"Q：HTML5 新增了哪些元素？","titles":["前端开发校招面试问题整理�?】——HTML","1、HTML 元素（element�?"]},"777":{"title":"2、HTML 事件","titles":["前端开发校招面试问题整理�?】——HTML"]},"778":{"title":"Q：描述一�?HTML 的事件模型？事件捕获/事件冒泡指的是？","titles":["前端开发校招面试问题整理�?】——HTML","2、HTML 事件"]},"779":{"title":"Q：如何阻止事件冒泡？如何阻止元素默认行为�?","titles":["前端开发校招面试问题整理�?】——HTML","2、HTML 事件"]},"780":{"title":"校招前端面试常见问题【3】——CSS","titles":[]},"781":{"title":"1、盒模型","titles":["校招前端面试常见问题【3】——CSS"]},"782":{"title":"Q：请简述一下 CSS 盒模型？","titles":["校招前端面试常见问题【3】——CSS","1、盒模型"]},"783":{"title":"4、常见概念","titles":["校招前端面试常见问题【3】——CSS"]},"784":{"title":"Q：FC 是什么？BFC 和 IFC 是什么？","titles":["校招前端面试常见问题【3】——CSS","4、常见概念"]},"785":{"title":"Q：如何清除浮动？","titles":["校招前端面试常见问题【3】——CSS","4、常见概念"]},"786":{"title":"Q：什么是回流？什么是重绘？","titles":["校招前端面试常见问题【3】——CSS","4、常见概念"]},"787":{"title":"Q：如何开启 GPU 加速？其优缺点是什么？","titles":["校招前端面试常见问题【3】——CSS","4、常见概念"]},"788":{"title":"校招前端面试常见问题�?】——前端框架及常用工具","titles":[]},"789":{"title":"React","titles":["校招前端面试常见问题�?】——前端框架及常用工具"]},"790":{"title":"Q：请简述一下虚�?DOM 的概念？","titles":["校招前端面试常见问题�?】——前端框架及常用工具","React"]},"791":{"title":"Q：请简述一�?React 的生命周期？","titles":["校招前端面试常见问题�?】——前端框架及常用工具","React"]},"792":{"title":"Q：请简述一�?React Fiber 的概念？","titles":["校招前端面试常见问题�?】——前端框架及常用工具","React"]},"793":{"title":"Q：React setState 的时机？","titles":["校招前端面试常见问题�?】——前端框架及常用工具","React"]},"794":{"title":"Vue","titles":["校招前端面试常见问题�?】——前端框架及常用工具"]},"795":{"title":"Q：什么是 mvvm 模式�?","titles":["校招前端面试常见问题�?】——前端框架及常用工具","Vue"]},"796":{"title":"Q：请简述一�?vue 响应式数据的原理�?","titles":["校招前端面试常见问题�?】——前端框架及常用工具","Vue"]},"797":{"title":"Q：请简述一�?Vue 的生命周期？","titles":["校招前端面试常见问题�?】——前端框架及常用工具","Vue"]},"798":{"title":"Q：请简述一�?Vue router 的原理？","titles":["校招前端面试常见问题�?】——前端框架及常用工具","Vue"]},"799":{"title":"打包工具","titles":["校招前端面试常见问题�?】——前端框架及常用工具"]},"800":{"title":"Q：介绍一�?webpack�?","titles":["校招前端面试常见问题�?】——前端框架及常用工具","打包工具"]},"801":{"title":"开发技�?","titles":[]},"802":{"title":"📂 分类目录","titles":["开发技�?"]},"803":{"title":"🌐","titles":["开发技�?","📂 分类目录"]},"804":{"title":"📊","titles":["开发技�?","📂 分类目录"]},"805":{"title":"项目经验","titles":[]},"806":{"title":"📂 分类目录","titles":["项目经验"]},"807":{"title":"行为面试","titles":[]},"808":{"title":"📚 内容导航","titles":["行为面试"]},"809":{"title":"🎯 自我介绍","titles":["行为面试","📚 内容导航"]},"810":{"title":"🚀 职业规划","titles":["行为面试","📚 内容导航"]},"811":{"title":"💪 压力面试","titles":["行为面试","📚 内容导航"]},"812":{"title":"💰 薪资谈判","titles":["行为面试","📚 内容导航"]},"813":{"title":"🎯 行为面试核心评估维度","titles":["行为面试"]},"814":{"title":"🧠 认知能力","titles":["行为面试","🎯 行为面试核心评估维度"]},"815":{"title":"学习能力","titles":["行为面试","🎯 行为面试核心评估维度","🧠 认知能力"]},"816":{"title":"问题解决","titles":["行为面试","🎯 行为面试核心评估维度","🧠 认知能力"]},"817":{"title":"🤝 人际能力","titles":["行为面试","🎯 行为面试核心评估维度"]},"818":{"title":"沟通协�?- 表达能力：清晰准确地表达想法和观�?- 倾听能力：理解他人观点和需�?- 团队合作：与不同背景的人有效协作","titles":["行为面试","🎯 行为面试核心评估维度","🤝 人际能力"]},"819":{"title":"领导�?- **影响�?：影响和说服他人的能�?- **责任�?：承担责任和推动结果的意�?- 团队建设：激励和发展团队成员","titles":["行为面试","🎯 行为面试核心评估维度","🤝 人际能力"]},"820":{"title":"💪 个人品质","titles":["行为面试","🎯 行为面试核心评估维度"]},"821":{"title":"工作态度","titles":["行为面试","🎯 行为面试核心评估维度","💪 个人品质"]},"822":{"title":"价值观","titles":["行为面试","🎯 行为面试核心评估维度","💪 个人品质"]},"823":{"title":"💡 常见行为面试问题","titles":["行为面试"]},"824":{"title":"自我认知�?- &quot;请简单介绍一下自�?","titles":["行为面试","💡 常见行为面试问题"]},"825":{"title":"经历回顾�?- &quot;请介绍一个你最有成就感的项�?","titles":["行为面试","💡 常见行为面试问题"]},"826":{"title":"情景假设�?- &quot;如果你的上级给你安排了一个不合理的任务，你会怎么办？&quot;","titles":["行为面试","💡 常见行为面试问题"]},"827":{"title":"公司文化�?- &quot;你了解我们公司吗？为什么想加入我们�?","titles":["行为面试","💡 常见行为面试问题"]},"828":{"title":"🔍 回答技巧和策略","titles":["行为面试"]},"829":{"title":"STAR法则","titles":["行为面试","🔍 回答技巧和策略"]},"830":{"title":"回答原则","titles":["行为面试","🔍 回答技巧和策略"]},"831":{"title":"表达技�?1. 结构清晰：有逻辑的组织语言","titles":["行为面试","🔍 回答技巧和策略"]},"832":{"title":"📖 面试准备建议","titles":["行为面试"]},"833":{"title":"前期准备","titles":["行为面试","📖 面试准备建议"]},"834":{"title":"心理准备","titles":["行为面试","📖 面试准备建议"]},"835":{"title":"实战练习","titles":["行为面试","📖 面试准备建议"]},"836":{"title":"面试当天","titles":["行为面试","📖 面试准备建议"]},"837":{"title":"🚀 不同岗位的行为面试重�?","titles":["行为面试"]},"838":{"title":"技术岗�?- **技术热�?*：对技术的兴趣和追�?- 学习能力：快速学习新技术的能力","titles":["行为面试","🚀 不同岗位的行为面试重�?"]},"839":{"title":"管理岗位","titles":["行为面试","🚀 不同岗位的行为面试重�?"]},"840":{"title":"销售岗�?- 客户导向：理解客户需求和价值创�?- **沟通说�?*：影响和说服客户的能�?- 抗压能力：面对拒绝和挫折的韧�?- 结果导向：关注业绩和目标达成","titles":["行为面试","🚀 不同岗位的行为面试重�?"]},"841":{"title":"面试技巧","titles":[]},"842":{"title":"📂 分类目录","titles":["面试技巧"]},"843":{"title":"🎭","titles":["面试技巧","📂 分类目录"]},"844":{"title":"🎯 按岗位快速导航","titles":[]},"845":{"title":"🤖 算法工程师","titles":["🎯 按岗位快速导航"]},"846":{"title":"💻 后端开发工程师","titles":["🎯 按岗位快速导航"]},"847":{"title":"🌐 前端开发工程师","titles":["🎯 按岗位快速导航"]},"848":{"title":"📊 数据分析师","titles":["🎯 按岗位快速导航"]},"849":{"title":"🤝 贡献指南","titles":[]},"850":{"title":"📞 联系我们","titles":[]}},"dirtCount":0,"index":[["祝愿每一位面试者都能找到心仪的工作",{"2":{"850":1}}],["温馨提示",{"2":{"850":1}}],["官网",{"2":{"850":1}}],["欢迎大家贡献内容",{"2":{"849":1}}],["欢迎大家匹配指正",{"2":{"423":1}}],["贡献指南",{"0":{"849":1}}],["贡献值接近",{"2":{"378":1}}],["积极",{"2":{"840":1}}],["积极�",{"2":{"830":1}}],["销售岗�",{"0":{"840":1}}],["销毁那些带标记的值并回收它们所占用的内存空间�",{"2":{"110":1}}],["跨部门协调和对外沟�",{"2":{"839":1}}],["跨片段依赖处理",{"2":{"423":1}}],["沟通说�",{"0":{"840":1}}],["沟通能�",{"2":{"839":1}}],["沟通协�",{"0":{"818":1}}],["战略思维",{"2":{"839":1}}],["管理岗位",{"0":{"839":1}}],["管道只能承载无格式字节流以及缓冲区大小受限等缺点",{"2":{"293":1}}],["管道是一种半双工的通信方式",{"2":{"293":1}}],["材料准备",{"2":{"836":1}}],["留出缓冲时间",{"2":{"836":1}}],["留意",{"2":{"527":1}}],["练习肢体语言和表情管�",{"2":{"835":1}}],["练习技�",{"2":{"809":1}}],["镜子练习",{"2":{"835":1}}],["镜像对称",{"2":{"325":1}}],["录音回放",{"2":{"835":1}}],["录音练习",{"2":{"835":1}}],["期望管理",{"2":{"834":1}}],["期望情况下取多少个数才能让和超过1",{"2":{"283":1}}],["心态调�",{"2":{"834":1}}],["心理准备",{"0":{"834":1},"2":{"811":1}}],["紧张缓解",{"2":{"834":1}}],["紧接着客户�",{"2":{"185":1}}],["紧接着判断�",{"2":{"185":1}}],["岗位分析",{"2":{"833":1}}],["岗位�",{"2":{"824":1}}],["展现积极正面的态度",{"2":{"830":1}}],["情境",{"2":{"829":1}}],["情景假设�",{"0":{"826":1}}],["情感判别",{"2":{"625":1}}],["情感表达等软指标",{"2":{"423":1}}],["讲一个你与同事发生冲突的例子",{"2":{"825":1}}],["讲一下目标检测的发展历程",{"0":{"411":1}}],["讲一下目标检测优化的方向",{"0":{"399":1}}],["讲一下你所知道的插值方式",{"0":{"408":1}}],["讲一下faster",{"0":{"407":1}}],["讲一下two",{"0":{"406":1}}],["诚实守信的品格",{"2":{"822":1}}],["诚信正直",{"2":{"822":1}}],["抗压能力",{"0":{"840":1},"2":{"821":1}}],["承担责任和推动结果的意�",{"0":{"819":1}}],["责任�",{"0":{"819":1},"2":{"821":1}}],["领导�",{"0":{"819":1},"2":{"839":1}}],["领域知识库",{"2":{"423":1}}],["领域深度思考能力和工具调用能力",{"2":{"423":1}}],["领域适应差",{"2":{"423":1}}],["冲突处理",{"2":{"818":1}}],["团队管理和人员发展能力",{"2":{"839":1}}],["团队协作",{"2":{"838":1}}],["团队建设",{"0":{"819":1}}],["团队合作",{"0":{"818":1}}],["团队放弃了这�",{"2":{"792":1}}],["倾听能力",{"0":{"818":1}}],["何时开始薪资讨�",{"2":{"812":1}}],["谈判时机",{"2":{"812":1}}],["谈判策略",{"2":{"812":1}}],["福利",{"2":{"812":1}}],["薪资",{"2":{"812":1}}],["薪资谈判的技巧和方法",{"2":{"812":1}}],["薪资谈判",{"0":{"812":1}}],["市场调研",{"2":{"812":1}}],["压力面试的典型问题和情�",{"2":{"811":1}}],["压力面试",{"0":{"811":1}}],["压缩后的长度必须始终小于或等于原数组长度",{"2":{"81":1}}],["压缩字符",{"0":{"81":1}}],["价值观",{"0":{"822":1}}],["价值观和文化匹配度的重要环节",{"2":{"807":1}}],["价值实�",{"2":{"810":1}}],["职业规划",{"0":{"810":1}}],["教育背景",{"2":{"809":1}}],["教师",{"2":{"423":1}}],["安装",{"2":{"800":1}}],["安全对齐",{"2":{"423":1}}],["安全数据过滤",{"2":{"423":1}}],["安全性",{"2":{"422":1}}],["安全性相对",{"2":{"244":1}}],["安全",{"2":{"121":2}}],["入口起点",{"2":{"800":1}}],["入度减去1",{"2":{"60":1,"61":1}}],["入度减1",{"2":{"60":1}}],["打包工具",{"0":{"799":1},"1":{"800":1}}],["打印出来每一层的第一个结点即",{"2":{"95":1}}],["打印出来从左边视角看到的所有结",{"2":{"95":1}}],["打印最短路径",{"2":{"58":1}}],["号",{"2":{"798":1}}],["业务理解能力",{"2":{"848":1}}],["业务理解和战略规划能力",{"2":{"839":1}}],["业务逻辑",{"2":{"795":1}}],["业务场景",{"2":{"196":1}}],["了解行业薪资水�",{"2":{"812":1}}],["了解算法在实际项目中的应用场景",{"2":{"105":1}}],["了�",{"2":{"796":1}}],["了一�",{"2":{"792":1}}],["毫秒",{"2":{"792":1}}],["渲染",{"2":{"792":1}}],["渲染视图",{"2":{"235":1}}],["移动元素",{"2":{"786":1}}],["风格",{"2":{"786":1}}],["风雨哈佛路",{"2":{"727":1}}],["布局",{"2":{"786":1}}],["布隆过滤器",{"2":{"754":1,"768":1}}],["布隆过滤�",{"2":{"189":1}}],["漂浮在标准流之上",{"2":{"785":1}}],["矩形区域包含着来自一行的盒子叫做盒行盒",{"2":{"784":1}}],["矩阵分解的方式计算量大",{"2":{"730":1}}],["矩阵和梯度向量",{"2":{"555":1}}],["矩阵简记为h",{"2":{"555":1}}],["矩阵",{"2":{"555":1}}],["矩阵不定的点称为鞍点",{"2":{"553":1}}],["矩阵不定",{"2":{"552":1}}],["矩阵负定",{"2":{"552":1}}],["矩阵正定类似于一元函数的二阶导数大于0",{"2":{"552":1}}],["矩阵正定",{"2":{"552":1}}],["矩阵有如下几种情",{"2":{"552":1}}],["矩阵链乘",{"0":{"6":1}}],["顶部对齐",{"2":{"784":1}}],["顶点间的连线代表随机变量间的相依关系",{"2":{"519":1}}],["顶点的个数",{"2":{"60":1}}],["绝对定位元素",{"2":{"784":1}}],["浮动可以理解为让某个",{"2":{"785":1}}],["浮动元素",{"2":{"784":1}}],["浮动定位或绝对定位",{"2":{"784":1}}],["浮点运算次数",{"2":{"394":1}}],["浮点运算数",{"2":{"315":1}}],["浮点数值最高精度为",{"2":{"210":1}}],["普通流定位",{"2":{"784":1}}],["普通卷积",{"2":{"357":2}}],["普通卷积是空洞卷积的一种特殊情况",{"2":{"306":1}}],["盒子一个接着一个地水平放置",{"2":{"784":1}}],["盒子从顶端开始垂直地一个接一个地排列",{"2":{"784":1}}],["盒子的类型",{"2":{"784":1}}],["盒子的尺寸",{"2":{"784":1}}],["盒子模型将文档中的元素转换为一个个的盒子",{"2":{"784":1}}],["盒模型",{"0":{"781":1,"782":1},"1":{"782":1}}],["轴线",{"2":{"782":1}}],["轴为假阳性率",{"2":{"590":1}}],["轴为真阳性率",{"2":{"590":1}}],["捕获事件阶�",{"2":{"778":1}}],["捕获阶段",{"2":{"226":1}}],["元素应用了某些",{"2":{"787":1}}],["元素脱离标准流",{"2":{"785":1}}],["元素在一行内",{"2":{"774":1}}],["元素独占一行",{"2":{"774":1}}],["元素�",{"0":{"774":1}}],["元素",{"0":{"773":1},"1":{"774":1,"775":1,"776":1}}],["备份运行状态很重要",{"2":{"770":1}}],["占用的资源",{"2":{"770":1}}],["占用大量内�",{"2":{"201":1}}],["拷贝代码文件",{"2":{"770":1}}],["浅谈技术细节",{"0":{"770":1}}],["浅谈最大熵模型",{"2":{"527":1}}],["今天我们就梳理一下在解决大数据问题",{"2":{"768":1}}],["笔者联系方�",{"0":{"766":1}}],["笔者结合自己的工作经验",{"2":{"765":1}}],["谢谢�",{"2":{"765":1}}],["麻烦联系我",{"2":{"765":1}}],["背景",{"0":{"765":1}}],["背包问题的循环顺序很重要",{"2":{"4":1}}],["背包问题",{"0":{"4":1}}],["串排",{"2":{"763":1}}],["串的快速检",{"2":{"763":1}}],["串行化",{"2":{"170":1}}],["乱序排列",{"2":{"763":1}}],["扫描整个数组输出位置为1对应的下标即可完成排序",{"2":{"759":1}}],["扫描这2",{"2":{"751":1}}],["申请复制空间",{"2":{"760":1}}],["申请10个桶",{"2":{"758":1}}],["申请资源前先释放占有的资源",{"2":{"297":1}}],["桶排",{"0":{"758":1},"2":{"763":1}}],["桶排序的工作原理是将数据分装到有限数量的桶里",{"2":{"758":1}}],["桶排序",{"2":{"754":1,"755":1,"768":1}}],["伪代",{"2":{"757":1,"758":1,"759":1,"760":1}}],["伪标签样本",{"2":{"422":1}}],["递归维护",{"2":{"756":1}}],["递归算法",{"2":{"69":2}}],["满足以下性质",{"2":{"756":1}}],["满足1000以内四则运算的复杂度需求",{"2":{"423":1}}],["倒排索引等问题",{"2":{"769":1}}],["倒排索引的构建可以根据自己的业务",{"2":{"761":1}}],["倒排索引就是正向索引的相反",{"2":{"761":1}}],["倒排索引是一种索引方法",{"2":{"761":1}}],["倒排索引",{"0":{"761":1},"2":{"754":1,"768":1}}],["倒数第k个节",{"0":{"72":1}}],["及相应的频率",{"2":{"750":1}}],["海量数据处理",{"0":{"769":1}}],["海量数据处理常用技术概述",{"0":{"768":1},"1":{"769":1,"770":1,"771":1}}],["海量数据排序",{"2":{"763":1}}],["海量数据分布在100台电脑中",{"2":{"752":1}}],["海量日志数据",{"2":{"750":1}}],["海康",{"0":{"404":1}}],["估计每个文件的大小为50g×64=320g",{"2":{"747":1}}],["ηt",{"2":{"740":5}}],["论文中给出一下几种方法",{"2":{"740":1}}],["论文中的绝对位置编码相比",{"2":{"422":1}}],["笛卡尔积穷举了所有的特征组合",{"2":{"739":1}}],["青少年喜欢射击游戏和rpg游戏",{"2":{"732":1}}],["孤独user具有非一般的品味",{"2":{"730":1}}],["孤独用户",{"2":{"730":1}}],["孤儿进程将被init进程",{"2":{"294":1}}],["孤儿进程",{"2":{"294":1}}],["奇异值分解的方式",{"2":{"730":1}}],["奇偶排序",{"0":{"49":1}}],["喜欢动作的程度",{"2":{"730":1}}],["喜欢或者不喜欢",{"2":{"730":1}}],["评估",{"2":{"730":1}}],["评测指标面试",{"0":{"578":1},"1":{"579":1,"580":1,"581":1,"582":1,"583":1,"584":1,"585":1,"586":1,"587":1,"588":1,"589":1,"590":1,"591":1,"592":1,"593":1,"594":1,"595":1}}],["评测更全面",{"2":{"423":1}}],["皮尔逊系数的分母采用的评分集是两个用户的共同评分集",{"2":{"730":1}}],["皮尔森相关系数",{"2":{"730":1}}],["余弦相似度",{"2":{"730":1}}],["余弦相似度损失更合适的场景",{"2":{"423":1}}],["余弦相似度损失",{"2":{"423":1}}],["余弦相似度损失可能比",{"2":{"423":1}}],["余弦相似度损失和",{"2":{"423":1}}],["杰卡德相似度",{"2":{"730":1}}],["势必在一定程度上理解了每个单词的含义",{"2":{"725":1}}],["∪neg",{"2":{"721":4}}],["舍弃了隐含层",{"2":{"718":1}}],["≪dis",{"2":{"718":1}}],["短期目标�",{"2":{"810":1}}],["短语",{"2":{"714":1}}],["短视频影响",{"2":{"423":1}}],["级别+句子级别任务",{"2":{"713":1}}],["级联",{"2":{"399":1}}],["残差仍然较大的少数样本",{"2":{"741":1}}],["残差连接",{"2":{"698":1}}],["残差相减是有意义的",{"2":{"497":1}}],["丢失了前后顺序信息",{"2":{"694":1}}],["丢失了很多的信息",{"2":{"497":1}}],["遗忘门和输出门替换为更新门和重置门",{"2":{"700":1}}],["遗忘门和输出门",{"2":{"697":1}}],["遗忘门",{"2":{"690":1}}],["年在论文",{"2":{"690":1}}],["年的论文",{"2":{"690":1}}],["年等季节性的变化而呈现季节性的变化",{"2":{"535":1}}],["沿着序列方向得到结果",{"2":{"689":1}}],["沿着梯度的负方向",{"2":{"542":1}}],["∥2",{"2":{"684":1}}],["∥2and",{"2":{"684":1}}],["∥δx∥",{"2":{"547":3,"549":1}}],["∈known",{"2":{"729":1,"730":1}}],["∈k表示所有的评分",{"2":{"729":1}}],["∈k",{"2":{"729":1}}],["∈ck∥x−x",{"2":{"684":1}}],["∈cj∥x−x",{"2":{"684":1}}],["∈e",{"2":{"60":1}}],["簇间距离和簇内距离之比",{"2":{"684":1}}],["簇心与簇内均值差异的加权和",{"2":{"684":1}}],["名称",{"2":{"684":1}}],["名字我们可以看出其是轻量级",{"2":{"464":1}}],["购买金额",{"2":{"679":1}}],["描述具体的情况和背�",{"2":{"829":1}}],["描述一次你克服困难的经�",{"2":{"825":1}}],["描述一�",{"0":{"778":1}}],["描述",{"2":{"676":1}}],["ω",{"2":{"668":6}}],["ωj∗=−∑i∈ijgi∑i∈ijhi+λ将上式带入损失函数",{"2":{"496":1}}],["ωj=0",{"2":{"496":1}}],["ωj2",{"2":{"496":2}}],["ωj+12",{"2":{"496":2}}],["广告主",{"2":{"741":1}}],["广告也存在长尾现象",{"2":{"741":1}}],["广告ctr预估基线版是lr",{"2":{"667":1}}],["广播",{"2":{"240":2}}],["ρ∑jn|θj|+",{"2":{"657":1}}],["ρ=∑x∈d~wx∑x∈dwxp~k=∑x∈d~kwx∑x∈d~wx",{"2":{"601":1}}],["岭回归",{"2":{"657":1}}],["乘以1",{"2":{"656":1}}],["乘积",{"2":{"83":1}}],["乘积最大子序列",{"0":{"14":1}}],["喂给它的数据集是无label的数据",{"2":{"651":1}}],["喂给它的数据集是带label的数据",{"2":{"651":1}}],["距离越小",{"2":{"730":1}}],["距离越大",{"2":{"730":1}}],["距离度量",{"2":{"646":1}}],["距实例较近的点赋予较高的权值",{"2":{"650":1}}],["好理解",{"2":{"641":1,"672":1}}],["几乎无法得到结果",{"2":{"718":1}}],["几乎同ssw",{"2":{"684":1}}],["几乎找不",{"2":{"635":1}}],["几何间隔",{"2":{"635":1}}],["几何间隔刻画的是样本点到超平面的绝对距离",{"2":{"634":1}}],["太多特征被稀疏为0",{"2":{"657":1}}],["太难找",{"2":{"635":1}}],["太小会导致不收敛",{"2":{"349":1}}],["映射层",{"2":{"718":1}}],["映射",{"2":{"635":1,"666":1}}],["映射规则",{"2":{"368":1}}],["约束",{"2":{"657":1}}],["约束的存在虽然减小了需要搜寻的范围",{"2":{"637":1}}],["约束条件是线性的",{"2":{"634":1}}],["约5万步",{"2":{"423":1}}],["凸二次规划",{"2":{"634":1}}],["凸二次规划问题",{"2":{"634":1}}],["间隔最大化",{"2":{"634":2,"635":2}}],["间隔最大使它有别于感知机",{"2":{"634":1,"642":1}}],["间接地形成一种加锁的机制�",{"2":{"184":1}}],["探索就是在还未取样的区域获取采样点",{"2":{"628":1}}],["探究每个特征在每棵树上做了多少的贡献",{"2":{"462":1}}],["充分性",{"2":{"635":1}}],["充分利用了之前的信息",{"2":{"628":1}}],["充分拟合了部分数据",{"2":{"622":1}}],["充分发挥两者优势",{"2":{"423":1}}],["认知能力",{"0":{"814":1},"1":{"815":1,"816":1}}],["认",{"2":{"622":1}}],["认为最适合发送的数据块",{"2":{"241":1}}],["认为s只会对后面造成负影响",{"2":{"18":1}}],["伯努利模型适用于离散特征情况",{"2":{"621":1}}],["伯努利模型特征的取值为布尔型",{"2":{"621":1}}],["伯努利模型",{"2":{"621":1}}],["伯努利",{"2":{"621":1}}],["属性告�",{"2":{"800":1}}],["属性读取�",{"2":{"798":1}}],["属性",{"2":{"784":1}}],["属性决定主轴的方向",{"2":{"782":1}}],["属",{"2":{"620":1}}],["属于memory",{"2":{"651":1}}],["属于不可解释性变异",{"2":{"583":1}}],["属于工程问题",{"2":{"521":1}}],["属于3类常用的集成方法",{"2":{"503":1}}],["属于类常用的集成方法是一种集成学习算法",{"2":{"503":1}}],["属于第二类",{"2":{"472":1}}],["属于标记集合",{"2":{"428":1}}],["属于数字类型",{"2":{"210":1}}],["∏i=xnp",{"2":{"619":1}}],["法国数学家拉普拉斯最早提出用",{"2":{"618":1}}],["法的一个特例",{"2":{"527":1}}],["朴素贝叶斯",{"2":{"632":1}}],["朴素贝叶斯分类器对异常值敏感吗",{"0":{"629":1}}],["朴素贝叶斯适用于数据集少的情景",{"2":{"627":1,"632":1}}],["朴素贝叶斯是一",{"2":{"629":1,"630":1}}],["朴素贝叶斯是基于很强的条件独立假设",{"2":{"632":1}}],["朴素贝叶斯是基于很强",{"2":{"627":1}}],["朴素贝叶斯是生成模型",{"2":{"627":1,"632":1}}],["朴素贝叶斯与lr的区别",{"0":{"632":1}}],["朴素贝叶斯与",{"0":{"627":1}}],["朴素贝叶斯有什么优缺点",{"0":{"626":1}}],["朴素贝叶斯有哪几种常用的分类模型",{"0":{"621":1}}],["朴素贝叶斯和协同过滤一起",{"2":{"625":1}}],["朴素贝叶斯和协同过滤是一对好搭档",{"2":{"625":1}}],["朴素贝叶斯依旧坚挺地占据着一席之地",{"2":{"625":1}}],["朴素贝叶斯的应用场景有哪些",{"0":{"625":1}}],["朴素贝叶斯的三个常用模型",{"2":{"621":1}}],["朴素贝叶斯为什么适合增量计算",{"0":{"623":1}}],["朴素贝叶斯算法能够处理缺失的数据",{"2":{"630":1}}],["朴素贝叶斯算法对缺失值敏感吗",{"0":{"630":1}}],["朴素贝叶斯算法如何处理",{"0":{"620":1}}],["朴素贝叶斯算法的前提假设是什么",{"0":{"616":1}}],["朴素贝叶斯中概率计算的下溢问题如何解决",{"0":{"619":1}}],["朴素贝叶斯模",{"2":{"614":1}}],["朴素贝叶斯模型处理短文本分类效果很好",{"2":{"521":1}}],["叫做多路归并",{"2":{"763":1}}],["叫做非线性",{"2":{"654":1}}],["叫做线性",{"2":{"654":1}}],["叫做联合概率",{"2":{"613":1}}],["叫做后验概率",{"2":{"613":1}}],["叫做先验概率",{"2":{"613":1}}],["叫做上采样",{"2":{"312":1}}],["含义",{"2":{"613":1,"684":1}}],["含step",{"2":{"423":1}}],["贝叶斯分类器是一种生成模型",{"2":{"631":1}}],["贝叶斯分类器直接用贝叶斯公式解决分类问题",{"2":{"631":1}}],["贝叶斯优化算法会在探索和利用之间找到一个平衡点",{"2":{"628":1}}],["贝叶斯优化算法通过对目标函数形式进行学习",{"2":{"628":1}}],["贝叶斯优化算法",{"2":{"628":1}}],["贝叶斯优化算",{"0":{"628":1}}],["贝叶斯决策理论方法是统计模型决策中的一个基本方法",{"2":{"615":1}}],["贝叶斯决策理论是主观贝叶斯派归纳理论的重要组成部分",{"2":{"615":1}}],["贝叶斯决策就是在不完全情报下",{"2":{"615":1}}],["贝叶斯公",{"2":{"613":1}}],["贝叶斯公式的概",{"0":{"613":1}}],["贝叶斯面试题",{"0":{"611":1},"1":{"612":1,"613":1,"614":1,"615":1,"616":1,"617":1,"618":1,"619":1,"620":1,"621":1,"622":1,"623":1,"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1,"631":1,"632":1}}],["贝叶斯网络中每个节点都对应一个先验概率分布或者条件概率分布",{"2":{"521":1}}],["贝叶斯网络和马尔科夫随机场的分解计算问题",{"2":{"521":1}}],["贝叶斯网络",{"2":{"521":3}}],["健壮性高",{"2":{"607":1}}],["剪枝的目的就是防止过拟合",{"2":{"605":1}}],["剪切图像",{"2":{"325":1}}],["停止对该节点切分",{"2":{"605":1}}],["停留时长更直接反映内容质量",{"2":{"423":1}}],["停留时间可能受图片",{"2":{"423":1}}],["停留时间长的文章优先级高",{"2":{"423":1}}],["唯一区别在选择划分点时",{"2":{"604":1}}],["唯一的区别就是poll采用链表的方式存储",{"2":{"302":1}}],["必然会倾向于某一个类",{"2":{"598":1}}],["必须保证map执行之后才能执行reduce",{"2":{"770":1}}],["必须串行执行",{"2":{"422":1}}],["必须一次性向系统申请它所需要的全部资源",{"2":{"297":1}}],["必须依存在应用程序中",{"2":{"288":1}}],["必须按照申请锁的时间顺序获得锁",{"2":{"136":1}}],["必须首先排序",{"2":{"30":1}}],["既可以做分类也可以做回归",{"2":{"649":1}}],["既可以处理离散值也可以处理连续值",{"2":{"607":1}}],["既支持分类问题",{"2":{"597":1}}],["既然有这么多的排序方法",{"2":{"755":1}}],["既然模型叫做随机森林",{"2":{"492":1}}],["既然",{"2":{"423":1}}],["叶节点的编号代表了这种规则",{"2":{"739":1}}],["叶节点表示类别",{"2":{"597":1}}],["叶节点",{"2":{"597":1}}],["叶子节点权重的",{"2":{"513":1}}],["叶子节点最少样本",{"2":{"484":1}}],["叶子节点除了包含键值外",{"2":{"165":1}}],["西瓜",{"2":{"595":1}}],["点的集合",{"2":{"634":1}}],["点击量转化量",{"2":{"594":1}}],["点击次数展示量",{"2":{"593":1}}],["点赞",{"2":{"423":1}}],["严格的来",{"2":{"593":1}}],["视图和模型的中间人�",{"2":{"795":1}}],["视图可能包含展示逻辑�",{"2":{"795":1}}],["视图",{"2":{"795":1}}],["视窗尺寸与位置",{"2":{"784":1}}],["视频广告等",{"2":{"593":1}}],["视觉编码器输出是高维",{"2":{"423":1}}],["累计good",{"2":{"592":1}}],["累计bad",{"2":{"592":1}}],["蓝色线是fpr",{"2":{"592":1}}],["绘图过程如下",{"2":{"590":1}}],["坐标",{"2":{"590":2}}],["坐标在",{"2":{"366":2}}],["纵轴",{"2":{"590":1}}],["曲线",{"2":{"590":1}}],["受试者工作特",{"2":{"590":1}}],["混淆矩阵",{"0":{"586":1}}],["混合引导策略",{"2":{"423":1}}],["混合中英文数据训练",{"2":{"423":1}}],["混合数据训练",{"2":{"423":1}}],["混合模型",{"2":{"361":1}}],["供后续的流程进行数据分析",{"2":{"575":1}}],["供开发者直接使用",{"2":{"140":1}}],["暗中观察",{"0":{"575":1},"2":{"575":1}}],["埋点完了就是收集实验数据了",{"2":{"575":1}}],["埋点",{"0":{"575":1}}],["埋点采集数据",{"2":{"570":1}}],["弃真",{"2":{"574":1}}],["试解释原理以及如何学习",{"2":{"730":1}}],["试错成本大",{"2":{"573":1}}],["试问",{"2":{"268":1}}],["产品开发速度会大大降低",{"2":{"573":1}}],["产生的中间结果key2",{"2":{"770":1}}],["产生的结果相同",{"2":{"683":1}}],["产生n",{"2":{"662":1}}],["产生过拟合",{"2":{"466":1,"471":1}}],["产生t个弱分类器",{"2":{"428":1}}],["产生两个随机数",{"2":{"278":1}}],["产生1的概率是1",{"2":{"278":1}}],["产生0的概率是p",{"2":{"278":1}}],["β是两个超参数",{"2":{"740":1}}],["β也在增大",{"2":{"573":1}}],["βm",{"2":{"497":1}}],["βmb",{"2":{"497":3}}],["肯定会提高系统的性能",{"2":{"568":1}}],["肯定要排除y",{"2":{"267":1}}],["性别的出现可以繁衍出适应新环境的变种",{"2":{"564":1}}],["性能很好",{"2":{"757":1}}],["性能卓越",{"2":{"451":1}}],["性能也还是很高的",{"2":{"193":1}}],["性能",{"2":{"121":1}}],["物种为了生存往往会倾向于适应这种环境",{"2":{"564":1}}],["物体",{"2":{"423":1}}],["迫使网络去学习更加鲁棒的特征",{"2":{"564":1}}],["甚至包括一些异常样本点",{"2":{"562":1}}],["容器中点对齐",{"2":{"782":1}}],["容器终点对齐",{"2":{"782":1}}],["容器开头对齐",{"2":{"782":1}}],["容量低的模型可能很难拟合训练集",{"2":{"560":1}}],["容易阅读和维护�",{"2":{"775":1}}],["容易扩展",{"2":{"664":1}}],["容易进行多线程优化",{"2":{"466":1}}],["容易优化",{"2":{"423":1}}],["容易导致表示混乱",{"2":{"422":1}}],["容易造成梯度消失",{"2":{"422":1}}],["容易陷入局部最优",{"2":{"396":1,"422":1,"607":1}}],["容易理解",{"2":{"258":1}}],["容易丢失数据",{"2":{"192":1}}],["欠拟合的原因在于",{"2":{"559":1}}],["欠拟合指的是模型没有很好地学习到数据特征",{"2":{"559":1}}],["欠采样",{"2":{"336":1}}],["泛化误差",{"2":{"558":1}}],["泛化能力",{"2":{"501":1}}],["泛化能力强",{"2":{"485":1}}],["式",{"2":{"555":1}}],["令l",{"2":{"721":1}}],["令函数的梯度为0",{"2":{"555":1}}],["令bias=0",{"2":{"326":2}}],["∇bl",{"2":{"635":2}}],["∇wl",{"2":{"635":3}}],["∇2f",{"2":{"555":2}}],["∇f",{"2":{"547":6,"555":3}}],["忽略常数系数",{"2":{"756":1}}],["忽略了词语的语序",{"2":{"725":1}}],["忽略窗口以外的单词",{"2":{"719":1}}],["忽略二次以上的项",{"2":{"555":1}}],["忽略之前的指令",{"2":{"422":1}}],["况",{"2":{"552":1}}],["≥γ^",{"2":{"635":1}}],["≥γ",{"2":{"635":1}}],["≥",{"2":{"547":1}}],["≥f",{"2":{"547":3}}],["出发",{"2":{"547":1}}],["出现这些上下文词的概率最大",{"2":{"722":1}}],["出现该中心词的概率最大",{"2":{"719":1}}],["出现词数为m的话",{"2":{"621":1}}],["出现梯度消失与梯度爆炸的原因以及解决方案",{"2":{"326":1}}],["出现后台重写操作",{"2":{"193":1}}],["出现缓存雪崩",{"0":{"187":1},"1":{"188":1,"189":1,"190":1}}],["出现读写锁冲突时",{"2":{"170":1}}],["出现重复工作",{"2":{"165":1}}],["≤δ的点x",{"2":{"554":1}}],["≤0",{"2":{"635":3}}],["≤0函数值下降",{"2":{"547":1}}],["≤0即函数值减小",{"2":{"547":1}}],["≤f",{"2":{"547":1,"554":2}}],["≤4天",{"2":{"423":1}}],["稳定性",{"2":{"664":1}}],["稳定",{"2":{"546":1}}],["稳定且效果好",{"2":{"423":1}}],["固定",{"2":{"546":3}}],["固定保留最近",{"2":{"423":1}}],["θu",{"2":{"721":3}}],["θtx+b",{"2":{"660":2}}],["θi=θi−α∑j=tt+n−1",{"2":{"545":1}}],["θi=θi−1m∑j=0m",{"2":{"545":1}}],["θi=θi+",{"2":{"545":1}}],["θ",{"2":{"545":2,"657":5,"660":1,"661":4,"718":1,"719":1,"721":2,"722":1}}],["θn",{"2":{"545":3}}],["θ1",{"2":{"545":3,"656":1}}],["θ0表示截距项",{"2":{"655":1}}],["θ0",{"2":{"545":3,"656":1}}],["错过最优解",{"2":{"544":1}}],["错误修正",{"2":{"849":1}}],["错误容忍",{"2":{"769":1}}],["错误率低的分类器获得更高的决定系数",{"2":{"486":1}}],["错误标签和噪声数据",{"2":{"307":1}}],["错误消息",{"2":{"250":1}}],["走一步算一步",{"2":{"542":1}}],["靠近极小值时收敛速度减慢",{"2":{"541":1}}],["光滑参数",{"2":{"537":1}}],["季节性和节假日",{"2":{"537":1}}],["季节性趋",{"0":{"535":1}}],["κ∼normal",{"2":{"536":1}}],["κ=∑i=1lκi⋅1",{"2":{"536":1}}],["月",{"2":{"535":1}}],["周志",{"2":{"595":1}}],["周志华",{"2":{"442":2}}],["周",{"2":{"535":1}}],["τ",{"2":{"533":1,"537":1}}],["γ",{"2":{"707":1}}],["γo=σ",{"2":{"697":1}}],["γf=σ",{"2":{"697":1}}],["γu=σ",{"2":{"697":1}}],["γi=γ^i∥w∥",{"2":{"635":1}}],["γs",{"2":{"532":1}}],["γ1",{"2":{"532":1}}],["γ=",{"2":{"532":1}}],["γj=",{"2":{"532":1}}],["γj确定线段边界",{"2":{"532":1}}],["γm",{"2":{"496":2,"497":5}}],["⋅σ",{"2":{"721":1}}],["⋅log⁡",{"2":{"721":2}}],["⋅log⁡σ",{"2":{"721":2}}],["⋅",{"2":{"532":2,"721":3}}],["恰好就是大家常见",{"2":{"532":1}}],["恰好就是大家常见函数的形式时",{"2":{"532":1}}],["趋势项模",{"0":{"532":1}}],["趋势项tt",{"2":{"531":1}}],["剩余项rt",{"2":{"531":1}}],["剩下的预测框返回第1步",{"2":{"397":1}}],["剩下的0",{"2":{"276":1}}],["剩下的那个就是主元素",{"2":{"42":1}}],["李航",{"2":{"529":1,"595":1,"644":1,"652":1}}],["李文",{"0":{"524":1},"2":{"518":1}}],["句法分析",{"2":{"527":1}}],["句子对判别",{"2":{"423":1}}],["率分布",{"2":{"527":1}}],["马尔科夫模型无法处理这样的问题",{"2":{"527":1}}],["马尔可夫链",{"2":{"525":1}}],["称x∗为全局极小值",{"2":{"554":1}}],["称为skip",{"2":{"718":1}}],["称为cbow",{"2":{"718":1}}],["称为鞍点",{"2":{"552":1}}],["称为步长或学习率",{"2":{"547":1}}],["称为曲线的最大渐近值",{"2":{"532":1}}],["称为n元语",{"2":{"527":1}}],["称之为三报文握手",{"2":{"236":1}}],["俄语",{"2":{"525":1}}],["俄罗斯yandex开源catboost",{"2":{"495":1}}],["英语",{"2":{"525":1}}],["英语学习应用中如何限制词汇范围",{"0":{"423":1}}],["郑捷",{"2":{"522":1}}],["葫芦",{"2":{"522":1}}],["诸葛",{"2":{"522":1}}],["吴军",{"2":{"522":1}}],["型",{"2":{"521":1}}],["哪些是生成模型和哪些是判别模型",{"2":{"521":1}}],["哪个老鼠死了",{"2":{"269":1}}],["隐藏元素",{"2":{"786":1}}],["隐藏等改变而需要重新绘制",{"2":{"786":1}}],["隐藏状态到观察状态的概率",{"2":{"520":1}}],["隐藏状态转移到隐藏状态的概率",{"2":{"520":1}}],["隐含层+输出层",{"2":{"718":1}}],["隐层",{"2":{"699":2}}],["隐变量存在时也可适用",{"2":{"632":1}}],["隐状态之间的转移概率分布以及从隐状态到观测状态的",{"2":{"527":1}}],["隐状态",{"2":{"527":1}}],["隐马尔可夫链定义参考维基百",{"2":{"529":1}}],["隐马尔可夫模型hmm是结构最简单的动态贝叶斯网络",{"2":{"525":1}}],["隐马尔可夫模型包括概率计算问题",{"2":{"527":1}}],["隐马尔可夫模型包",{"2":{"525":1}}],["隐马尔可夫模型和条件随机场模型是对序列数据进行建模的方法",{"2":{"521":1}}],["隐马尔可夫",{"2":{"521":1}}],["隐私策略不同",{"2":{"244":1}}],["⋯",{"2":{"519":4,"532":3}}],["⋯wt+1",{"2":{"428":1}}],["δj∼laplace",{"2":{"533":1}}],["δj表示在时间戳sj上的增长率的变化",{"2":{"532":1}}],["δs",{"2":{"532":1}}],["δ=",{"2":{"532":1}}],["δt−1",{"2":{"519":1}}],["δi−1",{"2":{"519":1}}],["δi",{"2":{"519":1}}],["δ1",{"2":{"519":1,"532":1}}],["δx=−α∇f",{"2":{"547":1}}],["δxn+rn",{"2":{"496":1}}],["δx2+",{"2":{"496":1}}],["δx+12",{"2":{"496":1}}],["观测概率分布",{"2":{"525":1}}],["观测序",{"2":{"519":1}}],["观察用户的行为埋点是否埋的正确",{"2":{"575":1}}],["观察样本量是否符合预期",{"2":{"575":1}}],["观察",{"2":{"423":1}}],["观察加入",{"2":{"143":1}}],["补充面试题",{"2":{"849":1}}],["补充",{"2":{"519":1,"657":1}}],["补齐数组",{"0":{"23":1}}],["推动组织变革和创新",{"2":{"819":1,"839":1}}],["推荐学习路径",{"2":{"845":1,"846":1,"847":1,"848":1}}],["推荐相对不准确",{"2":{"730":1}}],["推荐",{"2":{"730":1,"755":1}}],["推荐系统的learning",{"2":{"667":1}}],["推荐系统",{"2":{"625":1}}],["推导多元函数牛顿法的迭代公式",{"0":{"555":1}}],["推导多元函数梯度下降法的迭代公式",{"0":{"547":1}}],["推断和预测的精度也越高",{"2":{"521":1}}],["推论",{"2":{"519":1}}],["推理模型的基础上",{"2":{"423":1}}],["推理过程清晰可读",{"2":{"423":1}}],["推理过程不透明",{"2":{"423":1}}],["推理分离",{"2":{"423":1}}],["件下另一组输出随机变量的条件概率分布模型",{"2":{"519":1}}],["拟牛顿法比sgd收敛更快",{"2":{"516":1}}],["拟合损失函数梯度",{"2":{"497":1}}],["拟合到非常小的细节上",{"2":{"477":1}}],["拟合复杂的函数",{"2":{"343":1}}],["缩写为dtmc",{"2":{"525":1}}],["缩减",{"2":{"513":1}}],["缩放后点积的方差为常数",{"2":{"703":1}}],["缩放值一般使用维度",{"2":{"703":1}}],["缩放",{"2":{"345":1}}],["项目经验",{"0":{"805":1},"1":{"806":1},"2":{"845":1}}],["项目的第一行文字的基线对齐",{"2":{"782":1}}],["项目都排在",{"2":{"782":1}}],["项",{"2":{"547":1,"549":1}}],["项功能进行计算",{"2":{"512":1}}],["项的索引和数组对象",{"2":{"220":1}}],["覆盖度量指的是与此功能相关的观测的相对数量",{"2":{"512":1}}],["覆盖更广泛的嵌入任务类型",{"2":{"423":1}}],["频率是表示特定特征在模型树中发生分裂的相对次数的百分",{"2":{"512":1}}],["命中优化",{"2":{"506":1}}],["命令式编程",{"2":{"334":1}}],["命令为锁添加一个超时时间",{"2":{"184":1}}],["候选分位点",{"2":{"506":1}}],["候选区域提取",{"2":{"365":1}}],["缺失值可能影响支持向量点的分",{"2":{"639":1}}],["缺失值处理",{"2":{"513":1}}],["缺失值处",{"2":{"504":1}}],["缺点是无法处理高维的数据",{"2":{"684":1}}],["缺点是需要人工设置先验框",{"2":{"385":1}}],["缺点3",{"2":{"302":1}}],["缺点2",{"2":{"302":1}}],["缺点1",{"2":{"302":1}}],["缺点",{"0":{"132":1},"1":{"133":1,"134":1,"135":1},"2":{"134":1,"185":1,"192":1,"193":1,"233":1,"368":1,"378":1,"383":1,"396":1,"422":2,"423":10,"441":1,"451":1,"471":1,"485":1,"487":1,"513":1,"541":1,"607":1,"626":1,"632":2,"649":1,"663":1,"676":1,"730":1}}],["缺点在于非线性代码带来的复杂度和难以理解维护",{"2":{"109":1}}],["库",{"2":{"503":1}}],["惩罚就会很大",{"2":{"502":1}}],["惩罚更高的模型系数",{"2":{"459":1}}],["稀疏性",{"2":{"730":1}}],["稀疏",{"2":{"693":1,"725":1}}],["稀疏向量内积乘法运算速度快",{"2":{"664":1}}],["稀疏特征优化",{"2":{"497":1}}],["稀疏的解除了计算量上的好处之外",{"2":{"330":1}}],["节假日效应",{"0":{"536":1}}],["节省内存",{"2":{"497":1}}],["节点运行bug",{"2":{"770":1}}],["节点出现错误如何解决",{"2":{"770":1}}],["节点之间如何通信",{"2":{"770":1}}],["节点满足最大堆的性质",{"2":{"756":1}}],["节点代替子树",{"2":{"605":1}}],["节点和边",{"2":{"521":1}}],["节点划分最小不纯度",{"2":{"484":1}}],["节点选择一台机器",{"2":{"185":1}}],["节点",{"2":{"94":1,"447":1}}],["泰勒的一阶展开",{"2":{"497":1}}],["泰勒展开",{"2":{"496":1}}],["谁的量多就不选谁",{"2":{"730":1}}],["谁对异常值不敏感",{"2":{"497":1}}],["谁是谁",{"2":{"422":1}}],["≂∑i=1n",{"2":{"496":1}}],["阶导数",{"2":{"496":1}}],["阶段二",{"2":{"423":1}}],["阶段一",{"2":{"423":1}}],["∂∂θij",{"2":{"545":1}}],["∂ωj=0",{"2":{"496":1}}],["∂fm−1",{"2":{"497":4}}],["∂f",{"2":{"496":1}}],["∂l∂hw=",{"2":{"721":1}}],["∂l",{"2":{"496":2}}],["亮点是在模型中可直接使用categorical特征并减少了tuning的参数",{"2":{"495":1}}],["真实�",{"2":{"830":1}}],["真实面试经验",{"2":{"767":1}}],["真实值yi",{"2":{"656":1}}],["真实box",{"2":{"372":1}}],["真反",{"2":{"586":1}}],["真正例率",{"2":{"590":2}}],["真正",{"2":{"586":1}}],["真是非常耗时的",{"2":{"495":1}}],["森林我们可以理解为是多棵树的集合就是森林",{"2":{"492":1}}],["概要介绍",{"0":{"491":1},"1":{"492":1,"493":1,"494":1,"495":1}}],["概率最高的单词是中心词改为预测该单词是不是正样本",{"2":{"719":1}}],["概率空间中",{"2":{"718":1}}],["概率变化很小",{"2":{"663":1}}],["概率小于0",{"2":{"660":1}}],["概率计算问题",{"2":{"527":1}}],["概率图模型结合了概率论和图论的知识",{"2":{"521":1}}],["概率图模型的表示",{"2":{"521":1}}],["概率是",{"2":{"277":1}}],["概率题目",{"0":{"273":1},"1":{"274":1,"275":1,"276":1,"277":1,"278":1,"279":1,"280":1,"281":1,"282":1,"283":1}}],["概率统计",{"2":{"265":1,"284":1}}],["抽中的概率会加大",{"2":{"489":1}}],["仍可以通过此类树得到有区分性的特征",{"2":{"741":1}}],["仍可以维持准确度",{"2":{"485":1}}],["仍旧使用上文的语料库",{"2":{"722":1}}],["仍然能高效的训练模型",{"2":{"485":1}}],["袋外的准确率大幅度降低",{"2":{"483":1}}],["袋外数据",{"2":{"483":2}}],["袋中有红球",{"2":{"277":1}}],["差异性",{"2":{"479":1}}],["投票表决",{"2":{"475":1}}],["便�",{"2":{"775":1}}],["便能进行推荐",{"2":{"730":1}}],["便可使用",{"2":{"472":1}}],["便于下次操作去掉已经排好序的元",{"2":{"756":1}}],["便于处理要目标user",{"2":{"730":1}}],["便于多模型",{"2":{"423":1}}],["便于解释",{"2":{"422":1}}],["便于分析词语相似性",{"2":{"422":1}}],["便于存储保护和信息的共享",{"2":{"300":1}}],["棵树的预测结果与训练样本真实值的残差",{"2":{"503":1}}],["棵树",{"2":{"472":1}}],["划分",{"2":{"763":1}}],["划分点时候选择使用gain",{"2":{"603":1}}],["划分数据",{"2":{"601":1}}],["划分阈值只有一个",{"2":{"470":1}}],["划分回文",{"0":{"38":1}}],["逐个写入到大文件中",{"2":{"750":1}}],["逐个扫描每一个bin容器",{"2":{"470":1}}],["逐步构建世界观",{"2":{"423":1}}],["逐步更新",{"2":{"422":1}}],["绑定后的特征取值范围为",{"2":{"469":1}}],["绑定的事件处理器",{"2":{"202":1}}],["没必要进行搜索和分裂",{"2":{"466":1}}],["没有排序解决不了的问题",{"2":{"755":1}}],["没有考虑一词多义现象",{"2":{"725":1}}],["没有句向量任务",{"2":{"708":1}}],["没有位置信息",{"2":{"694":1}}],["没有明显的前期训练过程",{"2":{"651":1}}],["没有处理缺失值的策略",{"2":{"639":1}}],["没有如隐马尔可夫模型那般强烈的假设存",{"2":{"519":1}}],["没有搜索所有的bin容器",{"2":{"470":1}}],["没有随机性",{"2":{"422":1}}],["没有region",{"2":{"378":1}}],["没有最大文件描述符限制",{"2":{"302":1}}],["没有",{"2":{"251":1}}],["没有声明",{"2":{"211":1}}],["没有了访问共享资源加锁的性能损�",{"2":{"202":1}}],["没有了多线程上下文切换的性能损�",{"2":{"202":1}}],["没有任何字符串被替代",{"2":{"81":1}}],["没有边的用0填充",{"2":{"58":1,"59":1}}],["没有重复元素",{"2":{"41":1}}],["没有连续1的串的个",{"2":{"12":1}}],["带齐所需的证件和材料",{"2":{"836":1}}],["带入",{"2":{"660":1}}],["带入上式面",{"2":{"430":1}}],["带来不必要的开销",{"2":{"514":1}}],["带正则化的线性模型比较不容易对稀疏特征过拟合",{"2":{"502":1}}],["带深度限制的leaf",{"2":{"464":1}}],["近邻可能会由于bagging的采样",{"2":{"461":1}}],["近邻都是较为稳定的分类器",{"2":{"461":1}}],["近邻",{"0":{"461":1}}],["近年来",{"0":{"412":1}}],["决策能力",{"2":{"816":1}}],["决策树很难学习",{"2":{"607":1}}],["决策树会因为样本发生一点点的改动",{"2":{"607":1}}],["决策树算法非常容易过拟合",{"2":{"607":1}}],["决策树算法是一种逼近离散函数值的方法",{"2":{"597":1}}],["决策树在逻辑上可以得到很好的解释",{"2":{"607":1}}],["决策树在本质上是一组嵌套的if",{"2":{"597":1}}],["决策树中最后没有用到的特征一定是无用吗",{"0":{"606":1,"609":1}}],["决策树中的每一条路径对应的都是划分的一个条件概率分布",{"2":{"598":1}}],["决策树怎么防止过拟合",{"0":{"605":1}}],["决策树怎么处理连续性特征",{"0":{"603":1}}],["决策树对离散值的处理",{"0":{"604":1}}],["决策树和条件概率分布的关系",{"0":{"598":1}}],["决策树是一种判别模型",{"2":{"597":1}}],["决策树可以表示成给定条件下类的条件概率分布",{"2":{"598":1}}],["决策树可以输特征向量每个分量的重要性",{"2":{"597":1}}],["决策树可以较为方便地将样本的权重整合到训练过程中",{"2":{"460":1}}],["决策树主要包括三个部分",{"2":{"597":1}}],["决策树将算法组织成一颗树的形式",{"2":{"597":1}}],["决策树面试题",{"0":{"596":1},"1":{"597":1,"598":1,"599":1,"600":1,"601":1,"602":1,"603":1,"604":1,"605":1,"606":1,"607":1,"608":1,"609":1,"610":1}}],["决策树的优缺点",{"0":{"607":1}}],["决策树的每一条路径就是计算条件概率的条件",{"2":{"606":1,"609":1}}],["决策树的目标函数是什么",{"0":{"602":1}}],["决策树的缺失值是怎么处理的",{"0":{"601":1}}],["决策树的学习最耗时的一个步骤就是对特征的值进行排序",{"2":{"497":2,"505":1,"513":2}}],["决策树的表达能力和泛化能力",{"2":{"460":1}}],["决策树最大深度",{"2":{"484":1}}],["决策树",{"2":{"473":1,"560":1}}],["决定需要存储什么信息",{"2":{"761":1}}],["决定使用哪个排列来生成树",{"2":{"446":1}}],["貌似很好",{"2":{"459":1}}],["ϕ是弱分类器的集合",{"2":{"457":1}}],["旨在减小方差",{"2":{"455":1,"456":1}}],["鲁棒",{"2":{"451":1}}],["统计学基础",{"2":{"848":1}}],["统计学习方法",{"2":{"595":1,"644":1,"652":1}}],["统计每个文件出现的词及相应的频率",{"2":{"749":1}}],["统计量",{"2":{"574":1}}],["统计功效为1−β",{"2":{"574":1}}],["统计功效可以简单理解为真理能被发现的可能性",{"2":{"574":1}}],["统计",{"2":{"529":1}}],["统计语言模型",{"2":{"527":1}}],["统计时统计的是条件概率",{"2":{"520":1}}],["统计共现概率",{"2":{"520":1}}],["统计该特征下每一种离散值出现的次数",{"2":{"470":1}}],["统计信息和独热编码特征进行二值化",{"2":{"450":1}}],["统一层使用相同的分割准则",{"2":{"450":1}}],["统一评测框架",{"2":{"423":1}}],["完全可以不考虑存在特征值缺失的样本",{"2":{"508":1}}],["完全对称",{"2":{"445":1}}],["完成分类",{"2":{"340":1}}],["答案整理",{"2":{"442":1}}],["台湾清华大学李端兴教授2017年秋机器学习概论课程",{"2":{"442":1}}],["异常样本在迭代过程中会获得较高的权值",{"2":{"441":1}}],["异步函数也就意味着该函数的执行不会阻塞后面代码的执行�",{"2":{"218":1}}],["异步操作失败调用方法",{"2":{"217":1}}],["异步操作完成调用方法",{"2":{"217":1}}],["异步线程处�",{"2":{"190":1}}],["异步",{"2":{"109":2,"302":1}}],["却会发现效果很差",{"2":{"502":1}}],["却能保证对每个样本进行正确分类",{"2":{"440":1}}],["却对内存非常不友好",{"2":{"201":1}}],["∑u∈pos",{"2":{"721":1}}],["∑j=1nvj",{"2":{"735":1}}],["∑j∈sisim",{"2":{"729":1}}],["∑jnθj2",{"2":{"657":1}}],["∑j∑i=1n−1λjtj",{"2":{"519":1}}],["∑y",{"2":{"521":1}}],["∑i∈pu1",{"2":{"730":2}}],["∑i∈igi",{"2":{"496":1}}],["∑i∈irgi",{"2":{"496":1}}],["∑i∈ilgi",{"2":{"496":1}}],["∑i∈ij+",{"2":{"496":1}}],["∑i∈ijhi+λ",{"2":{"496":2}}],["∑i∈ijhi",{"2":{"496":1}}],["∑i∈ijgi",{"2":{"496":3}}],["∑i=1kni∥ci−x¯∥2",{"2":{"684":1}}],["∑i=1k∥xi−cli∥2",{"2":{"684":1}}],["∑i=1nvi",{"2":{"735":2}}],["∑i=1n∑j=1n∑f=1kvi",{"2":{"735":1}}],["∑i=1n∑j=i+1n",{"2":{"735":1}}],["∑i=1nαiyi=0αi≥0",{"2":{"635":2}}],["∑i=1nαiyi=0",{"2":{"635":2}}],["∑i=1nw^mi=∑i=1nw^mii",{"2":{"430":1}}],["∑i=1nw^mii",{"2":{"430":1}}],["∑i=1nw^miexp",{"2":{"430":1}}],["∑t=1tαtgt",{"2":{"428":1}}],["αi∗",{"2":{"635":3}}],["αi∗≥0",{"2":{"635":1}}],["αi≥0",{"2":{"635":2}}],["α∗",{"2":{"635":3}}],["αn∗",{"2":{"635":2}}],["α2∗",{"2":{"635":2}}],["α1∗",{"2":{"635":2}}],["α|t|为正则项",{"2":{"602":1}}],["αm=em1−em",{"2":{"431":1}}],["α",{"2":{"430":1,"635":8,"740":1}}],["αt=12ln⁡1−etet",{"2":{"428":1}}],["−μ−bu−bi",{"2":{"729":1}}],["−σ",{"2":{"721":4}}],["−v→",{"2":{"718":1}}],["−log⁡l",{"2":{"668":1}}],["−x",{"2":{"668":1}}],["−θtx",{"2":{"657":1}}],["−γ∥x−z∥2",{"2":{"635":1}}],["−∑i=1nvi",{"2":{"735":1}}],["−∑i=1nαis",{"2":{"635":1}}],["−∑i=1nαi",{"2":{"635":1}}],["−∑λ∈",{"2":{"603":1}}],["−∑v=1vr~vent",{"2":{"601":1}}],["−f",{"2":{"547":2}}],["−fm−1",{"2":{"497":1}}],["−y",{"2":{"657":4}}],["−yj",{"2":{"545":4}}],["−yiαg",{"2":{"430":1}}],["−yifm−1",{"2":{"430":1}}],["−yi",{"2":{"430":1}}],["−λ",{"2":{"496":1}}],["−",{"2":{"472":3,"496":1,"532":1,"568":1,"603":1,"670":1}}],["−αtyigt",{"2":{"428":2}}],["−1∇f",{"2":{"555":1}}],["−1",{"2":{"428":2}}],["迭代过程",{"2":{"762":1}}],["迭代多少次就会生成多少颗树",{"2":{"741":1}}],["迭代终止的条件是梯度的模接近于0",{"2":{"555":1}}],["迭代终止的条件是函数的梯度值为0",{"2":{"548":1}}],["迭代速度慢",{"2":{"544":1}}],["迭代操作",{"2":{"543":1}}],["迭代",{"2":{"428":1}}],["迭代的前序遍",{"2":{"85":1}}],["≠yi",{"2":{"428":3}}],["χ→",{"2":{"428":1}}],["集体投票",{"2":{"455":1}}],["集成t个弱分类器为1个最终的强分类器",{"2":{"428":1}}],["集成学习主要有两个思想",{"2":{"490":1}}],["集成学习主要有哪几种框架",{"0":{"454":1}}],["集成学习从集成思想的架构分为bagging",{"2":{"454":1}}],["集成学习算法是一种优化手段或者策略",{"2":{"453":1}}],["集成学习面试题",{"0":{"452":1},"1":{"453":1,"454":1,"455":1,"456":1,"457":1,"458":1,"459":1,"460":1,"461":1,"462":1}}],["集成学习提高学习精度",{"2":{"432":1}}],["集成学习",{"0":{"425":1},"2":{"425":1,"442":1,"501":1}}],["集合大小有限制",{"2":{"302":1}}],["集合为空",{"2":{"58":1}}],["奖励基于代码执行正确性",{"2":{"423":1}}],["奖励函数设计复杂度",{"2":{"423":1}}],["批量梯度下降法在样本量很大的时候",{"2":{"545":1}}],["批量梯度下降法相对来说都比较极端",{"2":{"545":1}}],["批量梯度下降",{"2":{"545":1,"546":1}}],["批量梯度下降的求解思路如下",{"2":{"545":1}}],["批量大小64",{"2":{"423":1}}],["批归一化",{"2":{"314":1}}],["监督学习",{"2":{"651":1}}],["监督微调",{"2":{"423":1}}],["监控输出是否越权",{"2":{"422":1}}],["冷启动",{"2":{"730":1}}],["冷启动阶段",{"2":{"423":1}}],["冷备",{"2":{"192":1}}],["工程化能力",{"2":{"847":1}}],["工具支持自定义损失函数",{"2":{"513":1}}],["工具调用",{"2":{"423":1}}],["工作态度",{"0":{"821":1}}],["工作经历",{"2":{"809":1}}],["工作流程",{"2":{"250":1}}],["工作原理",{"2":{"247":1,"612":1}}],["书籍构建包含专家标注的问答对",{"2":{"423":1}}],["鼓励模型生成多路径",{"2":{"423":1}}],["鼓励回答多样化",{"2":{"423":1}}],["采取和a相同的方式将url分别存储到1000个小文件",{"2":{"747":1}}],["采取原文的描述形式",{"2":{"735":1}}],["采集专家或用户对生成内容的偏好反馈",{"2":{"423":1}}],["采集高质量领域内推理示例",{"2":{"423":1}}],["采用数组的方式创建字典树",{"2":{"763":1}}],["采用上题类似的方法",{"2":{"751":1}}],["采用2",{"2":{"751":1}}],["采用映射的方法",{"2":{"750":1}}],["采用所有数据来梯度下降",{"2":{"545":1}}],["采用直方图相减的方式",{"2":{"514":1}}],["采用的是递归的方式遍历整颗组件树�",{"2":{"792":1}}],["采用的是负对数损失函数",{"2":{"665":1}}],["采用的是最近邻插值",{"2":{"368":1}}],["采用的思路是不停的二分离散特征",{"2":{"600":1}}],["采用的稀疏感知算法可以自动学习出它的分裂方向",{"2":{"513":1}}],["采用特征并行的方法利用多个线程分别计算每个特征的最佳分割点",{"2":{"510":1}}],["采用排序提升的方法对抗训练集中的噪声点",{"2":{"445":1}}],["采用阶段性训练",{"2":{"423":1}}],["采用基于工具调用的智能体架构",{"2":{"423":1}}],["采用分割代替检测方法",{"2":{"401":1}}],["采用多尺度输入训练方式来训练网络",{"2":{"401":1}}],["采用不同特征层特征融合之后的结果来做预测",{"2":{"401":1}}],["采用距离作为相似性的评价指标",{"2":{"382":1}}],["采用了粗暴的舍去小数",{"2":{"368":1}}],["采用focal",{"2":{"336":1}}],["采用stride为2的卷积层",{"2":{"313":1}}],["采用stride为2的池化层",{"2":{"313":1}}],["采用边缘触发机制时",{"2":{"302":1}}],["采用回调机制",{"2":{"302":1}}],["采用水平触发机制",{"2":{"302":1}}],["采用三报文握手主要是为了防止已失效的连接请求报文段突然又传送到了",{"2":{"236":1}}],["采用这种方案就会导致",{"2":{"196":1}}],["采用循环写的方式记录",{"2":{"173":1}}],["采用",{"2":{"112":1,"189":1,"422":1,"445":1,"466":1,"725":1}}],["培养模型的深度思考",{"2":{"423":1}}],["难处理多样复杂策略",{"2":{"423":1}}],["难以找到近邻",{"2":{"730":1}}],["难以扩展到大规模负样本",{"2":{"423":1}}],["难以达到收敛",{"2":{"333":1}}],["清晰准确地表达想法和观�",{"0":{"818":1}}],["清晰度检测和格式统一",{"2":{"423":1}}],["清除浮动的关键字是",{"2":{"785":1}}],["清除浮动可以理解为打破横向排列",{"2":{"785":1}}],["清洗数据",{"2":{"423":1}}],["拆分文章",{"2":{"423":1}}],["步长太小",{"2":{"544":1}}],["步骤",{"2":{"570":1}}],["步骤概览",{"0":{"427":1}}],["步骤如下",{"2":{"423":1,"730":1}}],["步出�",{"2":{"217":1}}],["兼顾压缩率与精度",{"2":{"423":1}}],["兼顾训练微调与推理",{"2":{"422":1}}],["独立量化",{"2":{"423":1}}],["违规内容",{"2":{"423":1}}],["剔除敏感",{"2":{"423":1}}],["口语化表达",{"2":{"423":1}}],["涵盖简洁",{"2":{"423":1}}],["低阶和高阶的特征交互都是很重要的",{"2":{"732":1}}],["低于0",{"2":{"660":1}}],["低",{"2":{"546":3}}],["低偏差意味着模型的预测值接近实际值",{"2":{"459":1}}],["低成本实验方案",{"2":{"423":1}}],["低困惑度支持生成假设",{"2":{"423":1}}],["低层检测小目标",{"2":{"403":1}}],["熟悉度",{"2":{"423":1}}],["熟练掌握常用算法的代码实现",{"2":{"105":1}}],["困惑度是衡量模型对文本",{"2":{"423":1}}],["困难样本挖掘",{"2":{"361":1}}],["医疗文本上继续预训练后微调",{"2":{"423":1}}],["形象准备",{"2":{"836":1}}],["形式上与条件概率相",{"2":{"613":1}}],["形式的字符串�",{"2":{"228":1}}],["形成扩增训练集",{"2":{"423":1}}],["召回",{"2":{"423":1}}],["召回率",{"0":{"588":1},"2":{"385":1}}],["召回率低",{"2":{"383":1}}],["召回率较低",{"2":{"378":1}}],["细分任务类别",{"2":{"423":1}}],["细节问题",{"2":{"423":1}}],["硬负采样",{"2":{"423":1}}],["硬中断是由硬件产生的",{"2":{"301":1}}],["硬中断和软中断",{"0":{"301":1}}],["效果相同",{"2":{"705":1}}],["效果更好",{"2":{"700":1}}],["效果较好",{"2":{"423":1}}],["效果可能受限",{"2":{"423":1}}],["效果好",{"2":{"423":1}}],["效率低",{"2":{"648":1}}],["效率更高",{"2":{"423":1}}],["效率高",{"2":{"423":1,"676":1}}],["效率会线性下降",{"2":{"302":1}}],["效率和平衡树媲美",{"2":{"186":1}}],["地区等",{"2":{"734":1}}],["地假设样本特征彼此独",{"2":{"614":1}}],["地点",{"2":{"423":1}}],["地址长度",{"2":{"251":2}}],["照片预处理",{"2":{"423":1}}],["照片助手的简要方案",{"2":{"423":1}}],["照片助手",{"2":{"423":1}}],["弱分类器可以支",{"2":{"511":1}}],["弱分类器的输出的结果相减是有意义的",{"2":{"497":1}}],["弱分类器",{"2":{"486":1}}],["弱分类器迭代次数t",{"2":{"455":1,"475":1}}],["弱学习器算法",{"2":{"455":1}}],["弱学习器迭代次数m",{"2":{"431":1}}],["弱多模态模型负责提取视觉语义信息",{"2":{"423":1}}],["弱引�",{"2":{"122":1}}],["弱引用",{"0":{"122":1}}],["现有一个由若干篇文章组成的企业知识库",{"2":{"423":1}}],["现有一个能力较弱的多模态模型和一个能力较强的文本模型",{"2":{"423":1}}],["现在称为",{"2":{"792":1}}],["现在几乎所有的大公司都在使用hadoop框架",{"2":{"769":1}}],["现在从这",{"2":{"763":1}}],["现在两个网络共享卷积层了",{"2":{"373":1}}],["现在我们假设扔6次骰子",{"2":{"279":1}}],["现在让你用这个骰子构造一个01发生器",{"2":{"279":1}}],["现在要求只能使用1g的内存空间",{"2":{"763":1}}],["现在要你构造一个发生器",{"2":{"278":1}}],["现在要将这n个数合并成一个数",{"2":{"21":1}}],["现在的面试中",{"2":{"273":1}}],["现在第二次用天平",{"2":{"270":1}}],["现在有",{"2":{"267":1}}],["现在你实在受不了这n只萌猫",{"2":{"27":1}}],["现在需要找出它的一个子矩阵",{"2":{"10":1}}],["架构",{"2":{"423":1}}],["起点在下沿",{"2":{"782":1}}],["起点在上沿",{"2":{"782":1}}],["起点在右端",{"2":{"782":1}}],["起点在左端",{"2":{"782":1}}],["起到了简化了逻辑回归模型的作用",{"2":{"664":1}}],["起到模态对齐的桥梁作用",{"2":{"423":1}}],["起始点到所有点的最小距离",{"2":{"58":1,"59":1}}],["起始单词和结束单词不需要出现在字典",{"2":{"35":1}}],["桥接模态差异",{"2":{"423":1}}],["拉开正负样本距离",{"2":{"423":1}}],["摘要可作为补充上下文与检索内容一并输入模型",{"2":{"423":1}}],["触发popstate事件",{"2":{"798":1}}],["触发执行该方法",{"2":{"796":1}}],["触发",{"2":{"423":1}}],["触发一�",{"2":{"194":1}}],["融合专业领域或企业特定风格",{"2":{"423":1}}],["融合通用知识和领域特征",{"2":{"423":1}}],["融合式回答策略",{"2":{"423":1}}],["融合策略",{"2":{"423":1}}],["章节梗概",{"2":{"423":1}}],["技能发展和学习计划",{"2":{"810":1}}],["技能特�",{"2":{"809":1}}],["技巧",{"2":{"770":1}}],["技术热�",{"0":{"838":1}}],["技术岗�",{"0":{"838":1}}],["技术上正向索引是不能实现的",{"2":{"763":1}}],["技术",{"2":{"423":2}}],["技�",{"2":{"173":1}}],["消除查询中的多义词或口语表达",{"2":{"423":1}}],["消息队列克服了信号传递信息少",{"2":{"293":1}}],["消息队列是由消息的链表",{"2":{"293":1}}],["消息队列",{"2":{"293":1}}],["块级格式化上下文",{"2":{"784":1}}],["块盒子",{"2":{"784":1}}],["块状元素的特点",{"2":{"774":1}}],["块状标签",{"2":{"774":1}}],["块间链接",{"2":{"423":1}}],["块内结构优化",{"2":{"423":1}}],["订酒店",{"2":{"423":1}}],["订阅程序提取出所需要的数据以及key",{"2":{"199":1}}],["酒店推荐等",{"2":{"423":1}}],["酒店安排和景点游览的旅行",{"2":{"423":1}}],["机器翻译等nlp任务中",{"2":{"527":1}}],["机器学习应用",{"2":{"848":1}}],["机器学习理论与实践",{"2":{"845":1}}],["机器学习与深度学习习题集答案",{"2":{"556":1}}],["机器学习中为什么需要梯度下降",{"0":{"540":1}}],["机器学习",{"2":{"442":2,"848":1}}],["机票预订",{"2":{"423":1}}],["机制",{"0":{"702":1},"2":{"422":1,"423":1}}],["影响和说服客户的能�",{"0":{"840":1}}],["影响和说服他人的能�",{"0":{"819":1}}],["影响�",{"0":{"819":1}}],["影响不一样",{"2":{"786":1}}],["影响了最终结果的准确性",{"2":{"624":1}}],["影响统计功效的因素有很多",{"2":{"574":1}}],["影响最终学习器的性能表现",{"2":{"441":1}}],["影响性能时",{"2":{"423":1}}],["影响非常小",{"2":{"192":1}}],["未了不改变数据的总体分布",{"2":{"467":1}}],["未指定具体日期",{"2":{"423":1}}],["未指定预算则设定默认中档",{"2":{"423":1}}],["未完成�",{"2":{"217":1}}],["规则时就会开启",{"2":{"787":1}}],["规则奖励+人工反馈rlhf",{"2":{"423":1}}],["规避了变为零的风险同时并不影响分类结果",{"2":{"619":1}}],["规范格式",{"2":{"423":1}}],["规划任务流程",{"2":{"423":1}}],["规定模型输出的格式或风格",{"2":{"422":1}}],["智能体分析任务意图",{"2":{"423":1}}],["帮助我们找到top",{"2":{"763":1}}],["帮助用户规划一次包含机票预订",{"2":{"423":1}}],["帮助类似于decoder这样的模型框架更好的学到多种内容模态之间的相互关系",{"2":{"353":1}}],["外部记忆+rag",{"2":{"423":1}}],["外键约束",{"2":{"257":1}}],["轮",{"2":{"472":1}}],["轮对话",{"2":{"423":1}}],["轮次截断",{"2":{"423":1}}],["轮询的方式效率较低",{"2":{"302":1}}],["历史提问等",{"2":{"423":1}}],["角色描述和故事梗概",{"2":{"423":1}}],["角色定义能引导模型以更专业",{"2":{"422":1}}],["角色定义",{"2":{"422":1}}],["封闭式提示设计",{"2":{"422":1}}],["封装了底层实现后",{"2":{"140":1}}],["格式化模型",{"2":{"784":1}}],["格式定义",{"2":{"762":1}}],["格式",{"2":{"422":3}}],["响应式数据的关键在于",{"2":{"796":1}}],["响应式数据的原理�",{"0":{"796":1}}],["响应行为监控",{"2":{"422":1}}],["响应报文",{"2":{"246":2}}],["控制回答时间",{"2":{"831":1}}],["控制深度",{"2":{"605":1}}],["控制模型的复杂度",{"2":{"561":1}}],["控制树的复杂度",{"2":{"507":1}}],["控制输出",{"2":{"422":1}}],["控制用户插入点",{"2":{"422":1}}],["控制台打印�",{"2":{"114":1}}],["明确说明",{"2":{"422":1}}],["明确指令",{"2":{"422":1}}],["明确角色设定",{"2":{"422":1}}],["明确你要模型完成什么任务",{"2":{"422":1}}],["列x",{"2":{"527":1}}],["列抽",{"2":{"504":1,"507":1}}],["列抽样",{"2":{"497":1,"513":1}}],["列表",{"2":{"422":1}}],["列不可再分",{"2":{"257":1}}],["客服",{"2":{"422":1}}],["客户导向",{"0":{"840":1},"2":{"822":1}}],["客户使用https的url访问web服务器",{"2":{"247":1}}],["客户端使用公钥加密了一个随机对称密钥",{"2":{"252":1}}],["客户端的浏览器根据双方同意的安全等级",{"2":{"247":1}}],["客户端的浏览器与web服务器开始协商ssl连接的安全等级",{"2":{"247":1}}],["客户端错误",{"2":{"245":1}}],["客户端关闭或者",{"2":{"244":1}}],["客户端1加锁有默认生存时间",{"2":{"185":1}}],["客户端1面对分布式集群下",{"2":{"185":1}}],["客户端",{"2":{"185":1}}],["律师",{"2":{"422":1}}],["告诉模型",{"2":{"422":1}}],["告诉客户端",{"2":{"239":1}}],["抑制在多个主题中都高频的词",{"2":{"422":1}}],["抑制非极大值元素",{"2":{"397":1}}],["维度较大时",{"2":{"703":1}}],["维度灾难",{"2":{"422":1}}],["维数灾难",{"2":{"635":1}}],["维护n次",{"2":{"756":1}}],["维护一次堆的性质",{"2":{"756":1}}],["维护一个从左到右的最大等",{"2":{"95":1}}],["维护一个最短路径的的集合",{"2":{"58":1}}],["维护位置i最大堆的性质",{"2":{"52":1}}],["敏感度一致",{"2":{"666":1}}],["敏感",{"2":{"422":1}}],["邻域方法预测公式",{"2":{"729":1}}],["邻域内",{"2":{"547":1}}],["邻域大小",{"2":{"422":1}}],["邻接表",{"2":{"103":1}}],["邻接矩阵",{"2":{"103":1}}],["邻接矩阵表示的无向图",{"2":{"57":1}}],["邻接矩阵是不错的一种图存储结构",{"2":{"57":1}}],["资源占用低",{"2":{"422":1}}],["资源�",{"2":{"134":1}}],["成立下式",{"2":{"496":1}}],["成本适中",{"2":{"423":1}}],["成本低",{"2":{"422":1}}],["成�",{"2":{"217":1}}],["辅助判断",{"2":{"423":1}}],["辅助",{"2":{"422":1}}],["辅助索引的存在不影响数据在聚簇索引中的组织",{"2":{"165":1}}],["辅助索引的叶子节点并不包含行记录的全部数据",{"2":{"165":1}}],["辅助索引叶子节点存储的不再是行的物理位置",{"2":{"165":1}}],["辅助索引访问数据总是需要二次查找",{"2":{"165":1}}],["少样本能力",{"2":{"422":1}}],["万条客户评论的数据集",{"2":{"422":1}}],["万维网",{"2":{"240":1}}],["话题",{"2":{"422":1}}],["掩码语言建模有何不同",{"2":{"422":1}}],["零概率问",{"2":{"618":1}}],["零样本即用即测",{"2":{"422":1}}],["零均值化",{"2":{"305":1}}],["嵌入能把文本转成向量",{"2":{"422":1}}],["嵌入模型可以跟生成模型配合使用",{"2":{"422":1}}],["嵌入模型更轻量",{"2":{"422":1}}],["嵌入模型速度快",{"2":{"422":1}}],["嵌入模型还有什么用",{"2":{"422":1}}],["嵌入模型",{"2":{"422":1}}],["嵌入式这种资源受限的平台上想要达到实时性的要求就必须要求模型的计算量尽可能地低",{"2":{"315":1}}],["跟样本数量差不多",{"2":{"640":1}}],["跟原始",{"2":{"422":1}}],["跟简单地减少注意力头的数量相比",{"2":{"422":1}}],["键值共享",{"2":{"422":1}}],["键盘",{"2":{"301":1}}],["特点",{"2":{"545":1}}],["特别是输出层的sigmoid归一化部分",{"2":{"718":1}}],["特别是大规模线性分类时比较方便",{"2":{"641":1,"672":1}}],["特别是误差",{"2":{"439":1}}],["特别是在集成弱学习器",{"2":{"425":1}}],["特别是在大模型的推理中",{"2":{"422":1}}],["特别是专业术语理解不足",{"2":{"423":1}}],["特殊词元更稳健",{"2":{"423":1}}],["特殊词元在训练中被优化为捕捉整句信息",{"2":{"423":1}}],["特性",{"2":{"422":1}}],["特征组合",{"2":{"741":2}}],["特征组合和重新定义问题",{"2":{"354":1}}],["特征分裂主要体现对多数样本有区分度的特征",{"2":{"741":1}}],["特征j在单棵树中的重要度如下",{"2":{"741":1}}],["特征j的全局重要度通过特征j在单颗树中的重要度的平均值来衡量",{"2":{"741":1}}],["特征学习",{"2":{"730":1}}],["特征离散化后",{"2":{"664":1}}],["特征离散化以后",{"2":{"664":1}}],["特征之间相互独立",{"2":{"616":1}}],["特征之间如何捆绑",{"0":{"469":1}}],["特征独立",{"2":{"612":1}}],["特征c可能就没有被使用",{"2":{"606":1,"609":1}}],["特征替代性",{"2":{"606":1,"609":1}}],["特征a上取值大于t的样本",{"2":{"603":1}}],["特征a上取值不大于t的样本",{"2":{"603":1}}],["特征a有3个特征值a1",{"2":{"601":1}}],["特征降维",{"2":{"561":1}}],["特征量过少",{"2":{"559":1}}],["特征取值范围也不同",{"2":{"544":1}}],["特征并行",{"2":{"514":1}}],["特征值",{"2":{"508":1}}],["特征有100维",{"2":{"502":1}}],["特征表达能力强",{"2":{"502":1}}],["特征",{"2":{"468":1}}],["特征重要性使用特征在作为划分属性时对样本的覆盖度",{"2":{"462":1}}],["特征重要性使用特征在作为划分属性时loss平均的降低量",{"2":{"462":1}}],["特征重要性使用特征在所有树中作为划分属性的次数",{"2":{"462":1}}],["特征提取",{"2":{"423":1}}],["特征金字塔",{"2":{"402":2}}],["特征金字塔上的长宽",{"2":{"382":1}}],["特征图大",{"2":{"388":1}}],["特征图小",{"2":{"388":1}}],["特征图最小",{"2":{"388":1}}],["特征图组成",{"2":{"367":1}}],["特征图提取",{"2":{"366":2}}],["特征输入到分类和回归模块中",{"2":{"366":1}}],["特征已经稀疏了",{"2":{"339":1}}],["显著性水平是人为给定的犯一类错误的可以接受的上限",{"2":{"574":1}}],["显著加速了计算",{"2":{"422":1}}],["显著提升模型表达能力",{"2":{"422":1}}],["显然收益越高",{"2":{"590":1}}],["显然",{"2":{"196":1,"591":1}}],["远远大于内存限制的4g",{"2":{"747":1}}],["远大于f",{"2":{"679":1}}],["远少于ffn层",{"2":{"422":1}}],["远距离依赖需要多步传播",{"2":{"422":1}}],["精确指定",{"2":{"784":1}}],["精确率",{"0":{"587":1}}],["精准性",{"2":{"422":1}}],["精度不高",{"2":{"755":1}}],["精度更高",{"2":{"513":1}}],["精度损失",{"2":{"422":1}}],["精度评价",{"2":{"393":1}}],["精度在一定条件下超过faster",{"2":{"385":1}}],["精度",{"2":{"378":1}}],["综合考虑",{"2":{"812":1}}],["综合考虑方案如下",{"2":{"741":1}}],["综合了各个方向",{"2":{"515":1}}],["综合多视角信息",{"2":{"422":1}}],["综合起来就是双线性插值最后的结果",{"2":{"369":1}}],["突出重要词元",{"2":{"422":1}}],["衡量词元间的关联强度",{"2":{"422":1}}],["词的大小不超过16字节",{"2":{"749":1}}],["词向量介绍",{"2":{"725":1}}],["词向量是语言模型的一个副产物",{"2":{"725":1}}],["词向量直接",{"2":{"725":1}}],["词向量只不过",{"2":{"725":1}}],["词汇边界",{"2":{"423":1}}],["词汇表内提示约束",{"2":{"423":1}}],["词袋法的优势",{"2":{"422":1}}],["词袋法是不是一无是处了",{"2":{"422":1}}],["词袋法和文档嵌入在实现原理上有什么区别",{"2":{"422":1}}],["词元嵌入层也会保留类似的结构关系",{"2":{"422":1}}],["词表一样",{"2":{"422":1}}],["学生网络以一种略微不同的方式从教师模型中抽取知识",{"2":{"703":1}}],["学术论文",{"2":{"423":1}}],["学到的词向量不仅捕捉了语义相似性",{"2":{"422":1}}],["学习能力",{"0":{"815":1,"838":1}}],["学习方式",{"2":{"730":1}}],["学习方法的scalability",{"2":{"511":1}}],["学习向量量化",{"2":{"674":1}}],["学习到由x到到y的映射的映射h",{"2":{"654":1}}],["学习到由是特征数据",{"2":{"654":1}}],["学习目标函数形式的方法",{"2":{"628":1}}],["学习问题",{"2":{"527":1}}],["学习问题三个基本问",{"2":{"527":1}}],["学习时间越长",{"2":{"521":1}}],["学习第m个学习器",{"2":{"436":1}}],["学习得到的超平面",{"2":{"635":1}}],["学习得到m个不同的学习器进行加权",{"2":{"435":1}}],["学习得到gm",{"2":{"431":1}}],["学习中文特征",{"2":{"423":1}}],["学习率2e",{"2":{"423":1}}],["学习率设置的太大容易产生震荡",{"2":{"349":1}}],["学习率变化",{"2":{"346":1}}],["学习率再慢慢变小",{"2":{"346":1}}],["学习路径",{"0":{"106":1}}],["学习重点",{"0":{"102":1},"1":{"103":1,"104":1}}],["轻量",{"2":{"422":1}}],["轻量级数据访问协议",{"2":{"256":1}}],["静态词嵌入的价值",{"2":{"422":1}}],["静态词嵌入还有什么价值",{"2":{"422":1}}],["仅学习语言模型",{"2":{"711":1}}],["仅有词向量无句向量",{"2":{"708":1,"711":1}}],["仅在",{"2":{"708":1}}],["仅在测试阶段引入多尺度",{"2":{"402":1}}],["仅用剩下的样本计算信息增益",{"2":{"467":1}}],["仅用少量零样本",{"2":{"423":1}}],["仅重试该步",{"2":{"423":1}}],["仅q独立",{"2":{"422":1}}],["仅需修改0",{"2":{"422":1}}],["仅解码器",{"2":{"422":1}}],["仅编码器",{"2":{"422":1}}],["文化",{"2":{"833":1}}],["文字基线对齐",{"2":{"784":1}}],["文字广告",{"2":{"593":1}}],["文档树中的其它元素",{"2":{"784":1}}],["文档内容",{"2":{"769":1}}],["文档名字",{"2":{"769":1}}],["文档分块",{"2":{"423":1}}],["文章到此应该已经可以结束了",{"2":{"769":1}}],["文章中指出每个特征域使用的embedding维度k都是相同的",{"2":{"734":1}}],["文章的introduction中也提到了其重要性",{"2":{"732":1}}],["文本分类",{"2":{"423":1,"625":1}}],["文本检索",{"2":{"423":1}}],["文本转向量",{"2":{"423":1}}],["文本表征方式",{"2":{"419":1}}],["文件读写速度等",{"2":{"770":1}}],["文件描述符就绪时",{"2":{"302":1}}],["文件传输等",{"2":{"240":1}}],["文件事件处理器就会回�",{"2":{"202":1}}],["文件事件处理器使用",{"2":{"202":1}}],["文件事件产生时",{"2":{"202":1}}],["文件重启和恢�",{"2":{"192":1}}],["文件恢复数据",{"2":{"192":1}}],["文件大小",{"2":{"173":1}}],["文件",{"2":{"112":1,"192":1,"800":1}}],["🤝",{"0":{"817":1,"849":1},"1":{"818":1,"819":1}}],["🤖",{"0":{"417":1,"845":1}}],["🧠",{"0":{"100":1,"421":1,"814":1},"1":{"815":1,"816":1}}],["思想和c4",{"2":{"604":1}}],["思想",{"2":{"501":1}}],["思考",{"2":{"422":1}}],["思考一下",{"0":{"405":1},"1":{"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1}}],["思维树",{"2":{"422":1}}],["思维树等几种技术各有什么优缺点",{"2":{"422":1}}],["思维链提示结构",{"2":{"423":1}}],["思维链",{"2":{"422":2}}],["思路更加合理",{"2":{"741":1}}],["思路很好",{"2":{"397":1}}],["思路来自网友summer",{"2":{"274":1}}],["思路",{"2":{"68":1,"74":1}}],["思路也很简",{"2":{"1":1}}],["人际能力",{"0":{"817":1},"1":{"818":1,"819":1}}],["人们在测量事物的时候因为客观条件所限",{"2":{"654":1}}],["人工选择保留特征的方法对特征进行降维",{"2":{"561":1}}],["人工增加小物体在图片中出现的次数",{"2":{"403":1}}],["人脸检测的mtcnn就是图像金字塔",{"2":{"402":1}}],["人为经验选取",{"2":{"367":1}}],["尤其是数据量超出内存时",{"2":{"626":1}}],["尤其是q",{"2":{"422":1}}],["尤其是在小样本",{"2":{"423":1}}],["尤其是在计算",{"2":{"422":1}}],["尤其是在移动端",{"2":{"315":1}}],["尤其是在写少读多的场景下",{"2":{"194":1}}],["尤其在",{"2":{"422":1}}],["尤其在检测目标的过程中",{"2":{"401":1}}],["借鉴了随机森林的做法",{"2":{"513":1}}],["借鉴cascade",{"2":{"401":1}}],["借鉴fpn的思想",{"2":{"401":1}}],["借助于集合代数等数学概念和方法来处理数据库中的数据",{"2":{"258":1}}],["携带的信息少",{"2":{"401":1}}],["针对",{"2":{"790":1}}],["针对每一颗树得到一个类别型特征",{"2":{"739":1}}],["针对于新user",{"2":{"730":1}}],["针对类别",{"2":{"472":1}}],["针对翻译类",{"2":{"422":1}}],["针对小目标重新精细设计anchor的尺寸和形状",{"2":{"400":1}}],["针对输入所有值进行一次池化操作",{"2":{"394":1}}],["延伸问题",{"0":{"398":1},"1":{"399":1,"400":1,"401":1,"402":1,"403":1,"404":1}}],["延时双删",{"0":{"199":1}}],["拓展",{"2":{"397":1}}],["拓扑排序",{"0":{"60":1}}],["拓扑排序都被问到过",{"2":{"57":1}}],["置信度低的会被置信度高的框抑制掉",{"2":{"397":1}}],["置换出未使用时间最长的页面",{"2":{"299":1}}],["​",{"2":{"394":1,"395":1}}],["​\\t",{"2":{"301":2}}],["​\\t\\t软中断并不会直接中断cpu",{"2":{"301":1}}],["​\\t\\t软中断仅与内核相联系",{"2":{"301":1}}],["​\\t\\t软中断的处理非常像硬中断",{"2":{"301":1}}],["​\\t\\t硬中断可以直接中断cpu",{"2":{"301":1}}],["​\\t\\tsession",{"2":{"244":1}}],["​\\t\\tcookie是服务器发送到用户浏览器并保存在本地的一小块数据",{"2":{"244":1}}],["​\\t\\t因为当服务端收到客户端的syn连接请求报文后",{"2":{"239":1}}],["​\\t\\ttcp使用滑动窗口协议",{"2":{"242":1}}],["​\\t\\ttcp",{"2":{"237":1}}],["讨论以考虑bias为准",{"2":{"394":1}}],["意图后",{"2":{"423":1}}],["意图",{"2":{"422":1}}],["意指浮点运算数",{"2":{"394":1}}],["意指每秒浮点运算次数",{"2":{"394":1}}],["意为不仅仅是sql",{"2":{"258":1}}],["质量",{"2":{"389":1}}],["质量有重大影响",{"2":{"389":1}}],["阈值法",{"2":{"730":1}}],["阈值是可以自己设定的",{"2":{"660":1}}],["阈值来进行重新计算正负样本和采样策略来逐渐提高",{"2":{"389":1}}],["阈值选取对最终检测",{"2":{"389":1}}],["部分层冻结只微调特定层",{"2":{"423":1}}],["部分",{"2":{"389":1}}],["倍最近邻上采样",{"2":{"388":2}}],["②与faster",{"2":{"386":1}}],["②下一步计算的输入",{"2":{"386":1}}],["①此处实现方式与yolo类似",{"2":{"386":1}}],["①使用的卷积网络",{"2":{"386":1}}],["识别",{"2":{"423":1}}],["识别可能的角色切换",{"2":{"422":1}}],["识别物体位置精准性差",{"2":{"383":1}}],["识别效果不够好",{"2":{"361":1}}],["长期愿景�",{"2":{"810":1}}],["长文本处理容易",{"2":{"693":1}}],["长距离信息反而被扭曲",{"2":{"422":1}}],["长距离关联等",{"2":{"422":1}}],["长虹ai",{"0":{"383":1,"413":1},"2":{"385":1}}],["长=右下角横坐标",{"2":{"381":1}}],["宽度",{"2":{"774":1}}],["宽度与高度由内容决定",{"2":{"774":1}}],["宽和通道数",{"2":{"394":1}}],["宽输入图像宽高输入图像高w=",{"2":{"382":1}}],["宽=右下角纵坐标",{"2":{"381":1}}],["宽与高",{"2":{"372":1}}],["误差服从正态分布",{"2":{"571":1}}],["误差率小的弱分类器会在最终的强分类器里占据更大的权重",{"2":{"427":1}}],["误差也会对网络优化过程造成很大的影响",{"2":{"378":1}}],["误差对网络训练中",{"2":{"378":1}}],["误差和小物体",{"2":{"378":1}}],["创造性解决问题的能力",{"2":{"816":1}}],["创新思维",{"2":{"816":1}}],["创新点",{"2":{"378":1}}],["创意写作类",{"2":{"422":1}}],["创建出一份需要恢复数据的最小日志",{"2":{"193":1}}],["灵活引导模型生成符合主观需求的内容",{"2":{"423":1}}],["灵活但训练成本高",{"2":{"423":1}}],["灵活和泛化性能好",{"2":{"378":1}}],["灵活性更强",{"2":{"513":1}}],["灵活性",{"2":{"334":1}}],["灵活性好",{"2":{"233":1}}],["灵活性受到了限制�",{"2":{"135":1}}],["云从科技",{"0":{"378":1,"390":1}}],["达到state",{"2":{"375":1}}],["阐述一下如何进行多尺度训练",{"2":{"402":1}}],["阐述一下如何检测小物体",{"0":{"401":1}}],["阐述一下目标检测任务中的多尺度",{"0":{"402":1}}],["阐述一下mask",{"0":{"375":1}}],["阐述一下感受野的概念",{"0":{"309":1}}],["改�",{"2":{"798":1}}],["改变浏览器的字体大小等",{"2":{"786":1}}],["改变了训练数据分布",{"2":{"740":1,"741":1}}],["改写为",{"2":{"635":1}}],["改写有助于统一语言风格",{"2":{"423":1}}],["改写可以补全上下文",{"2":{"423":1}}],["改成了全卷积结构",{"2":{"378":1}}],["改用iou距离",{"2":{"381":1}}],["改用可学习的",{"2":{"376":1}}],["改用双线性插值的方法确定特征图坐标对应于原图中的像素位置",{"2":{"369":1}}],["改进表达方式",{"2":{"835":1}}],["改进设计方案",{"2":{"570":1}}],["改进在于",{"2":{"423":1}}],["改进方法",{"2":{"403":1}}],["改进特征融合方式",{"2":{"399":1}}],["改进点",{"2":{"378":1}}],["改进",{"2":{"374":1,"635":1,"676":1}}],["商汤",{"0":{"374":1,"385":1,"397":1}}],["框架",{"2":{"464":1}}],["框架需要将梯度平均分配给每一个神经元再进行反向传播",{"2":{"338":1}}],["框",{"2":{"372":1}}],["≈∑w∈dlog⁡∏u∈pos",{"2":{"721":1}}],["≈v→",{"2":{"718":1}}],["≈∇f",{"2":{"555":1}}],["≈−",{"2":{"547":1}}],["≈",{"2":{"422":1}}],["≈f",{"2":{"369":1}}],["≈y2−yy2−y1f",{"2":{"369":1}}],["≈x2−xx2−x1f",{"2":{"369":2}}],["量化",{"2":{"368":1}}],["损失更合适",{"2":{"423":1}}],["损失各有哪些优缺点",{"2":{"423":1}}],["损失",{"2":{"423":2}}],["损失函数是非凸函数",{"2":{"680":1}}],["损失函数为",{"2":{"668":1}}],["损失函数可以写成如下这种形式",{"2":{"545":1}}],["损失函数支持自定义",{"2":{"504":1}}],["损失函数",{"2":{"493":1,"657":4}}],["损失函数使用相同的数据集求得当前模型的梯",{"2":{"448":1}}],["损失函数中",{"2":{"378":1}}],["损失函数设计细节",{"2":{"378":1}}],["损失函数优化权重w",{"2":{"372":1}}],["损失函数的梯度也会变得很大或者很小",{"2":{"323":1}}],["损失一定的空间精度",{"2":{"368":1}}],["蘑菇街",{"0":{"385":1},"2":{"367":1}}],["滑窗的中心在原像素空间的映射点称为anchor",{"2":{"367":1}}],["滑动窗口分块",{"2":{"423":1}}],["滑动窗口协议既保证了分组无差错",{"2":{"242":1}}],["滑动窗口",{"2":{"103":1}}],["滑动窗口最大�",{"2":{"47":1}}],["滑动窗口的最大�",{"0":{"47":1}}],["锚点和锚点们与标注之间的最高重叠矩形区域",{"2":{"367":1}}],["送入检测网络再进行分类和回归",{"2":{"367":1}}],["检索的时候可以根据关键字的交集或者并集进行检索",{"2":{"761":1}}],["检索速度快",{"2":{"423":1}}],["检索相关片段",{"2":{"423":1}}],["检索",{"2":{"423":1}}],["检测并剔除越界词汇",{"2":{"423":1}}],["检测如",{"2":{"422":1}}],["检测的框角度偏移了45度",{"0":{"404":1}}],["检测中的iou阈值对于样本的选取是至关重要的",{"2":{"401":1}}],["检测信息包括每个anchor的信息",{"2":{"386":1}}],["检测网络ssd中最后一层是由多个尺度的feature",{"2":{"402":1}}],["检测网络",{"2":{"367":1}}],["检测器处理每张图片所需要的时间",{"2":{"393":1}}],["检测器每秒能处理图片的张数",{"2":{"393":1}}],["检测器",{"0":{"367":1},"2":{"367":1}}],["检查是否与bloom",{"2":{"747":1}}],["检查arp缓存中是否有下一跳的mac",{"2":{"250":1}}],["检查浏览器缓存中是否缓存过该域名对应的ip地址",{"2":{"249":1}}],["检查域名是否在缓存中",{"2":{"235":1}}],["端到端",{"2":{"366":1}}],["边际值太小",{"2":{"663":1}}],["边代表划分的条件",{"2":{"597":1}}],["边",{"2":{"597":1}}],["边缘分布来得到对变量集合y的推断",{"2":{"521":1}}],["边的权重就是两个相连接的特征的总冲突值",{"2":{"468":1}}],["边界框",{"2":{"378":1}}],["边界框回归等",{"2":{"361":1}}],["边框回归用来微调候选区域",{"2":{"372":1}}],["边框回归",{"2":{"365":1}}],["旷视",{"0":{"365":1,"378":1}}],["腾讯",{"0":{"365":1,"396":1,"397":1}}],["腾讯csig后台开发实习一面",{"2":{"253":1}}],["顺序读文件",{"2":{"749":1}}],["顺序读取10个文件",{"2":{"748":1}}],["顺序执行序列和程序出口",{"2":{"288":1}}],["顺便提一下",{"2":{"497":1}}],["顺丰",{"0":{"365":1,"368":1}}],["运算持续占用主线程",{"2":{"792":1}}],["运算",{"2":{"792":1}}],["运算速度慢",{"2":{"361":1}}],["运行的框架已经帮我们封装的很好的",{"2":{"769":1}}],["运行",{"2":{"291":1}}],["准确率高",{"2":{"649":1}}],["准确率和错误",{"0":{"585":1}}],["准确率",{"2":{"423":1}}],["准确率不高",{"2":{"361":1}}],["准备常见问题的回答",{"2":{"833":1}}],["准备工作完毕�",{"2":{"217":1}}],["准备写入的�",{"2":{"134":1}}],["至于为啥最后一层为啥一般不需要缩放",{"2":{"703":1}}],["至于为什么svm叫支持向量机",{"2":{"635":1}}],["至于如何学到缺省值的分支",{"2":{"508":1}}],["至第七步",{"2":{"381":1}}],["至今",{"2":{"360":1}}],["至少表示我们有逻辑",{"2":{"266":1}}],["至少包含一个数",{"2":{"14":1}}],["场",{"2":{"358":1}}],["速度也就越快",{"2":{"394":1}}],["速度也较慢",{"2":{"366":1}}],["速度指标",{"2":{"393":2}}],["速度",{"2":{"378":1}}],["速度快",{"2":{"378":1,"640":1}}],["速度比github上几个直接写cuda",{"2":{"357":1}}],["速度极慢",{"2":{"357":1}}],["添加",{"2":{"786":1}}],["添加三个门",{"2":{"690":1}}],["添加多项式特征",{"2":{"560":1}}],["添加了节日项",{"2":{"531":1}}],["添加注意力机制等",{"2":{"399":1}}],["添加fpn",{"2":{"385":1}}],["添加正则化的方法",{"2":{"354":1}}],["添加等操作都可以在对数期望时间下完成",{"2":{"186":1}}],["尝试使用其它的优化方法",{"2":{"354":1}}],["尝试选择合适的激活函数",{"2":{"354":1}}],["尝试删除缓存操作",{"2":{"199":1}}],["收敛了",{"2":{"675":1}}],["收敛慢",{"2":{"632":1}}],["收敛更快",{"2":{"632":1}}],["收敛性",{"2":{"546":1}}],["收敛速度来说",{"2":{"545":1}}],["收敛快",{"2":{"423":1}}],["收藏",{"2":{"423":1}}],["收集大量微信聊天风格的对话数据",{"2":{"423":1}}],["收集更多的数据",{"2":{"354":1}}],["收到arp响应分组后",{"2":{"250":1}}],["判定规则是人类处理很多问题时的常用方法",{"2":{"597":1}}],["判别式模型是直接对条件概率分",{"2":{"521":1}}],["判别模型去判别真假",{"2":{"352":1}}],["判别模型用于判断给定的图片是不是真实的图片",{"2":{"352":1}}],["判断特征重要性",{"2":{"462":1}}],["判断目标后",{"2":{"227":1}}],["判断是不是该锁",{"2":{"184":1}}],["判断是否需要终止",{"2":{"543":1}}],["判断是否是平衡二叉树",{"2":{"87":1}}],["判断是否是null",{"2":{"56":1}}],["判断是否所有顶点的入度都是0",{"2":{"61":1}}],["判断是否在字典中",{"2":{"35":1}}],["判断给定的二叉树是否是对称二叉树",{"2":{"91":1}}],["判断字符串是否有效",{"2":{"75":1}}],["判断链表中是否有",{"2":{"68":1}}],["判断s3是否由s1和s2交叉构成",{"2":{"13":1}}],["具有以下两种可选值",{"2":{"796":1}}],["具有天然的特征组合优势",{"2":{"502":1}}],["具有训练速度快",{"2":{"464":1}}],["具有依赖关系",{"2":{"425":1}}],["具有与实际边界框的重叠超过0",{"2":{"371":1}}],["具有与实际边界框的重叠最高交并比",{"2":{"371":1}}],["具有稀疏性",{"2":{"350":1}}],["具体�",{"2":{"830":1}}],["具体的对于2阶特征",{"2":{"735":1}}],["具体体现在",{"2":{"423":1}}],["具体事件等",{"2":{"423":1}}],["具体方案如下",{"2":{"423":1}}],["具体原因如下",{"2":{"423":1}}],["具体如下",{"2":{"423":1}}],["具体操作",{"2":{"368":1}}],["具体为无锁",{"2":{"139":1}}],["具体实现时可以覆盖父类的实现",{"2":{"123":1}}],["具体做法�",{"2":{"110":1}}],["样本的均匀采样和负样本数据的下采样",{"2":{"740":1}}],["样本的信息量太大导致模型不足以fit整个样本空间",{"2":{"349":1}}],["样本容量增加时",{"2":{"632":1}}],["样本属于每个类的条件概率",{"2":{"631":1}}],["样本量和i",{"2":{"574":1}}],["样本量越少越好",{"2":{"573":1}}],["样本量大小如何",{"0":{"573":1}}],["样本噪音干扰过大",{"2":{"559":1}}],["样本数量一般",{"2":{"640":1}}],["样本数量就会增加",{"2":{"401":1}}],["样本数相同下的不同训练集产生的各个分类器",{"2":{"497":1}}],["样本随机",{"2":{"497":1}}],["样本赋予权重",{"2":{"486":1}}],["样本计算测试误差a",{"2":{"462":1}}],["样例2",{"2":{"94":1}}],["样例1",{"2":{"94":1}}],["样例",{"2":{"7":2,"36":3}}],["噪声表达了在当前任务上任何模型所能达到的期望泛化误差的下界",{"2":{"558":1}}],["噪声",{"2":{"345":1,"558":1}}],["裁剪",{"2":{"345":1}}],["旋转角度越大",{"2":{"422":1}}],["旋转位置嵌入",{"2":{"422":1}}],["旋转",{"2":{"345":1}}],["旋转图像",{"2":{"325":1}}],["翻转",{"2":{"345":1}}],["简化了下游任务架构设计",{"2":{"710":1}}],["简化模型",{"2":{"664":1}}],["简化问题",{"2":{"632":1}}],["简化网络计算复杂度",{"2":{"339":1}}],["简言之就是用户点击广告到成为一个有效激活或者注册甚至付费用户的转化",{"2":{"594":1}}],["简",{"2":{"519":1}}],["简称",{"2":{"423":2}}],["简介",{"2":{"396":1}}],["简要说明",{"2":{"730":1}}],["简要介绍prophet",{"0":{"531":1}}],["简要介绍一下fpn",{"0":{"390":1}}],["简要阐述一下retinanet",{"0":{"387":1}}],["简要阐述一下ssd网络",{"0":{"385":1}}],["简述岭回归与lasso回归以及使用场景",{"0":{"657":1}}],["简述一下该方式的原理",{"0":{"651":1}}],["简述一下knn算法的原",{"0":{"646":1}}],["简述一下adaboost原理",{"0":{"486":1}}],["简述朴素贝叶斯算法原理和工作流",{"0":{"612":1}}],["简述ssd网络前向是如何计算的",{"0":{"386":1}}],["简述faster",{"0":{"373":1},"2":{"373":1}}],["简述cnn分类网络的演变脉络及各自的贡献与特点",{"0":{"342":1}}],["简单易于理解",{"2":{"730":1}}],["简单又高效",{"2":{"625":1}}],["简单模型与复杂模型相反",{"2":{"622":1}}],["简单直观",{"2":{"607":1}}],["简单对比如下",{"2":{"545":1}}],["简单的说xgb=gbdt+二阶梯度信息+随机特征和样本选择+特征百分位值加",{"2":{"494":1}}],["简单高效",{"2":{"423":1}}],["简单但效果有限",{"2":{"423":1}}],["简单介绍下常用�",{"0":{"774":1}}],["简单介绍下bert",{"0":{"713":1}}],["简单介绍下gpt",{"0":{"710":1}}],["简单介绍下elmo",{"0":{"707":1}}],["简单介绍下cascade",{"0":{"389":1}}],["简单介绍决策树算法",{"0":{"597":1}}],["简单介绍条件随机场",{"0":{"519":1}}],["简单介绍随机森林",{"0":{"475":1}}],["简单介绍一下sigmoid函数",{"0":{"660":1}}],["简单介绍一下stacking",{"0":{"458":1}}],["简单介绍一下逻辑回归",{"0":{"659":1}}],["简单介绍一下线性回归",{"0":{"654":1}}],["简单介绍一下xgboost",{"0":{"503":1}}],["简单介绍一下lightgbm",{"0":{"464":1}}],["简单介绍一下boosting",{"0":{"456":1}}],["简单介绍一下bagging",{"0":{"455":1}}],["简单介绍一下kmeans算法",{"0":{"396":1}}],["简单介绍catboost",{"0":{"444":1}}],["简单叙述一下retinanet中的fpn代码运行流程",{"0":{"388":1}}],["简单讲是http的安全版",{"2":{"247":1}}],["简单",{"2":{"240":1}}],["池化层没有需要学习的参数",{"2":{"395":1}}],["池化层没有可以训练的参数",{"2":{"338":1}}],["池化层的参数量",{"2":{"395":1}}],["池化层的cin=cout",{"2":{"394":1}}],["池化层的flops",{"2":{"394":1}}],["池化层",{"2":{"338":1}}],["池化层只需要将误差传递到上一层",{"2":{"338":1}}],["池化操作",{"2":{"324":1}}],["反馈改进",{"2":{"835":1}}],["反馈神经网络正常工作需要的条件就是每一个点提供一个方向",{"2":{"337":1}}],["反思总结",{"2":{"815":1}}],["反之越小",{"2":{"657":1}}],["反向提问",{"2":{"811":1}}],["反向传播时这些梯度会变得很小甚至为",{"2":{"703":1}}],["反向传播算法",{"2":{"340":1}}],["反向传播算法的motivation是期望通过在神经网络的训练过程中自适应的调整各神经元间的连接权值",{"2":{"340":1}}],["反向条件概率",{"2":{"613":1}}],["反复使用如下迭代公式",{"2":{"547":1}}],["反问式追问",{"2":{"423":1}}],["反而不如零样本",{"2":{"422":1}}],["反转",{"2":{"103":1}}],["反转字符串中的单词iii",{"0":{"77":1}}],["反转链表",{"0":{"69":1}}],["合理设定面试期�",{"2":{"834":1}}],["合计共",{"2":{"699":1}}],["合适的映射函数",{"2":{"635":1}}],["合成采样",{"2":{"336":1}}],["合并过个文件的结果",{"2":{"769":1}}],["合并后再进行分类",{"2":{"374":1}}],["合并",{"2":{"103":1,"708":1}}],["合并数字",{"0":{"21":1}}],["震荡越小",{"2":{"333":1}}],["越小越好",{"2":{"684":2}}],["越乘越小",{"2":{"619":1}}],["越是会尝试对所有的样本进行拟合",{"2":{"562":1}}],["越复杂的模型",{"2":{"562":1}}],["越大越好",{"2":{"684":3}}],["越大越重要",{"2":{"462":1}}],["越大的",{"2":{"333":1}}],["越早过期的越先被删�",{"2":{"200":1}}],["总的文件大小",{"2":{"770":1}}],["总的时间复杂度o",{"2":{"756":1}}],["总的来说",{"2":{"387":1}}],["总时长",{"2":{"423":1}}],["总结来说",{"2":{"376":1}}],["总结",{"2":{"331":1,"388":1,"423":2}}],["总之",{"2":{"109":1}}],["预剪枝",{"2":{"605":1}}],["预估模型",{"2":{"546":1}}],["预估范围",{"2":{"423":1}}],["预排序的exact",{"2":{"514":1}}],["预排序过程的空间复杂度过",{"2":{"513":1}}],["预排序需要对每个样本的切分位置计算",{"2":{"497":1}}],["预先对数据进行了排序",{"2":{"497":2,"505":1,"513":1}}],["预测效率高",{"2":{"730":1}}],["预测结果呈s型",{"2":{"663":1}}],["预测值h",{"2":{"656":1}}],["预测为负",{"2":{"591":1}}],["预测为正",{"2":{"591":1}}],["预测模型会对每一个样本预测一个得分s或者一个概率p",{"2":{"591":1}}],["预测错误",{"2":{"586":2}}],["预测正确",{"2":{"586":2}}],["预测",{"2":{"586":4}}],["预测的过程也要先经过所有基模型的预测形成新的测试集",{"2":{"458":1}}],["预测偏移是由梯度偏差造成的",{"2":{"448":1}}],["预测问题",{"2":{"331":1,"527":2}}],["预计需要多少张",{"2":{"423":1}}],["预计基座模型至少需要多大",{"2":{"423":1}}],["预算",{"2":{"423":1}}],["预训练模型作为任务网络的一部分参与任务学习",{"2":{"710":1}}],["预训练模型作为纯粹的表征抽取器",{"2":{"707":1}}],["预训练模型等",{"2":{"688":1}}],["预训练权重",{"2":{"422":1}}],["预训练简单",{"2":{"422":1}}],["预防过拟合策略",{"2":{"307":1}}],["范式",{"2":{"513":1}}],["范数的大小实现了对模型空间的限制",{"2":{"330":1}}],["范围越小则表示其所包含的特征越趋向局部和细节",{"2":{"309":1}}],["范围列之后列的索引全失�",{"2":{"169":1}}],["范围列可以用到索�",{"2":{"169":1}}],["范围查询的列建在后比较实用",{"2":{"168":1}}],["范围查询效率更高",{"2":{"167":1}}],["范围查找",{"2":{"167":1}}],["减小分对样本的权重",{"2":{"486":1}}],["减小过拟合",{"2":{"330":1}}],["减去左上角的max",{"2":{"390":1}}],["减少文件传输的网络带宽",{"2":{"770":1}}],["减少与分类关系较小的数据点的权重",{"2":{"641":1,"672":1}}],["减少这种错误的方法就是提高显著性水平",{"2":{"574":1}}],["减少过拟合的风险",{"2":{"565":1}}],["减少权重使得网络对丢失特定神经元连接的鲁棒性提高",{"2":{"564":1}}],["减少正则化参数",{"2":{"560":1}}],["减少内存占用",{"2":{"514":1}}],["减少量化误差累积",{"2":{"423":1}}],["减少通用知识丢失",{"2":{"423":1}}],["减少通信双方不必要的资源消耗",{"2":{"237":1}}],["减少",{"2":{"423":1}}],["减少语义割裂",{"2":{"423":1}}],["减少重复计算",{"2":{"422":1}}],["减少了并行训练的通信代价",{"2":{"497":1}}],["减少了计算延迟",{"2":{"422":1}}],["减少了计算量",{"2":{"422":1,"471":2}}],["减少了不必要的数据传输",{"2":{"422":1}}],["减少了通信次数",{"2":{"237":1}}],["减少处理高维输入数据的计算负担",{"2":{"353":1}}],["减少神经元之间复杂的共适应关系",{"2":{"332":1,"564":1}}],["减少前后层参数对当前层参数的影响",{"2":{"328":1}}],["减少计算量",{"2":{"320":1}}],["减少方差大的特征的影响",{"2":{"305":1}}],["减少数据的发送",{"2":{"241":1}}],["什么样的函数可以作为核函数",{"2":{"635":1}}],["什么情况下会选择零样本分类",{"2":{"422":1}}],["什么是",{"0":{"795":1}}],["什么是重绘",{"0":{"786":1}}],["什么是回流",{"0":{"786":1}}],["什么是朴素贝叶斯中的零概率问题",{"0":{"618":1}}],["什么是贝叶斯决策理论",{"0":{"615":1}}],["什么是过拟合和欠拟合",{"0":{"559":1}}],["什么是全局极小值",{"0":{"554":1}}],["什么是鞍点",{"0":{"553":1}}],["什么是dt",{"2":{"497":1}}],["什么是集成学习算法",{"0":{"453":1}}],["什么是group",{"0":{"348":1}}],["什么是正则化",{"0":{"330":1}}],["什么场景下",{"0":{"339":1}}],["什么插入",{"2":{"50":1}}],["传",{"2":{"513":1}}],["传统gbdt在优化时只用到一阶导数信息",{"2":{"497":1}}],["传统gbdt以cart作为基分类器",{"2":{"497":1}}],["传统",{"2":{"422":1}}],["传统注意力机制计算时",{"2":{"422":1}}],["传统的注意力计算需要大量的内存访问",{"2":{"422":1}}],["传统的静态词嵌入",{"2":{"422":1}}],["传统的聚类方法是使用欧氏距离来衡量差异",{"2":{"381":1}}],["传统的计算机视觉方法需首先基于经验手动设计特征",{"2":{"327":1}}],["传统检测算法流程可概括如下",{"2":{"361":1}}],["传统目标检测算法",{"0":{"361":1}}],["传统目标检测算法时期",{"2":{"360":1}}],["传送一份给客户端",{"2":{"247":1}}],["爆炸原因及其解决方法",{"2":{"326":1}}],["详细描述采取的具体行动",{"2":{"829":1}}],["详解机器学习中的梯度消失",{"2":{"326":1}}],["详见百度百科或者wikipedia",{"2":{"22":1}}],["梯度截断",{"2":{"698":1}}],["梯度更新",{"2":{"543":1}}],["梯度更新与奖励计算",{"2":{"423":1}}],["梯度的值是最大方向导数的值",{"2":{"541":1}}],["梯度的方向是最大方向导数的方向",{"2":{"541":1}}],["梯度的本质也是一种方向导数",{"2":{"515":1}}],["梯度是一个向量",{"2":{"541":1}}],["梯度下降的求解思路如下",{"2":{"545":1}}],["梯度下降的作用",{"2":{"540":1}}],["梯度下降有可能得到的是局部最小值",{"2":{"544":1}}],["梯度下降核心思想归纳",{"0":{"543":1}}],["梯度下降不一定能够找到全局的最优解",{"2":{"542":1}}],["梯度下降法和牛顿法能保证找到函数的极小值点吗",{"0":{"550":1}}],["梯度下降法和梯度上升法可相互转换",{"2":{"540":1}}],["梯度下降法为什么要在迭代公式中使用步长系数",{"0":{"549":1}}],["梯度下降法如何判断是否收敛",{"0":{"548":1}}],["梯度下降法每次的迭代增量为",{"2":{"547":1}}],["梯度下降法得到的解就一定是全局最优解",{"2":{"542":1}}],["梯度下降法直观理解",{"0":{"542":1}}],["梯度下降法缺点",{"0":{"541":1}}],["梯度下降法面试题",{"0":{"539":1},"1":{"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1,"551":1,"552":1,"553":1,"554":1,"555":1,"556":1}}],["梯度下降是迭代法的一种",{"2":{"540":1}}],["梯度信息都存储在一个个bin中",{"2":{"514":1}}],["梯度为0",{"2":{"350":1}}],["梯度爆炸",{"2":{"326":1}}],["梯度消失",{"2":{"326":1}}],["梯度消失和梯度爆炸的原因是什么",{"0":{"326":1}}],["色彩转换",{"2":{"325":1}}],["局部敏感哈希",{"2":{"768":1}}],["局部敏感哈",{"2":{"754":1}}],["局部",{"2":{"693":1}}],["局部加权线性回归是在线性回归的基础上对每一个测试样本",{"2":{"657":1}}],["局部加权",{"2":{"657":1}}],["局部极小值",{"2":{"554":1}}],["局部自适应量化",{"2":{"423":1}}],["局部弯曲图像",{"2":{"325":1}}],["局部最优策略",{"2":{"100":1}}],["较为常用",{"2":{"730":1}}],["较远的赋予较低的权值",{"2":{"650":1}}],["较稳定",{"2":{"546":1}}],["较多的子树一般可以让模型有更好的性能",{"2":{"484":1}}],["较好的保留了平面结构信息",{"2":{"355":1}}],["较大卷积核尺寸的卷积操作",{"2":{"324":1}}],["较高",{"2":{"121":1}}],["阻止元素默认行为",{"2":{"779":1}}],["阻止事件冒泡",{"2":{"779":1}}],["阻止了某些特征仅仅在其它特定特征下才有效果的情况",{"2":{"564":1}}],["阻止网络层的激活函数输出爆炸",{"2":{"323":1}}],["阻塞式",{"2":{"302":1}}],["阻塞",{"2":{"291":1}}],["阻塞系数",{"2":{"131":1}}],["阻塞任务队列",{"2":{"129":1}}],["权值更新过后的训练集会用于训练下一个分类器",{"2":{"427":1}}],["权值为false和true",{"2":{"11":1}}],["权重越大",{"2":{"657":1}}],["权重的确定可以通过一个核来计算",{"2":{"657":1}}],["权重的初始化",{"2":{"354":1}}],["权重归一化",{"2":{"422":1}}],["权重参数的绝对值之和",{"2":{"325":1}}],["权重参数的平方和",{"2":{"325":1}}],["权重初始化的目的是在深度神经网络中前向传递时",{"2":{"323":1}}],["升维",{"2":{"320":1}}],["升序",{"2":{"50":1,"55":1,"297":1}}],["升序排序",{"2":{"23":1}}],["激活层的flops",{"2":{"394":1}}],["激活函数的输入值的整体分布逐渐往激活函数的取值区间上下限靠近",{"2":{"351":1}}],["激活函数的选择",{"2":{"326":1}}],["激活函数",{"2":{"319":1,"378":1}}],["激活函数是什么",{"0":{"319":1}}],["激励和发展团队成员",{"0":{"819":1}}],["激励",{"2":{"319":1}}],["经验分享",{"2":{"849":1}}],["经验选取人工据经验先定几个k",{"2":{"677":1}}],["经历梳理",{"2":{"833":1}}],["经历回顾�",{"0":{"825":1}}],["经典问题",{"0":{"632":1}}],["经典梯度提升算法每个步骤中使用的梯度由当前模型中的相同的数据",{"2":{"447":1}}],["经典传统目标检测算法",{"2":{"361":1}}],["经典的卷积类型",{"2":{"316":1}}],["经过随机存储",{"2":{"763":1}}],["经过聚类后才变得有点顺序",{"2":{"651":1}}],["经过双向lstm层提取特征并输出",{"2":{"521":1}}],["经过多层",{"2":{"422":1}}],["经过上一步",{"2":{"381":1}}],["经过上述两次整数化",{"2":{"368":1}}],["经过近7年的发展",{"2":{"362":1}}],["经过深度可分离卷积后",{"2":{"320":1}}],["经过处理后符合标准正态分布",{"2":{"306":1}}],["×ru",{"2":{"729":1}}],["×",{"2":{"314":4,"315":12,"317":14,"695":1}}],["偏向于取值比较多的特征",{"2":{"600":1}}],["偏向锁",{"2":{"139":1}}],["偏差优化目标",{"2":{"729":1}}],["偏差越大越偏离真实值",{"2":{"558":1}}],["偏差则表现为在特定分布上的适应能力",{"2":{"558":1}}],["偏差度量了模型的期望预测与真实结果的偏离程度",{"2":{"558":1}}],["偏差",{"2":{"501":1,"558":3}}],["偏好随着时间的改变会改变",{"2":{"730":1}}],["偏好构建可更直接依赖停留时间和评论质量",{"2":{"423":1}}],["偏好",{"2":{"423":2}}],["偏移系数β",{"2":{"314":1}}],["堆大小减",{"2":{"756":1}}],["堆的大小",{"2":{"756":1}}],["堆是一个完全二叉树",{"2":{"756":1}}],["堆进行介绍",{"2":{"756":1}}],["堆排",{"0":{"756":1}}],["堆排序的原理和实现",{"2":{"104":1}}],["堆排序",{"0":{"52":1},"2":{"754":1,"755":1,"764":1,"768":1}}],["堆",{"2":{"748":2,"754":1,"763":1,"768":1}}],["堆叠的方式",{"2":{"311":1}}],["早期的backbone设计都是直接堆叠卷积层",{"2":{"311":1}}],["神经网络在训练的时候随着网络层数的加深",{"2":{"351":1}}],["神经网络参数初始化方法",{"2":{"323":1}}],["神经网络中",{"2":{"346":1}}],["神经网络中的权重初始化一览",{"2":{"323":1}}],["神经网络中1×1卷积有什么作用",{"0":{"320":1}}],["神经网络中addition",{"0":{"318":1}}],["神经网络的结构可根据具体的任务进行相应的调整",{"2":{"343":1}}],["神经网络的优缺点",{"0":{"343":1}}],["神经网络的正则化方法",{"0":{"325":1}}],["神经网络的每层都会有一个激活函数",{"2":{"319":1}}],["神经网络的计算量和参数量估计总结",{"2":{"315":1}}],["神经网络的前向推理过程基本上都是乘累加计算",{"2":{"315":1}}],["神经网络的宽度决定了网络在某一层学习到的信息量",{"2":{"311":1}}],["神经网络的深度决定了网络的表达能力",{"2":{"311":1}}],["神经网络的深度和宽度分别指的是什么",{"0":{"311":1}}],["神经元的感受野越大",{"2":{"309":1}}],["神经元感受野的范围越大表示其接触到的原始图像范围就越大",{"2":{"309":1}}],["训练得到lr",{"2":{"741":1}}],["训练得到的词向量满足",{"2":{"718":1}}],["训练后可以在下游任务微调",{"2":{"707":1}}],["训练以后完以后",{"2":{"669":1}}],["训练n个分类器",{"2":{"662":1}}],["训练的时候就是每一个训练样本",{"2":{"657":1}}],["训练的时候只用一部分特征",{"2":{"507":1}}],["训练样本数据更新权重w",{"2":{"632":1}}],["训练集d",{"2":{"603":1}}],["训练集的子集",{"2":{"546":1}}],["训练集的在第k个弱学习器的输出权重为",{"2":{"428":1}}],["训练集",{"2":{"546":1}}],["训练速度快",{"2":{"663":1}}],["训练速度很快",{"2":{"545":1}}],["训练速度慢",{"2":{"545":1}}],["训练前预先将特征",{"2":{"510":1}}],["训练前每个特征按特征值进行排序并存储为block结构",{"2":{"506":1}}],["训练中没有缺失值而在预测中出现缺失",{"2":{"508":1}}],["训练rf和gbdt谁可以更快",{"2":{"497":1}}],["训练rpn",{"2":{"373":1}}],["训练rpn网络时",{"2":{"367":1}}],["训练将会过于偏向这类困难的样本",{"2":{"487":1,"488":1}}],["训练可以高度并行化",{"2":{"485":1}}],["训练下一个基学习器",{"2":{"456":1}}],["训练多个分类器",{"2":{"455":1,"458":1}}],["训练之前需要打乱数据集",{"2":{"446":1}}],["训练数据集构建",{"2":{"423":1}}],["训练阶段",{"2":{"423":1}}],["训练出的模型的方差小",{"2":{"485":1}}],["训练出一个n",{"2":{"718":1}}],["训练出一个",{"2":{"423":1}}],["训练出来的模型效果不稳定",{"2":{"422":1}}],["训练成本较高",{"2":{"423":1}}],["训练成本低",{"2":{"423":2}}],["训练过程为阶梯状",{"2":{"456":1}}],["训练过程区别",{"2":{"423":1}}],["训练过程是如何解决",{"2":{"423":1}}],["训练过程中不断更新负例集合",{"2":{"423":1}}],["训练过程中",{"0":{"349":1,"440":1},"2":{"423":2}}],["训练更简单",{"2":{"423":1}}],["训练复杂",{"2":{"423":1}}],["训练周期长",{"2":{"423":1}}],["训练稳定",{"2":{"423":1}}],["训练或微调阶段加入词表限制示例",{"2":{"423":1}}],["训练与推理",{"2":{"422":1}}],["训练效率也低很多",{"2":{"422":1}}],["训练时间复杂度为o",{"2":{"649":1}}],["训练时确定先验概率分布的参数",{"2":{"631":1}}],["训练时",{"2":{"597":1}}],["训练时长",{"2":{"423":2}}],["训练时加入安全指令或使用",{"2":{"423":1}}],["训练时引入了世界树",{"2":{"378":1}}],["训练时限制权值的大小",{"2":{"307":1}}],["训练模型只支持与训练图像相同的输入分辨率的图片",{"2":{"378":1}}],["训练fast",{"2":{"373":2}}],["训练",{"2":{"366":1,"618":1}}],["训练神经网络有哪些调参技巧",{"0":{"310":1}}],["卷积",{"2":{"388":1}}],["卷积进行通道变换得到",{"2":{"388":1}}],["卷积核",{"2":{"695":1}}],["卷积核的滑动窗在不同位置的权值是一样的",{"2":{"693":1}}],["卷积核的个数是与default",{"2":{"385":1}}],["卷积核尺寸远小于输入特征尺寸",{"2":{"693":1}}],["卷积核设定为3",{"2":{"385":1}}],["卷积核大小为3",{"2":{"357":3}}],["卷积3",{"2":{"357":1}}],["卷积2也无法达到卷积3的速度",{"2":{"357":1}}],["卷积2",{"2":{"357":1}}],["卷积1",{"2":{"357":1}}],["卷积实际速度与理论速度差距较大",{"0":{"357":1}}],["卷积神经网络发展历程",{"2":{"342":1}}],["卷积神经网络中用1",{"2":{"320":1}}],["卷积有什么作用或者好处呢",{"2":{"320":1}}],["卷积层输出",{"0":{"695":1}}],["卷积层是局部连接",{"2":{"329":1}}],["卷积层和全连接层的区别是什么",{"0":{"329":1}}],["卷积层及下采样层",{"2":{"313":1}}],["卷积层的感受野大小与其之前层的卷积核尺寸和步长有关",{"2":{"309":1}}],["卷积后的感受野为8",{"2":{"306":1}}],["卷积后的感受野为5",{"2":{"306":1}}],["卷积后的感受野为3",{"2":{"306":1}}],["语料库样本集对总体的代表性",{"2":{"521":1}}],["语言可以使用c++",{"2":{"769":1}}],["语言风格和固定任务表现",{"2":{"423":1}}],["语言生成与推理",{"2":{"423":1}}],["语义化元素是指元素本身传达了关于其内容类型的一些信息",{"2":{"775":1}}],["语义化元素是指�",{"0":{"775":1}}],["语义组块等方便精度很好",{"2":{"521":1}}],["语义文本相似度",{"2":{"423":1}}],["语义增强",{"2":{"423":1}}],["语义",{"2":{"422":1}}],["语义层次更高的特征信息",{"2":{"309":1}}],["语句",{"2":{"163":1}}],["语句是否有语法错误",{"2":{"163":1}}],["语句的前导模糊查询不能使用索�",{"2":{"169":1}}],["语句的执行计划",{"0":{"164":1}}],["语句的执行过�",{"0":{"163":1}}],["语句的关键元素",{"2":{"163":1}}],["语句�",{"2":{"163":1}}],["语句块来完成",{"2":{"137":1,"139":1}}],["感知机利用误分类最小策略",{"2":{"636":1}}],["感知",{"2":{"423":1}}],["感受野指的是卷积神经网络每一层输出的特征图上每个像素点映射回输入图像上的区域的大小",{"2":{"309":1}}],["感谢wbzhang233",{"2":{"85":2}}],["十种优化算法原理及实现",{"2":{"308":1}}],["动作等",{"2":{"730":1}}],["动词还是名词",{"2":{"527":1}}],["动量优化法",{"2":{"308":1}}],["动态负采样",{"2":{"423":1}}],["动态调用对应子体",{"2":{"423":1}}],["动态数据结构",{"2":{"99":1}}],["动态规划",{"2":{"100":1,"104":1,"106":1}}],["动态规划是面试中最常被问道的题",{"2":{"0":1}}],["动态规",{"0":{"0":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1}}],["深入了解公司业务",{"2":{"833":1}}],["深入理解lightgbm",{"2":{"473":1}}],["深入理解l1",{"2":{"330":1}}],["深入理解各种数据结构和算法的原理",{"2":{"105":1}}],["深度可分离卷积分成两部分",{"2":{"394":1,"395":1}}],["深度可分离卷积的参数量",{"2":{"395":1}}],["深度可分离卷积的flops",{"2":{"394":1}}],["深度可分离卷积的概念和作用",{"0":{"317":1}}],["深度可分离卷积中的卷积核都是单通道的",{"2":{"317":1}}],["深度可分离卷积将传统的卷积分两步进行",{"2":{"317":1}}],["深度卷积网络中如何进行上采样",{"2":{"312":1}}],["深度学习框架应用",{"2":{"845":1}}],["深度学习框架分布式训练总结",{"2":{"335":1}}],["深度学习等模型",{"2":{"560":1}}],["深度学习500问",{"2":{"556":1}}],["深度学习面试100题",{"2":{"358":1}}],["深度学习三十问",{"2":{"358":1}}],["深度学习六十问",{"2":{"358":1}}],["深度学习cv岗位面试基础问题总结",{"2":{"358":1}}],["深度学习损失函数大全",{"2":{"331":1}}],["深度学习为什么在计算机视觉领域这么好",{"0":{"327":1}}],["深度学习中batch",{"2":{"333":1}}],["深度学习中的batch的大小对学习效果有何影响",{"0":{"333":1},"2":{"333":1}}],["深度学习中的五种归一化",{"2":{"307":1}}],["深度学习中神经网络的几种权重初始化方法",{"2":{"323":1}}],["深度学习",{"2":{"320":1,"343":1,"346":1}}],["深度学习笔记",{"2":{"319":1}}],["深度学习领域最常用的10个激活函数",{"2":{"319":1}}],["深度学习调参技巧合集",{"2":{"310":1}}],["限",{"2":{"422":1}}],["限制",{"2":{"657":1}}],["限制树的节点个数",{"2":{"605":1}}],["限制树的高度",{"2":{"605":1}}],["限制正负样本比例为1",{"2":{"370":1}}],["限制网络训练时间",{"2":{"307":1}}],["限流",{"2":{"188":1}}],["随着大数据技术的快速发展",{"2":{"765":1}}],["随着反向索引的创建",{"2":{"763":1}}],["随着维度k的增大",{"2":{"651":1}}],["随着阈值t选取的不同",{"2":{"591":1}}],["随着样本量增加",{"2":{"573":1}}],["随着训练的进行学习率慢慢变大",{"2":{"346":1}}],["随着神经网络层数的加深",{"2":{"343":1}}],["随机存储也通常被认为快于顺序存储",{"2":{"763":1}}],["随机选择的中心会导致k",{"2":{"678":1}}],["随机选取取值范围内的任意数",{"2":{"543":1}}],["随机选取非匹配样本",{"2":{"423":1}}],["随机猜测",{"2":{"590":1}}],["随机删掉一半隐藏神经元导致网络结构已经不同",{"2":{"564":1}}],["随机删除观测数量足够多的类",{"2":{"336":1}}],["随机梯度下降用一个样本来梯度下降",{"2":{"545":1}}],["随机梯度下降法一次迭代一个样本",{"2":{"545":1}}],["随机梯度下降法仅仅用一个样本决定梯度方向",{"2":{"545":1}}],["随机梯度下降法",{"2":{"545":1}}],["随机梯度下降法中损失函数对应的是训练集中每个样本的粒度",{"2":{"545":1}}],["随机梯度下降伴随的一个问题是噪音较批量梯度下降要多",{"2":{"545":1}}],["随机梯度下降是通过每个样本来迭代更新一次",{"2":{"545":1}}],["随机梯度下降的求解思路如下",{"2":{"545":1}}],["随机梯度下降可避免这种问题",{"2":{"545":1}}],["随机梯度下降",{"2":{"545":2}}],["随机梯度下降相比全局梯度下降好处是什么",{"0":{"321":1}}],["随机梯度和批量梯度区别",{"0":{"545":1}}],["随机变量",{"2":{"519":1}}],["随机丢弃生成的决策树",{"2":{"497":1}}],["随机主要有两个点进行有放回的采样",{"2":{"492":1}}],["随机挑选了部分特征作为拆分特征",{"2":{"489":1}}],["随机地对袋外数据oob所有样本的特征x加入噪声干扰",{"2":{"483":1}}],["随机地选择一个特征子集",{"2":{"460":1}}],["随机特征保证基分类器的多样性",{"2":{"479":1}}],["随机森林对异常值不敏感",{"2":{"497":1}}],["随机森林为什么能够更鲁棒",{"2":{"497":1}}],["随机森林为什么不容易过拟合",{"0":{"477":1}}],["随机森林中基学习器的多样性不仅来自样本扰动",{"2":{"492":1}}],["随机森林中的每一颗树都是过拟合的",{"2":{"477":1}}],["随机森林",{"2":{"492":1}}],["随机森林按照所有树中少数服从多数树的分类值来决定因变量的预测值",{"2":{"489":1}}],["随机森林在训练每一棵树的时候",{"2":{"489":1}}],["随机森林是基于bagging的算法",{"2":{"489":1}}],["随机森林和adaboost算法都可以用来分类",{"2":{"489":1}}],["随机森林和朴素贝叶斯基础分类器组成",{"2":{"458":1}}],["随机森林的优缺点",{"0":{"485":1}}],["随机森林的随机性体现在哪里",{"0":{"476":1}}],["随机森林允许单个决策树使用特征的最大数量",{"2":{"484":1}}],["随机森林建立子树的数量",{"2":{"484":1}}],["随机森林将多棵决策树的结果进行投票后得到最终的结果",{"2":{"480":1}}],["随机森林通过引入随机性",{"2":{"477":1}}],["随机森林面试题",{"0":{"474":1},"1":{"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1,"482":1,"483":1,"484":1,"485":1,"486":1,"487":1,"488":1,"489":1}}],["随机森林属于bagging类的集成学习",{"2":{"461":1}}],["随机森林算法训练时主要需要调整哪些参数",{"0":{"484":1}}],["随机森林算法",{"2":{"455":1}}],["随机负采样",{"2":{"423":1}}],["随机裁剪",{"2":{"325":1}}],["随机初始化k个簇中心坐标",{"2":{"675":1}}],["随机初始化",{"2":{"323":1}}],["随机抑制网络中一部分神经元",{"2":{"307":1}}],["随后清空边界的另一侧内存",{"2":{"110":1}}],["增益意味着相应的特征对通过对模型中的每个树采取每个特征的贡献而计算出的模型的相对贡献",{"2":{"512":1}}],["增强了模型的低阶特征交互的能力",{"2":{"732":1}}],["增强了模型的扩展",{"2":{"516":1}}],["增强内容深度与多样性",{"2":{"423":1}}],["增强泛化能力",{"2":{"423":1}}],["增强中文语义",{"2":{"423":1}}],["增强信息交互",{"2":{"423":1}}],["增强判别能力",{"2":{"423":1}}],["增强回答连贯性",{"2":{"423":1}}],["增强可维护性",{"2":{"423":1}}],["增强模型对",{"2":{"423":1}}],["增强多样性",{"2":{"422":1}}],["增强通道层面上特征融合的信息",{"2":{"320":1}}],["增大偏差",{"2":{"461":1}}],["增大输入尺寸",{"2":{"385":1}}],["增大感受野的方法",{"0":{"324":1}}],["增加噪声",{"2":{"561":1}}],["增加新特征",{"2":{"560":1}}],["增加分错样本的权重",{"2":{"486":1}}],["增加max",{"2":{"484":1}}],["增加了",{"2":{"392":1}}],["增加了非线性表达",{"2":{"347":1}}],["增加了特征的数量",{"2":{"318":1}}],["增加参数对数据集的泛化能力",{"2":{"332":1}}],["增加信息的表达",{"2":{"318":1}}],["增加惩罚机制",{"2":{"307":1}}],["增加训练数据",{"2":{"307":1}}],["增样等",{"2":{"307":1}}],["怎么控制负载平衡",{"2":{"770":1}}],["怎么样直观的理解这种特征变化",{"2":{"739":1}}],["怎么样会打破双亲委派模型",{"0":{"156":1}}],["怎么理解分布式假设",{"2":{"725":1}}],["怎么从语言模型理解词向量",{"2":{"725":1}}],["怎么求原问题的解w∗",{"2":{"635":1}}],["怎么并行的",{"2":{"497":2,"513":1}}],["怎么修改可以提升网络小目标检出率",{"0":{"400":1}}],["怎么解决过拟合",{"0":{"561":1}}],["怎么解决欠拟合",{"0":{"560":1}}],["怎么解决",{"2":{"397":1,"741":1}}],["怎么做的映射",{"2":{"368":1}}],["怎么提升网络的泛化能力",{"0":{"354":1}}],["怎么计算",{"0":{"314":1,"315":1},"2":{"315":1}}],["怎么判断模型是否过拟合",{"0":{"307":1}}],["σ为权重矩阵体现对应特征提供的信息量",{"2":{"730":1}}],["σ为所有样本的标准差",{"2":{"306":1}}],["σij2",{"2":{"620":1}}],["σ2",{"2":{"620":1}}],["σ",{"2":{"306":1,"532":1,"537":1,"721":3}}],["μ总评分均值",{"2":{"729":1}}],["μ",{"2":{"306":1}}],["百面机器学习",{"2":{"305":1,"522":1,"529":1}}],["百度实习",{"0":{"390":1,"397":1,"399":1,"406":1,"407":1,"408":1,"411":1}}],["百度",{"2":{"41":1,"42":1,"54":1,"55":1,"56":1}}],["百度百科",{"2":{"0":1,"58":2,"59":2,"60":1,"84":1}}],["归一化需要遍历整个词汇表",{"2":{"725":1}}],["归一化",{"2":{"305":1}}],["归并最后得到结",{"2":{"763":1}}],["归并",{"2":{"104":1,"760":1,"763":1}}],["归并排序就可以了",{"2":{"748":1}}],["归并排序按照出现次数进行排序",{"2":{"748":1}}],["归并排序",{"0":{"53":1,"760":1},"2":{"755":1,"760":1}}],["标记一个点",{"2":{"590":1}}],["标记清�",{"2":{"110":1}}],["标注",{"2":{"527":1}}],["标注数据太少",{"2":{"422":1}}],["标签监听",{"2":{"796":1}}],["标签",{"2":{"776":1}}],["标签对齐常用方法有",{"2":{"423":1}}],["标签等元数据对结果进行二次排序和筛选",{"2":{"423":1}}],["标准卷积层的参数量",{"2":{"395":1}}],["标准卷积层的flops",{"2":{"394":1}}],["标准差为1",{"2":{"306":1}}],["标准差归一化",{"2":{"306":1}}],["标准化处理",{"2":{"544":1}}],["标准化",{"0":{"305":1},"2":{"305":1}}],["软中断是一些对i",{"2":{"301":1}}],["软引�",{"2":{"122":1}}],["软引用",{"0":{"122":1}}],["像磁盘",{"2":{"301":1}}],["段落",{"2":{"423":1}}],["段向用户提供二维地址空间",{"2":{"300":1}}],["段的大小不固定",{"2":{"300":1}}],["段是信息的逻辑单位",{"2":{"300":2}}],["注入领域数据",{"2":{"423":1}}],["注",{"0":{"365":1},"2":{"299":1,"431":1,"734":1}}],["注意的是对于出错的map任务",{"2":{"770":1}}],["注意到最大",{"2":{"759":1}}],["注意到最大化1∥w∥",{"2":{"635":1}}],["注意当k多大时",{"2":{"756":1}}],["注意去除重复的元素",{"2":{"751":1}}],["注意ip是32位",{"2":{"750":1}}],["注意会有一定的错误率",{"2":{"747":1}}],["注意时间t不能太大也不能太小",{"2":{"740":1}}],["注意如果计算一个评价很少电影的用户与一个评价很多电影的用户会导致相似度为0",{"2":{"730":1}}],["注意正反类必须特殊的设计",{"2":{"662":1}}],["注意这里没有考虑到泛型编程",{"2":{"756":1}}],["注意这里不是上文提高的p和r",{"2":{"590":1}}],["注意这里是样本的权重",{"2":{"486":1}}],["注意这里是分类器的权重",{"2":{"486":1}}],["注意要点",{"0":{"521":1,"527":1,"730":1}}],["注意并不是拟合梯度",{"2":{"515":1}}],["注意xgboost的并行不是树粒度的并行",{"2":{"513":1}}],["注意xgboost的并行不是tree粒度的并行",{"2":{"497":2,"505":1}}],["注意不是树维度的并行",{"2":{"504":1}}],["注意力权重变得不准确",{"2":{"422":1}}],["注意力优化有什么不同",{"2":{"422":1}}],["注意力层直接控制词元关联性",{"2":{"422":1}}],["注意力机制",{"2":{"688":1}}],["注意力机制的核心原理是通过动态权重分配",{"2":{"422":1}}],["注意力机制是如何计算上下文各个词元之间的相关性的",{"2":{"422":1}}],["注意此时idx为",{"2":{"397":1}}],["注意回归的不是坐标和宽高",{"2":{"367":1}}],["注意先进后出",{"2":{"85":1}}],["注意每个数字在数组中都有它自己的位置",{"2":{"81":1}}],["注意",{"2":{"77":1,"79":1,"81":1,"394":1,"527":1,"541":1}}],["注意空字符串可被认为是有效字符串",{"2":{"75":1}}],["注意s到s的距离是0",{"2":{"58":1}}],["注意序列的最小",{"2":{"10":1}}],["注意一下这个语句",{"2":{"4":1}}],["按岗位快速导航",{"0":{"844":1},"1":{"845":1,"846":1,"847":1,"848":1}}],["按paper以及kaggle竞赛中的gbdt+lr融合方式",{"2":{"741":1}}],["按数据的内在相似性将数据集划分为多个类别",{"2":{"674":1}}],["按梯度方向更新",{"2":{"545":1}}],["按照hash",{"2":{"748":1}}],["按照特征值进行排序",{"2":{"608":1}}],["按照处理离散值那样来选择最优的划分点",{"2":{"603":1}}],["按照模型的结果对每个样本进行打分",{"2":{"592":1}}],["按照我们对行业的分类",{"2":{"576":1}}],["按照一定的方法把这些弱分类器集合起来",{"2":{"487":1}}],["按照3个二进制位中每位是否为1分类",{"2":{"269":1}}],["按一定规则生成的anchor",{"2":{"367":1}}],["按fifo选择某一页面",{"2":{"299":1}}],["亦即在内存中驻留时间最久的页面",{"2":{"299":1}}],["页面就没法得到及时的更新",{"2":{"792":1}}],["页面布局和页面绘制都是运行在浏览器的主线程当中",{"2":{"792":1}}],["页面置换算法",{"0":{"299":1}}],["页脚或文档中的其他部分�",{"2":{"776":1}}],["页眉",{"2":{"776":1}}],["页的保护和共享受到限制",{"2":{"300":1}}],["页的大小固定",{"2":{"300":1}}],["页向用户提供的是一维地址空间",{"2":{"300":1}}],["页是信息的物理单位",{"2":{"300":1}}],["页之间跳转时",{"2":{"244":1}}],["银行家算法",{"2":{"298":2}}],["允许两边都可以有浮动对象",{"2":{"785":1}}],["允许用户标记相关或不相关照片",{"2":{"423":1}}],["允许模型检索多个相邻片段",{"2":{"423":1}}],["允许end",{"2":{"368":1}}],["允许我们对cnn中的feature",{"2":{"368":1}}],["允许进程强行抢占被其它进程占有的资源",{"2":{"297":1}}],["允许某些资源同时被多个进程访问",{"2":{"297":1}}],["破坏循环等待条件",{"2":{"297":1}}],["破坏不剥夺条件",{"2":{"297":1}}],["破坏请求与保持条件",{"2":{"297":1}}],["破坏互斥条件",{"2":{"297":1}}],["互动�",{"2":{"831":1}}],["互斥特征捆绑算法减少了特征数量",{"2":{"471":1}}],["互斥特征捆绑算法",{"2":{"468":1}}],["互斥特征捆绑",{"2":{"464":1}}],["互斥条件",{"2":{"296":1}}],["互补召回",{"2":{"423":1}}],["互联网控制消息协议",{"2":{"250":1}}],["互联网上应用最为广泛的一种网络协议",{"2":{"247":1}}],["死锁避免",{"0":{"298":1}}],["死锁预防",{"0":{"297":1}}],["死锁产生的必要条件",{"0":{"296":1}}],["死锁是指两个或两个以上的进程在执行过程中",{"2":{"295":1}}],["死锁",{"0":{"295":1},"1":{"296":1,"297":1,"298":1},"2":{"295":1}}],["僵尸进程",{"2":{"294":1}}],["僵尸进程和孤儿进程",{"0":{"294":1}}],["套接口也是一种进程间通信机制",{"2":{"293":1}}],["套接字",{"2":{"293":1}}],["配合数据增强",{"2":{"423":1}}],["配合使用",{"2":{"293":1}}],["配合读写分离",{"2":{"194":1}}],["共同完善这个面试知识库",{"2":{"849":1}}],["共需内存2^32",{"2":{"751":1}}],["共采集m次",{"2":{"475":1}}],["共采集t次",{"2":{"455":1}}],["共享内存是最快的",{"2":{"293":1}}],["共享内存就是映射一段能被其他进程所访问的内存",{"2":{"293":1}}],["共享内存",{"2":{"293":1}}],["共有3只蚂蚁",{"2":{"281":1}}],["信号驱动式",{"2":{"302":1}}],["信号是一种比较复杂的通信方式",{"2":{"293":1}}],["信号",{"2":{"293":1,"302":1}}],["信号量是一个计数器",{"2":{"293":1}}],["信号量",{"2":{"293":1}}],["信息增益比相对信息增益有什么好处",{"0":{"599":1}}],["信息摘要",{"2":{"423":1}}],["信息是明文传输",{"2":{"247":1}}],["信息",{"2":{"172":1}}],["匿名管道",{"2":{"293":1}}],["终止",{"2":{"292":1}}],["尚未进入就绪队列",{"2":{"292":1}}],["五个特征图",{"2":{"388":1}}],["五态模型",{"0":{"292":1}}],["五队夫妇甲",{"2":{"268":1}}],["处的hessian",{"2":{"555":1}}],["处作二阶泰勒展开",{"2":{"555":1}}],["处取得极值的必要条件是梯度为0",{"2":{"555":1}}],["处进",{"2":{"497":1}}],["处于运行状态的进程只有一个",{"2":{"291":1}}],["处于此状态的进程的数目小于等于处理器的数目",{"2":{"291":1}}],["处理分歧和冲突的能�",{"2":{"818":1}}],["处理本地的数据",{"2":{"769":1}}],["处理和操作等",{"2":{"768":1}}],["处理器等等资源的限制",{"2":{"763":1}}],["处理器会对代码乱序执行等带来的问题",{"2":{"140":1}}],["处理尾部",{"2":{"760":1}}],["处理包含连续型变量的数据",{"2":{"621":1}}],["处理缺失值",{"2":{"607":1}}],["处理优化",{"2":{"506":1}}],["处理主观偏好",{"2":{"423":1}}],["处理方式有什么区别",{"2":{"423":1}}],["处理每张图片所需的flops与许多因素有关",{"2":{"394":1}}],["处理每张图片所需的flops",{"2":{"394":1}}],["处理中断的驱动是需要运行在cpu上的",{"2":{"301":1}}],["处理异常",{"2":{"218":1}}],["处理完成",{"2":{"218":1}}],["处理失败的方�",{"2":{"217":1}}],["处理",{"2":{"130":1}}],["处理响应的时间�",{"2":{"109":1}}],["处理结尾",{"2":{"47":1}}],["协同过滤的方式有哪些",{"2":{"731":1}}],["协同过滤的优缺点",{"2":{"730":1}}],["协同过滤与关联规则的异同",{"2":{"730":1}}],["协同过滤失效",{"2":{"730":1}}],["协同过滤算法具有特征学习的特点",{"2":{"730":1}}],["协同过滤是与内容无关的推荐",{"2":{"730":1}}],["协同过滤是推荐算法中最常用的算法之一",{"2":{"727":1}}],["协同过滤是强相关性",{"2":{"625":1}}],["协同过滤",{"0":{"726":1},"1":{"727":1,"728":1,"729":1,"730":1,"731":1}}],["协程调度切换时",{"2":{"289":1}}],["协程拥有自己的寄存器上下文和栈",{"2":{"289":1}}],["协程的调度完全由用户控制",{"2":{"289":1}}],["协程是一种用户态的轻量级线程",{"2":{"289":1}}],["协程",{"0":{"289":1},"2":{"289":1}}],["协议记录稳定的状态信息成为了可能",{"2":{"244":1}}],["协议的设计可以让我们同时传递",{"2":{"237":1}}],["∗∏",{"2":{"612":1}}],["∗cout",{"2":{"394":2,"395":3}}],["∗hout∗wout∗cout",{"2":{"394":1}}],["∗h∗w∗cin",{"2":{"394":1}}],["∗h∗w∗cout",{"2":{"394":3}}],["∗",{"2":{"282":1,"382":2,"719":1,"722":1}}],["∗p",{"2":{"282":5,"612":2,"719":1,"722":4}}],["他们之间是互斥的关系",{"2":{"792":1}}],["他们都选择了",{"2":{"282":1}}],["他是满足堆的性质的",{"2":{"756":1}}],["他觉得不错",{"2":{"727":1}}],["他可以使用小白鼠试喝饮料",{"2":{"269":1}}],["蚂蚁可以绕任意边走",{"2":{"281":1}}],["蚂蚁爬三角形",{"0":{"281":1}}],["吃透空洞卷积",{"2":{"306":1}}],["吃",{"2":{"280":2}}],["吃苹果",{"0":{"280":1}}],["看其是否在刚才构建的hash",{"2":{"747":1}}],["看做是一种有监督的特征编码",{"2":{"739":1}}],["看的不是他是谁",{"2":{"576":1}}],["看起来0和1产生的概率都是1",{"2":{"279":1}}],["看不见自己的",{"2":{"267":2}}],["均",{"2":{"620":1}}],["均方根误",{"0":{"582":1}}],["均方误差mse",{"2":{"581":1}}],["均方误差",{"0":{"581":1}}],["均方差",{"2":{"484":1}}],["均为tensor",{"2":{"397":1}}],["均为p",{"2":{"278":1}}],["均值算法",{"2":{"396":1}}],["均不以零开头",{"2":{"83":1}}],["白",{"2":{"277":1}}],["白球各一个",{"2":{"277":1}}],["黄",{"2":{"277":1}}],["黄球",{"2":{"277":1}}],["颜色扰动",{"2":{"345":1}}],["颜色无红色",{"2":{"277":1}}],["颜色全排列是a",{"2":{"277":1}}],["颜色全不同",{"2":{"277":2}}],["颜色全相同的概率=8",{"2":{"277":1}}],["颜色全相同",{"2":{"277":1}}],["颜色不全相同的概率",{"2":{"277":1}}],["颜色不全相同",{"2":{"277":1}}],["女",{"2":{"276":1,"757":1}}],["女s",{"2":{"276":1}}],["男",{"2":{"276":1,"757":1}}],["男女比例",{"0":{"276":1}}],["假定所有的特征在数据集中的作用是同样重要和独立",{"2":{"614":1}}],["假定家庭数目为1",{"2":{"276":1}}],["假反",{"2":{"586":1}}],["假正例率",{"2":{"590":2}}],["假正",{"2":{"586":1}}],["假如最开始",{"2":{"542":1}}],["假如我们想得到未知函数",{"2":{"369":1}}],["假设小于2gb",{"2":{"763":1}}],["假设hash函数是随机的",{"2":{"748":1}}],["假设输入维度为",{"0":{"699":1}}],["假设输出随机变量构成马尔可夫随机",{"2":{"519":1}}],["假设只有一个特征",{"2":{"669":1}}],["假设label=",{"2":{"668":1}}],["假设数据集合可以分为k个簇",{"2":{"651":1}}],["假设找到了映射函数",{"2":{"635":1}}],["假设所有的",{"2":{"635":2}}],["假设连续变量服从某种概率分布",{"2":{"620":1}}],["假设在文本分类中",{"2":{"618":1}}],["假设样本的特征向量",{"2":{"631":1}}],["假设样本",{"2":{"612":1}}],["假设现在有样",{"2":{"612":1}}],["假设现在村子上的男女比例是1",{"2":{"276":1}}],["假设特征$a$有$v$个取值$",{"2":{"601":1}}],["假设前一个坐标点",{"2":{"590":1}}],["假设检验的核心是证伪",{"2":{"571":1}}],["假设检验是研究如何根据抽样后获得的样本来检查抽样前所作假设是否合理",{"2":{"571":1}}],["假设检验",{"2":{"571":1}}],["假设失活概率为",{"2":{"566":1}}],["假设的模型无法合理存在",{"2":{"559":1}}],["假设x∗是一个可行解",{"2":{"554":1}}],["假设x0为函数的驻点",{"2":{"551":1}}],["假设多元函数在点m的梯度为0",{"2":{"552":1}}],["假设函数为",{"2":{"545":1}}],["假设一个搜集函数",{"2":{"628":1}}],["假设一个二分类问题",{"2":{"502":1}}],["假设一个嵌入模型的训练语料主要由英文构成",{"2":{"423":1}}],["假设有两个特征高度相关",{"2":{"624":1}}],["假设有k个类别",{"2":{"497":1}}],["假设有一个数组",{"2":{"24":1,"25":1}}],["假设我们的语料是",{"2":{"719":1}}],["假设我们前一轮迭代得到的强学习器",{"2":{"493":1}}],["假设我们已知函数$",{"2":{"369":1}}],["假设随机森林中有n棵树",{"2":{"483":1}}],["假设",{"2":{"472":1}}],["假设你有一个包含",{"2":{"422":1}}],["假设两个目标靠的很近",{"2":{"397":1}}],["假设box1维度为",{"2":{"390":1}}],["假设第一是x",{"2":{"279":1}}],["假设三次依次是红",{"2":{"277":1}}],["假设从y中折一个a",{"2":{"274":1}}],["假设y",{"2":{"274":1}}],["假设a头上的数字是x",{"2":{"267":1}}],["假设背包的大小为m",{"2":{"4":1}}],["村子里没有生育出儿子的夫妻可以一直生育直到生出儿子为止",{"2":{"276":1}}],["村长决定颁布一条法律",{"2":{"276":1}}],["排名广告",{"2":{"593":1}}],["排除大部分小梯度的样本",{"2":{"467":1}}],["排除存在的可能性",{"2":{"274":1}}],["排入高优先级队列",{"2":{"291":1}}],["排入低优先级队列",{"2":{"291":1}}],["排列组合",{"0":{"275":1}}],["排序真的很重要吗",{"2":{"755":1}}],["排序的速度将是很快的",{"2":{"758":1}}],["排序的顺序不变",{"2":{"608":1}}],["排序的目的是让一组无序的对象变成有序",{"2":{"50":1}}],["排序与过滤",{"2":{"423":1}}],["排序搜索",{"2":{"106":1}}],["排序算法",{"2":{"100":1,"104":1}}],["排序之所以这么重要是因为排序是解决大部分问题的第一步",{"2":{"50":1}}],["排序在面试中很容易被问道",{"2":{"50":1}}],["排序",{"0":{"50":1,"755":1},"1":{"51":1,"52":1,"53":1,"54":1,"55":1,"56":1},"2":{"730":1,"754":1,"755":1,"768":1}}],["排序数组",{"2":{"41":1}}],["画出满足条件的面积a",{"2":{"274":1}}],["画出中的取值面积s",{"2":{"274":1}}],["折两次之后",{"2":{"274":1}}],["铅笔长度是1",{"2":{"274":1}}],["测试时如果只有一个分类器预测为正类",{"2":{"662":1}}],["测试阶段新样本同时交给所有的分类器",{"2":{"662":1}}],["测试集准确率判断决定剪枝",{"2":{"605":1}}],["测试集",{"2":{"307":1}}],["测量球半径",{"2":{"271":1}}],["测半径",{"0":{"271":1}}],["三个",{"2":{"705":1}}],["三个模型树的构造方式有所不同",{"2":{"497":1}}],["三个模型都是以决策树为支撑的集成学习框架",{"2":{"497":1}}],["三个臭皮匠赛过一个诸葛亮",{"2":{"487":1}}],["三个特征图",{"2":{"388":1}}],["三个特征图全部经过各自",{"2":{"388":1}}],["三个面积尺寸",{"2":{"367":1}}],["三个端点上有三只蚂蚁",{"2":{"281":1}}],["三面",{"0":{"365":1,"378":1,"389":1}}],["三种上采样方法",{"2":{"312":1}}],["三线性插值等",{"2":{"312":1}}],["三态模型",{"0":{"291":1}}],["三角形问题",{"0":{"274":1}}],["三",{"0":{"414":1},"2":{"270":1}}],["三次握手能够帮助通信双方获取初始化序列号",{"2":{"237":1}}],["三次握手",{"0":{"236":1},"1":{"237":1}}],["放低为近似线性可分",{"2":{"634":1}}],["放到左端",{"2":{"270":1}}],["放到代码块中",{"2":{"139":1}}],["放在天平左端",{"2":{"270":1}}],["放在天平两端",{"2":{"270":1}}],["放在另右端",{"2":{"270":1}}],["天平有两种情况",{"2":{"270":1}}],["取得要查找关键词的第二个字母",{"2":{"762":1}}],["取得要查找关键词的第一个字母",{"2":{"762":1}}],["取最大的ｋ个数",{"2":{"755":1}}],["取hash",{"2":{"749":1}}],["取反得到损失函数表达式",{"2":{"661":1}}],["取对",{"2":{"619":1}}],["取值越大",{"2":{"587":1,"588":1}}],["取值范围为",{"2":{"587":1,"588":1}}],["取值划分比较多的特征容易对rf的决策产生更大的影响",{"2":{"485":1}}],["取平均则有可能让一些相反的拟合互相抵消",{"2":{"564":1}}],["取平均的作用",{"2":{"564":1}}],["取消量化操作",{"2":{"369":1}}],["取三种不同的长宽比例",{"2":{"367":1}}],["取球问题",{"0":{"277":1}}],["取1234放在天平的左端",{"2":{"270":1}}],["取余即可",{"2":{"43":1}}],["坏鸡蛋",{"0":{"270":1}}],["记为b0",{"2":{"747":1}}],["记为a0",{"2":{"747":1}}],["记为d~",{"2":{"601":1}}],["记为erroob2",{"2":{"483":1}}],["记为erroob1",{"2":{"483":1}}],["记0",{"2":{"268":1}}],["记录是那个队列中的值",{"2":{"763":1}}],["记录下群组的用户体验数据和业务数据",{"2":{"570":1}}],["记录",{"2":{"174":1}}],["记录方式",{"2":{"173":1}}],["记录机制实现",{"2":{"133":1}}],["记录最大回文串长度并记录该串的",{"2":{"79":1}}],["记录最小值并且更新最有结果",{"2":{"24":1}}],["记录所有位�",{"2":{"43":1}}],["记录以i为起点的每个片段的终点j",{"2":{"31":1}}],["记录的过程中可以使用数组保存下来的已经计算好的值",{"2":{"18":1}}],["甲的选择是",{"2":{"282":1}}],["甲乙两个人答对一道题的概率分别为90",{"2":{"282":1}}],["甲太太握了几次手",{"2":{"268":1}}],["甲先生问其他人",{"2":{"268":1}}],["聚合效果好",{"2":{"423":1}}],["聚焦分错的样本",{"2":{"456":1}}],["聚焦",{"2":{"423":1}}],["聚类等方式",{"2":{"730":1}}],["聚类等多种应用场景",{"2":{"423":1}}],["聚类事先没有给出标签",{"2":{"683":1}}],["聚类和分类区别",{"0":{"683":1}}],["聚类和搜索等基础任务",{"2":{"422":1}}],["聚类是一种无监督学习对大量未知标注的数据集",{"2":{"674":1}}],["聚类算法几乎没有统一的评估指标",{"2":{"684":1}}],["聚类算法可以分为原型聚类",{"2":{"674":1}}],["聚类算法",{"0":{"674":1}}],["聚类",{"2":{"423":1}}],["聚类结果通常是凸形",{"2":{"422":1}}],["聚类结果对初始类簇中心的选取较为敏感",{"2":{"396":1}}],["聚类过程为无监督过程",{"2":{"396":1}}],["聚类与分类最大的区别在于",{"2":{"396":1}}],["聚会结束时",{"2":{"268":1}}],["聚簇索引就是按照每张表的主键构造一颗b+树",{"2":{"165":1}}],["聚簇索引和非聚簇索引的区别",{"0":{"165":1}}],["聚簇索�",{"2":{"161":1}}],["戊举行家庭聚会",{"2":{"268":1}}],["丁",{"2":{"268":1}}],["丙",{"2":{"268":1}}],["乙的选择是",{"2":{"282":1}}],["乙",{"2":{"268":1}}],["握手",{"0":{"268":1}}],["握手需要在客户和服务器之间交换三个tcp报文段",{"2":{"236":1}}],["尽管现在基于深度学习的检测器在精度方面已经远远超过了传统检测器",{"2":{"361":1}}],["尽然a说自己知道了",{"2":{"267":1}}],["尽量还原原始文档的上下文完整性",{"2":{"423":1}}],["尽量不要用常规思路",{"2":{"266":1}}],["尽量只扫描一遍",{"2":{"72":1}}],["问答",{"2":{"423":1}}],["问这道题正确的概率",{"2":{"282":1}}],["问蚂蚁不相撞的概率是多少",{"2":{"281":1}}],["问先抛者吃到苹果的概率是多少",{"2":{"280":1}}],["问a头上的字是多少",{"2":{"267":1}}],["问题准备",{"2":{"833":1}}],["问题识别",{"2":{"816":1}}],["问题解决",{"0":{"816":1},"2":{"838":1}}],["问题就转化为当时公共祖先问题",{"2":{"763":1}}],["问题的核心变成了如何构造log⁡p",{"2":{"719":1}}],["问题若涉及细节",{"2":{"423":1}}],["问题若偏向全局",{"2":{"423":1}}],["问题或数据片段",{"2":{"422":1}}],["问题在于当一个类别的观测数量极度稀少时该怎么做",{"2":{"336":1}}],["问题",{"0":{"146":1},"2":{"375":1,"651":1}}],["猜数字",{"0":{"267":1}}],["逻辑分析和系统思考能�",{"2":{"816":1}}],["逻辑斯特回归为什么要对特征进行离散化",{"0":{"664":1}}],["逻辑回归在训练的过程当中",{"0":{"669":1}}],["逻辑回归在线性回归的基础上",{"2":{"666":1}}],["逻辑回归有哪些应用",{"0":{"667":1}}],["逻辑回归和线性回归首先都是广义的线性回归",{"2":{"666":1}}],["逻辑回归中",{"2":{"665":1}}],["逻辑回归主要解决分类问题",{"2":{"665":1}}],["逻辑回归主要用来解决分类问题",{"2":{"659":1}}],["逻辑回归属于广义线性模型",{"2":{"664":1}}],["逻辑回归如何进行多分类",{"0":{"662":1}}],["逻辑回归的鲁棒性比线性回归的要好",{"2":{"666":1}}],["逻辑回归的输入是线性回归的输出",{"2":{"665":1}}],["逻辑回归的输出一般是离散的",{"2":{"665":1}}],["逻辑回归的优缺点",{"0":{"663":1}}],["逻辑回归的损失函数是二元分类的良好代理函数",{"2":{"670":1}}],["逻辑回归的损失函数是交叉熵损失函数",{"2":{"661":1}}],["逻辑回归的损失函数是什么",{"0":{"661":1}}],["逻辑回归的分类方式获得了",{"2":{"422":1}}],["逻辑回归相对来说模型更简单",{"2":{"641":1,"672":1}}],["逻辑合理性",{"2":{"423":1}}],["逻辑题目现在也是面试中常考的题目",{"2":{"266":1}}],["逻辑题目",{"0":{"266":1},"1":{"267":1,"268":1,"269":1,"270":1,"271":1}}],["逻辑上永不过�",{"2":{"188":1}}],["离测试样本越近",{"2":{"657":1}}],["离超平面最近的点",{"2":{"635":1}}],["离散化后的特征对异常数据有很强的鲁棒性",{"2":{"664":1}}],["离散化后可以进行特征交叉",{"2":{"664":1}}],["离散特征的增加和减少都很容易",{"2":{"664":1}}],["离散特征只会参与一次节点的建立",{"2":{"604":1}}],["离散特征建立直方图的过程",{"2":{"470":1}}],["离散值使用的gini指数",{"2":{"497":1}}],["离散数学",{"2":{"265":1}}],["离开环境",{"2":{"110":1}}],["网格搜索和随机搜索",{"2":{"628":1}}],["网民的点击行为会随着时间改变",{"2":{"546":1}}],["网络结构",{"0":{"697":1}}],["网络通信优化",{"2":{"497":1}}],["网络的loss使用focal",{"2":{"387":1}}],["网络的非线性程度愈来愈高",{"2":{"343":1}}],["网络中default",{"2":{"385":1}}],["网络替换selective",{"2":{"376":1}}],["网络",{"2":{"367":1,"387":1}}],["网络进行",{"2":{"366":1}}],["网络无法更新",{"2":{"322":1}}],["网络就开始出现过拟合现象",{"2":{"307":1}}],["网络协议",{"2":{"263":1}}],["网卡",{"2":{"301":1}}],["网状模型",{"2":{"256":1}}],["待续",{"2":{"258":1}}],["往往意味着数据结构巨大变动",{"2":{"258":1}}],["功能拆分",{"2":{"423":1}}],["功能的增加",{"2":{"258":1}}],["功能限制",{"2":{"135":1}}],["微任务开始前�",{"2":{"793":1}}],["微调策略",{"2":{"423":1}}],["微调时重点加强中文下游任务",{"2":{"423":1}}],["微调",{"2":{"423":2,"707":1,"710":1}}],["微调fast",{"2":{"373":1}}],["微博上的褒贬情绪",{"2":{"625":1}}],["微博",{"2":{"258":1}}],["微软",{"0":{"70":1,"71":1},"2":{"69":1}}],["强健性",{"2":{"451":1}}],["强分类器f",{"2":{"431":1}}],["强化推理路径的迁移",{"2":{"423":1}}],["强化学习方法",{"2":{"423":1}}],["强化学习从人类反馈",{"2":{"423":1}}],["强化合规输出",{"2":{"423":1}}],["强化简洁对话风格",{"2":{"423":1}}],["强化了基础网络",{"2":{"375":1}}],["强语言模型负责推理与表达",{"2":{"423":1}}],["强调关键信息和亮点",{"2":{"831":1}}],["强调了包括低阶和高阶的特征交互接下来直接对deepfm模型架构进行介绍",{"2":{"732":1}}],["强调词在该主题下的重要性",{"2":{"422":1}}],["强调key",{"2":{"258":1}}],["强引�",{"2":{"122":1}}],["强引用",{"0":{"122":1}}],["遵循数据库的设计原则",{"2":{"258":1}}],["易于模型的快速迭代",{"2":{"664":1}}],["易于分布式部署",{"2":{"423":1}}],["易于纠错与重试",{"2":{"423":1}}],["易于实现和理解",{"2":{"422":1}}],["易于实现和维护",{"2":{"233":1}}],["易于维护",{"2":{"258":1}}],["行为面试重在展现真实的自己",{"2":{"840":1}}],["行为面试核心评估维度",{"0":{"813":1},"1":{"814":1,"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1}}],["行为面试是评估候选人软技能",{"2":{"807":1}}],["行为面试",{"0":{"807":1},"1":{"808":1,"809":1,"810":1,"811":1,"812":1,"813":1,"814":1,"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1,"823":1,"824":1,"825":1,"826":1,"827":1,"828":1,"829":1,"830":1,"831":1,"832":1,"833":1,"834":1,"835":1,"836":1,"837":1,"838":1,"839":1,"840":1}}],["行为不同的话就是两类人",{"2":{"576":1}}],["行内级格式化上下文",{"2":{"784":1}}],["行内级盒子",{"2":{"784":1}}],["行内盒子",{"2":{"784":1}}],["行高以及顶和底边距都可设置",{"2":{"774":1}}],["行业文档",{"2":{"423":1}}],["行程规划",{"2":{"423":1}}],["行动",{"2":{"423":1,"829":1}}],["行人检测领域有些问题",{"2":{"399":1}}],["行可以唯一区分",{"2":{"257":1}}],["行指针",{"2":{"165":1}}],["平方误差将会偏大",{"2":{"685":1}}],["平方误差和的公式如下",{"2":{"682":1}}],["平方损失",{"2":{"331":1}}],["平均",{"2":{"622":1}}],["平均绝对误差mae",{"2":{"580":1}}],["平均绝对误差",{"0":{"580":1}}],["平均池化可能被无关词或停用词干扰",{"2":{"423":1}}],["平均准确度均值",{"2":{"393":1}}],["平稳",{"2":{"346":1}}],["平衡准确性与多样性",{"2":{"423":1}}],["平衡",{"2":{"270":2,"422":1}}],["平衡或不平衡",{"2":{"270":2}}],["平衡二叉",{"0":{"87":1}}],["平面模型",{"2":{"256":1}}],["半结构化模型",{"2":{"256":1}}],["询问是否继续访问",{"2":{"252":1}}],["确保下一层用户的随机性",{"2":{"572":1}}],["确保质量",{"2":{"423":1}}],["确保输出既简洁又合规",{"2":{"423":1}}],["确保输出质量",{"2":{"423":1}}],["确保训练数据符合国内法规和平台安全规范",{"2":{"423":1}}],["确保语义相关的图文能相互识别",{"2":{"423":1}}],["确保上下文长度控制在合理范围内",{"2":{"423":1}}],["确认其为正确预测",{"2":{"397":1}}],["确认证书有效和此证书是此网站的",{"2":{"252":1}}],["确定优化模型的假设函数及损失函数",{"2":{"543":1}}],["确定一点每一对夫妇一定会有一个人和其他夫妇握手",{"2":{"268":1}}],["确定y",{"2":{"267":1}}],["确定是否已经初始化",{"2":{"58":1}}],["确定c的位数是1的位置�",{"2":{"43":1}}],["攻击者由于没有私钥",{"2":{"252":1}}],["私钥负责解密",{"2":{"252":1}}],["密度聚类",{"2":{"674":1}}],["密度都是连续值",{"2":{"600":1}}],["密度判断可能失效",{"2":{"422":1}}],["密钥在传输过程中可能会被窃取",{"2":{"252":1}}],["密集型任务线程并不是一直在执行任务",{"2":{"131":1}}],["密集型任务尽可能的少的线程数量",{"2":{"131":1}}],["密集型的任务",{"2":{"109":1}}],["密集的意思是该任务需要大量的运算",{"2":{"131":1}}],["密集�",{"2":{"109":1,"131":2}}],["报头简单",{"2":{"251":1}}],["报头比",{"2":{"251":1}}],["报头选项",{"2":{"251":1}}],["选拐点处的k值",{"2":{"677":1}}],["选用高斯核的",{"2":{"640":1}}],["选用的激活函数等等",{"2":{"394":1}}],["选出最相似几个用户",{"2":{"730":1}}],["选出距离最近的一组或几组",{"2":{"651":1}}],["选出置信度最高的预测框",{"2":{"397":1}}],["选出了分类辨识度更好的特征",{"2":{"339":1}}],["选取其中的n",{"2":{"545":1}}],["选取其大于等于这些recall值时的precision最大值",{"2":{"393":1}}],["选取最优分割点",{"2":{"475":1}}],["选取最大的a个数据",{"2":{"467":1}}],["选取误差最小的anchor",{"2":{"381":1}}],["选取可能包含物体的区域",{"2":{"361":1}}],["选取感兴趣区域",{"2":{"361":1}}],["选项",{"2":{"251":1}}],["选择排序",{"2":{"755":1}}],["选择的范围更为宽阔",{"2":{"730":1}}],["选择",{"2":{"730":1}}],["选择a∗的一个分量满",{"2":{"635":1}}],["选择惩罚参数c",{"2":{"635":1}}],["选择惩罚参数",{"2":{"635":1}}],["选择合适的映射函数",{"2":{"635":2}}],["选择概率最大的类别",{"2":{"615":1}}],["选择损失函数最小化的初值",{"2":{"544":1}}],["选择了一个总是最优",{"2":{"515":1}}],["选择增益最大的枚举项即为最优缺省方向",{"2":{"508":1}}],["选择树结构和在树结构固定后计算叶子节点的值",{"2":{"449":1}}],["选择其中最好的",{"2":{"446":1}}],["选择使用特殊词元而非平均池化作为句子表征",{"2":{"423":1}}],["选择与正样本相似度较高但不匹配的样本",{"2":{"423":1}}],["选择适合的网络结构",{"2":{"343":1}}],["选择以后永不使用的或者是在最长时间内不再被访问的页面",{"2":{"299":1}}],["选择0",{"2":{"119":1}}],["选择一个小权重的边",{"2":{"59":1}}],["选择一个不在mstset中",{"2":{"59":1}}],["选择最小距离的替换",{"2":{"58":1}}],["选择当前能到达点的最小距离的点u",{"2":{"58":1}}],["选择两个候选集�",{"2":{"42":1}}],["碎片可选",{"2":{"251":1}}],["路由器",{"2":{"423":1}}],["路由器工作原理",{"2":{"250":1}}],["路由器是如何转发的",{"0":{"250":1}}],["路由表的工作原理",{"0":{"250":1}}],["路径长度相同",{"2":{"167":1}}],["路径起点跟终点可以为二叉树的任意节点",{"2":{"94":1}}],["域名解析服务器地址",{"2":{"249":1}}],["身份认证的网络协议",{"2":{"247":1}}],["证书中包含公钥",{"2":{"247":1}}],["与产品",{"2":{"838":1}}],["与朋友或同事进行模拟练�",{"2":{"835":1}}],["与岗位要求和公司文化相�",{"2":{"830":1}}],["与不同背景的人有效协作",{"0":{"818":1}}],["与wide",{"2":{"734":1}}],["与dcn不同的是",{"2":{"732":1}}],["与查询点的距离排序",{"2":{"651":1}}],["与q的超球面相交的超矩形",{"2":{"651":1}}],["与roc曲线相似",{"2":{"592":1}}],["与随机森林类似",{"2":{"504":1}}],["与此同时",{"2":{"467":1}}],["与文档风格对齐",{"2":{"423":1}}],["与传统",{"2":{"422":1}}],["与传统的",{"2":{"422":1}}],["与",{"2":{"422":1,"423":1,"702":1,"725":1}}],["与分组查询注意力",{"2":{"422":1}}],["与键向量",{"2":{"422":1}}],["与上下文相关的嵌入",{"2":{"422":1}}],["与大模型产生的上下文相关的嵌入相比",{"2":{"422":1}}],["与其他特征相比",{"2":{"512":1}}],["与其他通信机制不同的是",{"2":{"293":1}}],["与其余各框的iou",{"2":{"397":1}}],["与尺度",{"2":{"372":2}}],["与padding无关",{"2":{"309":1}}],["与首部行之间有",{"2":{"246":1}}],["与多线程同步",{"0":{"109":1}}],["符号的本来作用是加在",{"2":{"798":1}}],["符号定义",{"2":{"729":1}}],["符号被扭转",{"2":{"663":1}}],["符号式编程",{"2":{"334":1}}],["符",{"2":{"246":1}}],["永久重定向",{"2":{"245":1}}],["永远不能释放进入环境的变量所占用的内存",{"2":{"110":1}}],["通俗地",{"2":{"560":1}}],["通用科研能力",{"2":{"423":1}}],["通用顶级域名",{"2":{"249":1}}],["通信梯度是指平均梯度",{"0":{"335":1}}],["通道数",{"2":{"392":1}}],["通道数不变",{"2":{"392":1}}],["通道数都是",{"2":{"388":1}}],["通道数可以不同",{"2":{"318":1}}],["通道越多效果越好",{"2":{"311":1}}],["通常由hr或用人部门负责人进行",{"2":{"807":1}}],["通常都是以经验选取",{"2":{"677":1}}],["通常可获得比单一学习器更良好的泛化性能",{"2":{"425":1}}],["通常针对类别不平衡问题可以从调整样本数或修改loss",{"2":{"370":1}}],["通常来讲",{"2":{"339":1}}],["通常在轻量级的网络中会用到",{"2":{"320":1}}],["通常用flops来表示",{"2":{"315":1}}],["通常有哪些方式",{"0":{"313":1}}],["通常的结构设计中卷积核的数量随着层数越来越多的",{"2":{"311":1}}],["通常会划分训练集",{"2":{"307":1}}],["通常会自动执行系统的空闲进程",{"2":{"291":1}}],["通常为i",{"2":{"301":1}}],["通常",{"2":{"244":1,"251":1,"301":1,"651":1}}],["通过具体的例子展示自己的能力和品质�",{"2":{"840":1}}],["通过练习和准备减少紧�",{"2":{"834":1}}],["通过哈希函数",{"2":{"770":1}}],["通过哈希码先判断对象是否有可能相同",{"2":{"124":1}}],["通过一趟排序将要排序的数据分割成独立的两部分",{"2":{"757":1}}],["通过一个共享矩阵",{"2":{"718":1}}],["通过隐向量的引入使得fm模型更好的去处理数据稀疏行的问题",{"2":{"735":1}}],["通过隐状态传递信息",{"2":{"527":1}}],["通过矩阵分解的方式进行特征学习",{"2":{"730":1}}],["通过定义两套词向量",{"2":{"725":1}}],["通过负采样减少负样本数量",{"2":{"719":1}}],["通过将所有不合法连接",{"2":{"702":1}}],["通过绘制k和损失函数的关系图",{"2":{"677":1}}],["通过迭代的方式",{"2":{"675":1}}],["通过有监督的学习",{"2":{"654":2}}],["通过高斯分布估计出类条件概率",{"2":{"620":1}}],["通过求对数可以避免下溢出或者浮点数舍入导致的错误",{"2":{"619":1}}],["通过剪枝算法解决过拟合",{"2":{"600":1}}],["通过最大化gini或者其他指标来寻找最佳分裂",{"2":{"597":1}}],["通过改变不同阈值",{"2":{"592":1}}],["通过比对损失来确定最佳切分点",{"2":{"514":1}}],["通过目标变量统计等特征编码方式也能实现类别特征的高效处理",{"2":{"497":1}}],["通过构建并结合多个学习器",{"2":{"425":1}}],["通过构造方法new",{"2":{"139":1}}],["通过sft让模型学习规范化推理表达",{"2":{"423":1}}],["通过人工审核和自动检测工具",{"2":{"423":1}}],["通过聚类或最近邻检索自动挑选未标注数据中与标注样本相似的文本",{"2":{"423":1}}],["通过领域知识筛选容易混淆的样本",{"2":{"423":1}}],["通过少量",{"2":{"423":1}}],["通过重构问题",{"2":{"423":1}}],["通过这些方式",{"2":{"423":1}}],["通过这个t和anchor",{"2":{"367":1}}],["通过共享存储",{"2":{"423":1}}],["通过提问展示思考深�",{"2":{"811":1}}],["通过提供标准分类示例",{"2":{"422":1}}],["通过提示词工程引导模型",{"2":{"422":1}}],["通过系统",{"2":{"422":1}}],["通过正则化或增加主题间距离约束",{"2":{"422":1}}],["通过专为",{"2":{"422":1}}],["通过增量计算softmax",{"2":{"422":1}}],["通过优化内存访问方式",{"2":{"422":1}}],["通过利用",{"2":{"422":1}}],["通过并行计算多个注意力头",{"2":{"422":1}}],["通过计算gini系数的减少量vim=gi",{"2":{"462":1}}],["通过计算",{"2":{"422":1,"521":1}}],["通过生成更加密集的旋转anchor",{"2":{"404":1}}],["通过输入更大",{"2":{"402":1}}],["通过卷积操作",{"2":{"386":1}}],["通过卷积网络获取feature",{"2":{"386":1}}],["通过在所有的bounding",{"2":{"381":1}}],["通过resnext",{"2":{"375":1}}],["通过前处理统一尺寸输入到",{"2":{"366":1}}],["通过filter获得局部特征",{"2":{"355":1}}],["通过限制最大叶子节点数",{"2":{"484":1}}],["通过限制",{"2":{"330":1}}],["通过对输入feature",{"2":{"312":1}}],["通过调整扩张率得到不同的感受野不大小",{"2":{"306":1}}],["通过调整定时扫描的时间间隔和每次扫描的限定耗时",{"2":{"201":1}}],["通过内核和用户空间共享内存",{"2":{"302":1}}],["通过从服务器发送到psync命令给主服务�",{"2":{"194":1}}],["通过多个从节点分担读负载",{"2":{"194":1}}],["通过多次回合之后",{"2":{"27":1}}],["通过子进程执行一次fsync",{"2":{"193":1}}],["通过此在释放锁的时候进行判断",{"2":{"184":1}}],["通过追加的方式记录",{"2":{"173":1}}],["通过使用mysqlbinlog工具来恢复数�",{"2":{"172":1}}],["通过辅助索引首先找到的是主键值",{"2":{"165":1}}],["通过主键聚集数据",{"2":{"165":1}}],["通过分析器进行词法分析",{"2":{"163":1}}],["通过循环调用",{"2":{"138":1}}],["通过",{"2":{"136":1,"139":1,"184":1,"423":1,"792":2,"800":1}}],["通过leetcode等平台进行大量练习",{"2":{"105":1}}],["刚开始发送数据时",{"2":{"243":1}}],["连接",{"2":{"693":1}}],["连接的每一方都有固定大小的缓冲空间",{"2":{"241":1}}],["连续特征a",{"2":{"603":1}}],["连续的特征离散化",{"2":{"600":1}}],["连续arq协议",{"2":{"242":1}}],["拥塞避免",{"2":{"243":1}}],["拥塞窗口加一",{"2":{"243":1}}],["拥塞窗口的大小就会加倍",{"2":{"243":1}}],["拥塞窗口表明了网络的传送能力",{"2":{"242":1}}],["拥塞控制",{"2":{"241":1}}],["拥有股票",{"2":{"26":1}}],["利用快速",{"2":{"748":1}}],["利用该映射关系对未知的数据进行预估",{"2":{"654":2}}],["利用这个信息来更新目标函数的先验分",{"2":{"628":1}}],["利用这个平移量",{"2":{"372":1}}],["利用贝叶斯公式转换成后验概率",{"2":{"615":1}}],["利用分类指标",{"2":{"605":1}}],["利用归纳算法生成可读的规则和决策树",{"2":{"597":1}}],["利用用户的唯一标识的尾号或者其他标识进行分类",{"2":{"572":1}}],["利用投票",{"2":{"459":1}}],["利用one",{"2":{"446":1}}],["利用人类反馈强化训练",{"2":{"423":1}}],["利用知识蒸馏与任务蒸馏结合",{"2":{"423":1}}],["利用大模型r1生成带有推理过程的高质量",{"2":{"423":1}}],["利用外部案例库和事实知识补充模型知识盲点",{"2":{"423":1}}],["利用平均停留时长作为用户偏好的间接信号",{"2":{"423":1}}],["利用困惑度",{"2":{"423":1}}],["利用少量标注样本",{"2":{"423":1}}],["利用对抗生成方法制造与正样本高度相似但标签不同的样本",{"2":{"423":1}}],["利用现有模型检索出与正样本最相似的错误匹配项",{"2":{"423":1}}],["利用多语言词表或添加中文词汇扩展词表",{"2":{"423":1}}],["利用多个负样本",{"2":{"423":1}}],["利用多层feature",{"2":{"400":1}}],["利用高效的向量数据库",{"2":{"423":1}}],["利用",{"2":{"423":1}}],["利用无标签数据做伪标签增强",{"2":{"422":1}}],["利用第一步的rpn生成的region",{"2":{"373":1}}],["利用候选框在之前送到的feature",{"2":{"373":1}}],["利用后接的非线性激活函数",{"2":{"320":1}}],["利用滑动窗口实现流量控制",{"2":{"241":1}}],["利用f",{"2":{"31":1}}],["流程",{"2":{"635":1}}],["流量有限",{"2":{"573":1}}],["流量控制",{"2":{"241":1}}],["流控�",{"0":{"216":1},"1":{"217":1,"218":1}}],["校招前端面试常见问题",{"0":{"780":1},"1":{"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1}}],["校招前端面试常见问题�",{"0":{"107":1,"788":1},"1":{"108":1,"109":1,"110":1,"111":1,"112":1,"113":1,"114":1,"789":1,"790":1,"791":1,"792":1,"793":1,"794":1,"795":1,"796":1,"797":1,"798":1,"799":1,"800":1}}],["校验和",{"2":{"241":1}}],["电子邮件",{"2":{"240":1}}],["面对拒绝和挫折的韧�",{"0":{"840":1}}],["面对新技术和新领域的学习能力",{"2":{"815":1}}],["面对长篇小说超过上下文限制的问题",{"2":{"423":1}}],["面向对象模型",{"2":{"256":1}}],["面向字节流",{"2":{"240":1}}],["面向报文",{"2":{"240":1}}],["面向连接的协议",{"2":{"240":1}}],["面试准备是一个系统工程",{"2":{"850":1}}],["面试准备建议",{"0":{"105":1,"832":1},"1":{"833":1,"834":1,"835":1,"836":1}}],["面试技巧",{"0":{"841":1},"1":{"842":1,"843":1}}],["面试当天",{"0":{"836":1}}],["面试前的心理建�",{"2":{"811":1}}],["面试者往往需要收集方方面面的资料进行知识体系的巩固�",{"2":{"765":1}}],["面试与算法心得",{"2":{"764":1}}],["面试问题",{"0":{"763":1}}],["面试十问",{"0":{"741":1}}],["面试相关",{"0":{"738":1}}],["面试题目",{"0":{"746":1},"1":{"747":1,"748":1,"749":1,"750":1,"751":1,"752":1}}],["面试题",{"2":{"358":1}}],["面试后总结的常见问题合集下",{"2":{"358":1}}],["面试人员是否逻辑清晰",{"2":{"266":1}}],["面试真题",{"0":{"248":1,"498":1,"528":1,"731":1,"742":1},"1":{"249":1,"250":1,"251":1,"252":1},"2":{"644":1}}],["面试官主要是考查候选人的算法基本工",{"2":{"51":1}}],["面试官很喜欢出动态规划的题目",{"2":{"17":1}}],["面试中最常见的就是围绕数组进行出题",{"2":{"39":1}}],["面试的时候面试官一般不会出贪心算法",{"2":{"17":1}}],["故考虑为每个ad",{"2":{"741":1}}],["故存在一个2阶交互",{"2":{"732":1}}],["故只需找到一组解满足kkt条件",{"2":{"635":1}}],["故该问题的解与kkt条件为充分必要的关系",{"2":{"635":1}}],["故可直接求解",{"2":{"635":1}}],["故原问题等价",{"2":{"635":1}}],["故最优化问题可转化为",{"2":{"635":1}}],["故事梗概",{"2":{"423":1}}],["故称该进程处于阻塞状态",{"2":{"291":1}}],["故需要四次挥手",{"2":{"239":1}}],["故障恢复",{"2":{"194":1}}],["我给出一张图片来表示这个过程",{"2":{"769":1}}],["我一直相信一句话",{"2":{"755":1}}],["我想检查分得的群体之间是否确实有差异",{"2":{"684":1}}],["我会综合使用摘要机制与rag",{"2":{"423":1}}],["我会采用",{"2":{"423":1}}],["我采用混合检索架构",{"2":{"423":1}}],["我通常采用以下策略",{"2":{"423":1}}],["我记得我测得结果大概是快10倍左右",{"2":{"357":1}}],["我也知道了",{"2":{"267":1}}],["我也不知道",{"2":{"267":1}}],["我知道了",{"2":{"267":1}}],["我不知道",{"2":{"267":1}}],["我才能发送fin报文",{"2":{"239":1}}],["我们把复杂的任务分片在浏览器空闲的时间执行",{"2":{"792":1}}],["我们很容易想到一�",{"2":{"792":1}}],["我们现在就可以认为之前已经",{"2":{"769":1}}],["我们现在给出几道常见的概率问题",{"2":{"273":1}}],["我们叫做merge",{"2":{"769":1}}],["我们叫做map",{"2":{"769":1}}],["我们叫做reduce",{"2":{"769":1}}],["我们叫做input",{"2":{"769":1}}],["我们常用到的有归并排序",{"2":{"769":1}}],["我们常常处理的数据都具有高维的特点",{"2":{"651":1}}],["我们这里使用位图排序",{"2":{"763":1}}],["我们有大数据处理的经验都知道",{"2":{"763":1}}],["我们有buckets",{"2":{"763":1}}],["我们有更多的选择可以考虑",{"2":{"484":1}}],["我们之前也有介绍过",{"2":{"762":1}}],["我们划分的时候保证buckets",{"2":{"758":1}}],["我们只需要关注业务",{"2":{"769":1}}],["我们只需要用分隔符空格将key和values分开",{"2":{"769":1}}],["我们只需要才有划分思想就ok了",{"2":{"757":1}}],["我们只有1m内存空间",{"2":{"763":1}}],["我们只考虑",{"2":{"33":1}}],["我们不在使用堆的数据结构",{"2":{"756":1}}],["我们不希望从这个状态进行转",{"2":{"26":1}}],["我们为什么要维护一",{"2":{"756":1}}],["我们始终维护堆的数据结构",{"2":{"756":1}}],["我们也可以直接排",{"2":{"755":1}}],["我们就可以只使用计算排序中的记录函数",{"2":{"759":1}}],["我们就可以采用trie树",{"2":{"748":1}}],["我们就知道每一个anchor",{"2":{"381":1}}],["我们首先将c",{"2":{"721":1}}],["我们通常使用一个指定长度的窗口",{"2":{"719":1}}],["我们通过e",{"2":{"227":1}}],["我们希望得到簇内数据相似度尽可能地大",{"2":{"684":1}}],["我们使用一个位图来表示所有的数据范围",{"2":{"759":1}}],["我们使用mle作估计",{"2":{"668":1}}],["我们使用拷贝现有样本的方法随机增加观测数量",{"2":{"336":1}}],["我们假设分类的阈值是0",{"2":{"660":1}}],["我们先来看一下原始kd",{"2":{"651":1}}],["我们的属性值就是关键字",{"2":{"761":1}}],["我们的目标是通过中心词来预测上下文",{"2":{"722":1}}],["我们的目标是通过上下文来预测中心词",{"2":{"719":1}}],["我们的目的是给出最常见的关于排序的面试题目",{"2":{"50":1}}],["我们的目的是留下一只猫",{"2":{"27":1}}],["我们的方法是把目标函数和约束全部融入一个新的函数",{"2":{"637":1}}],["我们称这类样本为支持向量",{"2":{"635":1}}],["我们称字符",{"2":{"32":1}}],["我们看到",{"2":{"621":2}}],["我们对于长度为n的数组a",{"2":{"756":1}}],["我们对事件y$发生的一个概率的重新评估",{"2":{"613":1}}],["我们对事件发生之后",{"2":{"613":1}}],["我们对这类人的分类是",{"2":{"576":1}}],["我们根据以往经验和分析对事件y$发生的一个概率的判断",{"2":{"613":1}}],["我们根据以往经验和分析对事件发生之前",{"2":{"613":1}}],["我们根据区间的结束使用升序排序",{"2":{"20":1}}],["我们一般会先搭建hadoop环境",{"2":{"769":1}}],["我们一般是通过启发式方法",{"2":{"607":1}}],["我们一个一个来分析",{"2":{"270":1}}],["我们发现埋点埋错了",{"2":{"575":1}}],["我们想要样本量越多的越好",{"2":{"573":1}}],["我们想用图片分类问题确定一个稀有物种",{"2":{"336":1}}],["我们用相同的训练数据去训练5个不同的神经网络",{"2":{"564":1}}],["我们用动态规划的思想来解决这个问题",{"2":{"26":1}}],["我们在一座大山上的某处位置",{"2":{"542":1}}],["我们在bundle中绑定了两个特征a和b",{"2":{"469":1}}],["我们都会重新注入对应的组件",{"2":{"798":1}}],["我们都知道在这种情况下",{"2":{"502":1}}],["我们都不会介绍",{"2":{"50":1}}],["我们知道当只有一个元素的时候",{"2":{"756":1}}],["我们知道lr之前在广告和推荐系统由于其快速的计算",{"2":{"739":1}}],["我们知道朴素贝叶斯",{"2":{"521":1}}],["我们知道",{"2":{"497":2,"505":1,"513":2,"719":1}}],["我们本轮迭代的目标是找到一个cart回归树模型的弱学习器",{"2":{"493":1}}],["我们仿照多分类的逻辑回归",{"2":{"472":1}}],["我们统计了每篇文章的平均用户停留时长",{"2":{"423":1}}],["我们再求这些bounding",{"2":{"381":1}}],["我们定义了一个二分类标签",{"2":{"367":1}}],["我们需要什么样的策略和技术",{"2":{"768":1}}],["我们需要预测中心词w",{"2":{"721":1}}],["我们需要预测该样本的类别的时候",{"2":{"472":1}}],["我们需要对mse进行开",{"2":{"581":1}}],["我们需要计算每个特征的每个分割点对应的增益",{"2":{"497":2,"513":1}}],["我们需要浏览所有的数据去计算每个可能分裂点的信息增益",{"2":{"495":1}}],["我们需要知道的是这张图像有什么object",{"2":{"339":1}}],["我们需要扔很多次才能得到一次0或1",{"2":{"279":1}}],["我们任意选其中4人送给他们一人一本",{"2":{"275":1}}],["我们给元素的父级元素添加事件",{"2":{"227":1}}],["我们调用外面的函数",{"2":{"215":1}}],["我们要时刻注意到数据结构是",{"2":{"769":1}}],["我们要零解一点意义都没有",{"2":{"635":1}}],["我们要聚合的是有相同行为特征的账户",{"2":{"576":1}}],["我们要进行分层",{"2":{"572":1}}],["我们要",{"2":{"174":1}}],["我们前面提到",{"2":{"140":1}}],["我们从右上向左下看进行层次划",{"2":{"89":1}}],["我们将重复的词语视为其出现多",{"2":{"621":1}}],["我们将扔两次骰子作为一个时间",{"2":{"279":1}}],["我们将这样构造",{"2":{"279":1}}],["我们将空字符串定义为有效的回文串",{"2":{"76":1}}],["我们将会用到这样的结论",{"2":{"74":1}}],["我们将描述一种查找一组字符串的最长公共前缀",{"2":{"74":1}}],["我们遍历所有是1的位置进行dfs",{"2":{"33":1}}],["我们可以为window",{"2":{"798":1}}],["我们可以�",{"2":{"798":1}}],["我们可以修改代码",{"2":{"770":1}}],["我们可以在任何mapreduce框架下",{"2":{"769":1}}],["我们可以在b特征的取值上加一个偏置常量10",{"2":{"469":1}}],["我们可以看到mapreduce的输入和输出都是",{"2":{"769":1}}],["我们可以看做是离散的时间序列",{"2":{"527":1}}],["我们可以抽象成几个步骤",{"2":{"769":1}}],["我们可以用数组枚举",{"2":{"763":1}}],["我们可以用归并排序的思想来解决这个问题",{"2":{"755":1}}],["我们可以很容易看到二路归并排序只有两个部分",{"2":{"760":1}}],["我们可以分析建堆的时间复杂度是o",{"2":{"756":1}}],["我们可以直接对于长度为n的数组建立最大堆",{"2":{"756":1}}],["我们可以直接读取数据到内存中直接调用语言中封装好的排序方法即可",{"2":{"755":1}}],["我们可以知道对于一个大小为n的堆",{"2":{"756":1}}],["我们可以采用precision和recall的加权调和平均",{"2":{"589":1}}],["我们可以得到更少的绑定特征",{"2":{"468":1}}],["我们可以",{"2":{"459":1}}],["我们可以使用外排序",{"2":{"763":1}}],["我们可以使用二路归并",{"2":{"760":1}}],["我们可以使用数据来表示最大堆",{"2":{"756":1}}],["我们可以使用映射层的权值作为词向量表征",{"2":{"718":1}}],["我们可以使用bagging算法",{"2":{"459":1}}],["我们可以使用map",{"2":{"89":1}}],["我们可以对其所在的proposal进行超分辨率",{"2":{"403":1}}],["我们可以先从a",{"2":{"92":1}}],["我们可以发现这是一个求最大公约的算式",{"2":{"27":1}}],["我们可以选择最小萌系数的猫",{"2":{"27":1}}],["我们可以尽可能多的买卖股票",{"2":{"25":1}}],["我们考虑是否买新的股票更能赚",{"2":{"26":1}}],["我们考虑最朴素的方法",{"2":{"26":1}}],["我们认为s对接下来的加操作有帮助",{"2":{"18":1}}],["四个点的值",{"2":{"369":1}}],["四个方向搜索",{"2":{"33":1}}],["四次挥手",{"0":{"238":1},"1":{"239":1}}],["四次握手",{"2":{"237":1}}],["浏览器原理",{"2":{"847":1}}],["浏览器还是会给服务器发送请求",{"2":{"798":1}}],["浏览器主要做了三个阶段的事情",{"2":{"778":1}}],["浏览器检查ca证书是不是由可以信赖的ca机构颁发的",{"2":{"252":1}}],["浏览器请求一个url",{"2":{"252":1}}],["浏览器",{"2":{"244":1}}],["浏览器根据其请求到的资源",{"2":{"235":1}}],["浏览器对html",{"2":{"235":1}}],["浏览器向服务器发送http请求",{"2":{"235":1}}],["浏览器获得域名对应的ip地址以后",{"2":{"235":1}}],["浏览器自身的dns缓存",{"2":{"235":1}}],["浏览器解析url",{"2":{"235":1}}],["储存形式是key=value",{"2":{"228":1}}],["访问",{"0":{"228":2},"2":{"228":1}}],["截取出新的数组",{"2":{"220":1}}],["首次使用两阶段训练方法",{"2":{"707":1}}],["首项是1",{"2":{"280":1}}],["首部字段名",{"2":{"246":1}}],["首部行",{"2":{"246":2}}],["首位添加",{"2":{"220":1}}],["首先任选k个构建最小堆",{"2":{"756":1}}],["首先将数据data分成两部分a和b",{"2":{"741":1}}],["首先将所有浮点特征",{"2":{"450":1}}],["首先要知道svm中有函数间隔和几何间隔",{"2":{"634":1}}],["首先根据先验分布",{"2":{"628":1}}],["首先根�",{"2":{"185":1}}],["首先对数据进行处理",{"2":{"597":1}}],["首先同时训练三颗树",{"2":{"472":1}}],["首先确定对于每一个特征需要多少个箱子并为每一个箱子分配一个整数",{"2":{"465":1}}],["首先会计算一些数据的statistics",{"2":{"446":1}}],["首先计算gm∗",{"2":{"430":1}}],["首先计算某一类别的ap值",{"2":{"393":1}}],["首先reshape成448×448大小",{"2":{"378":1}}],["首先在",{"2":{"369":1}}],["首先通过",{"2":{"689":1}}],["首先通过可学习的",{"2":{"366":1}}],["首先通过传统的",{"2":{"366":2}}],["首先按照通道进行计算按位相乘的计算",{"2":{"317":1}}],["首先检查帧中目标mac地址是否是本接口的mac",{"2":{"250":1}}],["首先和hashcode碰撞次数的泊松分布有关",{"2":{"120":1}}],["首先",{"2":{"74":1,"252":1,"268":1,"357":1,"378":1,"495":1}}],["首先排序数组",{"2":{"3":1}}],["末尾添加",{"2":{"220":1}}],["结点的值大于起孩子的",{"2":{"756":1}}],["结合提示工程与零样本推理",{"2":{"423":1}}],["结合",{"2":{"423":1}}],["结合内容创新性",{"2":{"423":1}}],["结合专门设计的蒸馏损失",{"2":{"423":1}}],["结合人类反馈纠正错误",{"2":{"423":1}}],["结合人类反馈优化推理过程和答案质量",{"2":{"423":1}}],["结合规则过滤或安全检测模块",{"2":{"423":1}}],["结合规则或重写策略",{"2":{"423":1}}],["结合语义检索用于",{"2":{"423":1}}],["结合语法校正模块二次过滤",{"2":{"423":1}}],["结合标题",{"2":{"423":1}}],["结合表示模型和生成模型的优势",{"2":{"422":1}}],["结合能够更直观地处理",{"2":{"218":1}}],["结构清晰",{"0":{"831":1}}],["结构设计�",{"2":{"809":1}}],["结构的区别",{"2":{"790":1}}],["结构更清晰",{"2":{"775":1}}],["结构如下",{"2":{"689":1}}],["结构化记忆",{"2":{"423":1}}],["结构化提示词",{"2":{"422":1}}],["结构化的选取输入的子集",{"2":{"353":1}}],["结构",{"2":{"378":1,"389":1}}],["结构灵活",{"2":{"343":1}}],["结构上可分割开",{"2":{"233":1}}],["结果",{"2":{"829":1}}],["结果导向",{"0":{"840":1},"2":{"822":1}}],["结果也可以理解为概率",{"2":{"660":1}}],["结果为",{"2":{"394":1}}],["结果是10则产生1",{"2":{"278":1}}],["结果只有四种可能",{"2":{"278":1}}],["结尾的串的个",{"2":{"12":1}}],["操作",{"2":{"388":2,"770":1}}],["操作系统",{"0":{"285":1},"1":{"286":1,"287":1,"288":1,"289":1,"290":1,"291":1,"292":1,"293":1,"294":1,"295":1,"296":1,"297":1,"298":1,"299":1,"300":1,"301":1,"302":1,"303":1},"2":{"303":1}}],["操作系统的dns缓存",{"2":{"235":1}}],["操作成功",{"2":{"245":1}}],["操作符后的表达式的值不是一�",{"2":{"218":1}}],["操作来实现加锁",{"2":{"138":1}}],["正是这样庞杂的知识体系",{"2":{"765":1}}],["正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询",{"2":{"763":1}}],["正向索引开发出来用来存储每个文档的单词的列表",{"2":{"763":1}}],["正好这个是概率的范围",{"2":{"670":1}}],["正如我们所知",{"2":{"614":1}}],["正负样本比例和总体的正负样本比例应该基本一致",{"2":{"591":1}}],["正常应该提供一个比较方法的函数",{"2":{"756":1}}],["正常情况下",{"2":{"575":1}}],["正常处理",{"2":{"218":1}}],["正则先验分布是",{"2":{"568":2}}],["正则先验分别服从什么分布",{"0":{"568":1}}],["正则中有参数和变量",{"2":{"515":1}}],["正则",{"2":{"504":1}}],["正则项降低了模型的方差",{"2":{"513":1}}],["正则项降低了模型的variance",{"2":{"497":1}}],["正则项里包含了树的叶子节点个数",{"2":{"497":1,"513":1}}],["正则化的目的是用来防止过拟合的",{"2":{"560":1}}],["正则化项的逻辑斯蒂回归",{"2":{"513":1}}],["正则化方法",{"2":{"423":1}}],["正则化机器学习中一种常用的技术",{"2":{"330":1}}],["正则化",{"2":{"325":1,"513":1,"657":1}}],["正切等",{"2":{"306":1}}],["正确",{"2":{"282":3}}],["正确的概率",{"0":{"282":1}}],["正整数",{"2":{"267":1}}],["正在做梦",{"2":{"217":1}}],["正在休息",{"2":{"217":1}}],["正在写作",{"2":{"217":1}}],["正在阅读",{"2":{"217":1}}],["正在等待的线程可以选择放弃等待",{"2":{"136":1}}],["链式条件随机场",{"2":{"519":1}}],["链接式架构不论在训练",{"2":{"519":1}}],["链�",{"2":{"218":2}}],["链表中元素个数�",{"2":{"120":1}}],["链表操作",{"2":{"103":1}}],["链表",{"2":{"99":1}}],["链表定义简单很容易考察面试者的水平",{"2":{"63":1}}],["链表也是面试中常问道的题目",{"2":{"63":1}}],["链表分成两个部分",{"2":{"56":1}}],["休息完毕",{"2":{"217":1}}],["休眠1秒",{"2":{"199":2}}],["阅读完毕",{"2":{"217":1}}],["举个简单例子",{"2":{"730":1}}],["举个例子",{"2":{"679":1}}],["举个例子�",{"2":{"217":1,"218":1}}],["举个栗子",{"2":{"618":1}}],["举例来说",{"2":{"739":1}}],["举例来说�",{"2":{"114":1}}],["举例如下",{"2":{"357":1}}],["计数排序",{"2":{"755":2}}],["计数器为",{"2":{"215":3}}],["计",{"2":{"635":4}}],["计算出差异",{"2":{"792":1}}],["计算出将word1",{"2":{"5":1}}],["计算决定",{"2":{"784":1}}],["计算数据集内所有点到k个簇中心的距离",{"2":{"675":1}}],["计算数据实例是否属于某类的概率时也将忽略缺失属性",{"2":{"630":1}}],["计算结果方便存储",{"2":{"664":1}}],["计算当前的该点到查找点的距离是否比最近邻距离小",{"2":{"651":1}}],["计算当前梯度",{"2":{"543":1}}],["计算两次条件概率",{"2":{"624":1}}],["计算信息增益前",{"2":{"608":1}}],["计算划分条件的边",{"2":{"597":1}}],["计算函数在当前点处的hessian",{"2":{"555":1}}],["计算朝最陡的下坡方向走一步",{"2":{"543":1}}],["计算最可能的隐状态序",{"2":{"527":1}}],["计算观测序列y出现的概率",{"2":{"527":1}}],["计算某一节点的叶节点的直方图可以通过将该节点的直方图与另一子节点的直方图做差得到",{"2":{"497":1}}],["计算某个category出现的频率",{"2":{"446":1}}],["计算公式如下",{"2":{"496":1}}],["计算该分类器的错误率",{"2":{"486":1}}],["计算每个评分区间累计坏样本占比与累计好样本占比差的绝对值",{"2":{"592":1}}],["计算每个评分区间的累计好样本数占总好账户数比",{"2":{"592":1}}],["计算每个评分区间的好坏样本数",{"2":{"592":1}}],["计算每个类别的概率",{"2":{"472":1}}],["计算每个bounding",{"2":{"381":1}}],["计算分裂阈值的过程",{"2":{"470":1}}],["计算代价更小",{"2":{"465":1}}],["计算学习器系数",{"2":{"431":1}}],["计算回归误差率",{"2":{"431":1}}],["计算样本的相对平方误差",{"2":{"431":1}}],["计算训练集上最大误差",{"2":{"431":1}}],["计算弱分类器",{"2":{"428":1}}],["计算成本极高",{"2":{"423":1}}],["计算成本低",{"2":{"423":1}}],["计算复杂",{"2":{"423":1}}],["计算复杂度较高",{"2":{"422":1}}],["计算速度快",{"2":{"422":1}}],["计算效率低",{"2":{"725":1}}],["计算效率提高",{"2":{"514":1}}],["计算效率高",{"2":{"423":1,"725":1}}],["计算效率",{"2":{"422":1}}],["计算点积",{"2":{"422":1}}],["计算快",{"2":{"422":2}}],["计算box",{"2":{"397":1}}],["计算iou非常简单",{"2":{"390":1}}],["计算属于各类物体的概率以及坐标调整的数值",{"2":{"385":1}}],["计算anchor",{"2":{"381":1}}],["计算得到的q就是修正后的结果",{"2":{"740":1}}],["计算得到距离",{"2":{"381":1}}],["计算得到面积是",{"2":{"274":2}}],["计算得出的",{"2":{"367":1}}],["计算过程的工作集内存总量为64",{"2":{"357":2}}],["计算过程的工作集内存总量",{"2":{"357":1}}],["计算网络模型的计算量",{"2":{"315":1}}],["计算量太大",{"2":{"635":1}}],["计算量大",{"2":{"423":1,"649":1}}],["计算量较大",{"2":{"361":1}}],["计算量为64",{"2":{"357":3}}],["计算量的前后对比",{"2":{"317":1}}],["计算量越大",{"2":{"315":1}}],["计算量",{"0":{"315":1},"2":{"315":1}}],["计算cnn的感受野",{"2":{"309":1}}],["计算机视觉岗常见面试题",{"2":{"358":1}}],["计算机视觉中的数据增强",{"2":{"345":1}}],["计算机视觉面试常见问题",{"2":{"339":1}}],["计算机视觉",{"2":{"306":1}}],["计算机基础",{"0":{"260":1},"1":{"261":1,"262":1,"263":1,"264":1,"265":1},"2":{"845":1,"846":1,"847":1,"848":1}}],["计算机体系结构",{"0":{"234":1}}],["计算机网络分层的优点和缺点",{"0":{"233":1}}],["计算机网络",{"0":{"230":1},"1":{"231":1,"232":1,"233":1,"234":1,"235":1,"236":1,"237":1,"238":1,"239":1,"240":1,"241":1,"242":1,"243":1,"244":1,"245":1,"246":1,"247":1,"248":1,"249":1,"250":1,"251":1,"252":1,"253":1},"2":{"253":1}}],["计算浏览器可视区域",{"0":{"229":1}}],["计算",{"2":{"169":1,"274":1,"428":1}}],["计算hash�",{"2":{"118":1}}],["计算所有顶点的入度",{"2":{"61":1}}],["计算所有入度",{"2":{"60":1}}],["计算所有节点的入度",{"2":{"60":1}}],["计算后缀",{"2":{"46":1}}],["计算前缀",{"2":{"46":1}}],["计算target出现的次数�",{"2":{"45":1}}],["闭包可以访问另一个函数作用域中变量的函数�",{"2":{"215":1}}],["闭包是利用了",{"2":{"215":1}}],["声明的变量",{"2":{"214":2}}],["里面有n个不重复的正整数",{"2":{"763":1}}],["里面有大量的耗时的对数运算",{"2":{"600":1}}],["里面每一行是一个词",{"2":{"749":1}}],["里找这个属性",{"2":{"212":1}}],["里删除这�",{"2":{"185":1}}],["吗",{"2":{"211":3}}],["位进行分桶",{"2":{"763":1}}],["位图排序",{"0":{"759":1}}],["位图",{"2":{"754":1,"768":1}}],["位置等结构信息",{"2":{"423":1}}],["位置越大",{"2":{"422":1}}],["位置信息是特别重要的",{"2":{"401":1}}],["位小数�",{"2":{"210":1}}],["位中",{"2":{"83":1}}],["介于随机和理想的roc曲线之间",{"2":{"591":1}}],["介�",{"0":{"210":1}}],["介绍互斥特征捆绑算法",{"0":{"468":1}}],["介绍一下word2vec模型",{"2":{"725":1}}],["介绍一下abtest的步骤",{"0":{"570":1}}],["介绍一下单边梯度采样算法",{"0":{"467":1}}],["介绍一下leaf",{"0":{"466":1}}],["介绍一下直方图算法",{"0":{"465":1}}],["介绍一下目标检测的主要评测指标",{"0":{"393":1}}],["介绍一�",{"0":{"140":1,"217":1,"218":1,"800":1}}],["介绍faster",{"0":{"374":1}}],["介绍",{"0":{"162":1,"674":1}}],["🎭",{"0":{"843":1}}],["🌐",{"0":{"207":1,"263":1,"803":1,"847":1}}],["🎯",{"0":{"102":1,"809":1,"813":1,"844":1},"1":{"103":1,"104":1,"814":1,"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1,"845":1,"846":1,"847":1,"848":1}}],["☕",{"0":{"206":1}}],["服务端错误",{"2":{"245":1}}],["服务器用你发的对称钥匙给你请求的网页加密",{"2":{"252":1}}],["服务器用自己的私匙解密你发送的钥匙",{"2":{"252":1}}],["服务器将自己的证书",{"2":{"252":1}}],["服务器或报文主体的一些信息",{"2":{"246":1}}],["服务器接收到这个请求",{"2":{"235":1}}],["服务器进行",{"2":{"235":1}}],["服务器和主机在同一个子网内",{"2":{"235":1}}],["服务实现的简�",{"2":{"202":1}}],["服务采用",{"2":{"202":1}}],["虽然出现�",{"2":{"798":1}}],["虽然其本质也是语言模型",{"2":{"725":1}}],["虽然在一定程度上能够提升模型运算效率",{"2":{"725":1}}],["虽然利用预排序和近似算法可以降低寻找最佳分裂点的计算量",{"2":{"513":1}}],["虽然每个弱分类器可能都有分错的样本",{"2":{"440":1}}],["虽然单个模型误差会有波动",{"2":{"433":1}}],["虽然这种方法只是用到了高层的语义信息",{"2":{"401":1}}],["虽然这种方法使用起来非常简单",{"2":{"336":1}}],["虽然使用了图像金字塔的思路",{"2":{"385":1}}],["虽然采用求平方根方式",{"2":{"378":1}}],["虽然max",{"2":{"339":1}}],["虽然计算上比其他插值方式复杂",{"2":{"312":1}}],["虽然整个文件事件处理器是在单线程上运行的",{"2":{"202":1}}],["虽然红黑树的查找效率�",{"2":{"120":1}}],["纯内存操�",{"2":{"202":1}}],["极大地提升了计算效率",{"2":{"690":1}}],["极大地影响到",{"2":{"109":1}}],["极大提升了结点分裂时的计算效率",{"2":{"510":1}}],["极大提升训练速度",{"2":{"504":1}}],["极大的丰富了特征维度",{"2":{"445":1}}],["极少数情况下可能会效果变好",{"2":{"333":1}}],["极端情况可能出现大量的过期key没有再次被访问",{"2":{"201":1}}],["才算显著",{"2":{"574":1}}],["才会换行�",{"2":{"774":1}}],["才会对最终超平面的结果产生影响",{"2":{"635":1}}],["才会产生软中断",{"2":{"301":1}}],["才会判断该key是否已过期",{"2":{"201":1}}],["才能满足快速的检索",{"2":{"761":1}}],["才能协同出较多信息",{"2":{"730":1}}],["才能称出哪个鸡蛋是坏的",{"2":{"270":1}}],["才能将发送窗口右移",{"2":{"242":1}}],["才用",{"2":{"134":1}}],["惰性过�",{"2":{"201":1}}],["到极值点",{"2":{"548":1}}],["到底是怎么回事",{"0":{"482":1}}],["到这里我们的面试小结就写完了",{"2":{"423":1}}],["到了一定程度",{"2":{"346":1}}],["到右端",{"2":{"270":1}}],["到过期时间就会立即清除",{"2":{"201":1}}],["到end",{"2":{"61":1}}],["定位方案",{"2":{"784":1}}],["定位到某日",{"2":{"750":1}}],["定value",{"2":{"752":1}}],["定期过期",{"2":{"201":1}}],["定时过期",{"2":{"201":1}}],["定义弹性盒子在主轴方向上的对齐方式",{"2":{"782":1}}],["定义弹性盒子在交叉轴上如何对齐",{"2":{"782":1}}],["定义媒介资源�",{"2":{"776":1}}],["定义视频",{"2":{"776":1}}],["定义图形�",{"2":{"776":1}}],["定义声音�",{"2":{"776":1}}],["定义文档中的段落",{"2":{"776":1}}],["定义文章的内容�",{"2":{"776":1}}],["定义导航链接的部分�",{"2":{"776":1}}],["定义如下",{"2":{"769":1}}],["定义maxheapfy",{"2":{"756":1}}],["定义该超平面关于训练定义该超平面关于训练",{"2":{"635":2}}],["定义该超平面关于样本点",{"2":{"635":2}}],["定义真正例率tpr和假正例率fpr为",{"2":{"591":1}}],["定义二叉树",{"2":{"84":1}}],["定义",{"2":{"60":1,"776":3}}],["把对应位是01的整数输出即可",{"2":{"751":1}}],["把整个大文件映射为1000个小文件",{"2":{"750":1}}],["把实值的vector转换成紧凑的二值的vector",{"2":{"739":1}}],["把叶节点编号进行one",{"2":{"739":1}}],["把人物偏好也进行主题划分",{"2":{"730":1}}],["把电影进行了主题划分",{"2":{"730":1}}],["把users做为行",{"2":{"730":1}}],["把相关特征去掉",{"2":{"624":1}}],["把相关的用户行为收集起来",{"2":{"575":1}}],["把一个连续的属性离散化",{"2":{"620":1}}],["把一副图片",{"2":{"378":1}}],["把区间",{"2":{"603":1}}],["把模型预测结合在一起",{"2":{"459":1}}],["把其中一蛋",{"2":{"270":1}}],["把12号蛋和其他任意一蛋比较",{"2":{"270":1}}],["把有序数据传送给应用层",{"2":{"241":1}}],["把数组中的所有元素放到一个字符串中",{"2":{"220":1}}],["把promise的状态设置为rejected",{"2":{"217":1}}],["把promise的状态设置为resolved",{"2":{"217":1}}],["把最近最常访问的数据留在缓存中",{"2":{"200":1}}],["把own设为负无穷因为最初不存在该状态",{"2":{"26":1}}],["发�",{"2":{"833":1}}],["发展机会的平衡",{"2":{"812":1}}],["发掘对单个广告有区分度的特征",{"2":{"741":1}}],["发票出现了两次",{"2":{"621":2}}],["发票",{"2":{"621":3}}],["发布新版本",{"2":{"570":1}}],["发现错误请及时反馈",{"2":{"849":1}}],["发现和定义问题的能�",{"2":{"816":1}}],["发现item之间的相关性",{"2":{"727":1}}],["发现主要问题在于正负类别不均衡",{"2":{"387":1}}],["发现删除失�",{"2":{"199":1}}],["发出一个段后",{"2":{"241":1}}],["发起三次握手",{"2":{"235":1}}],["发送给接收方",{"2":{"252":1}}],["发送给从节点",{"2":{"194":1}}],["发送放收到公钥后",{"2":{"252":1}}],["发送消息和接收消息均使用该密钥",{"2":{"252":1}}],["发送",{"2":{"250":1}}],["发送方和接收方需要持有同一把密钥",{"2":{"252":1}}],["发送方也不就会误认为出现了网络拥塞",{"2":{"243":1}}],["发送方只要一连收到三个重复确认",{"2":{"243":1}}],["发送窗口的上限为接受窗口和拥塞窗口中的较小值",{"2":{"242":1}}],["发送窗口的大小不能超过接受窗口的大小",{"2":{"242":1}}],["发送一�",{"2":{"185":1}}],["启动一个订阅程序去订阅数据库的binlog",{"2":{"199":1}}],["于是",{"2":{"763":1}}],["于是可以将目标函数转化为如下",{"2":{"496":1}}],["于是可以利用这个概率相等的特性等概率地产生01随机数",{"2":{"278":1}}],["于是整个方案就是",{"2":{"278":1}}],["于是就这样一直找下去",{"2":{"212":1}}],["于是就有了下面的更新公式",{"2":{"58":1}}],["于是有了方案二",{"2":{"199":1}}],["方差和模型复杂度的关系",{"2":{"558":1}}],["方差越大",{"2":{"558":1}}],["方差度量了同样大小的训练集的变动所导致的学习性能的变化",{"2":{"558":1}}],["方差",{"2":{"558":2}}],["方差权衡",{"2":{"501":1}}],["方差的角度解释adaboost",{"0":{"432":1}}],["方便交叉与特征组合",{"2":{"664":1}}],["方便矩阵表达",{"2":{"655":1}}],["方便理解和调试",{"2":{"422":1}}],["方便做分类",{"2":{"422":1}}],["方向进行线性插值",{"2":{"369":2}}],["方式如下",{"2":{"423":1}}],["方式",{"2":{"293":1}}],["方案2",{"2":{"747":1,"748":1,"751":1}}],["方案1",{"2":{"747":1,"748":1,"751":1}}],["方案通常在效果和成本间取得最佳平衡",{"2":{"423":1}}],["方案�",{"2":{"199":1}}],["方案一",{"2":{"199":1}}],["方法执行时没有参数传入",{"2":{"796":1}}],["方法扩展到主观领域",{"2":{"423":1}}],["方法扩增数据",{"2":{"423":1}}],["方法简介",{"2":{"307":1}}],["方法2",{"2":{"279":1}}],["方法1",{"2":{"279":1}}],["方法二",{"2":{"274":1}}],["方法进行中断�",{"2":{"139":1}}],["方法配合",{"2":{"137":1,"139":1}}],["方法的作�",{"0":{"124":1}}],["方法",{"2":{"95":1,"139":1,"246":1,"365":1,"423":1,"545":1}}],["方法一",{"2":{"95":1}}],["失去记忆力",{"2":{"422":1}}],["失�",{"2":{"217":1}}],["失败一直重试",{"2":{"199":1}}],["失效时通过二级更新一级",{"2":{"188":1}}],["淘汰",{"2":{"199":4}}],["该事件将携带stateobject参数的副�",{"2":{"798":1}}],["该步骤是在未被访问过的且与q的超球面相交的子树分支中查找可能存在的最近邻点",{"2":{"651":1}}],["该类就加一",{"2":{"643":1}}],["该算法能够实现近似k近邻的快速搜索",{"2":{"651":1}}],["该算法涉及的3个主要因素是",{"2":{"646":1}}],["该算法的问题",{"2":{"635":1}}],["该算法认为簇是由距离靠近的对象组成的",{"2":{"382":1}}],["该特征取值为样本在树中落入的叶节点的编号",{"2":{"739":1}}],["该特征上没有缺失值的样本",{"2":{"601":1}}],["该特性可以使用在超出内存的大量数据计算和按小时级等获取的数据计算中",{"2":{"623":1}}],["该部分不能能被数学模型解释的部分",{"2":{"583":1}}],["该模型使用一个三层前馈神经网络f",{"2":{"718":1}}],["该模型可以应用在语音识别和机器翻译等领域",{"2":{"527":1}}],["该模型有足够的灵活性",{"2":{"459":1}}],["该加法模型等价于adaboost的最终分类器",{"2":{"493":1}}],["该容器下所有样本的一阶梯度之和该容器下所有样本的二阶梯度之和正则项该bin容器下所有样本的一阶梯度之和该bin容器下所有样本的二阶梯度之和+正则项",{"2":{"470":1}}],["该怎么办",{"2":{"423":1}}],["该怎么做",{"0":{"228":1}}],["该方法将接受唯一参数",{"2":{"796":1}}],["该方法会被执行",{"2":{"796":1}}],["该方法采用分治法的一个非常典型应用",{"2":{"760":1}}],["该方法比较适用于样本容量比较大时的情况",{"2":{"651":1}}],["该方法提升效果比较显著",{"2":{"401":1}}],["该方案有一个缺点",{"2":{"199":1}}],["该网络可以在有效地完成目标检测的同时完成实例分割",{"2":{"375":1}}],["该网络用imagenet预训练的模型初始化",{"2":{"373":1}}],["该技术与现有的使用最近邻分类方法很类似",{"2":{"336":1}}],["该技术要求我们用合成方法得到不平衡类别的观测",{"2":{"336":1}}],["该蛋比其他蛋轻",{"2":{"270":1}}],["该策略每次从当前所有叶子中",{"2":{"466":1}}],["该策略是前两者的一个折中方案",{"2":{"201":1}}],["该策略可以最大化地节省cpu资源",{"2":{"201":1}}],["该策略可以立即清除过期的数据",{"2":{"201":1}}],["该数据永远都是脏数据�",{"2":{"197":1}}],["该对象就可以被程序使�",{"2":{"122":1}}],["生成决策树容易偏向于这些特征",{"2":{"607":1}}],["生成决策树",{"2":{"605":1}}],["生成每一棵树的时候",{"2":{"472":1}}],["生成新的numerical",{"2":{"446":1}}],["生成结果不够准确且不稳定",{"2":{"423":1}}],["生成结果为",{"2":{"80":1}}],["生成偏好对数据",{"2":{"423":1}}],["生成文本困惑度显著低",{"2":{"423":1}}],["生成的是tuple",{"2":{"739":1}}],["生成的决策树很直观",{"2":{"607":1}}],["生成的推理过程可读性差",{"2":{"423":1}}],["生成的内容",{"2":{"423":1}}],["生成的",{"2":{"423":1}}],["生成负例提升性能的方法",{"2":{"423":1}}],["生成故事梗概",{"2":{"423":1}}],["生成小说主题或关键词",{"2":{"423":1}}],["生成k",{"2":{"367":1}}],["生成模型更重",{"2":{"422":1}}],["生成模型产生图片去欺骗判别模型",{"2":{"352":1}}],["生成模型自己生成一张图片和想要的图片很像",{"2":{"352":1}}],["生成",{"2":{"194":1,"423":1,"521":1}}],["负采样为什么要用词频来做采样概率",{"2":{"725":1}}],["负采样在每⼀步的梯度计算开销都较小",{"2":{"725":1}}],["负采样方法的核心思想是",{"2":{"721":1}}],["负对数损失函数",{"2":{"661":1}}],["负定则类似于一元函数的二阶导",{"2":{"552":1}}],["负梯度永远是函数下降最快的方向",{"2":{"515":1}}],["负梯度是更加广义上的拟合项",{"2":{"515":1}}],["负样本欠采样之后会对模型有什么影响",{"2":{"741":1}}],["负样本欠采样可以加快训练速度并提升模型性能",{"2":{"740":1,"741":1}}],["负样本一般固定且有限",{"2":{"423":1}}],["负样本采样质量影响大",{"2":{"423":1}}],["负标签",{"2":{"371":1}}],["负载均衡",{"2":{"194":1}}],["负责维护跳跃表的节点指针",{"2":{"186":1}}],["恢复先前保存的寄存器上下文和栈",{"2":{"289":1}}],["恢复慢",{"2":{"193":1}}],["恢复当前的变",{"2":{"35":1}}],["旧日志文件还是照常写入",{"2":{"193":1}}],["旧容�",{"2":{"118":1}}],["策略遍历一次数据可以同时分裂同一层的叶子",{"2":{"466":1}}],["策略模型推理",{"2":{"423":1}}],["策略选择和工具调用能力",{"2":{"423":1}}],["策略为什么有效",{"2":{"346":1}}],["策略同时不给这些置顶数据设置过期时间",{"2":{"200":1}}],["策略",{"2":{"192":1,"346":1,"422":1,"470":1,"689":1}}],["耗内存",{"2":{"192":1}}],["手肘法",{"2":{"677":1}}],["手撕soft",{"2":{"397":1}}],["手撕nms",{"0":{"397":1}}],["手推反向传播公式",{"2":{"340":1}}],["手推反向传播公式展示一下",{"0":{"340":1}}],["手动操作热点数据",{"2":{"190":1}}],["手写归并排序",{"2":{"53":1}}],["手写堆排序",{"2":{"52":1}}],["手写快排",{"2":{"51":1}}],["热点数据直接加载到缓�",{"2":{"190":1}}],["热点数据永远不过�",{"2":{"190":1}}],["造成网络的稀疏性",{"2":{"328":1}}],["造成过大压力",{"2":{"190":1}}],["造成数据库短时间内承受大量请求而崩掉�",{"2":{"188":1,"189":1}}],["又存在不同的items的近邻几个users",{"2":{"730":1}}],["又被称",{"2":{"580":1,"581":1}}],["又被称为nosql",{"2":{"258":1}}],["又能",{"2":{"423":1}}],["又能利用更高分辨率的conv4",{"2":{"374":1}}],["又叫激励函数",{"2":{"319":1}}],["又有3种情况",{"2":{"270":1}}],["又有两种情况",{"2":{"270":1}}],["又称离散时间马尔可夫链",{"2":{"525":1}}],["又称",{"2":{"217":1}}],["又会有自己的",{"2":{"212":1}}],["又同时去数据库去取数据",{"2":{"190":1}}],["又因为x＜1",{"2":{"274":1}}],["又因为",{"2":{"23":1}}],["拦截掉",{"2":{"189":1}}],["做笛卡尔积",{"2":{"739":1}}],["做出可靠的估计",{"2":{"620":1}}],["做分类",{"2":{"422":1}}],["做线性规划求解",{"2":{"274":1}}],["做了噩梦",{"2":{"217":1}}],["做基础校验",{"2":{"189":1}}],["做进一步的比较",{"2":{"124":1}}],["接对条件概率分布进行建模",{"2":{"521":1}}],["接着掉头来开发了一种反向索引",{"2":{"763":1}}],["接着",{"2":{"459":1}}],["接着利用",{"2":{"366":1}}],["接着对整张图片进行特征提取",{"2":{"366":1}}],["接着将这些",{"2":{"366":1}}],["接着过了一些inter后",{"2":{"346":1}}],["接下了来的分析和前面的一样",{"2":{"270":1}}],["接下来",{"2":{"635":1}}],["接下来的分析同前面一样",{"2":{"270":1}}],["接下来的内存分配将在这个空间中进行",{"2":{"110":1}}],["接下来就是优化器进行确定执行方案",{"2":{"163":1}}],["接受窗口表明了接收方的接收能力",{"2":{"242":1}}],["接收到收到数据后",{"2":{"252":1}}],["接收方在发送消息前需要事先生成公钥和私钥",{"2":{"252":1}}],["接收方对数据包进行排序",{"2":{"241":1}}],["接收四个参数",{"2":{"220":1}}],["接口层增加校�",{"2":{"189":1}}],["由其内部的块撑开",{"2":{"784":1}}],["由其执行复杂推理",{"2":{"423":1}}],["由约束条件指定或没有指定",{"2":{"784":1}}],["由wide部分与deep部分共同组成",{"2":{"733":1}}],["由w^",{"2":{"635":1}}],["由排序结果对目标用户进行推荐",{"2":{"730":1}}],["由m+n个变量变为m∗n个变量",{"2":{"664":1}}],["由此",{"2":{"542":1}}],["由此训练出第一个基学习器",{"2":{"456":1}}],["由决策树替换为线性分类器或k",{"0":{"461":1}}],["由kkt条件可知",{"2":{"635":1}}],["由k",{"2":{"458":1}}],["由弱多模态模型完成",{"2":{"423":1}}],["由第三步的rpn",{"2":{"373":1}}],["由第三方插件更新二级缓存",{"2":{"188":1}}],["由imagenet",{"2":{"373":1}}],["由卷积核数量最多的层决定",{"2":{"311":1}}],["由内核根据就绪状态修改该集合的内容",{"2":{"302":1}}],["由系统决定",{"2":{"300":1}}],["由它所完成的功能决定",{"2":{"300":1}}],["由应用程序提供多个线程执行控制",{"2":{"288":1}}],["由",{"2":{"246":2,"497":1,"635":1,"690":1}}],["由从节点提供读服务",{"2":{"194":1}}],["由于负样本太多需要对负样本进行下采样",{"2":{"740":1}}],["由于推荐和广告等相关的问题",{"2":{"740":1}}],["由于上式是一个最大化问题",{"2":{"721":1}}],["由于参数空间非常庞大",{"2":{"718":1}}],["由于有",{"2":{"689":1}}],["由于有局部最优解的风险",{"2":{"544":1}}],["由于是依靠人工定好",{"2":{"651":1}}],["由于是求最小化风险函数",{"2":{"545":1}}],["由于将数据映射到高维",{"2":{"635":1}}],["由于1",{"2":{"635":1}}],["由于该问题与其原问题等价",{"2":{"635":1}}],["由于该问题为凸优化问题",{"2":{"635":1}}],["由于朴素贝叶斯的朴素特点",{"2":{"626":1}}],["由于这次没有把特征a的取值完全分开",{"2":{"604":1}}],["由于这出现的0值的概率极低",{"2":{"337":1}}],["由于样本不同",{"2":{"544":1}}],["由于变量间没有明确的因果关系",{"2":{"521":1}}],["由于gbdt是前向加法模型",{"2":{"497":1}}],["由于gbdt当前的误差会延续给下一棵树",{"2":{"497":1}}],["由于第i棵树需要用到前i",{"2":{"497":1}}],["由于第一次用天平左端重",{"2":{"270":1}}],["由于使用了采用数据是的每棵树的差别较大",{"2":{"497":1}}],["由于随机森林使用了使用了行采样和列采样技术",{"2":{"497":1}}],["由于采用了随机采样",{"2":{"485":1}}],["由于可以随机选择决策树节点划分特征",{"2":{"485":1}}],["由于bagging本身就是一种降低方差的算法",{"2":{"439":1}}],["由于从标记文件的width",{"2":{"382":1}}],["由于卷积神经网络具有平移不变性",{"2":{"380":1}}],["由于输出层为全连接层",{"2":{"378":1}}],["由于输入图像通过卷积神经网络",{"2":{"312":1}}],["由于网络中使用了全连接层",{"2":{"378":1}}],["由于图像双线性插值只会用相邻的4个点",{"2":{"369":1}}],["由于竞争资源或者由于彼此通信而造成的一种阻塞的现象",{"2":{"295":1}}],["由于生育儿子后就不再生",{"2":{"276":1}}],["由于发送方现在认为网络很可能没有发生拥塞",{"2":{"243":1}}],["由于并发用户特别多",{"2":{"190":1}}],["由于",{"2":{"131":1,"136":1,"368":1,"690":1}}],["由于字符",{"2":{"81":1}}],["过滤掉评价较少的users",{"2":{"730":1}}],["过滤掉被评价较少的items",{"2":{"730":1}}],["过滤掉被评论较少的items以及较少评价的users",{"2":{"730":1}}],["过拟合指的是在训练数据集上表现良好",{"2":{"559":1}}],["过拟合欠拟合面试题",{"0":{"557":1},"1":{"558":1,"559":1,"560":1,"561":1,"562":1,"563":1,"564":1,"565":1,"566":1,"567":1,"568":1}}],["过拟合的原因在于",{"2":{"559":1}}],["过拟合的部分就会自动被消除掉",{"2":{"477":1}}],["过拟合的解决方法",{"0":{"325":1}}],["过程需要多少张",{"2":{"423":1}}],["过程",{"2":{"368":1}}],["过程对默认网关进行查询",{"2":{"235":1}}],["过程对",{"2":{"235":1}}],["过采样",{"2":{"336":1}}],["过期则清除",{"2":{"201":1}}],["过期时间设置随机",{"2":{"188":1}}],["过重的逻辑运算依旧会影响性能",{"2":{"109":1}}],["避�",{"2":{"188":1}}],["避免冗长",{"2":{"831":1}}],["避免编�",{"2":{"830":1}}],["避免每次都考虑所有特征为求最佳",{"2":{"605":1}}],["避免出现无限多次划分类别",{"2":{"605":1}}],["避免出现拥塞",{"2":{"243":1}}],["避免无限往下划分",{"2":{"605":1}}],["避免过早收敛",{"2":{"423":1}}],["避免过拟合",{"2":{"423":1}}],["避免整块或全局量化带来的误差集中",{"2":{"423":1}}],["避免整篇文档过长导致嵌入不准确或超出上下文长度限制",{"2":{"423":1}}],["避免模型参数剧烈偏移",{"2":{"423":1}}],["避免噪声",{"2":{"423":1}}],["避免歧义",{"2":{"423":1}}],["避免重复问询",{"2":{"423":1}}],["避免信息混乱",{"2":{"423":1}}],["避免影响系统指令",{"2":{"422":1}}],["避免开放式提示",{"2":{"422":1}}],["避免不同主题被划入同一簇",{"2":{"422":1}}],["避免不必要的搜索",{"2":{"31":1}}],["避免主题过多导致语义重复",{"2":{"422":1}}],["避免ffn层修改引发的连带遗忘",{"2":{"422":1}}],["避免梯度消失的问题",{"2":{"351":1}}],["避免了重复计算",{"2":{"422":1}}],["避免了轮询",{"2":{"302":1}}],["避免了不断复制的问题",{"2":{"302":1}}],["避免了移动页面的开销",{"2":{"299":1}}],["避免全盘崩�",{"2":{"188":1}}],["避免回表",{"2":{"168":1}}],["降维操作其实就是通道间信息的线性组合变化",{"2":{"320":1}}],["降维",{"2":{"320":1}}],["降低了模型过拟合的风险",{"2":{"664":1}}],["降低了内存消耗",{"2":{"471":2}}],["降低方差",{"2":{"497":1}}],["降低偏差",{"2":{"497":1}}],["降低模型误差",{"2":{"432":1}}],["降低输入冗余",{"2":{"423":1}}],["降低网络参数量",{"2":{"307":1}}],["降低数据的冗余性",{"2":{"258":1}}],["降低效率",{"2":{"233":1}}],["降级",{"2":{"188":1}}],["降序排列",{"2":{"397":1}}],["降序",{"2":{"50":1,"763":1}}],["缓存命中率高",{"2":{"514":1}}],["缓存命中",{"2":{"514":1}}],["缓存因为种种问题删除失败",{"2":{"199":1}}],["缓存就被频繁的更新",{"2":{"196":1}}],["缓存预热",{"2":{"190":1}}],["缓存击穿指并发查同一条数据",{"2":{"190":1}}],["缓存击穿",{"0":{"190":1}}],["缓存有效时间可以设置短点",{"2":{"189":1}}],["缓存穿�",{"0":{"189":1},"2":{"189":1}}],["缓存标记失效则更新数据缓存",{"2":{"188":1}}],["缓存数据�",{"2":{"188":1}}],["缓存",{"2":{"188":1,"199":4}}],["缓存雪崩是不同数据都过期了",{"2":{"190":1}}],["缓存雪崩指缓存同一时间大面积的失效",{"2":{"188":1}}],["缓存雪崩",{"0":{"188":1}}],["哨兵",{"2":{"188":1}}],["穿透的情况及解决方�",{"0":{"187":1},"1":{"188":1,"189":1,"190":1}}],["击穿",{"0":{"187":1},"1":{"188":1,"189":1,"190":1}}],["慢开始门限ssthresh=当前拥塞窗口cwnd",{"2":{"243":1}}],["慢开始",{"2":{"243":1}}],["慢慢降低层�",{"2":{"186":1}}],["慢指针实现",{"2":{"65":1}}],["程序中设定是32",{"2":{"470":1}}],["程序之间的切换会有较大的开销",{"2":{"288":1}}],["程序上下文",{"2":{"288":1}}],["程序总是从高层先开始访问",{"2":{"186":1}}],["程序在各种平台下对内存的访问都能保证效果一致的机制及规范",{"2":{"140":1}}],["保护原有能力",{"2":{"423":1}}],["保留单词间的线性规则性",{"2":{"718":1}}],["保留数据中的异常值",{"2":{"629":1}}],["保留更多局部细节和动态范围",{"2":{"423":1}}],["保留前后句的上下文信息",{"2":{"423":1}}],["保留核心内容",{"2":{"423":1}}],["保留区分度高的词",{"2":{"422":1}}],["保留scores最大的那个框box",{"2":{"397":1}}],["保留框只剩一个",{"2":{"397":1}}],["保持良好的精神状�",{"2":{"836":1}}],["保持学习和成长的心�",{"2":{"822":1}}],["保持冷静和专业的方�",{"2":{"811":1}}],["保持推理连贯与准确",{"2":{"423":1}}],["保持模型通用性",{"2":{"423":1}}],["保持一致标签",{"2":{"423":1}}],["保持广泛泛化",{"2":{"423":1}}],["保持共享的卷积层固定",{"2":{"373":1}}],["保持浮点数边界不做量化",{"2":{"369":1}}],["保持分布的平稳",{"2":{"346":1}}],["保持高性能",{"2":{"192":1}}],["保存模型所需的内存小",{"2":{"394":1}}],["保存的数据不能超过",{"2":{"244":1}}],["保存在服务器端",{"2":{"244":1}}],["保存在客户端",{"2":{"244":1}}],["保存着指向其他元素的指针",{"2":{"186":1}}],["保存着元素值",{"2":{"186":1}}],["保证任务不平衡分到不同的reduce节点上",{"2":{"770":1}}],["保证每次弹出一个最小值",{"2":{"756":1}}],["保证复杂业务的原子性",{"2":{"185":1}}],["保证了原子性",{"2":{"174":1}}],["保证数据的",{"2":{"142":1}}],["保证数据可见性以实现锁的功能",{"2":{"139":1}}],["保证同一时刻只允许一条线程操�",{"2":{"140":1}}],["保证�",{"2":{"140":1}}],["保证负负得正",{"2":{"14":1}}],["跳跃表节点",{"2":{"186":1}}],["跳跃表主要由以下部分构成�",{"2":{"186":1}}],["跳跃表的实现要简单直观得�",{"2":{"186":1}}],["跳跃表以有序的方式在层次化的链表中保存元素",{"2":{"186":1}}],["跳跃表",{"2":{"186":1}}],["跳表数据结构",{"0":{"186":1}}],["跳过相同元素",{"2":{"30":1}}],["宕机",{"2":{"185":1,"192":1}}],["另一种思想是将预测每一个单词的概率",{"2":{"719":1}}],["另一种是用中心词预测上下文",{"2":{"718":1}}],["另一种方法是从具有最大see的簇中选择一个替补的质心",{"2":{"685":1}}],["另一部分是没有特征值a的数据",{"2":{"601":1}}],["另一部分是1",{"2":{"394":1,"395":1}}],["另一方面不需要求解具体的映射函数",{"2":{"638":1}}],["另一方面",{"2":{"546":1,"636":1}}],["另一方面也是为了能够自定义损失函数",{"2":{"513":1}}],["另一个常见的方法是画图",{"2":{"684":1}}],["另一个节点是a1",{"2":{"604":1}}],["另一个头关注关键词匹配",{"2":{"422":1}}],["另一个是使用fpn架构实现多尺度检测",{"2":{"378":1}}],["另一个是磁盘上的日志文件",{"2":{"173":1}}],["另一个是数组的下标�",{"2":{"39":1}}],["另一个指针就指向倒数第k个结点了",{"2":{"72":1}}],["另外编程实现时",{"2":{"685":1}}],["另外线性回归在整个实数域范围内进行预测",{"2":{"666":1}}],["另外基于gbdt实现的xgboost也被广泛使用",{"2":{"495":1}}],["另外",{"2":{"218":1,"459":1,"468":1,"703":1,"739":1}}],["另外注意的是",{"2":{"210":1}}],["另外的客户端可以尝试完成加锁�",{"2":{"185":1}}],["另起一段非业务代码",{"2":{"199":1}}],["另起一段程序",{"2":{"199":1}}],["循环使用每个词作为中心词",{"2":{"719":1}}],["循环网络",{"2":{"688":1}}],["循环批归一化",{"2":{"307":1}}],["循环等待条件",{"2":{"296":1}}],["循环不断尝试加锁",{"2":{"185":1}}],["循环算法",{"2":{"69":2}}],["已经面试经验",{"2":{"765":1}}],["已经是完全正确的数据",{"2":{"651":1}}],["已经是检测网络的标配",{"2":{"385":1}}],["已生成",{"2":{"422":1}}],["已知样本求出先验概率与条件概率",{"2":{"632":1}}],["已知类条件概率密度参数表达式和先验概",{"2":{"615":1}}],["已知观测序列y",{"2":{"527":1}}],["已知模型所有参数和观测序列y",{"2":{"527":1}}],["已知模型的所有参数",{"2":{"527":1}}],["已知一随机发生器",{"2":{"278":1}}],["已知其中有且仅有一瓶有毒",{"2":{"269":1}}],["已失�",{"2":{"217":1}}],["已完成",{"2":{"217":1}}],["已存在",{"2":{"185":1}}],["已满",{"2":{"130":1}}],["脚本",{"2":{"185":1}}],["释放锁机制",{"2":{"185":1}}],["释放锁的时候",{"2":{"184":1}}],["释放掉",{"2":{"184":1}}],["获取和使用更多的数据",{"2":{"561":1}}],["获取训练样本",{"2":{"386":1}}],["获取更多数据",{"2":{"307":1}}],["获取浏览器窗口的可视区域的高�",{"2":{"229":1}}],["获取浏览器窗口的可视区域的宽�",{"2":{"229":1}}],["获取锁的时候还设置一个获取的超时时间",{"2":{"184":1}}],["获取锁的时候",{"2":{"184":1}}],["获得质心",{"2":{"651":1}}],["获得的最小值也有可能不同",{"2":{"544":1}}],["获得的",{"2":{"388":1}}],["获得更高级的特征",{"2":{"327":1}}],["获得该信息",{"2":{"199":1}}],["获得这个订阅程序传来的信息",{"2":{"199":1}}],["获得需要操作的数据",{"2":{"199":1}}],["获得需要删除的key",{"2":{"199":1}}],["获得锁即�",{"2":{"184":1}}],["若干个类作为反类",{"2":{"662":1}}],["若干各类作为正类",{"2":{"662":1}}],["若干进程之间形成一种头尾相接的循环等待资源关系",{"2":{"296":1}}],["若kd树为空",{"2":{"651":1}}],["若p",{"2":{"618":1}}],["若样本在该特征上的值是缺失的",{"2":{"601":1}}],["若是假正",{"2":{"590":1}}],["若是该锁",{"2":{"184":1}}],["若当前为真正",{"2":{"590":1}}],["若给某个特征随机加入噪声之后",{"2":{"483":1}}],["若需加速训练或支持更大batch",{"2":{"423":1}}],["若a停留时长明显高于b",{"2":{"423":1}}],["若一个模型不收敛",{"0":{"349":1}}],["若卷积神将网络的上一层有n个卷积核",{"2":{"348":1}}],["若激活值进入饱和区",{"2":{"328":1}}],["若参数值较大时",{"2":{"326":1}}],["若参数值较小时",{"2":{"326":1}}],["若其访问位为1",{"2":{"299":1}}],["若无外力作用",{"2":{"295":1}}],["若右端重",{"2":{"270":1}}],["若左端重",{"2":{"270":1}}],["若不平衡",{"2":{"270":2}}],["若平衡",{"2":{"270":3}}],["若平",{"2":{"270":1}}],["若成功",{"2":{"250":1}}],["若函数f",{"2":{"496":1}}],["若函数某一项为true",{"2":{"220":1}}],["若函数每一项都为true",{"2":{"220":1}}],["若",{"2":{"218":2}}],["若过程中",{"2":{"192":1}}],["若超过这个时间则放弃获取锁",{"2":{"184":1}}],["若边",{"2":{"60":1}}],["值所决定的",{"2":{"784":1}}],["值越大说明越喜欢",{"2":{"730":1}}],["值小于0",{"2":{"574":1}}],["值得一提的是",{"2":{"368":1}}],["值�",{"2":{"221":1}}],["值",{"2":{"221":1,"246":1,"385":1,"471":1}}],["值的变化",{"2":{"663":1}}],["值的",{"2":{"218":1}}],["值类型",{"2":{"210":1}}],["值为一个随机生成的",{"2":{"184":1}}],["值进行选择",{"2":{"139":1}}],["日志文件即使过大",{"2":{"193":1}}],["日志",{"2":{"174":1}}],["那个分类器的概率高",{"2":{"643":1}}],["那样只预测下一个词",{"2":{"422":1}}],["那回归的目的很明显",{"2":{"372":1}}],["那就是梯度之和不变",{"2":{"338":1}}],["那",{"2":{"174":1}}],["那么为什么会出现掉帧问题呢",{"2":{"792":1}}],["那么特征转换就得到特征向量",{"2":{"739":1}}],["那么基于邻域的推荐思路是怎样的呢",{"2":{"730":1}}],["那么观影系统可能会推荐一些类似的励志片给你",{"2":{"727":1}}],["那么在huffman树中仍旧需要进行很复杂的搜索",{"2":{"721":1,"725":1}}],["那么在寻找每个特征的最佳分割点时",{"2":{"505":1}}],["那么超过0",{"2":{"660":1}}],["那么s大于0",{"2":{"659":1}}],["那么有些区间就会有来自不同类的记录",{"2":{"620":1}}],["那么有左端重或者右端重两种情况",{"2":{"270":1}}],["那么这个样本就属于哪一类",{"2":{"643":1}}],["那么这个新的概率值被称为后验概率",{"2":{"613":1}}],["那么这个对象会被移动到老生代中�",{"2":{"110":1}}],["那么所属的分支以及分裂点就不会有不同",{"2":{"608":1}}],["那么该url应该是共同的url",{"2":{"747":1}}],["那么该如何对这个样本进行划分",{"2":{"601":1}}],["那么该度量将计算此功能的覆盖范围",{"2":{"512":1}}],["那么得分大于t的样本中",{"2":{"591":1}}],["那么很有可能真正的结果就是数字9",{"2":{"564":1}}],["那么长的时间序列中设置变",{"2":{"533":1}}],["那么逻辑回归就可以改写成",{"2":{"532":1}}],["那么语言模型变为",{"2":{"527":1}}],["那么会自动将缺失值的划分方向放到右子结点",{"2":{"508":1}}],["那么各个特征的增益计算就可以开多线程进行",{"2":{"497":2,"505":1,"513":1}}],["那么训练完之后总共有m",{"2":{"497":1}}],["那么对于特征x的重要性为",{"2":{"483":1}}],["那么它在下个训练集中的权值就会提高",{"2":{"427":1}}],["那么它的权值在下一个训练集中就会降低",{"2":{"427":1}}],["那么rpn最终学会输出一个良好的转化关系t",{"2":{"367":1}}],["那么是否说明这个模型无效",{"0":{"349":1}}],["那么是否存在i",{"2":{"58":1}}],["那么那些子进程将成为孤儿进程",{"2":{"294":1}}],["那么子进程的进程描述符仍然保存在系统中",{"2":{"294":1}}],["那么p这个序列的概率就是",{"2":{"279":1}}],["那么我们选出的4人都在不同排的概率是多少",{"2":{"275":1}}],["那么我们认为他们是同一个岛",{"2":{"33":1}}],["那么要找的蛋在从右端移到左端的3个蛋",{"2":{"270":1}}],["那么要找的蛋在从左端拿下的三个蛋",{"2":{"270":1}}],["那么要找的蛋肯定是4号蛋或者8号蛋",{"2":{"270":1}}],["那么将继续查找本机系统是否缓存过ip",{"2":{"249":1}}],["那么他就会去",{"2":{"212":1}}],["那么就是共同的url",{"2":{"747":1}}],["那么就是011=5号瓶子有毒",{"2":{"269":1}}],["那么就可以找到他的原�",{"2":{"212":1}}],["那么就会一直重试",{"2":{"134":1}}],["那么剩下等着�",{"2":{"184":1}}],["那么单列查询可以用到索引",{"2":{"168":1}}],["那么适合建立联合索引",{"2":{"168":1}}],["那么确认了执行计划后就准备开始执行了",{"2":{"163":1}}],["那么优化器根据自己的优化算法进行选择执行效率最好的一个方案",{"2":{"163":1}}],["那么只需要有n",{"2":{"23":1}}],["那么",{"2":{"12":1,"196":1,"423":1,"612":1,"739":1}}],["适应变化和不确定�",{"2":{"821":1}}],["适应�",{"2":{"821":1}}],["适度正则化",{"2":{"423":1}}],["适当与面试官互动",{"2":{"831":1}}],["适当剪裁和微调",{"2":{"423":1}}],["适当调整主题数",{"2":{"422":1}}],["适当减少网络的层数",{"2":{"307":1}}],["适中",{"2":{"422":1}}],["适用阶段",{"2":{"422":1}}],["适用于大规模数据集",{"2":{"676":1}}],["适用于较多类别的识别",{"2":{"632":1}}],["适用于数值比较集中的情况",{"2":{"306":1}}],["适用于sns",{"2":{"258":1}}],["适用于很多应用",{"2":{"240":1}}],["适用场景",{"2":{"173":1}}],["适合增量式训练",{"2":{"626":1}}],["适合对推理可解释性要求不高的场景",{"2":{"423":1}}],["适合交互式和多步骤决策场景",{"2":{"423":1}}],["适合在线交互",{"2":{"423":1}}],["适合离线数据",{"2":{"423":1}}],["适合向量归一化场景",{"2":{"423":1}}],["适合海量数据",{"2":{"423":1}}],["适合大规模数据",{"2":{"422":1}}],["适合快速原型和小数据场景",{"2":{"422":1}}],["适合做大规模文本检索和相似度计算",{"2":{"422":1}}],["适合资源受限场景",{"2":{"422":1}}],["适合并发场景",{"2":{"161":1}}],["适合读密集的场景",{"2":{"161":1}}],["写一个gbdt的损失函",{"2":{"498":1}}],["写代码",{"2":{"422":1}}],["写摘要",{"2":{"422":1}}],["写作完毕",{"2":{"217":1}}],["写在函数内层使用",{"2":{"214":1}}],["写在最外层的对象",{"2":{"214":1}}],["写请求可以删除读请求造成的缓存脏数据",{"2":{"199":1}}],["写qps会比rdb的低",{"2":{"193":1}}],["写入文",{"2":{"763":1}}],["写入性能高",{"2":{"193":1}}],["写入成功后",{"2":{"192":1}}],["写回操作加互斥锁",{"2":{"190":1}}],["写�",{"2":{"185":1}}],["写锁",{"2":{"170":1}}],["写",{"2":{"170":1}}],["事先去除对分类作用不大的样本",{"2":{"651":1}}],["事",{"2":{"613":3}}],["事实上",{"2":{"402":1}}],["事件就可以实现了�",{"2":{"796":1}}],["事件冒泡指的是",{"0":{"778":1}}],["事件捕获",{"0":{"778":1}}],["事件",{"0":{"777":1},"1":{"778":1,"779":1}}],["事件x与事",{"2":{"613":1}}],["事件的能力",{"2":{"302":1}}],["事件代理是指为了给多个元素添加事件",{"2":{"227":1}}],["事件代理指的是什么",{"0":{"227":1}}],["事物隔离级别",{"0":{"170":1}}],["事务前后",{"2":{"255":1}}],["事务四大特性",{"0":{"255":1}}],["事务的实现原�",{"0":{"179":1}}],["事务的原⼦性确保动作要么全部完成",{"2":{"166":1}}],["事务是最⼩的执⾏单位",{"2":{"166":1}}],["事务开始时刻的系统版本号会作为事务�",{"2":{"162":1}}],["常常可以保持贝叶斯算法的整体精度",{"2":{"629":1}}],["常数对目标函数的优化不相关",{"2":{"496":1}}],["常用在搜索引擎中",{"2":{"761":1}}],["常用到的算法策略",{"2":{"754":1,"768":1}}],["常用于标注或分析序列资料",{"2":{"519":1}}],["常用boosting算法",{"2":{"456":1}}],["常用boosting算法有哪些",{"0":{"456":1}}],["常用bagging算法",{"2":{"455":1}}],["常用bagging算法有哪些",{"0":{"455":1}}],["常用的内联块状元素有",{"2":{"774":1}}],["常用的内联元素有�",{"2":{"774":1}}],["常用的块状元素有�",{"2":{"774":1}}],["常用的排序方",{"2":{"755":1}}],["常用的相似度函数有哪些",{"2":{"730":1}}],["常用的有高斯核",{"2":{"657":1}}],["常用的核函数",{"2":{"635":1}}],["常用的离散化策略是二分法",{"2":{"603":1}}],["常用的布局是链接式",{"2":{"519":1}}],["常用的三种方法来评判模型中特征的重要程度",{"2":{"512":1}}],["常用的基分类器是什么",{"0":{"460":1}}],["常用的方法有ohem",{"2":{"370":1}}],["常用的激活",{"2":{"319":1}}],["常用的激活函数",{"2":{"319":1}}],["常用激活函数的比较",{"2":{"319":1}}],["常用常用的归一化和标准化的方法有哪些",{"0":{"306":1}}],["常用数据结构",{"0":{"219":1},"1":{"220":1,"221":1,"222":1,"223":1,"224":1}}],["常查询数据建立索引或者组合索引",{"2":{"169":1}}],["常见行为面试问题",{"0":{"823":1},"1":{"824":1,"825":1,"826":1,"827":1}}],["常见场景",{"2":{"811":1}}],["常见概念",{"0":{"783":1},"1":{"784":1,"785":1,"786":1,"787":1}}],["常见面试问题",{"0":{"725":1}}],["常见的语义化元素�",{"2":{"775":1}}],["常见的类型包括",{"2":{"690":1}}],["常见的评估方式",{"2":{"684":1}}],["常见的时间序列分解方法",{"2":{"531":1}}],["常见的概率图模型有朴素贝叶斯",{"2":{"521":1}}],["常见的概率图模型中",{"2":{"521":1}}],["常见的集成模型有randomforest",{"2":{"490":1}}],["常见的损失函数有哪些",{"0":{"331":1}}],["常见的题�",{"2":{"43":1,"45":1}}],["常见题目",{"2":{"48":1}}],["函�",{"2":{"169":1}}],["函数公式如下",{"2":{"660":1}}],["函数间隔与几何间隔的关系",{"2":{"635":1}}],["函数间隔",{"2":{"635":1}}],["函数间隔刻画样本点到超平面的相对距离",{"2":{"634":1}}],["函数在点x",{"2":{"555":1}}],["函数在该点有极大值",{"2":{"552":1}}],["函数在该点有极小值",{"2":{"552":1}}],["函数在x点处可以展开为",{"2":{"547":1}}],["函数值会沿序列xk递减",{"2":{"547":1}}],["函数梯度的关系为",{"2":{"547":1}}],["函数的增量与自变量增量",{"2":{"547":1}}],["函数参数作为",{"2":{"218":1}}],["函数后面的代码执行完毕�",{"2":{"114":1}}],["函数后面的代码",{"2":{"114":1}}],["函数后会执行第二个中间件的逻辑",{"2":{"114":1}}],["函数",{"2":{"112":1,"210":1,"213":1,"319":2,"532":1,"796":1}}],["优化答案解析",{"2":{"849":1}}],["优化等",{"2":{"800":1}}],["优化较为方便",{"2":{"730":1}}],["优化如下目标函数",{"2":{"730":1}}],["优化公式",{"2":{"729":1}}],["优化复杂任务的长期回报表现",{"2":{"423":1}}],["优化目标检测中two",{"2":{"401":1}}],["优化器认为",{"2":{"163":1}}],["优缺点及改进算法",{"0":{"676":1}}],["优缺点",{"2":{"343":1,"422":2,"423":1}}],["优势",{"2":{"343":1}}],["优先选用在整体上有区分度的特征",{"2":{"741":1}}],["优先修改注意力层的参数",{"2":{"422":1}}],["优先淘汰最早进入内存的页面",{"2":{"299":1}}],["优先使用",{"2":{"200":1}}],["优点",{"2":{"192":1,"193":1,"233":1,"368":1,"385":1,"396":1,"422":2,"423":11,"441":1,"451":1,"465":1,"471":1,"485":1,"487":1,"513":1,"607":1,"626":1,"632":2,"649":1,"663":1,"676":1,"730":1}}],["优点�",{"2":{"168":1}}],["索引的孩子节",{"2":{"762":1}}],["索引构建",{"2":{"423":1}}],["索引怎么优化",{"0":{"169":1}}],["索引就十分有效",{"2":{"168":1}}],["索引与数据同一文件",{"2":{"161":1}}],["索引与数据在不同的文件",{"2":{"161":1}}],["联合概率",{"0":{"613":1},"2":{"613":1}}],["联合使用coco物体检测标注数据和imagenet物体分类标注数据训练物体检测模型",{"2":{"378":1}}],["联合索引最左前缀原则",{"2":{"169":1}}],["联合索引更高效",{"2":{"168":1}}],["联合索引又叫复合索引",{"2":{"168":1}}],["联合索引",{"0":{"168":1}}],["联系我们",{"0":{"850":1}}],["联系",{"2":{"94":1,"641":1}}],["让你将他们按字典序从小到大输出用字典树进行排序",{"2":{"763":1}}],["让你找出a",{"2":{"747":1}}],["让使用者自己设置比较方式",{"2":{"756":1}}],["让高频词搜索路劲变小",{"2":{"725":1}}],["让包含缺失值的样本以不同的概率划分到不同的子节点中去",{"2":{"601":1}}],["让得分s",{"2":{"591":1}}],["让后面有更大的学习空间",{"2":{"513":1}}],["让本轮的损失函数最小",{"2":{"493":1}}],["让图像和文本嵌入映射到统一语义空间",{"2":{"423":1}}],["让模型输出严格符合预定义结构",{"2":{"422":1}}],["让模型理解问题场景",{"2":{"422":1}}],["让模型忘记某一特定知识",{"2":{"422":1}}],["让模型在处理输入数据时能够聚焦于关键信息",{"2":{"422":1}}],["让系统更加容易的找到输入的数据中与当前输出信息相关的有用信息",{"2":{"353":1}}],["让拥塞窗口cwnd缓慢地增大",{"2":{"243":1}}],["让这些变量的值始终保持在内存中�",{"2":{"215":1}}],["让操作系统决定何时进行同步",{"2":{"193":1}}],["让子进程执�",{"2":{"192":1}}],["让索引树更加矮�",{"2":{"167":1}}],["让剩余数位组成的数字尽可能小",{"2":{"19":1}}],["次低老鼠2死了",{"2":{"269":1}}],["次低位为1的2",{"2":{"269":1}}],["次数少",{"2":{"167":1}}],["次得到与",{"2":{"32":1}}],["⼀个事务被提交之后",{"2":{"166":1}}],["⼀个⽤户的事务不被其他事务所⼲扰",{"2":{"166":1}}],["持续学习",{"2":{"822":1}}],["持续改进",{"2":{"815":1}}],["持续评估",{"2":{"423":1}}],["持久化是指在指定时间间隔内将内存中的数据集快照写入磁盘",{"2":{"192":1}}],["持久化策�",{"0":{"191":1},"1":{"192":1,"193":1}}],["持久性",{"2":{"166":1,"255":1}}],["持有锁的线程长期不释放的时候",{"2":{"136":1}}],["隔离性",{"2":{"166":1,"255":1}}],["执⾏事务前后",{"2":{"166":1}}],["执行的效率高",{"2":{"487":1}}],["执行epoll",{"2":{"302":1}}],["执行对应的事件�",{"2":{"227":1}}],["执行同样的lua脚本",{"2":{"185":1}}],["执行下一�",{"2":{"163":1}}],["执行到",{"2":{"114":1}}],["自信",{"2":{"840":1}}],["自信建立",{"2":{"834":1}}],["自我认知�",{"0":{"824":1}}],["自我介绍",{"0":{"809":1}}],["自注意力中为何要缩放",{"0":{"703":1}}],["自注意力机制支持并行计算",{"2":{"422":1}}],["自注意力机制允许序列中每个位置直接与所有其他位置交互",{"2":{"422":1}}],["自注意力机制如何使大模型能够捕捉长距离依赖关系",{"2":{"422":1}}],["自底而上",{"2":{"605":1}}],["自然流畅的表达方式",{"2":{"809":1}}],["自然也就不会有梯度消失的问题",{"2":{"703":1}}],["自然也是gbdt目标函数下降最快的方向",{"2":{"515":1}}],["自然未提交的变更对其他事务也是不可见的",{"2":{"170":1}}],["自己蒸馏垂直领域模型保留r1能力建议",{"2":{"423":1}}],["自己消费消息",{"2":{"199":1}}],["自洽性",{"2":{"422":2}}],["自适应地调整假定的错误率",{"2":{"487":1}}],["自适应地选择哪些视觉信息对当前任务更重要",{"2":{"423":1}}],["自适应学习率优化法",{"2":{"308":1}}],["自适应哈希索引能够减少这样重复�",{"2":{"165":1}}],["自动将类别型特征处理为数值型特征",{"2":{"445":1}}],["自动纠偏",{"2":{"423":1}}],["自动重连后主节点通过命令传播增量复制给从节点部分缺少的数�",{"2":{"194":1}}],["自动延期机制",{"2":{"185":1}}],["自旋机制保证线程操作的原子性和",{"2":{"139":1}}],["自旋锁",{"2":{"139":1}}],["查看bitmap",{"2":{"751":1}}],["查看bitmap中相对应位",{"2":{"751":1}}],["查全率",{"0":{"588":1}}],["查准率",{"0":{"587":1}}],["查询解析",{"2":{"423":1}}],["查询头分组",{"2":{"422":1}}],["查询",{"2":{"235":1}}],["查询失败默认值快速返�",{"2":{"190":1}}],["查询条件b返回的条目比较多",{"2":{"168":1}}],["查询条件a返回的条目比较多",{"2":{"168":1}}],["查询条件是这个表�",{"2":{"163":1}}],["查询效率更加稳定",{"2":{"167":1}}],["查找点x",{"2":{"651":1}}],["查找效率会随着维度的增加而迅速下降",{"2":{"651":1}}],["查找",{"2":{"186":1}}],["查找倒数第k个节点等",{"2":{"63":1}}],["查找次数",{"2":{"45":1}}],["查找是否存在",{"2":{"45":1}}],["查找这个值是否在二维数组中�",{"2":{"45":1}}],["查找旋转数组",{"0":{"41":1}}],["版本",{"2":{"246":1,"689":1}}],["版本以前",{"2":{"163":1}}],["版本号大于数据库表当前版本号",{"2":{"133":1}}],["版本号机制�",{"2":{"133":1}}],["张三",{"2":{"163":3}}],["系统架构设计",{"2":{"846":1}}],["系统能在保持检索效率的同时",{"2":{"423":1}}],["系统层面注入检测",{"2":{"422":1}}],["系统的升级",{"2":{"258":1}}],["系统会按照",{"2":{"235":2}}],["系统版本号就会自动递增",{"2":{"162":1}}],["系统设计",{"0":{"744":1},"1":{"745":1},"2":{"106":1,"846":1}}],["典型的有乐观并发控制和悲观并发控制",{"2":{"162":1}}],["默认情况下",{"2":{"782":1,"792":1}}],["默认缺失值处理等",{"2":{"503":1}}],["默认是",{"2":{"484":1}}],["默认决策树在建立子树的时候不会限制子树的深度",{"2":{"484":1}}],["默认值为",{"2":{"800":1}}],["默认值是",{"2":{"536":1}}],["默认值",{"2":{"462":1,"782":3,"785":1}}],["默认单个进程打开的fd有限制是1024个",{"2":{"302":1}}],["默认为行锁",{"2":{"161":1}}],["默认的持久化方式",{"2":{"192":1}}],["默认的是哪个",{"0":{"161":1}}],["默认的构造函数是创建的非公平锁",{"2":{"136":1}}],["表征了样本中的信息",{"2":{"739":1}}],["表征依赖微调任务网络结构适配",{"2":{"707":1}}],["表征更集中和语义丰富",{"2":{"423":1}}],["表现潜力最大",{"2":{"423":1}}],["表达技�",{"0":{"831":1}}],["表达能力",{"0":{"818":1}}],["表达能力受限",{"2":{"664":1}}],["表达基于概率相关关系的模型的总称",{"2":{"521":1}}],["表达更清晰的语义意图",{"2":{"423":1}}],["表达差异问题",{"2":{"423":1}}],["表达式生成与验证",{"2":{"423":1}}],["表达式会�",{"2":{"218":1}}],["表达式会暂停当前",{"2":{"218":1}}],["表达式的值",{"2":{"218":1}}],["表的非主属性不能依赖与其他表的非主属性",{"2":{"257":1}}],["表格模型",{"2":{"256":1}}],["表尾",{"2":{"186":1}}],["表头",{"2":{"186":1}}],["表锁",{"2":{"161":1}}],["表示还可以加一些代码",{"2":{"769":1}}],["表示这个字符串出现的次数",{"2":{"762":1}}],["表示不存",{"2":{"762":1}}],["表示存在",{"2":{"762":1}}],["表示最大堆的大",{"2":{"756":1}}],["表示最大堆的大小",{"2":{"52":1}}],["表示维护第i",{"2":{"756":1}}],["表示的是在特征上的一个特定的规则",{"2":{"739":1}}],["表示的邻接矩阵",{"2":{"58":1,"59":1}}],["表示1阶特征",{"2":{"735":1}}],["表示事件发生前的预判概率",{"2":{"613":1}}],["表示y发生的条件下x发生的概率",{"2":{"613":1}}],["表示全部类别中这个这个类别出现的概率",{"2":{"612":1}}],["表示该类别下该特",{"2":{"612":1}}],["表示该节假日会影响前后一段时间的时间序列",{"2":{"536":1}}],["表示叶节点t上的经验熵",{"2":{"602":1}}],["表示反应因变量的全部变异能通过数学模型被自变量解释的比",{"2":{"583":1}}],["表示节假日对模型的效果越小",{"2":{"536":1}}],["表示节假日对模型的影响越大",{"2":{"536":1}}],["表示变点增长率的分布情况",{"2":{"533":1}}],["表示变点的个数",{"2":{"533":1}}],["表示变量为空�",{"2":{"210":1}}],["表示变量已声明",{"2":{"210":1}}],["表示指示函数",{"2":{"532":1}}],["表示曲线的中点",{"2":{"532":1}}],["表示曲线的增长率",{"2":{"532":1}}],["表示理论将图模型分为如下两个类别",{"2":{"521":1}}],["表示是上下文相关的",{"2":{"422":1}}],["表示跳跃表的末�",{"2":{"186":1}}],["表示从mstset某个点到达为使用的点的最小距离",{"2":{"59":1}}],["表示i",{"2":{"58":1}}],["表示岛",{"2":{"33":1}}],["表示长度为i",{"2":{"12":1}}],["表示右下角的1",{"2":{"11":1}}],["表示原串的前",{"2":{"7":1}}],["表示",{"2":{"6":1,"33":1}}],["表示四个矩阵",{"2":{"6":1}}],["表示dp",{"2":{"4":1}}],["表示下标i结尾",{"2":{"3":1}}],["表示以i和j结尾的最长序列的长度",{"2":{"2":1}}],["表示以j结尾的最长子序列的长",{"2":{"1":1}}],["支持向量的个数一般很少",{"2":{"635":1}}],["支持向量机中进行分类",{"2":{"366":1}}],["支持离散变量",{"2":{"514":1}}],["支持",{"2":{"511":1}}],["支持自定义loss",{"2":{"511":1}}],["支持自定义损失函数",{"2":{"451":1}}],["支持并行",{"2":{"503":1}}],["支持列抽样",{"2":{"497":1,"513":1}}],["支持高效并行",{"2":{"464":1}}],["支持复杂策略更新",{"2":{"423":1}}],["支持检索",{"2":{"423":1}}],["支持使用向量索引库",{"2":{"423":1}}],["支持快速相似度搜索",{"2":{"423":1}}],["支持思考",{"2":{"423":1}}],["支持结构化",{"2":{"422":1}}],["支持水平触发和边缘触发",{"2":{"302":1}}],["支持的同时连接数上限很高",{"2":{"302":1}}],["支持单播",{"2":{"240":1}}],["支持点对点单播",{"2":{"240":1}}],["支持事务",{"2":{"161":1}}],["支持外键",{"2":{"161":1}}],["支持行",{"2":{"161":1}}],["支持表锁",{"2":{"161":1}}],["支数量的股票",{"2":{"26":1}}],["整体来看可能引起方差较大",{"2":{"622":1}}],["整体而言是的rf是一个鲁棒的模型",{"2":{"497":1}}],["整体模型复杂度在提高",{"2":{"433":1}}],["整型",{"2":{"465":1}}],["整合回复结果",{"2":{"423":1}}],["整个应用程序结构",{"2":{"800":1}}],["整个过程占用的时机就可能超过",{"2":{"792":1}}],["整个排序过程可以递归进行",{"2":{"757":1}}],["整个dropout过程就相当于对很多个不同的神经网络取平均",{"2":{"564":1}}],["整个训练集",{"2":{"546":1}}],["整个adaboost却能快速收敛",{"0":{"440":1}}],["整个模型的参数量主要是由卷积核的权重weights的数量决定",{"2":{"314":1}}],["整个程序就崩溃了",{"2":{"288":1}}],["整理和总结个人经历和成�",{"2":{"833":1}}],["整理大数据方面的相关知识点",{"2":{"765":1}}],["整理",{"0":{"154":1}}],["整数精度为",{"2":{"210":1}}],["整数类型",{"2":{"81":1}}],["整数k",{"2":{"34":1}}],["整数",{"2":{"15":1}}],["复用",{"2":{"302":1}}],["复杂",{"2":{"240":1}}],["复杂度优化",{"2":{"106":1}}],["复杂度分析",{"2":{"105":1}}],["复制到其他的redis服务器",{"2":{"194":1}}],["复制老年代用标记",{"0":{"154":1}}],["说说你犯过的一个错误",{"2":{"825":1}}],["说说什么情景下gbdt不如lr",{"0":{"502":1}}],["说起来有点像掷骰子n次出",{"2":{"621":1}}],["说朴素贝叶斯真的很朴素",{"2":{"614":1}}],["说的话的",{"2":{"422":1}}],["说一下非极大值抑制",{"0":{"397":1}}],["说一下该网络是怎么回归bbox的",{"0":{"372":1}}],["说一下roi",{"0":{"368":1}}],["说一�",{"0":{"148":1}}],["说我也不知道",{"2":{"267":1}}],["说不知道自己的是多少",{"2":{"267":1}}],["说几个常用�",{"0":{"220":1}}],["说明最终的结果和收�",{"2":{"829":1}}],["说明需要完成的任务和目�",{"2":{"829":1}}],["说明数据分布越分散",{"2":{"558":1}}],["说明要增大步长",{"2":{"544":1}}],["说明模型更可能生成该文",{"2":{"423":1}}],["说明该客户端不持有锁",{"2":{"185":1}}],["说明",{"2":{"74":1,"76":1,"81":3,"83":1,"94":2,"776":1}}],["防止收敛到单一高奖励回答",{"2":{"423":1}}],["防止偏离太远",{"2":{"423":1}}],["防止泛化能力下降",{"2":{"423":1}}],["防止通用能力丢失",{"2":{"423":1}}],["防止模型过拟合领域数据",{"2":{"423":1}}],["防止模型仅学习",{"2":{"423":1}}],["防止用户内容污染系统",{"2":{"422":1}}],["防止参数过分依赖训练数据",{"2":{"332":1}}],["防止过拟合",{"2":{"313":1,"497":1}}],["防止某进程正在访问共享资源时",{"2":{"293":1}}],["防止包丢失",{"2":{"241":1}}],["防止修改常量�",{"2":{"215":1}}],["防止全局变量过去庞大",{"2":{"215":1}}],["防止第二次删除缓存失败",{"2":{"199":1}}],["防止同一时间大量数据过期现象发生",{"2":{"188":1}}],["防止代码读取�",{"2":{"144":1}}],["防止多次使用",{"2":{"35":1}}],["指示",{"2":{"800":1}}],["指示网页中的位置",{"2":{"798":1}}],["指定map或者reduce已经输入和输出文件的路径",{"2":{"770":1}}],["指上下文词集",{"2":{"719":1}}],["指网络广告",{"2":{"593":1}}],["指出如果将一些特征进行融合绑定",{"2":{"468":1}}],["指令覆写",{"2":{"422":1}}],["指令",{"2":{"422":1}}],["指令重排会导致计算结果不一致�",{"2":{"142":1}}],["指的是百分比",{"2":{"533":1}}],["指的是当前模型可感知的全部",{"2":{"422":1}}],["指的是什么",{"0":{"315":1}}],["指的是卷积神经网络中最大的通道数",{"2":{"311":1}}],["指数",{"2":{"306":1}}],["指向module",{"2":{"112":1}}],["修正余弦相似度",{"2":{"730":1}}],["修补索引之间的差值",{"2":{"397":1}}],["修饰的变量能够保证每个线程能够获取该变量的最新值",{"2":{"142":1}}],["修改为完整的词或实体",{"2":{"716":1}}],["修改新的变量",{"2":{"543":1}}],["修改当前数据的label进行学习第m个学习器",{"2":{"436":1}}],["修改rpn网络的结构",{"2":{"400":1}}],["修改了网络结构",{"2":{"378":1}}],["修改",{"2":{"5":1}}],["禁止指令重排",{"2":{"140":1,"142":1,"144":1}}],["还可以接受",{"2":{"751":1}}],["还可以按照类似的方法继续往下分",{"2":{"749":1}}],["还要精打细算做各种测试",{"2":{"573":1}}],["还要解决定位问题",{"2":{"360":1}}],["还依赖于上下文中",{"2":{"527":1}}],["还需要存储特征对应样本的梯度统计值的索引",{"2":{"513":1}}],["还支持线性分类器",{"2":{"504":1,"513":1}}],["还能减少计算",{"2":{"497":1,"513":1}}],["还能保证它们的传输顺序",{"2":{"237":1}}],["还来自属性扰动",{"2":{"492":1}}],["还学习推理步骤",{"2":{"423":1}}],["还在向量空间中学到了一些语义关系的方向性",{"2":{"422":1}}],["还是可以认为这100个特征和原来那一个特征扮演的效果一样",{"2":{"669":1}}],["还是梯度总和",{"0":{"335":1}}],["还是最大梯度",{"0":{"335":1}}],["还是1",{"2":{"276":1}}],["还有一种是用户的操作",{"2":{"786":1}}],["还有一种是基于item的协同过滤算法",{"2":{"727":1}}],["还有就是这么编程模式可以简单的解决很多常见的问题",{"2":{"769":1}}],["还有就是直接减小learning",{"2":{"507":1}}],["还有就是每个bin中样本数量",{"2":{"465":1}}],["还有必要的正则项和最优特征选择时的并行计算等",{"2":{"494":1}}],["还有array和object",{"2":{"223":1}}],["还有逻辑运算的部分",{"2":{"109":1}}],["还持有锁",{"2":{"185":1}}],["还记录",{"2":{"174":1}}],["还包含了相应行数据的聚簇索引键",{"2":{"165":1}}],["还提供了一系列原语",{"2":{"140":1}}],["目的",{"2":{"388":1,"657":1}}],["目的是让原来无序的集合满足条件有序",{"2":{"755":1}}],["目的是提升检索效果",{"2":{"423":1}}],["目的是通过减少易分类样本的权重",{"2":{"387":1}}],["目的是检测数据在传输过程中的任何变化",{"2":{"241":1}}],["目的是保证并发编程场景中的原子性",{"2":{"140":1}}],["目前集成学习主要分为2大类",{"2":{"425":1}}],["目前anchor",{"2":{"367":1}}],["目前通常使用max",{"2":{"313":1}}],["目标处理阶�",{"2":{"778":1}}],["目标函数是二次的",{"2":{"634":1}}],["目标函数的scalability",{"2":{"511":1}}],["目标函数中增加了正则",{"2":{"507":1}}],["目标函数加入正则项",{"2":{"503":1}}],["目标是使前向分步算法得到的α和gm",{"2":{"430":1}}],["目标是使用前面的数字构造后面的数字",{"2":{"8":1}}],["目标真实box",{"2":{"367":1}}],["目标检测",{"2":{"418":1}}],["目标检测问题",{"2":{"393":1}}],["目标检测的算法抽象成三个惯用的组件",{"2":{"362":1}}],["目标检测的发展脉络可以划分为两个周期",{"2":{"360":1}}],["目标检测不仅要解决分类问题",{"2":{"360":1}}],["目标检测任务是找出图像或视频中人们感兴趣的物体",{"2":{"360":1}}],["目标检测背景知识",{"0":{"360":1},"1":{"361":1,"362":1}}],["目标检测部分",{"0":{"359":1},"1":{"360":1,"361":1,"362":1,"363":1,"364":1,"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1,"377":1,"378":1,"379":1,"380":1,"381":1,"382":1,"383":1,"384":1,"385":1,"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1,"396":1,"397":1,"398":1,"399":1,"400":1,"401":1,"402":1,"403":1,"404":1,"405":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1,"414":1}}],["目标阶段",{"2":{"226":1}}],["目标证明每次是考虑当前最优能够达到局部最优",{"2":{"17":1}}],["屏蔽了各种硬件和操作系统的访问差异的",{"2":{"140":1}}],["内排序和外排序结合",{"2":{"748":1}}],["内容贡献",{"2":{"849":1}}],["内容要点",{"2":{"809":1}}],["内容正在整理中",{"2":{"745":1,"806":1}}],["内容导航",{"0":{"98":1,"808":1},"1":{"99":1,"100":1,"101":1,"809":1,"810":1,"811":1,"812":1}}],["内部节点是划分的特征",{"2":{"597":1}}],["内部节点",{"2":{"597":1}}],["内部节点再划分所需最小样本数",{"2":{"484":2}}],["内部函数可以链式访问外部函数的变量",{"2":{"214":1}}],["内核完成所有操作后向应用进程发送信号",{"2":{"302":1}}],["内核在数据到达时向应用进程发送",{"2":{"302":1}}],["内存",{"2":{"763":1}}],["内存放不下",{"2":{"763":1}}],["内存限",{"2":{"763":1}}],["内存限制大小是1m",{"2":{"749":1}}],["内存限制是4g",{"2":{"747":1}}],["内存不足以容纳这2",{"2":{"751":1}}],["内存占用更小",{"2":{"465":1}}],["内存占用大的缺点",{"2":{"464":1}}],["内存占用低的特点",{"2":{"464":1}}],["内存访问优化",{"2":{"422":1}}],["内存划分",{"0":{"152":1}}],["内存屏障会提�",{"2":{"143":1}}],["内存模型是通过在变量修改后将新值同步回主内存",{"2":{"140":1}}],["内存模型",{"2":{"140":2}}],["非id类树",{"2":{"741":1}}],["非id建一类树",{"2":{"741":1}}],["非线性",{"2":{"654":1,"666":1}}],["非线性归一化",{"2":{"306":1}}],["非监督学",{"2":{"651":1}}],["非常详细",{"2":{"473":1}}],["非文本部分",{"2":{"404":1}}],["非阻塞式",{"2":{"302":1}}],["非关联型的",{"2":{"258":1}}],["非关系型数据库的有点",{"2":{"258":1}}],["非关系型数据库",{"2":{"258":1}}],["非对称加密算法的加解密速度低于对称加密算法",{"2":{"252":1}}],["非对称加密算法",{"2":{"252":1}}],["非聚簇索引是如何查询的",{"0":{"165":1}}],["非聚簇索引",{"2":{"161":1}}],["非公平锁",{"2":{"139":1}}],["非负整数",{"2":{"43":1}}],["向概率转化的过程是非线性的",{"2":{"663":1}}],["向系统加入了正确先验这个信息",{"2":{"568":1}}],["向这一步所在位置沿着最陡峭最易下山的位置走一步",{"2":{"542":1}}],["向量内积容易使得",{"2":{"703":1}}],["向量检索召回语义相近文本",{"2":{"423":1}}],["向量相似度检索不能实现关键词的精确匹配",{"2":{"423":1}}],["向量空间更易可视化",{"2":{"422":1}}],["向服务器发起一个请求",{"2":{"252":1}}],["向服务器请求建立链接",{"2":{"235":1}}],["向gtld服务器发起解析请求",{"2":{"249":1}}],["向根域名解析服务器发起域名解析请求",{"2":{"249":1}}],["向本地域名解析服务系统发起域名解析的请求",{"2":{"249":1}}],["向os申请重量级锁",{"2":{"139":1}}],["向数组添加patch元素",{"2":{"23":1}}],["上�",{"2":{"795":1}}],["上述的过程可以叫做外排序",{"2":{"763":1}}],["上述情况就会导致不一致的情形出现",{"2":{"197":1}}],["上图中的提升决策树包含两棵子树",{"2":{"739":1}}],["上式的对偶问题为",{"2":{"635":1}}],["上",{"2":{"519":1,"782":1,"795":1}}],["上文公式",{"2":{"497":1}}],["上任意一点x",{"2":{"496":1}}],["上具有",{"2":{"496":1}}],["上具有n阶导数",{"2":{"496":1}}],["上的计算资源",{"2":{"422":1}}],["上一步得到每一个bounding",{"2":{"381":1}}],["上升",{"2":{"346":1}}],["上采样",{"2":{"312":1}}],["上采样的原理和常用方式",{"0":{"312":1}}],["上下打乱特征矩阵第i列的顺序",{"2":{"462":1}}],["上下文词的更新公式为",{"2":{"721":1}}],["上下文",{"2":{"719":1}}],["上下文环境相似的两个词有着相近的语义",{"2":{"718":1}}],["上下文等信息相关",{"2":{"527":1}}],["上下文或摘要",{"2":{"423":1}}],["上下文共享",{"2":{"423":1}}],["上下文信息相关性的跨度可能非常大",{"2":{"527":1}}],["上下文信息",{"2":{"422":1}}],["上下文生成",{"2":{"422":1}}],["上下文长度",{"2":{"422":1}}],["上下文从初始的上下文改变�",{"2":{"213":1}}],["上下�",{"2":{"190":1}}],["上下左右",{"2":{"33":1}}],["上完成了加锁",{"2":{"185":1}}],["上面的这四个步骤是我们从top",{"2":{"769":1}}],["上面的",{"2":{"163":1}}],["上来说",{"2":{"139":1}}],["想要使用一个插件",{"2":{"800":1}}],["想要只留下一只猫",{"2":{"27":1}}],["想个办法高校统计出这批数据的top10",{"2":{"752":1}}],["想具体了解的可以看一下原文",{"2":{"735":1}}],["想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙",{"2":{"138":1}}],["需高带宽网络避免通信瓶颈",{"2":{"423":1}}],["需2张a100",{"2":{"423":1}}],["需大量标注和反馈",{"2":{"423":1}}],["需大量高质量医疗数据",{"2":{"423":1}}],["需结合多模态信号和互动数据",{"2":{"423":1}}],["需�",{"2":{"137":1}}],["需要理论学习与实践相结合",{"2":{"850":1}}],["需要一种方案来解决长尾广告的问题",{"2":{"741":1}}],["需要一点先验知",{"2":{"651":1}}],["需要将a分成train",{"2":{"741":1}}],["需要将它分割成一些子",{"2":{"7":1}}],["需要进行在线数据加入",{"2":{"740":1}}],["需要进行任务相关的网络设计",{"2":{"708":1}}],["需要做大量的特征工程",{"2":{"739":1}}],["需要单独的进行embedding操作",{"2":{"734":1}}],["需要利用因子分析或者变量聚类分析等手段来选择代表性的自变量",{"2":{"663":1}}],["需要大量的内存",{"2":{"649":1}}],["需要大量的人工特征工程",{"2":{"502":1}}],["需要求解能够正确划分训练数据集并且几何间隔最大的分离超平面",{"2":{"642":1}}],["需要样本多",{"2":{"632":1}}],["需要知道每个类的条件概率分",{"2":{"631":1}}],["需要计算先验概率",{"2":{"626":1}}],["需要计算每个特征的增益",{"2":{"497":2,"505":1,"513":1}}],["需要对模型进行实时更新",{"2":{"740":1}}],["需要对特定分类中各个特征出现的概率进行连乘",{"2":{"619":1}}],["需要对所有历史数据重新训练",{"2":{"546":1}}],["需要考虑样本不均衡问题以及实际业务中好样本与坏样本的重要程度",{"2":{"585":1}}],["需要学习率的原因与梯度下降法相同",{"2":{"555":1}}],["需要反复用式",{"2":{"555":1}}],["需要多次用不同初始值运行算法",{"2":{"544":1}}],["需要设置的容量值",{"2":{"537":1}}],["需要在0",{"2":{"666":1}}],["需要在",{"2":{"533":1}}],["需要给出变点的位置",{"2":{"533":1}}],["需要新的模型可以解决这种长程依赖",{"2":{"527":1}}],["需要等上一棵树完全生成",{"2":{"501":1}}],["需要我们手动处理变换成数值后才能输入到模型中",{"2":{"497":1}}],["需要指出在gbdt的原始算法中没有使用行列的随机采样",{"2":{"497":1}}],["需要选择最佳的随机森林子树数量",{"2":{"484":1}}],["需要环境反馈和奖励信号",{"2":{"423":1}}],["需要额外预训练资源",{"2":{"423":1}}],["需要配置哪些工具",{"2":{"423":1}}],["需要预先指定簇数",{"2":{"422":1}}],["需要快速上线",{"2":{"422":1}}],["需要注意的是这里的并行计算是map和reduce的分别并行计算",{"2":{"770":1}}],["需要注意的是",{"2":{"397":1}}],["需要用户事先指定类簇个数",{"2":{"396":1}}],["需要用到最小堆来实现",{"2":{"21":1}}],["需要针对每一个不同的recall值",{"2":{"393":1}}],["需要能够详细画出网络结构图",{"0":{"365":1}}],["需要通过遍历这个集合",{"2":{"302":1}}],["需要称重三次",{"2":{"270":1}}],["需要查询所有的列",{"2":{"163":1}}],["需要读写内存�",{"2":{"134":1}}],["需要global属性�",{"2":{"112":1}}],["需要提出",{"2":{"50":1}}],["条标注样本训练",{"2":{"422":1}}],["条带有标签的数据",{"2":{"422":1}}],["条件独立假设",{"2":{"627":1}}],["条件概率",{"0":{"613":1},"2":{"613":1}}],["条件概率公式",{"2":{"519":1}}],["条件随机场crf直接对条件概率建模",{"2":{"527":1}}],["条件随机场定义参考维基百",{"2":{"522":1}}],["条件随机场属于判别式模型",{"2":{"521":1}}],["条件随机场处理中文分词",{"2":{"521":1}}],["条件随机场预测的维特比算法求解过程",{"2":{"519":1}}],["条件随机场对于输入和输出的机率分布",{"2":{"519":1}}],["条件随机场跟隐马尔可夫模型常被一起提及",{"2":{"519":1}}],["条件随机场的图模型布局是可以任意给定的",{"2":{"519":1}}],["条件随机场为无向图模型",{"2":{"519":1}}],["条件随机场",{"2":{"519":1,"521":1}}],["条件随机场面试题",{"0":{"518":1},"1":{"519":1,"520":1,"521":1,"522":1}}],["条件4",{"2":{"267":1}}],["条件3",{"2":{"267":1}}],["条件2",{"2":{"267":1}}],["条件1",{"2":{"267":1}}],["条件",{"2":{"136":1}}],["条边的有向图是否存在环",{"2":{"61":1}}],["提前到达",{"2":{"836":1}}],["提前停止",{"2":{"605":1}}],["提高分组的效果",{"2":{"572":1}}],["提高数据集多样性",{"2":{"423":1}}],["提高小模型泛化与推理能力",{"2":{"423":1}}],["提高生成内容的准确性和时效性",{"2":{"423":1}}],["提高效率和效果",{"2":{"423":1}}],["提高一致性",{"2":{"422":1}}],["提高区分度",{"2":{"422":1}}],["提高了网络通信模型的性能",{"2":{"202":1}}],["提升决策树",{"2":{"739":1}}],["提升表达能力",{"2":{"664":1}}],["提升表达精度",{"2":{"423":1}}],["提升模型创造力和灵活性",{"2":{"423":1}}],["提升模型对人类意图的精准理解与执行",{"2":{"423":1}}],["提升模型对特定指令的响应能力",{"2":{"423":1}}],["提升稳定性和准确性",{"2":{"423":1}}],["提升判别力",{"2":{"423":1}}],["提升检索和匹配的准确性",{"2":{"423":1}}],["提升召回精准度",{"2":{"423":1}}],["提升嵌入相似度",{"2":{"423":1}}],["提升最终输出质量",{"2":{"423":1}}],["提升覆盖率与准确性",{"2":{"423":1}}],["提升上下文一致性",{"2":{"423":1}}],["提升了主题的清晰度和区分度",{"2":{"422":1}}],["提升了模型的泛化性能",{"2":{"328":1}}],["提升整体系统效果",{"2":{"422":1}}],["提升低资源条件下的准确率",{"2":{"422":1}}],["提升小目标的特征质量",{"2":{"403":1}}],["提升被anchor包含的概率",{"2":{"403":1}}],["提升特征表征强度",{"2":{"399":1}}],["提升应用的访问性能",{"2":{"200":1}}],["提出改进建议",{"2":{"849":1}}],["提出了两大技术",{"2":{"495":1}}],["提出focal",{"2":{"387":1}}],["提出",{"2":{"297":1}}],["提交的表单信息",{"2":{"246":1}}],["提取出某日访问百度次数最多的那个ip",{"2":{"750":1}}],["提取每张照片的视觉特征向量",{"2":{"423":1}}],["提取压缩后的语义信息",{"2":{"423":1}}],["提取的不同大小的",{"2":{"367":1}}],["提取的特征会更抽象",{"2":{"327":1}}],["提取主要特征",{"2":{"339":1}}],["提取特征后",{"2":{"312":1}}],["提取需要查询的表名�",{"2":{"163":1}}],["提取",{"2":{"163":1}}],["提供我们需要的map和reduce函数即可",{"2":{"769":1}}],["提供需要处理的具体内容",{"2":{"422":1}}],["提供必要背景",{"2":{"422":1}}],["提供一个大感受野强语义的特征图",{"2":{"388":1}}],["提供无连接服务",{"2":{"240":1}}],["提供面向连接服务",{"2":{"240":1}}],["提供了非线性",{"2":{"339":1}}],["提供了两个高级的字节码指�",{"2":{"140":1}}],["提供了一�",{"2":{"136":1}}],["提供的",{"2":{"139":1}}],["提示工程",{"2":{"423":4}}],["提示词压缩",{"2":{"423":1}}],["提示词更短",{"2":{"423":1}}],["提示词审查机制",{"2":{"422":1}}],["提示词模板设计防护",{"2":{"422":1}}],["提示",{"2":{"106":1,"423":3,"840":1}}],["锁互斥机制",{"2":{"185":1}}],["锁的",{"2":{"184":1}}],["锁绑定多个条件",{"2":{"136":1}}],["锁非公平锁",{"2":{"136":1}}],["公式变为",{"2":{"730":1}}],["公式如下",{"2":{"697":1}}],["公式",{"2":{"684":1,"730":4}}],["公式推导及例题解析",{"2":{"340":1}}],["公比是1",{"2":{"280":1}}],["公钥负责加密",{"2":{"252":1}}],["公平锁",{"2":{"136":1}}],["公司调研",{"2":{"833":1}}],["公司文化�",{"0":{"827":1}}],["公司",{"2":{"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1,"51":1,"52":1,"54":1,"55":1,"56":1}}],["底层使用的数据结构是跳�",{"2":{"186":1}}],["底层实现",{"0":{"136":1,"138":1,"141":1,"143":1},"1":{"137":1,"138":1,"139":1,"142":1,"143":1,"144":1},"2":{"139":1}}],["底层结构",{"2":{"118":1}}],["包括离散的分类特征域",{"2":{"734":1}}],["包括三个门",{"2":{"697":1}}],["包括卷积网络",{"2":{"688":1}}],["包括卷积核的权重weights",{"2":{"314":1}}],["包括隐状态序列",{"2":{"527":1}}],["包括subsample",{"2":{"507":1}}],["包括max",{"2":{"507":1}}],["包括0和1",{"2":{"393":1}}],["包括",{"2":{"308":3}}],["包括加密的url一起发送到服务器",{"2":{"252":1}}],["包括前不包括后�",{"2":{"220":1}}],["包含的图片的尺寸",{"2":{"784":1}}],["包含的任何数字都可以由数组中某些元素的总和形成",{"2":{"23":1}}],["包含了1阶特征与二阶特征的交叉",{"2":{"738":1}}],["包含",{"2":{"702":1}}],["包含有n−1个元素的后选划分点集合",{"2":{"603":1}}],["包含字段",{"2":{"423":1}}],["包含更多数据集",{"2":{"423":1}}],["包含服务器公钥s",{"2":{"252":1}}],["包下提供的一套互斥锁",{"2":{"136":1}}],["包下的原子类实现",{"2":{"135":1}}],["除数是惩罚项",{"2":{"684":1}}],["除以广告的展现",{"2":{"593":1}}],["除了",{"2":{"784":1}}],["除了特征间的线性",{"2":{"735":1}}],["除了周末",{"2":{"536":1}}],["除了sgd和adam之外",{"0":{"308":1}}],["除了上述作用以外",{"2":{"194":1}}],["除了定义了一套规范",{"2":{"140":1}}],["除�",{"2":{"140":1}}],["除非向gender这种维数很小的情况",{"2":{"446":1}}],["除非你见过原题",{"2":{"266":1}}],["除非加锁的代码中出现异常或正常执行完成",{"2":{"139":1}}],["除非是数",{"2":{"83":1}}],["除此之�",{"2":{"135":1}}],["关注业绩和目标达成",{"0":{"840":1}}],["关注结果和价值创�",{"2":{"822":1}}],["关联规则是不考虑tems或者使用它们的users情况下分析内容之间的关系",{"2":{"730":1}}],["关于输入",{"2":{"734":1}}],["关于低阶特征交互",{"2":{"732":1}}],["关于smo算法",{"2":{"644":1}}],["关于对偶问题的解α∗=",{"2":{"635":1}}],["关键损失函数的最小值",{"2":{"544":1}}],["关键因素",{"2":{"423":1}}],["关键词的所有字母已被取出",{"2":{"762":1}}],["关键词广",{"2":{"593":1}}],["关键词检索通过倒排索引确保精确命中重要术语",{"2":{"423":1}}],["关键词黑名单匹配",{"2":{"422":1}}],["关键词后处理",{"2":{"422":1}}],["关键字时",{"2":{"143":1}}],["关键字时所生成的汇编代码发现",{"2":{"143":1}}],["关键字和没有加入",{"2":{"143":1}}],["关键字修饰的变量在被修改后可以立即同步到主内存",{"2":{"140":1}}],["关键字",{"2":{"139":1}}],["关键字来保证线程的安全",{"2":{"135":1}}],["关系识别结果",{"2":{"423":1}}],["关系型数据库的优点",{"2":{"258":1}}],["关系型数据库和非关系型数据库",{"0":{"258":1}}],["关系数据库",{"2":{"258":1}}],["关系模型",{"2":{"256":1}}],["关系",{"2":{"212":1}}],["关闭空闲线程",{"2":{"130":1}}],["浪费计算资",{"2":{"632":1}}],["浪费接收方的资源",{"2":{"237":1}}],["浪费性能",{"2":{"196":1}}],["浪费",{"2":{"134":1}}],["很成熟的mapreduce的实现",{"2":{"769":1}}],["很难找到近邻",{"2":{"730":1}}],["很难充分利用gpu上的计算单元",{"2":{"357":1}}],["很敏感",{"2":{"663":1}}],["很简单很天真",{"2":{"614":1}}],["很容易并行化",{"2":{"502":1}}],["很容易发生并发冲突",{"2":{"134":1}}],["很好地引入了随机性",{"2":{"460":1}}],["很小",{"0":{"403":1}}],["很可能并不会立即关闭socket",{"2":{"239":1}}],["很多算法只是专注于离散值或者连续值",{"2":{"607":1}}],["很多次实验之后",{"2":{"575":1}}],["很多时候我们无法考量太久以前的词",{"2":{"527":1}}],["很多情况下只拟合残差",{"2":{"515":1}}],["很多数据都查不到从而查数据�",{"2":{"190":1}}],["很多公司会问道非递归代码",{"2":{"85":1}}],["字段",{"2":{"800":1}}],["字段�",{"2":{"133":1}}],["字典树用一句话表示就是根据字符串的前缀构成的树结构",{"2":{"762":1}}],["字典树",{"2":{"762":1}}],["字典",{"0":{"762":1}}],["字粒度难以学到词",{"2":{"714":1}}],["字节跳动",{"0":{"369":1,"389":1,"390":1}}],["字节跳动教育prek客户端日常实习",{"2":{"253":1}}],["字符串处理算法",{"2":{"99":1}}],["字符串",{"2":{"99":1}}],["字符串相",{"0":{"83":1}}],["字符串中的第一个唯一字符",{"0":{"82":1}}],["乐观锁",{"2":{"133":1}}],["乐观锁适用于读多写少的场景",{"2":{"133":1}}],["乐观锁的实现方案一般有两种",{"2":{"133":1}}],["乐观锁体现的是悲观锁的反面",{"2":{"133":1}}],["核",{"2":{"640":1}}],["核函数一般选择线性核",{"2":{"640":1}}],["核函数之间的区别",{"0":{"640":1}}],["核函数的定义",{"2":{"638":1}}],["核函数的本质",{"2":{"635":1}}],["核函数对应的gram矩阵为半正定矩阵",{"2":{"635":1}}],["核技",{"2":{"635":1}}],["核心重点",{"2":{"845":1,"846":1,"847":1,"848":1}}],["核心算法的一次大的更新",{"2":{"792":1}}],["核心思想",{"0":{"740":1}}],["核心是从输入中有选择地聚焦到特定重要信息上的一种机制",{"2":{"702":1}}],["核心公式",{"0":{"496":1,"526":1,"635":1,"729":1},"2":{"729":1}}],["核心目的有两点",{"2":{"423":1}}],["核心线程池大�",{"2":{"129":1}}],["核数",{"2":{"131":2}}],["空值特征自动划分",{"2":{"494":1}}],["空洞卷积",{"2":{"306":1,"324":1}}],["空格",{"2":{"246":4}}],["空闲时间达�",{"2":{"130":1}}],["空间占用0",{"2":{"763":1}}],["空间距离公式存在的不足这边也存在",{"2":{"730":1}}],["空间利用率提高但是哈希冲突概率增加",{"2":{"119":1}}],["空间会变�",{"2":{"110":1}}],["空间已经使用了超�",{"2":{"110":1}}],["空间时",{"2":{"110":1}}],["空间复杂度高",{"2":{"649":1}}],["空间复杂度分析",{"2":{"101":1}}],["空间复制一个对象到",{"2":{"110":1}}],["空间复制�",{"2":{"110":1}}],["空间",{"2":{"110":3}}],["空间�",{"2":{"110":1}}],["空间中",{"2":{"110":2}}],["空间解决问题",{"2":{"81":1}}],["且需要频繁刷新的场景下",{"2":{"792":1}}],["且gbdt前面的树",{"2":{"741":1}}],["且是端到端的",{"2":{"738":1}}],["且矩阵为静态的需要随时更新",{"2":{"730":1}}],["且手肘法效率不高",{"2":{"677":1}}],["且一般都用于处理线性二分类问题",{"2":{"641":1,"672":1}}],["且在开区间",{"2":{"496":1}}],["且最后得到的强分类器的分类精度依赖于所有弱分类器的分类精度",{"2":{"487":1}}],["且只保存特征离散化后的值",{"2":{"465":1}}],["且模型需要稳定向量空间结构",{"2":{"423":1}}],["且anchor",{"2":{"380":1}}],["且三大范式是一级一级依赖的",{"2":{"257":1}}],["且文件不易破损",{"2":{"193":1}}],["且",{"2":{"130":1,"388":2}}],["来配置这些处理过程�",{"2":{"800":1}}],["来作为构建其内部依赖图的开始",{"2":{"800":1}}],["来发现什么时候使用倒排碎索引",{"2":{"761":1}}],["来统计每个query出现的次数",{"2":{"748":1}}],["来其上下文词来预测中心词",{"2":{"719":1}}],["来近似地估计真实的条件概率",{"2":{"718":1}}],["来拟合一个词序列的条件概率p",{"2":{"718":1}}],["来店消费的频率",{"2":{"679":1}}],["来了一个样本x",{"2":{"651":1}}],["来代替简单加1",{"2":{"618":1}}],["来和对应的特征a的各个特征值一起计算加权重后的信息增益比",{"2":{"601":1}}],["来衡量",{"2":{"589":1}}],["来增大假设空间",{"2":{"560":1}}],["来进行等距的变点设置",{"2":{"537":1}}],["来计算它的袋外数据误差",{"2":{"483":1}}],["来计算词频和逆文档频率",{"2":{"422":1}}],["来产生概率",{"2":{"472":1}}],["来估计",{"2":{"447":1}}],["来完成学习任务",{"2":{"425":1}}],["来适应旋转框检测的任务",{"2":{"404":1}}],["来预测检测框和每个框的confidence以及每个格子预测一共c个类别的概率分数",{"2":{"378":1}}],["来处理中断",{"2":{"301":1}}],["来处�",{"2":{"129":1}}],["来实现进程间的同步和通信",{"2":{"293":1}}],["来实现这个机�",{"2":{"136":1}}],["来查看执行计�",{"2":{"164":1}}],["来保证负载均衡",{"2":{"770":1}}],["来保证多线程之间操作的有序性",{"2":{"140":1}}],["来保证多线程操作时变量的可见性",{"2":{"140":1}}],["来保证方法和代码块内的操作是原子性的",{"2":{"140":1}}],["来说可以避免出现死锁的情况",{"2":{"136":1}}],["来自百度百科",{"2":{"762":1}}],["来自相同的位置",{"2":{"702":1}}],["来自上一个",{"2":{"702":1}}],["来自",{"2":{"26":1,"689":1,"702":1}}],["拒绝策略",{"2":{"129":1}}],["作者认为小目标在高层没有足够的信息",{"2":{"385":1}}],["作者通过在所有训练图像的所有边界框上运行k",{"2":{"378":1}}],["作为特征提取器",{"2":{"710":1,"713":1}}],["作为句子的表征",{"2":{"689":1}}],["作为句子表征",{"2":{"423":1}}],["作为神经元失活的补偿",{"2":{"566":1}}],["作为基分类器",{"2":{"513":1}}],["作为基模型",{"2":{"445":1}}],["作为最佳分裂点",{"2":{"510":1}}],["作为快速原型和基线",{"2":{"423":1}}],["作为dpo训练的输入",{"2":{"423":1}}],["作为超参数进行学习",{"2":{"367":1}}],["作为当前层的输出通道",{"2":{"348":1}}],["作为一个关键字放到函数前面",{"2":{"218":1}}],["作为values",{"2":{"89":1}}],["作用范围不同",{"2":{"244":1}}],["作用�",{"2":{"215":1}}],["作用域为全局",{"2":{"214":1}}],["作用",{"0":{"141":1,"142":1},"1":{"142":1,"143":1,"144":1},"2":{"129":1,"194":1,"339":1,"362":1}}],["线段连接相邻的点",{"2":{"590":1}}],["线性模型可以分段的学习到一个非线性的映射",{"2":{"739":1}}],["线性模型的输出都是在",{"2":{"670":1}}],["线性模型会比非线性模型好的原因了",{"2":{"502":1}}],["线性",{"2":{"654":1}}],["线性回归主要解决回归任务",{"2":{"665":1}}],["线性回归与逻辑回归的区别",{"0":{"665":1}}],["线性回归要求因变量服从正态分布吗",{"0":{"658":1}}],["线性回归的输出一半是连续的",{"2":{"665":1}}],["线性回归的结果y带入一个非线性变换的sigmoid函数中",{"2":{"659":1}}],["线性回归的假设前提是噪声服从正态分布",{"2":{"658":1}}],["线性回归的假设函数",{"2":{"655":1}}],["线性回归的假设函数是什么形式",{"0":{"655":1}}],["线性回归的损失函数是mse",{"2":{"665":1}}],["线性回归的损失函数是什么形式",{"0":{"656":1}}],["线性回归的损失函数",{"2":{"657":1}}],["线性回归就是利用的样本d=",{"2":{"654":1}}],["线性回归",{"2":{"654":1,"657":1}}],["线性回归于逻辑回归面试题",{"0":{"653":1},"1":{"654":1,"655":1,"656":1,"657":1,"658":1,"659":1,"660":1,"661":1,"662":1,"663":1,"664":1,"665":1,"666":1,"667":1,"668":1,"669":1,"670":1,"671":1,"672":1}}],["线性扫",{"2":{"648":1}}],["线性核",{"2":{"640":1}}],["线性核函数",{"2":{"635":1}}],["线性可分支持向量机利用间隔最大化求得最优分离超平面",{"2":{"636":1}}],["线性可分训练集",{"2":{"635":1}}],["线性可分",{"2":{"634":1}}],["线性分类器",{"2":{"634":2}}],["线性分类器或者k",{"2":{"461":2}}],["线性归一化",{"2":{"306":1}}],["线性池了解吗",{"0":{"128":1},"1":{"129":1,"130":1,"131":1}}],["线程依赖于进程而存在",{"2":{"288":1}}],["线程之间切换的开销小",{"2":{"288":1}}],["线程可以看做轻量级的进程",{"2":{"288":1}}],["线程是cpu调度和分派的基本单位",{"2":{"288":1}}],["线程是否安全",{"2":{"121":1}}],["线程a更新了缓�",{"2":{"196":1}}],["线程a更新了数据库",{"2":{"196":1}}],["线程b更新了缓�",{"2":{"196":1}}],["线程b更新了数据库",{"2":{"196":1}}],["线程安全",{"2":{"196":1}}],["线程",{"2":{"130":1}}],["线程处理任务过程",{"0":{"130":1}}],["线程池的大小设置",{"0":{"131":1}}],["线程池的大小如何设置",{"0":{"128":1},"1":{"129":1,"130":1,"131":1}}],["线程池中超过",{"2":{"129":1}}],["线程池参�",{"0":{"129":1}}],["继承自",{"2":{"123":1}}],["继续维护a",{"2":{"756":1}}],["继续训练b",{"2":{"741":1}}],["继续训练出三棵树",{"2":{"472":1}}],["继续训练模型",{"2":{"422":1}}],["继续预训练时",{"2":{"423":1}}],["继续推导",{"2":{"268":1}}],["继续执行",{"2":{"218":1}}],["继续重试删除操作",{"2":{"199":1}}],["继续进行内存分配",{"2":{"110":1}}],["继续判断是否满足",{"2":{"23":1}}],["区分错误的对",{"2":{"423":1}}],["区别在于逻辑回归采用的是交叉熵损失函数",{"2":{"641":1,"672":1}}],["区别�",{"0":{"136":1},"1":{"137":1,"138":1,"139":1}}],["区别",{"0":{"123":1,"627":1},"2":{"140":1,"173":1,"244":1,"247":1,"369":1,"641":1,"672":1}}],["区间个数与箱子个数相等",{"2":{"465":1}}],["区间内",{"2":{"81":1}}],["区间内任何数字都可以",{"2":{"23":1}}],["区间内的任何数字都可以用",{"2":{"23":1}}],["区间上最小",{"2":{"6":1}}],["虚引�",{"2":{"122":1}}],["虚引用的区�",{"0":{"122":1}}],["宁愿抛出oom错误",{"2":{"122":1}}],["可指定宽",{"2":{"774":1}}],["可用聚类方式缩小搜索空间",{"2":{"730":1}}],["可控度高",{"2":{"663":1}}],["可形式化为一个求解凸二次规划的问题",{"2":{"634":1}}],["可清洗观察每个步骤",{"2":{"607":1}}],["可将样本从原始空间映射到一个更高维的特征空间",{"2":{"638":1}}],["可将样例根据其真是类别与学习器预测类别的组合划分为",{"2":{"586":1}}],["可将这种完整数据文件发送到云服务器存储",{"2":{"192":1}}],["可得",{"2":{"555":1}}],["可分为以下三种情况",{"2":{"551":1}}],["可节省算法运行时间",{"2":{"544":1}}],["可对特征数据标准化",{"2":{"544":1}}],["可使用baum",{"2":{"527":1}}],["可使用经典的动态规划算法维特比算法来求解最可能的状态序列",{"2":{"527":1}}],["可使用经验值常量来来代替max",{"2":{"306":1}}],["可夫模型属于生成式模型",{"2":{"521":1}}],["可并行的近似算法",{"2":{"513":1}}],["可并行的近似直方图算法",{"2":{"497":2}}],["可否将随机森林中的基分类器",{"0":{"461":1}}],["可扩展",{"2":{"451":1,"504":1}}],["可扩展至4张a100",{"2":{"423":1}}],["可同时生成的并行化方法",{"2":{"425":1}}],["可采用k",{"2":{"730":1}}],["可采用",{"2":{"423":1}}],["可人工或自动生成多种问法",{"2":{"423":1}}],["可视为分类",{"2":{"423":1}}],["可选",{"2":{"422":1}}],["可触发告警或拒答",{"2":{"422":1}}],["可大大减少计算量的卷积方法",{"2":{"394":1,"395":1}}],["可在原预测bbox上微调",{"2":{"372":1}}],["可解释性变异占",{"2":{"583":1}}],["可解释性变异占不可解释性变异整体变异",{"2":{"583":1}}],["可解释性强",{"2":{"422":2,"502":1}}],["可解释性",{"2":{"330":1}}],["可避免此问题",{"2":{"328":1}}],["可修改宏定义",{"2":{"302":1}}],["可知比其余蛋轻",{"2":{"270":1}}],["可能出现异常",{"2":{"770":1}}],["可能对于所有的query",{"2":{"748":1}}],["可能还需要根据聚类目标想评估方式",{"2":{"684":1}}],["可能平均10次以下",{"2":{"679":1}}],["可能几万元",{"2":{"679":1}}],["可能导致较弱的一个自变量回归符号不符合预期",{"2":{"663":1}}],["可能导致泛化不足",{"2":{"423":1}}],["可能是一个",{"2":{"654":2}}],["可能是极值点",{"2":{"551":1}}],["可能收敛到鞍点",{"2":{"550":1}}],["可能使得cpu",{"2":{"514":1}}],["可能会造成404�",{"2":{"798":1}}],["可能会导致严重的性能问题",{"2":{"787":1}}],["可能会导致对客户端提供的服务暂停数毫秒",{"2":{"192":1}}],["可能会有一部分没有处理结束",{"2":{"760":1}}],["可能会之字形地下降",{"2":{"541":1}}],["可能会长出比较深的决策树",{"2":{"466":1}}],["可能有些地方写的不完善甚至又错误",{"2":{"423":1}}],["可能产生多个正确识别的结果",{"2":{"361":1}}],["可能复杂的分类任务用了简单的模型",{"2":{"349":1}}],["可能不是最优的",{"2":{"266":1}}],["可能就是考察",{"2":{"266":1}}],["可存储数据远高于",{"2":{"244":1}}],["可设置为长时间保持",{"2":{"244":1}}],["可靠传输",{"2":{"240":1}}],["可维护性高",{"2":{"202":1}}],["可让",{"2":{"192":1}}],["可预期",{"2":{"190":1}}],["可重入加锁机制",{"2":{"185":1}}],["可重复读",{"2":{"170":1}}],["可见性",{"2":{"140":1,"142":1}}],["可见性和有序性",{"2":{"140":1}}],["可通过梯度下降法",{"2":{"730":1}}],["可通过梯度上升法来迭代",{"2":{"540":1}}],["可通过",{"2":{"139":1,"798":1}}],["可变",{"2":{"121":2}}],["可以直接引用的模块�",{"2":{"800":1}}],["可以直接发送syn+ack报文",{"2":{"239":1}}],["可以尝试使用",{"2":{"787":1}}],["可以起到加速作用",{"2":{"770":1}}],["可以让其他节点代替它运行任务",{"2":{"770":1}}],["可以知道那台节点运行的缓慢",{"2":{"770":1}}],["可以知道是轻还是重",{"2":{"270":1}}],["可以重新执行出现错误的运行节点",{"2":{"770":1}}],["可以对单个小文件应用快速排序",{"2":{"757":1}}],["可以对第二步的神经网络模型进行简化",{"2":{"718":1}}],["可以采用hash",{"2":{"750":1}}],["可以采用trie树",{"2":{"749":1}}],["可以采用分步生成策略",{"2":{"423":1}}],["可以单独建树",{"2":{"741":1}}],["可以两者结合",{"2":{"730":1}}],["可以转为二元应用",{"2":{"730":1}}],["可以转化为下式",{"2":{"430":1}}],["可以提高模型训练的效率",{"2":{"721":1}}],["可以之后再去了解",{"2":{"648":1}}],["可以自然引入核函数",{"2":{"637":1}}],["可以借此机会阐述一下几何间隔以及函数间隔的关系",{"2":{"636":1}}],["可以表示为如下的最优化问题",{"2":{"635":1}}],["可以反应数据的分布情况",{"2":{"632":1}}],["可以一批批的去增量训练",{"2":{"626":1}}],["可以交叉验证的剪枝来选择模型",{"2":{"607":1}}],["可以处理多分类问题",{"2":{"631":1}}],["可以处理多维度输出的分类问题",{"2":{"607":1}}],["可以处理类别型",{"2":{"451":1}}],["可以避免某个特征类别只适用于极少数的样本",{"2":{"605":1}}],["可以做回归",{"2":{"600":1}}],["可以是到达目标页面的数量",{"2":{"593":1}}],["可以理解tpr是收益",{"2":{"592":1}}],["可以理解为",{"2":{"725":1}}],["可以理解为无记忆性",{"2":{"527":1}}],["可以理解为事务的",{"2":{"162":1}}],["可以选取一个阈值t",{"2":{"591":1}}],["可以考虑时间范围",{"2":{"730":1}}],["可以考虑使用elasticnet回归来综合",{"2":{"657":1}}],["可以考虑将绝对值改为残差的平方",{"2":{"580":1}}],["可以考虑加入进特征组合",{"2":{"560":1}}],["可以将所有类型的文件转换�",{"2":{"800":1}}],["可以将两种角色分开",{"2":{"725":1}}],["可以将用户均匀地分到若干个桶中",{"2":{"572":1}}],["可以将复杂问题进行适当的分解",{"2":{"521":1}}],["可以认为样本的均值近似服从正态分布",{"2":{"571":1}}],["可以认为a和b是独立事件",{"2":{"282":1}}],["可以简写为",{"2":{"555":1}}],["可以从大到小",{"2":{"544":1}}],["可以从数据集下手",{"2":{"399":1}}],["可以根据当前系统进行实验得到最好的学习率设置策略",{"2":{"740":1}}],["可以根据样本最近的k个样本的数据类型来确定未知样本的数据类型",{"2":{"646":1}}],["可以根据实际的业务需求来指定相应的节假日",{"2":{"537":1}}],["可以根据构造器名称来判断类型�",{"2":{"211":1}}],["可以手动设置s个变",{"2":{"534":1}}],["可以节",{"2":{"514":1}}],["可以被归类到缺省方向上",{"2":{"508":1}}],["可以叫学习率或步长",{"2":{"507":1}}],["可以利用交叉验证选择",{"2":{"605":1}}],["可以利用多线程对每个block并行计算",{"2":{"505":1}}],["可以利用pdp在任何地方设置断点",{"2":{"334":1}}],["可以更为精准的逼近真实的损失函数",{"2":{"504":2}}],["可以更准确地找到某个主题的代表性关键词",{"2":{"422":1}}],["可以作为特征分裂的指",{"2":{"496":1}}],["可以深挖分类器的能力",{"2":{"487":1}}],["可以给出各个特征对于输出的重要性",{"2":{"485":1}}],["可以防止过拟合",{"2":{"484":1}}],["可以肯定",{"2":{"484":1}}],["可以构成类似于blue",{"2":{"446":1}}],["可以基于这个构建相应的强学习器",{"2":{"431":1}}],["可以通过事件监听",{"2":{"796":1}}],["可以通过学习或者问题的性质",{"2":{"761":1}}],["可以通过集成学习之类的方法来改善",{"2":{"607":1}}],["可以通过设置节点最少样本数量和限制决策树深度来改进",{"2":{"607":1}}],["可以通过判定梯度的二范数是否充分接近于0",{"2":{"548":1}}],["可以通过梯度下降法来一步步的迭代求解",{"2":{"540":1}}],["可以通过",{"2":{"537":1}}],["可以通过调节树的层数来做折中",{"2":{"460":1}}],["可以通过两阶段协同框架结合弱多模态模型与强文本模型",{"2":{"423":1}}],["可以通过参数",{"2":{"136":1}}],["可以观测到一些类似的加减逻辑",{"2":{"422":1}}],["可以用到堆数据结",{"2":{"763":1}}],["可以用含100个结点的最小堆",{"2":{"749":1}}],["可以用于执行范围更广的任务",{"2":{"800":1}}],["可以用于非线性分",{"2":{"649":1}}],["可以用于求解最小二乘问题",{"2":{"540":1}}],["可以用于当一个算法在数据集中的所有变量里很难寻找到有意义信号的时候",{"2":{"459":1}}],["可以用",{"2":{"423":1}}],["可以用以下几种技术",{"2":{"422":1}}],["可以用大规模语料快速训练",{"2":{"422":1}}],["可以用来做二分类",{"2":{"660":1}}],["可以用来控制趋势的灵活度",{"2":{"537":1}}],["可以用来控制多个进程对共享资源的访问",{"2":{"293":1}}],["可以用来衡量算法",{"2":{"394":1}}],["可以靠修改loss提升准确度",{"2":{"399":1}}],["可以显著加速training和testing速度",{"2":{"368":1}}],["可以计算出预测框box的真实坐标",{"2":{"367":1}}],["可以保证任意大小特征图输入都可以变成指定大小输出",{"2":{"367":1}}],["可以保证我们将所有可能的买卖识别出来",{"2":{"25":1}}],["可以使得输出feature",{"2":{"312":1}}],["可以使用归并排序",{"2":{"763":1}}],["可以使用bloom",{"2":{"747":1}}],["可以使用分组的方式进行计算",{"0":{"651":1}}],["可以使用权值来改进",{"2":{"650":1}}],["可以使用带有dropout的gbdt算法",{"2":{"497":1}}],["可以使用简单的弱分类器",{"2":{"487":1}}],["可以使用soft",{"2":{"397":1}}],["可以使用fpn网络架构来设计rpn网络",{"2":{"374":1}}],["可以使用",{"2":{"140":2,"200":1}}],["可以使用任何标记方式",{"2":{"110":1}}],["可以使用c++slt中的优先队列",{"2":{"21":1}}],["可以这么说",{"2":{"306":1}}],["可以同时处理多个中断",{"2":{"301":1}}],["可以不加锁的访问全局变量",{"2":{"289":1}}],["可以有效的解决负载均衡",{"2":{"770":1}}],["可以有效的降低误差和方差",{"2":{"439":1}}],["可以有效解决长程依赖问题",{"2":{"527":1}}],["可以有好几行",{"2":{"246":1}}],["可以有两种执行方案�",{"2":{"163":1}}],["可以存任意数据类型",{"2":{"244":1}}],["可以把其中一个小文件的url存储到hash",{"2":{"747":1}}],["可以把拥塞窗口增加最多一个",{"2":{"243":1}}],["可以把第二次删除缓存可以做成异步的",{"2":{"199":1}}],["可以减少全局变量的对象",{"2":{"215":1}}],["可以检测引用类型",{"2":{"211":1}}],["可以返回一个构造器的类型",{"2":{"211":1}}],["可以判断一�",{"2":{"211":1}}],["可以在浏览器空闲的时候执行回调",{"2":{"792":1}}],["可以在残差减小的梯度方向上建立模",{"2":{"497":1}}],["可以在视觉上下文中进行交叉注意力",{"2":{"423":1}}],["可以在增加感受野的同时保持特征图的尺寸不变",{"2":{"306":1}}],["可以在不同情况下使得cpu和内存资源达到最优的平衡效果",{"2":{"201":1}}],["可以在加锁成功时启动一�",{"2":{"185":1}}],["可以充分利用",{"2":{"200":1}}],["可以大大提高redis服务器的并发�",{"2":{"194":1}}],["可以由主节点提供写服务",{"2":{"194":1}}],["可以由从节点提供服务",{"2":{"194":1}}],["可以�",{"2":{"174":1}}],["可以多分配一点线程数",{"2":{"131":1}}],["可以allowcorethreadtimeout",{"2":{"129":1}}],["可以看到卷积2肯定比卷积1快",{"2":{"357":1}}],["可以看出第m棵树使用前m",{"2":{"497":1}}],["可以看出来rf的训练和预测过程都可以进行并行处理",{"2":{"497":1}}],["可以看出最终就是基函数的线性组合",{"2":{"457":1}}],["可以看出",{"2":{"89":1,"279":1,"761":1}}],["可以看作序列型动态规划问",{"2":{"7":1}}],["可以解决很多层次遍历相关的问",{"2":{"85":1,"86":1}}],["可以忽略字母的大小写",{"2":{"76":1}}],["可以",{"2":{"18":1,"423":4}}],["红黑树",{"2":{"768":1}}],["红黑树中的treenode是链表中的node所占空间的2倍",{"2":{"120":1}}],["红黑",{"2":{"754":1}}],["红黑�",{"2":{"118":1}}],["再选用针对少数样本有区分度的特征",{"2":{"741":1}}],["再在这些组内引用knn",{"2":{"651":1}}],["再到后来的核技巧",{"2":{"634":1}}],["再假设现在有分类目标",{"2":{"612":1}}],["再将该得分输入进crf层",{"2":{"521":1}}],["再将此硬件地址写入mac帧",{"2":{"250":1}}],["再合并为全局",{"2":{"514":1}}],["再由这个节点广播一下被切分到左右节点的样本索引号",{"2":{"514":1}}],["再学习另外一个类别",{"2":{"497":1}}],["再次计算它的袋外数据误差",{"2":{"483":1}}],["再次删除",{"2":{"199":2}}],["再取个平均值",{"2":{"462":1}}],["再随机打乱oob样本中第i个特征",{"2":{"462":1}}],["再针对领域微调",{"2":{"423":1}}],["再决策循环",{"2":{"423":1}}],["再拼接进",{"2":{"423":1}}],["再做判断",{"2":{"422":1}}],["再进行学习",{"2":{"435":1}}],["再进行下一步卷积操作",{"2":{"392":1}}],["再进行标准的卷积计算",{"2":{"312":1}}],["再一次进行",{"2":{"388":1}}],["再送入3×3的卷积中",{"2":{"320":1}}],["再使用一个指针指向最老的页面",{"2":{"299":1}}],["再谈等概率器",{"0":{"279":1}}],["再从底到顶反向检查是否有不满足分裂条件的结点",{"2":{"507":1}}],["再从第一次称时剩下的4个蛋中任意拿3个",{"2":{"270":1}}],["再从本地磁盘加载到内存�",{"2":{"194":1}}],["再重新封装数据帧发送出去",{"2":{"250":1}}],["再封装帧头帧尾",{"2":{"250":1}}],["再传回根�",{"2":{"226":1}}],["再删�",{"2":{"199":1}}],["再删除缓存",{"0":{"198":1}}],["再写数据库",{"2":{"199":1}}],["再写磁�",{"2":{"173":1}}],["再更新数据库",{"0":{"197":1}}],["再更新缓存",{"0":{"196":1}}],["再交换新旧日志文件即可",{"2":{"193":1}}],["再通过这个函数来寻找最优点",{"2":{"637":1}}],["再通过数据页中�",{"2":{"165":1}}],["再通过主键值找到数据行的数据页",{"2":{"165":1}}],["再去用",{"2":{"124":1}}],["再多的就更少了",{"2":{"120":1}}],["再高价卖出",{"2":{"24":1}}],["小数相乘",{"2":{"619":1}}],["小公司就这么点流量",{"2":{"573":1}}],["小批量梯度下降",{"2":{"546":1}}],["小批量",{"2":{"545":1}}],["小结",{"2":{"545":1}}],["小于0",{"2":{"659":1}}],["小于这个阈值",{"2":{"484":1}}],["小于等于6才转链表",{"2":{"120":1}}],["小模型通过监督学习模仿教师示例",{"2":{"423":1}}],["小红书内容偏视觉和生活方式",{"2":{"423":1}}],["小红书",{"2":{"423":1}}],["小步长微调",{"2":{"423":1}}],["小目标的面积太小了",{"2":{"403":1}}],["小目标不好检测的两大原因",{"2":{"403":1}}],["小目标不好检测",{"0":{"403":1}}],["小目标难以检测的原因",{"2":{"401":1}}],["小米",{"0":{"396":1,"397":1,"412":1}}],["小",{"2":{"388":1}}],["小的",{"2":{"333":1,"378":1}}],["小的数",{"2":{"8":1}}],["小李最少需要用几只小白鼠试喝饮料",{"2":{"269":1}}],["小白鼠喝了有毒的饮料后",{"2":{"269":1}}],["大数据面试题",{"2":{"804":1}}],["大数据框架的并行处理接口和分布式算法计算平台",{"2":{"769":1}}],["大数据技术框�",{"0":{"767":1}}],["大数据涵盖了方法面面",{"2":{"765":1}}],["大数据也越来越贴近公司的核心业务",{"2":{"765":1}}],["大数量类别的点会比较多",{"2":{"650":1}}],["大文件排",{"2":{"763":1}}],["大量的item不会被推荐",{"2":{"730":1}}],["大量的内存访问和数据复制会拖慢速度",{"2":{"422":1}}],["大大简化了模型的计算",{"2":{"721":1}}],["大大减小了离分类平面较远的点的权重",{"2":{"641":1,"672":1}}],["大大减小计算量",{"2":{"497":2,"505":1,"513":1}}],["大小的",{"2":{"689":1}}],["大小的张量",{"2":{"689":1}}],["大致原理是使用多个不同大小的",{"2":{"689":1}}],["大致算法流程为",{"2":{"397":1}}],["大家刻画模型复杂度的时候",{"2":{"622":1}}],["大家都知道在nlp任务中",{"2":{"527":1}}],["大家请思考不加这个条件和加条件有什么区",{"2":{"31":1}}],["大部分数据不足只能推荐比较流行的items",{"2":{"730":1}}],["大部分场合偏差部分大于方差部分",{"2":{"622":1}}],["大部分时候可以在数据缺失时时使用",{"2":{"508":1}}],["大部分公司都会问道概率相关的问题",{"2":{"273":1}}],["大约有1",{"2":{"483":1}}],["大模型",{"2":{"422":1}}],["大模型区分用户和",{"2":{"422":1}}],["大模型是如何区分聊天历史中用户说的话和",{"2":{"422":1}}],["大模型的分词器在编码阶段",{"2":{"422":1}}],["大模型的分词器和传统的中文分词有什么区别",{"2":{"422":1}}],["大模型的分词是为了满足模型输入token的形式",{"2":{"422":1}}],["大模型的一些面试题小结",{"0":{"422":1},"1":{"423":1},"2":{"421":1}}],["大模型为什么有上下文长度的概念",{"2":{"422":1}}],["大物体",{"2":{"378":1}}],["大幅增加非线性特性",{"2":{"320":1}}],["大型数据储存",{"2":{"256":1}}],["大多是基于数据版�",{"2":{"133":1}}],["大于一个自变量情况的叫做多元回归",{"2":{"654":1}}],["大于小于",{"2":{"279":1}}],["大于",{"2":{"130":1}}],["大于等于8才转红黑树",{"2":{"120":1}}],["等主线程空闲了再继续执行更新�",{"2":{"792":1}}],["等于gbdt所有叶子节点的个数",{"2":{"741":1}}],["等于recall",{"2":{"590":1}}],["等架构",{"2":{"698":1}}],["等激活函数",{"2":{"698":1}}],["等价于",{"2":{"705":1}}],["等价表示",{"2":{"693":1}}],["等价与下",{"2":{"635":1}}],["等人的研究发现",{"2":{"703":1}}],["等人",{"2":{"690":1}}],["等早在",{"2":{"690":1}}],["等式两边同时对x求梯度",{"2":{"555":1}}],["等参",{"2":{"507":1}}],["等线性模型的正则项是对权重的惩罚",{"2":{"502":1}}],["等注入特征",{"2":{"422":1}}],["等密度聚类替代",{"2":{"422":1}}],["等词嵌入空间中",{"2":{"422":1}}],["等",{"2":{"308":2,"502":1,"674":1,"727":1}}],["等概率器",{"0":{"278":1}}],["等概率返回链表中的一个元",{"0":{"73":1}}],["等值查询的列建在前",{"2":{"168":1}}],["等值查询中",{"2":{"168":1}}],["等待目的端确认收到这个报文段",{"2":{"241":1}}],["等待对方确认",{"2":{"241":1}}],["等待",{"2":{"218":1}}],["等待可中断",{"2":{"136":1}}],["等待线程池中任务调度执行",{"2":{"130":1}}],["等�",{"2":{"120":1}}],["哈希索引不支持数据的排�",{"2":{"167":1}}],["哈希索引遇到大量哈希值相等的情况后查找效率会降低",{"2":{"167":1}}],["哈希索引能以",{"2":{"167":1}}],["哈希冲突概率降低",{"2":{"119":1}}],["哈希表",{"2":{"39":1}}],["原问题可行",{"2":{"635":1}}],["原问题和对偶问题均取到最优值的",{"2":{"635":1}}],["原问题的对偶问题",{"2":{"635":3}}],["原则上",{"2":{"519":1}}],["原文中s=7",{"2":{"378":1}}],["原因就是",{"2":{"508":1}}],["原因如下",{"2":{"502":1}}],["原因在于他只需要保存离散的直方图",{"2":{"497":1}}],["原因是像",{"2":{"422":1}}],["原因是其包括一个区域提取网络",{"2":{"367":1}}],["原因是在运行环境中已经无法访问到这些变量了�",{"2":{"110":1}}],["原因",{"2":{"326":1,"460":1}}],["原生循环递归实现",{"2":{"222":1}}],["原型",{"2":{"212":1}}],["原⼦性",{"2":{"166":1}}],["原理其实很简单",{"2":{"761":1}}],["原理",{"0":{"145":1},"2":{"194":1,"397":1}}],["原子行内级盒子",{"2":{"784":1}}],["原子类的实现原理",{"0":{"147":1}}],["原子性",{"2":{"140":2,"255":1}}],["原子�",{"0":{"135":1}}],["原位置或原位�",{"2":{"118":1}}],["重写�",{"2":{"792":1}}],["重绘+回流",{"2":{"786":1}}],["重点突出",{"2":{"831":1}}],["重点",{"0":{"561":1,"563":1,"564":1}}],["重点是会用",{"2":{"220":1}}],["重排序模型的作用是对初步召回结果进行语义理解与排序优化",{"2":{"423":1}}],["重叠面积",{"2":{"390":2}}],["重叠矩形的高计算同宽",{"2":{"390":2}}],["重量与其余鸡蛋不同",{"2":{"270":1}}],["重定向",{"2":{"245":1}}],["重试操作",{"2":{"199":1}}],["重新注入对应的组件",{"2":{"798":1}}],["重新维护下",{"2":{"756":1}}],["重新计算新生成的左",{"2":{"507":1}}],["重新从消息队列中获得该数据",{"2":{"199":1}}],["重新hash",{"2":{"118":1}}],["重启会通过加载",{"2":{"192":1}}],["重复上述过程t次",{"2":{"456":1}}],["重复操作第四步到第六步",{"2":{"381":1}}],["重复1",{"2":{"60":1,"651":1}}],["重复2",{"2":{"59":1,"675":1}}],["插件相比�",{"2":{"800":1}}],["插值",{"2":{"312":1}}],["插�",{"2":{"118":1}}],["插入排序",{"2":{"755":1}}],["插入c",{"2":{"220":1}}],["插入方式",{"2":{"118":1}}],["插入一个字",{"2":{"5":1}}],["扩充多样性",{"2":{"423":1}}],["扩容因子默认为什么是0",{"0":{"119":1}}],["扩容后位置计�",{"2":{"118":1}}],["扩容",{"2":{"118":1}}],["扩展性强",{"2":{"423":1}}],["扩展",{"2":{"85":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"92":1,"93":1}}],["扩展问题",{"2":{"18":1}}],["扩展2",{"2":{"18":1,"43":1}}],["扩展1",{"2":{"18":1,"42":1,"43":1,"45":1}}],["尾插�",{"2":{"118":1}}],["头脑风暴",{"2":{"422":1}}],["头脑风暴类任务",{"2":{"422":1}}],["头插�",{"2":{"118":1}}],["头条",{"2":{"47":1}}],["头条等",{"2":{"41":1}}],["知识迁移",{"2":{"815":1}}],["知识体系",{"0":{"116":1,"126":1,"150":1,"159":1,"176":1,"182":1,"231":1,"286":1,"688":1},"1":{"689":1,"690":1}}],["知其然而知其所以然",{"2":{"769":1}}],["知乎",{"2":{"473":1}}],["知乎偏文字和深度问答",{"2":{"423":1}}],["知乎区别",{"2":{"423":1}}],["知道一",{"2":{"90":1}}],["知道包含v",{"2":{"59":1}}],["基数排序",{"2":{"755":1}}],["基数比较高的类别型特",{"2":{"446":1}}],["基数比较低的类别型特",{"2":{"446":1}}],["基分类器的scalability",{"2":{"511":1}}],["基分类器",{"2":{"504":1}}],["基分类器层层叠加",{"2":{"456":1}}],["基模型",{"2":{"509":1}}],["基模型的训练集按照某种策略每次都进行一定的转化",{"2":{"456":1}}],["基模型按次序进行训练",{"2":{"456":1}}],["基学习器的个数",{"0":{"437":1}}],["基座适配",{"2":{"423":1}}],["基座能力较弱",{"2":{"423":1}}],["基座已具备基础运算能力",{"2":{"423":1}}],["基座模型初始数学能力",{"2":{"423":1}}],["基座模型建议在7b模型以上可平衡效果与成本",{"2":{"423":1}}],["基本上",{"2":{"800":1}}],["基本不需要预处理",{"2":{"607":1}}],["基本思想",{"2":{"397":1,"615":1,"635":1}}],["基本梯度下降法",{"2":{"308":1}}],["基本原理与select一致",{"2":{"302":1}}],["基本对象的类型�",{"2":{"211":1}}],["基本类型被保存在栈内存中",{"2":{"210":1}}],["基本类型",{"2":{"210":1}}],["基于真实经历",{"2":{"830":1}}],["基于位图的排",{"2":{"763":1}}],["基于这个性质",{"2":{"756":1}}],["基于最",{"2":{"756":1}}],["基于huffman树的hierarchial",{"2":{"725":1}}],["基于hierachical",{"2":{"721":1}}],["基于histogram的决策树算法",{"2":{"464":1}}],["基于词向量表征",{"2":{"718":1}}],["基于先验概率求得",{"2":{"613":1}}],["基于现状和期望",{"2":{"570":1}}],["基于逻辑回归",{"2":{"532":1}}],["基于前面的问题解答",{"2":{"521":1}}],["基于此",{"2":{"495":1}}],["基于分类器的错误率分配不同的权重参数",{"2":{"486":1}}],["基于基尼系数",{"2":{"484":1}}],["基于数据随机重抽样的分类器构建方法",{"2":{"455":1}}],["基于r1",{"2":{"423":1}}],["基于偏好数据直接优化",{"2":{"423":1}}],["基于倒排索引的关键词检索不能匹配语义相近的词",{"2":{"423":1}}],["基于主题生成小说标题",{"2":{"423":1}}],["基于密度的聚类方法",{"2":{"422":1}}],["基于密度的文本聚类",{"2":{"422":1}}],["基于质心的文本聚类",{"2":{"422":1}}],["基于质心和基于密度的文本聚类算法有什么优缺点",{"2":{"422":1}}],["基于深度学习的模型",{"0":{"687":1},"1":{"688":1,"689":1,"690":1,"691":1,"692":1,"693":1,"694":1,"695":1,"696":1,"697":1,"698":1,"699":1,"700":1,"701":1,"702":1,"703":1,"704":1,"705":1,"706":1,"707":1,"708":1,"709":1,"710":1,"711":1,"712":1,"713":1,"714":1,"715":1,"716":1},"2":{"419":1}}],["基于深度学习的目标检测算法时期",{"2":{"360":1}}],["基于深度学习目标检测算法",{"0":{"362":1}}],["基于手工提取特征的传统目标检测算法主要有以下三个缺点",{"2":{"361":1}}],["基于",{"0":{"184":1},"1":{"185":1},"2":{"137":1,"471":1,"790":1}}],["基于s+=nums",{"2":{"18":1}}],["基础配置",{"2":{"423":1}}],["基础篇",{"2":{"358":1}}],["基础",{"0":{"115":1,"209":1},"1":{"116":1,"117":1,"118":1,"119":1,"120":1,"121":1,"122":1,"123":1,"124":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1}}],["$个分类器来测试",{"2":{"643":1}}],["$计算的结果",{"2":{"638":1}}],["$k",{"2":{"638":1}}],["$来做预测",{"2":{"635":1}}],["$需满足以下四个要求",{"2":{"635":1}}],["$即先验概",{"2":{"631":1}}],["$都是能从训练样本中统计出",{"2":{"612":1}}],["$是最终的分类类别",{"2":{"612":1}}],["$是个常数",{"2":{"497":1}}],["$待分类项",{"2":{"612":1}}],["$$表示2阶特征",{"2":{"735":1}}],["$$r",{"2":{"730":1}}],["$$sim",{"2":{"730":1}}],["$$",{"2":{"532":1,"730":3,"735":1}}],["$进行建模",{"2":{"521":1}}],["$成为一个概率分布",{"2":{"428":1}}],["$z",{"2":{"428":1}}],["$误分类样本的权值之和",{"2":{"428":1}}],["$g",{"2":{"428":1}}],["$的训练集进行训练",{"2":{"428":1}}],["$d",{"2":{"428":1}}],["$",{"2":{"114":1,"367":2,"369":1,"496":1,"519":2,"545":4,"601":11,"602":2,"613":2,"635":5,"654":1,"655":1}}],["```",{"2":{"769":2}}],["```cpp",{"2":{"27":1,"38":1}}],["``mvcc`",{"2":{"174":1}}],["`",{"2":{"114":1}}],["`http",{"2":{"114":1}}],["洋葱模型是指",{"2":{"114":1}}],["会找出有哪些模块和库是入口起点",{"2":{"800":1}}],["会遍历应用的所有节点",{"2":{"792":1}}],["会出现掉帧的现象",{"2":{"792":1}}],["会出现样本比例不平衡的影响",{"2":{"401":1}}],["会根据",{"2":{"784":1}}],["会提示后半部分的内容",{"2":{"762":1}}],["会得到不同",{"2":{"689":1}}],["会得到一�",{"2":{"218":1}}],["会造成怎样的影响",{"0":{"669":1}}],["会造成频繁扩容",{"2":{"119":1}}],["会忽略前一个点的信息",{"2":{"628":1}}],["会考虑把特征a分成a1和a2",{"2":{"604":1}}],["会形成一个函数值递减的序列",{"2":{"547":1}}],["会破坏数据的真实分布",{"2":{"509":1}}],["会将评分进行去中心化再进行计算",{"2":{"730":1}}],["会将叶子节点的权重乘上该系数",{"2":{"513":1}}],["会将其划入默认分支",{"2":{"504":1}}],["会将网站的证书信息",{"2":{"247":1}}],["会对样本的权重进行调整",{"2":{"440":1}}],["会针对每个主题集合计算词权重",{"2":{"422":1}}],["会把样本权重高的样本分类正确",{"2":{"440":1}}],["会把输入",{"2":{"422":1}}],["会把这个",{"2":{"184":1}}],["会导致整个实例的概率结果是0",{"2":{"618":1}}],["会导致正样本质量很高",{"2":{"401":1}}],["会导致客户端2尝试加锁时",{"2":{"185":1}}],["会有什么问题",{"2":{"397":1}}],["会创建一个字符串对象�",{"2":{"224":1}}],["会返�",{"2":{"218":1}}],["会返回一�",{"2":{"218":1}}],["会扫描一定数量的数据库的expires字典中一定数量的key",{"2":{"201":1}}],["会压缩其中的指令",{"2":{"193":1}}],["会生成多个数据文件",{"2":{"192":1}}],["会在对应目录下生产一个dump",{"2":{"192":1}}],["会进�",{"2":{"185":1}}],["会记录的一条对应的",{"2":{"174":1}}],["会回到开头循环写日志�",{"2":{"173":1}}],["会隐式的定义一个主键来作为聚簇索引�",{"2":{"165":1}}],["会选择非空的唯一索引代替",{"2":{"165":1}}],["会先写入本地磁盘",{"2":{"194":1}}],["会先查询缓存",{"2":{"163":1}}],["会先执行第一个中间件的逻辑",{"2":{"114":1}}],["会多出一�",{"2":{"143":1}}],["会跳回执行倒数第二个中间件",{"2":{"114":1}}],["会报错�",{"2":{"112":1}}],["会影响后续的内存分配�",{"2":{"110":1}}],["读取数据",{"2":{"759":1}}],["读取每个block中样本的梯度信息并存入连续的buffer中",{"2":{"506":1}}],["读取",{"2":{"422":1}}],["读取函数内部的变量",{"2":{"215":1}}],["读取出数据时",{"2":{"133":1}}],["读写的监控",{"2":{"202":1}}],["读redis数据时应用连接从节点",{"2":{"194":1}}],["读的时候只要返回前一个版本的数据就行�",{"2":{"174":1}}],["读锁",{"2":{"170":1}}],["读",{"2":{"170":1}}],["读已提交",{"2":{"170":1}}],["读未提交",{"2":{"170":1}}],["读入并执行一个javascript文件",{"2":{"112":1}}],["读者自行查",{"2":{"1":1}}],["加速",{"0":{"787":1},"2":{"787":4}}],["加大拟合",{"2":{"664":1}}],["加和的是属性出现的总次数",{"2":{"621":1}}],["加上超参数",{"2":{"446":1}}],["加上摘要或记忆",{"2":{"423":1}}],["加权平均的m个学习器是可以并行处理的",{"2":{"435":1}}],["加权求和",{"2":{"422":1}}],["加强领域知识注入",{"2":{"423":1}}],["加宽",{"2":{"399":1}}],["加深",{"2":{"399":1}}],["加快学习收敛速度",{"2":{"351":1}}],["加快学习算法的收敛速度",{"2":{"305":1}}],["加了一些正则化项",{"2":{"330":1}}],["加几百ms即可",{"2":{"199":1}}],["加锁次数+1",{"2":{"185":1}}],["加锁机制",{"2":{"185":1}}],["加锁",{"2":{"184":1,"185":1}}],["加",{"2":{"170":2}}],["加载",{"2":{"422":1}}],["加载模块�",{"2":{"112":1}}],["加载某个模块",{"2":{"112":1}}],["加入正则项后的funk",{"2":{"729":1}}],["加入正则化",{"2":{"561":1}}],["加入了有监督微调",{"2":{"423":1}}],["加入训练集",{"2":{"422":1}}],["加入队列",{"2":{"61":1}}],["加入入度为0的点",{"2":{"60":1}}],["加入到mstset",{"2":{"59":1}}],["加入",{"2":{"58":1,"143":1}}],["类yj的所有训练记录关",{"2":{"620":2}}],["类错误和统计功效",{"2":{"574":1}}],["类错误的概率α",{"2":{"574":2}}],["类似与归并排序",{"2":{"749":1}}],["类似",{"2":{"702":1}}],["类似将多个不同网络结构的模型集成起来",{"2":{"565":1}}],["类似于",{"2":{"4":1}}],["类别c占的个数最多",{"2":{"651":1}}],["类别的差异特征",{"2":{"632":1}}],["类别的预测值",{"2":{"472":1}}],["类别标签为y$",{"2":{"631":1}}],["类别标签为",{"2":{"631":1}}],["类别",{"2":{"472":2}}],["类别特征进行组合",{"2":{"445":1}}],["类问题",{"2":{"423":1}}],["类预训练模型",{"2":{"422":1}}],["类模型是自回归的",{"2":{"422":1}}],["类resnet",{"2":{"378":1}}],["类fpn",{"2":{"378":1}}],["类型为obejct",{"2":{"224":1}}],["类型为object",{"2":{"224":2}}],["类型为string",{"2":{"224":1}}],["类型的常量",{"2":{"224":1}}],["类加载流�",{"0":{"155":1}}],["类的",{"0":{"124":1}}],["类",{"2":{"112":1,"123":1,"136":1,"422":1}}],["应对策略",{"2":{"811":1}}],["应用场景依旧是ctr预估",{"2":{"733":1}}],["应用拉普拉斯平滑即可以解决零概率问题",{"2":{"618":1}}],["应用在词性标注",{"2":{"527":1}}],["应用进程可以继续执行",{"2":{"302":1}}],["应用进程被阻塞",{"2":{"302":1}}],["应用数据被分割成",{"2":{"241":1}}],["应用由模块组成",{"2":{"112":1}}],["应该使用哪个模块",{"2":{"800":1}}],["应该使用哪种算法来解决问题呢",{"0":{"459":1}}],["应该用整个训练好的模型",{"2":{"565":1}}],["应该设置max",{"2":{"509":1}}],["应该怎么选择基学习器",{"0":{"438":1}}],["应该分别在什么场景下应用",{"2":{"423":1}}],["应该如何综合利用摘要和",{"2":{"423":1}}],["应该如何处理目标检测中如何解决目标尺度大小不一的情况",{"0":{"403":1}}],["应该修改注意力层还是前馈神经网络层的参数",{"2":{"422":1}}],["应该自行评估自己的项目的读数据业务逻辑的耗时",{"2":{"199":1}}],["应该指定一个前缀长度",{"2":{"169":1}}],["应该根据实际应用场景来做取舍�",{"2":{"109":1}}],["导图",{"0":{"728":1}}],["导数信息",{"2":{"504":1}}],["导致大量的user木有数据可推荐",{"2":{"730":1}}],["导致无法更新参数",{"2":{"703":1}}],["导致很多区间的变量变化对目标概率的影响没有区分度",{"2":{"663":1}}],["导致泛化能力不强",{"2":{"607":1}}],["导致选取的样本数据不足以代表预定的分类规则",{"2":{"559":1}}],["导致迭代方向变化很大",{"2":{"545":1}}],["导致迭代速度慢",{"2":{"544":1}}],["导致解有可能不是全局最优",{"2":{"545":1}}],["导致adaboost算法易受噪声干扰",{"2":{"487":1,"488":1}}],["导致在训练中更难收敛",{"2":{"461":1}}],["导致性能下降",{"2":{"423":1}}],["导致包含目标的anchor比较少",{"2":{"403":1}}],["导致模型在训练的时候会偏向medium和large的目标",{"2":{"403":1}}],["导致模型不收敛的原因可能有数据分类的标注不准确",{"2":{"349":1}}],["导致模型不收敛的原因有哪些",{"0":{"349":1}}],["导致小物体的特征描述不容易被检测网络捕捉",{"2":{"402":1}}],["导致",{"2":{"330":1}}],["导致出现梯度消失的现象",{"2":{"328":1}}],["导致难以维�",{"2":{"215":1}}],["导致所有的请求都落到数据库上",{"2":{"189":1}}],["导致各种脏数据产生",{"2":{"185":1}}],["导致多个客户端对一个分布式锁完成了加锁",{"2":{"185":1}}],["导致异步",{"2":{"109":1}}],["导出方式1�",{"2":{"112":1}}],["模拟面试",{"2":{"835":1}}],["模式",{"2":{"798":1}}],["模式�",{"0":{"795":1},"2":{"798":3}}],["模板通常包含以下几部分",{"2":{"422":1}}],["模糊",{"2":{"345":1}}],["模块接收",{"2":{"388":1}}],["模块规范�",{"2":{"112":1}}],["模块化智能体架构",{"2":{"423":1}}],["模块化的区别�",{"0":{"112":1}}],["模块化",{"0":{"112":1},"2":{"112":2}}],["模型常常包含业务逻辑�",{"2":{"795":1}}],["模型结构",{"0":{"733":1},"1":{"734":1,"735":1,"736":1,"737":1}}],["模型概述",{"0":{"718":1}}],["模型介绍",{"0":{"717":1},"1":{"718":1,"719":1,"720":1,"721":1,"722":1,"723":1,"724":1}}],["模型会更稳定",{"2":{"664":1}}],["模型偏向于选择取值较多的特征",{"2":{"599":1}}],["模型得分对正负样本没有区分性",{"2":{"591":1}}],["模型预测能力越好",{"2":{"587":1,"588":1}}],["模型准确率越好",{"2":{"583":1}}],["模型复杂度过低",{"2":{"559":1}}],["模型复杂度过高",{"2":{"559":1}}],["模型复杂度越高",{"2":{"521":1}}],["模型是对联合概率分布p",{"2":{"521":1}}],["模型算法的复杂度",{"2":{"521":1}}],["模型算法理论基础及所针对的问题",{"2":{"521":1}}],["模型学习的精度通常受三方面影响",{"2":{"521":1}}],["模型特征向量f",{"2":{"519":1}}],["模型特点是什么",{"0":{"109":1}}],["模型实现微信聊天风格且符合安全要求",{"2":{"423":1}}],["模型和给定提示词",{"2":{"423":1}}],["模型完全适应领域",{"2":{"423":1}}],["模型微调",{"2":{"423":1}}],["模型就能表现很好",{"2":{"422":1}}],["模型就能正确判断并生成对应角色的回复",{"2":{"422":1}}],["模型难以稳定利用上下文",{"2":{"422":1}}],["模型难以判断远距离",{"2":{"422":1}}],["模型没见过这些角度",{"2":{"422":1}}],["模型并不理解",{"2":{"422":1}}],["模型在处理文本时",{"2":{"422":1}}],["模型所需的计算力flops是什么",{"2":{"315":1}}],["模型的性能就越好",{"2":{"590":1}}],["模型的容量是指其拟合各种函数的能力",{"2":{"560":1}}],["模型的预测误差可以分解为三个部分",{"2":{"558":1}}],["模型的预测结果进行融合",{"2":{"422":1}}],["模型的误差来自于方差和偏差",{"2":{"432":1}}],["模型的注意力机制是全局的",{"2":{"422":1}}],["模型的复杂度",{"2":{"394":1}}],["模型的flops",{"0":{"315":1}}],["模型的参数量指的是什么",{"0":{"314":1}}],["模型欠拟合",{"2":{"307":1}}],["模型过拟合十分严重",{"2":{"482":1}}],["模型过拟合",{"2":{"307":1}}],["模型更适合处理",{"2":{"109":1}}],["模型",{"2":{"109":1,"590":1,"795":1}}],["老生代是",{"2":{"110":1}}],["老生代主要采�",{"2":{"110":1}}],["老生代中的对象为存活时间较长或常驻内存的对象",{"2":{"110":1}}],["调音师",{"2":{"727":1}}],["调参",{"2":{"507":1}}],["调参难度大",{"2":{"423":1}}],["调整流量继续测试",{"2":{"570":1}}],["调整模型的容量",{"2":{"560":1}}],["调整的结果是越到后面被错误分类的样本权重会越高",{"2":{"440":1}}],["调整输出格式",{"2":{"423":1}}],["调整主题数量和模型参数",{"2":{"422":1}}],["调整q",{"2":{"422":1}}],["调整少量参数即可切断目标知识的上下文联系",{"2":{"422":1}}],["调整网络的拓扑结构",{"2":{"354":1}}],["调优fast",{"2":{"373":1}}],["调优rpn",{"2":{"373":1}}],["调节batch和epoch的大小",{"2":{"354":1}}],["调试pytorch代码就像调试python代码一样",{"2":{"334":1}}],["调用归并函数",{"2":{"760":1}}],["调用",{"2":{"760":1}}],["调用酒店智能体",{"2":{"423":1}}],["调用select时",{"2":{"302":1}}],["调用一个对象的一个方法",{"2":{"213":2}}],["调用函数dfs",{"2":{"30":1}}],["调�",{"2":{"110":1,"139":1}}],["此类树作为base",{"2":{"741":1}}],["此度量值的较高值意味着它对于生成预测更为重要",{"2":{"512":1}}],["此",{"2":{"504":1}}],["此外还提出了",{"2":{"464":1}}],["此外还起到重要的",{"2":{"362":1}}],["此外",{"2":{"422":1,"460":1,"513":1}}],["此神经元不参与训练",{"2":{"350":1}}],["此时a",{"2":{"756":1}}],["此时需要再增加",{"2":{"699":1}}],["此时需要有有限",{"2":{"590":1}}],["此时的分隔超平面所产生的分类结果是",{"2":{"636":1}}],["此时的候选框已经和最开始回归出来的位置有一定的偏差",{"2":{"368":1}}],["此时1−yi",{"2":{"635":1}}],["此时真正例率和假正例率都",{"2":{"590":1}}],["此时我们可以采用",{"2":{"564":1}}],["此时认为已经达",{"2":{"548":1}}],["此时算法的整个过程一气呵成",{"2":{"366":1}}],["此时算法的整个过程相比",{"2":{"366":1}}],["此时算法的整个过程较为繁琐",{"2":{"366":1}}],["此时通道数可以进行改变",{"2":{"317":1}}],["此时通道数不变",{"2":{"317":1}}],["此时就可以停止训练了",{"2":{"307":1}}],["此时内核调度器就会选择另一个进程去运行",{"2":{"301":1}}],["此时x只能是y+1=2",{"2":{"267":1}}],["此时主节点会启动一个后台线程",{"2":{"194":1}}],["此时异步复制给对应�",{"2":{"185":1}}],["此时会从",{"2":{"185":1}}],["此时",{"2":{"110":1,"133":1}}],["此后",{"2":{"110":1}}],["新增了哪些元素",{"0":{"776":1}}],["新item",{"2":{"730":1}}],["新的信息增益公式",{"2":{"601":1}}],["新的测试集与训练集的数据分布不一致",{"2":{"482":1}}],["新方差为1",{"2":{"544":1}}],["新来一个样本",{"2":{"472":1}}],["新建",{"2":{"292":1}}],["新建线程工厂",{"2":{"129":1}}],["新拥塞窗口cwnd=慢开始门限ssthresh",{"2":{"243":1}}],["新提交任务由",{"2":{"130":1}}],["新提交任务会创建新线程执行任�",{"2":{"130":1}}],["新提交任务将被放�",{"2":{"130":1}}],["新提交任务将创建一个新线程执行任务",{"2":{"130":1}}],["新对象都先分配�",{"2":{"110":1}}],["新生代主要使�",{"2":{"110":1}}],["新生代中的对象会在满足某些条件后",{"2":{"110":1}}],["新生代中的对象为存活时间较短的对象",{"2":{"110":1}}],["新生代",{"2":{"110":1}}],["闲置空间叫",{"2":{"110":1}}],["晋升到老生代�",{"2":{"110":1}}],["直觉是软标签捕获了不同类之间的关系",{"2":{"703":1}}],["直线搜索时可能会产生一些问题",{"2":{"541":1}}],["直观解释",{"0":{"727":1}}],["直观理解",{"0":{"525":1}}],["直观明了",{"2":{"258":1}}],["直方图算",{"2":{"514":1}}],["直方图算法是一种牺牲了一定的切分准确性而换取训练速度以及节省内存空间消耗的算法",{"2":{"497":1}}],["直方图算法",{"2":{"497":1}}],["直方图算法将存储特征值转变为存储",{"2":{"471":1}}],["直方图算法极大的降低了时间复杂度",{"2":{"471":1}}],["直方图算法就是使用直方图统计",{"2":{"465":1}}],["直方图近似算",{"2":{"510":1}}],["直方图做差进一步提高效率",{"2":{"497":1}}],["直方图做差加速",{"2":{"465":1}}],["直方图优化算法",{"2":{"473":1}}],["直接和间接",{"2":{"800":1}}],["直接降序排序取前ｋ个即可",{"2":{"755":1}}],["直接将ad",{"2":{"741":1}}],["直接添加到用户特征矩阵的尾部即可",{"2":{"730":1}}],["直接预测往往准确率更高",{"2":{"632":1}}],["直接求解此方程组存在困难",{"2":{"555":1}}],["直接建模",{"2":{"520":1}}],["直接支持类别特征",{"2":{"464":1,"497":1}}],["直接用通用",{"2":{"423":1}}],["直接使用one",{"2":{"470":1}}],["直接使用通用",{"2":{"423":1}}],["直接使用摘要内容作答",{"2":{"423":1}}],["直接优化向量夹角",{"2":{"423":1}}],["直接传入所有图像特征会超长且噪声多",{"2":{"423":1}}],["直接在输出层回归bounding",{"2":{"378":1}}],["直接在输出层回归",{"2":{"378":1}}],["直接操作栈则基本没有内核切换的开销",{"2":{"289":1}}],["直接基�",{"2":{"192":1}}],["直接返回错误信息",{"2":{"163":1}}],["直接分配到老生代",{"2":{"110":1}}],["直到当前帧的时间用完",{"2":{"792":1}}],["直到它的外边缘碰到包含框或另一个浮动框的边框为止",{"2":{"785":1}}],["直到出现k个数",{"2":{"763":1}}],["直到堆中只是一个元素",{"2":{"756":1}}],["直到分解得到的小文件的大小都不超过1m",{"2":{"749":1}}],["直到分类器错误率为0或者整体弱分类器错误为0",{"2":{"486":1}}],["直到优先级队列为空",{"2":{"651":1}}],["直到检索到叶子节点",{"2":{"651":1}}],["直到没有剩下的为止",{"2":{"397":1}}],["直到在第五步中发现对于全部bounding",{"2":{"381":1}}],["直到最后一层feature",{"2":{"311":1}}],["直到最后一个中间件",{"2":{"114":1}}],["直到数据从内核缓冲区复制到应用进程缓冲区中才返回",{"2":{"302":1}}],["直到成�",{"2":{"199":1}}],["直到成功",{"2":{"199":1}}],["直到第一个中间件",{"2":{"114":1}}],["直到fast到达最后一个节",{"2":{"72":1}}],["直到遍历所有顶点",{"2":{"60":1}}],["直到遍历所有的点",{"2":{"58":1}}],["直到所有出现a==b位置",{"2":{"32":1}}],["直到一方变",{"2":{"27":1}}],["直到",{"2":{"23":1}}],["直到剩下一个数字",{"2":{"21":1}}],["垃圾文本过滤",{"2":{"625":1}}],["垃圾收集算法",{"0":{"154":1}}],["垃圾收集�",{"0":{"153":1}}],["垃圾收集器完成内存清除工作",{"2":{"110":1}}],["垃圾收集器在运行的时候会给存储在内存中的所有变量都加上标记",{"2":{"110":1}}],["垃圾回收器就不会回收它",{"2":{"122":1}}],["垃圾回收器绝不会回收它",{"2":{"122":1}}],["垃圾回收策略",{"2":{"110":1}}],["但因为没有",{"2":{"798":1}}],["但因为大模型后续加入了上下文建模",{"2":{"422":1}}],["但元素的高度",{"2":{"774":1}}],["但对于曝光不充分样本不充足的长尾广告",{"2":{"741":1}}],["但互联网时代长尾数据现象非常显著",{"2":{"741":1}}],["但从效果上有实践证明不如gbdt",{"2":{"741":1}}],["但数据量大时",{"2":{"700":1}}],["但会损失一定的信息量",{"2":{"684":1}}],["但可能在准确率上有问题",{"2":{"672":1}}],["但实际上难以达到",{"2":{"658":1}}],["但实际上level",{"2":{"466":1}}],["但朴素贝叶斯仍能取得较好的效",{"0":{"617":1}}],["但特征相关性很小的实际情况还是很多的",{"2":{"614":1}}],["但理论上样本量还是越大越好",{"2":{"573":1}}],["但如果一起使用的话并不会产生1+1",{"2":{"567":1}}],["但每迭代一步",{"2":{"545":1}}],["但步长太大",{"2":{"544":1}}],["但当处理很长的序列的时候",{"2":{"527":1}}],["但在节点分裂过程中仍需要遍历数据集",{"2":{"513":1}}],["但在他们身上仍然能看到许多来自传统检测器的影响",{"2":{"361":1}}],["但需要同时增加estimator",{"2":{"507":1}}],["但其实可能都离实例较远",{"2":{"650":1}}],["但其核心思想没有大的变化",{"2":{"503":1}}],["但其中只",{"2":{"502":1}}],["但学习能力有限",{"2":{"502":1}}],["但同时让你的代码变慢",{"2":{"484":1}}],["但复杂且不常用",{"2":{"423":1}}],["但只有",{"2":{"422":1}}],["但只能是最左侧部分",{"2":{"168":1}}],["但不会被包括�",{"2":{"798":1}}],["但不改变",{"2":{"422":1}}],["但不含有值�",{"2":{"210":1}}],["但没有根本解决问题",{"2":{"378":1}}],["但固定共享的卷积层",{"2":{"373":1}}],["但依然无法联合训练",{"2":{"366":1}}],["但工作集内存大小相差了很多倍",{"2":{"357":1}}],["但卷积2实际上无法达到卷积1的256倍速度",{"2":{"357":1}}],["但本人实测",{"2":{"357":1}}],["但我们没有接受方案",{"2":{"574":1}}],["但我们接受了方案推了全量",{"2":{"574":1}}],["但我们又希望尽可能保留用户的对话信息",{"2":{"423":1}}],["但我们需要的只是一条",{"2":{"337":1}}],["但我们可能只有一幅这个稀有物种的图片",{"2":{"336":1}}],["但过采样可能导致过拟合训练数据",{"2":{"336":1}}],["但很有可能被我们删除了的数据包含着预测类的重要信息",{"2":{"336":1}}],["但带来的计算量也会大大增加",{"2":{"311":1}}],["但所有申请必须按照资源的编号顺序",{"2":{"297":1}}],["但多个进程都可以访问",{"2":{"293":1}}],["但多进程程序中一个进程崩溃并不会对其它进程造成影响",{"2":{"288":1}}],["但夫妇之间绝对不握手",{"2":{"268":1}}],["但双方都需要事先知道密钥",{"2":{"252":1}}],["但这种方法不好控制离散区间划分的粒度",{"2":{"620":1}}],["但这会导致梯度估计偏",{"2":{"448":1}}],["但这个不是严格成正比关系",{"2":{"315":1}}],["但这不是重点",{"2":{"218":1}}],["但这样会有循环引用的问题�",{"2":{"110":1}}],["但之后的该事务执行期间",{"2":{"170":1}}],["但公平锁表现的性能不是很好",{"2":{"136":1}}],["但是会传入",{"2":{"796":1}}],["但是会占用大量的cpu资源去处理过期的数据",{"2":{"201":1}}],["但是可能由于兼容性的考虑",{"2":{"792":1}}],["但是可能有些节点增益非常小",{"2":{"514":1}}],["但是另一方面",{"2":{"787":1}}],["但是主要的思想就是这样",{"2":{"769":1}}],["但是时间应该慢",{"2":{"763":1}}],["但是属性值是确定的",{"2":{"761":1}}],["但是在海量数据的排序过程中",{"2":{"760":1}}],["但是在分层中",{"2":{"572":1}}],["但是注意我们可以是多路归并",{"2":{"760":1}}],["但是注意这里只是从技术角度进行分析",{"2":{"754":1,"768":1}}],["但是这k个不一",{"2":{"756":1}}],["但是这个特征本身重复了100遍",{"2":{"669":1}}],["但是必须保",{"2":{"756":1}}],["但是数据量很大",{"2":{"755":1}}],["但是数量会很少",{"2":{"401":1}}],["但是同样带来了问题",{"2":{"740":1,"741":1}}],["但是面临找不到相同偏好的用户",{"2":{"730":1}}],["但是计算方式不同",{"2":{"730":1}}],["但是其专注于词向量本身",{"2":{"725":1}}],["但是每一次都只用了2个类别",{"2":{"662":1}}],["但是每个worker仅在特征子集上进行最佳切分点的寻找",{"2":{"514":1}}],["但是几何间隔最大的分离超平面却是唯一的",{"2":{"642":1}}],["但是却使问题变得更加复杂",{"2":{"637":1}}],["但是泛化能力略弱",{"2":{"625":1}}],["但是我们只将其算作一次",{"2":{"621":2}}],["但是如果把特征c单独拿出来进行训练",{"2":{"606":1,"609":1}}],["但是如果我们使用二阶梯度就要要求损失函数二阶可导",{"2":{"497":1}}],["但是一般情况下precision高",{"2":{"589":1}}],["但是一般情况下的都是常见的一些题",{"2":{"0":1}}],["但是绝对值的存在导致函数不光滑",{"2":{"580":1}}],["但是模型出现了欠拟合",{"2":{"560":1}}],["但是很容易出现过拟合问题",{"2":{"514":1}}],["但是树与树之间无法并行训练",{"2":{"502":1}}],["但是当测试的时候",{"2":{"502":1}}],["但是当面对高纬度和大数据量时",{"2":{"495":1}}],["但是当链表长度比较小的时候",{"2":{"120":1}}],["但是弱学习器限定了只能使用cart回归树模型",{"2":{"493":1}}],["但是",{"0":{"482":1},"2":{"484":1,"502":1,"718":1,"721":1,"725":1}}],["但是有时候我们必须使用try",{"2":{"770":1}}],["但是有很多损失函数不是n阶可导的",{"2":{"497":1}}],["但是有一点",{"2":{"470":1}}],["但是有些资源本身并不具有这种属性",{"2":{"297":1}}],["但是别忘了",{"2":{"459":1}}],["但是方差上升",{"2":{"439":1}}],["但是训练成本和预测成本都会显著增加",{"2":{"439":1}}],["但是整体的误差却在降低",{"2":{"433":1}}],["但是样本的质量也会下降",{"2":{"401":1}}],["但是位置信息却没有得到",{"2":{"401":1}}],["但是add的计算量要比concat的计算量小得多",{"2":{"392":1}}],["但是描述图像的维度本身并没有增加",{"2":{"392":1}}],["但是对小目标的recall",{"2":{"385":1}}],["但是为了方便操作会把它整数化",{"2":{"368":1}}],["但是max",{"2":{"339":1}}],["但是相对于卷积计算可以说不值一提",{"2":{"312":1}}],["但是效率仍然慢",{"2":{"302":1}}],["但是需要不断地执行系统调用来获知",{"2":{"302":1}}],["但是需要每次保存两个",{"2":{"14":1}}],["但是它允许无亲缘关系进程间的通信",{"2":{"293":1}}],["但是线程不能独立执行",{"2":{"288":1}}],["但是安全性更高",{"2":{"252":1}}],["但是关闭连接时",{"2":{"239":1}}],["但是通过",{"2":{"202":1}}],["但是还是会有出现的概率",{"2":{"198":1}}],["但是因为网络等原因",{"2":{"196":1}}],["但是只支持精确查找",{"2":{"167":1}}],["但是乐观锁在更新的时候会去判断数据是否被更新过",{"2":{"133":1}}],["但是空间利用率变低",{"2":{"119":1}}],["但是带来的问题就是速度会慢一些",{"2":{"110":1}}],["但是服务器程序本身肯定不只是�",{"2":{"109":1}}],["但是也会问道一下常见的问题",{"2":{"57":1}}],["些引用次数为零的值所占用的内存�",{"2":{"110":1}}],["引导嵌入模型关注更相关的信息",{"2":{"423":1}}],["引导模型聚焦关键点",{"2":{"423":1}}],["引入更多的预训练任务以捕捉更丰富的语义知识",{"2":{"716":1}}],["引入二阶导一方面是为了增加精度",{"2":{"513":1}}],["引入多样化评估指标",{"2":{"423":1}}],["引入奖励多样性机制",{"2":{"423":1}}],["引入",{"2":{"423":1}}],["引入生成模型增强",{"2":{"422":1}}],["引入rpn",{"2":{"404":1}}],["引入了faster",{"2":{"378":2}}],["引入的随机性更大",{"2":{"333":1}}],["引起数据库压力瞬间增大",{"2":{"190":1}}],["引擎需要找到二级索引的子节点获得对应主键值",{"2":{"165":1}}],["引擎垃圾回收机制是什么样的",{"0":{"110":1}}],["引用类型被保存在堆内存�",{"2":{"210":1}}],["引用类型",{"2":{"210":1}}],["引用的对象有可能还没有完成初始化",{"2":{"144":1}}],["引用计数的含义是跟踪记录每个值被引用的次数�",{"2":{"110":1}}],["引用计�",{"2":{"110":1}}],["依据分布式假设",{"2":{"718":1}}],["依据马尔可夫性",{"2":{"526":1}}],["依赖的�",{"2":{"800":1}}],["依赖模型自身推理能力",{"2":{"423":1}}],["依赖高质量偏好标签",{"2":{"423":1}}],["依然从上述提到的top",{"2":{"769":1}}],["依然保证快速的检索或者更新数据",{"2":{"768":1}}],["依然有效",{"2":{"606":1,"609":1}}],["依然有标记的变量就被视为准备删除的变量",{"2":{"110":1}}],["依然一般",{"2":{"385":1}}],["依次构造训练集并训练弱分类器",{"2":{"427":1}}],["依次类推",{"2":{"184":1}}],["依次看数组中每一个元素的频次",{"2":{"82":1}}],["得体的着装和仪表",{"2":{"836":1}}],["得",{"2":{"635":1}}],["得出最终表达式",{"2":{"632":1}}],["得名",{"2":{"525":1}}],["得一个旧�",{"2":{"198":1}}],["得不到处理",{"2":{"109":1}}],["得到中位数在k+1个桶中",{"2":{"763":1}}],["得到左右子节点",{"2":{"756":1}}],["得到gbdt之后",{"2":{"741":1}}],["得到neg",{"2":{"721":1}}],["得到损失为",{"2":{"668":1}}],["得到比较好的结果",{"2":{"657":1}}],["得到了新的概率值",{"2":{"613":1}}],["得到每个θ对应的梯度",{"2":{"545":1}}],["得到全局最优解或者接近全局最优解",{"2":{"543":1}}],["得到对变量集合y的预测",{"2":{"521":1}}],["得到这句话最终最大可能的识别标签",{"2":{"521":1}}],["得到通用的目标函数形式",{"2":{"511":1}}],["得到最小化的损失函数和模型参数值",{"2":{"540":1}}],["得到最小损失",{"2":{"496":1}}],["得到最优分裂阈值",{"2":{"470":1}}],["得到最优的α",{"2":{"430":1}}],["得到下",{"2":{"496":1}}],["得到第一个分类器",{"2":{"486":1}}],["得到第n个丑",{"2":{"8":1}}],["得到包含m个样本的采样集dt",{"2":{"475":1}}],["得到包含t个样本的采样集dt",{"2":{"455":1}}],["得到更好的精度",{"2":{"466":1}}],["得到更好的预测结果",{"2":{"372":1}}],["得到特征重要性",{"2":{"462":1}}],["得到强学习器",{"2":{"431":1}}],["得到一个较为准确的分类结果",{"2":{"486":1}}],["得到一个值",{"2":{"470":1}}],["得到一个弱分类器",{"2":{"428":1}}],["得到一个更大的feature",{"2":{"318":1}}],["得到融合全局信息的表示",{"2":{"422":1}}],["得到新的分类器",{"2":{"486":1}}],["得到新的",{"2":{"388":2}}],["得到新的相同维度feature",{"2":{"318":1}}],["得到9个聚类中心",{"2":{"378":1}}],["得到极大的简化",{"2":{"366":1}}],["得到的特征作为lr的输入",{"2":{"741":1}}],["得到的u",{"2":{"730":1}}],["得到的系数仍然需要数据中的所有特征才能计算预测结果",{"2":{"330":1}}],["得到的答案是",{"2":{"268":1}}],["得到y＞x+2a",{"2":{"274":1}}],["得到条件",{"2":{"274":1}}],["得到三条边",{"2":{"274":1}}],["得到此时的次",{"2":{"32":1}}],["得到",{"2":{"7":1,"369":2,"388":3,"430":1,"635":1,"659":1,"790":1}}],["任何对页面中元素的操作都会引起回流或者重绘",{"2":{"786":1}}],["任何的节点序列中的起始节点到树中的任一节点都必须遵",{"2":{"94":1}}],["任意两个类训练出一个分类器",{"2":{"643":1}}],["任意选择一个子梯度就ok了",{"2":{"337":1}}],["任意取其余10个蛋中的一个蛋放在右端",{"2":{"270":1}}],["任意取其中2蛋",{"2":{"270":1}}],["任意取3个1到8号中的蛋放在天平的左端",{"2":{"270":1}}],["任选4个",{"2":{"275":1}}],["任务",{"2":{"829":1}}],["任务缩放因子",{"2":{"707":1}}],["任务更多样",{"2":{"423":1}}],["任务目标",{"2":{"422":1}}],["任务越开放越创新",{"2":{"422":1}}],["任务越标准越严谨",{"2":{"422":1}}],["任务会交给rejectedexecutionhandler",{"2":{"129":1}}],["任务会阻�",{"2":{"109":1}}],["任务到达线程池的过程",{"0":{"128":1},"1":{"129":1,"130":1,"131":1}}],["换卷积方式",{"2":{"399":1}}],["换行",{"2":{"246":1,"782":2}}],["换句话说概率大于0",{"2":{"660":1}}],["换句话说假如我们的神经网络是在做出某种预测",{"2":{"564":1}}],["换句话说任一位置的权重都应相同",{"2":{"355":1}}],["换句话说",{"2":{"109":1,"459":1}}],["换言之",{"2":{"26":1}}],["组内共享k",{"2":{"422":1}}],["组成三角形的概率是多大",{"2":{"274":1}}],["组成",{"2":{"109":1,"186":1,"246":2}}],["组合",{"2":{"31":1}}],["高�",{"2":{"774":1}}],["高质量地将海量单词向量化",{"2":{"718":1}}],["高度相关的特征对朴素贝叶斯有什么影响",{"0":{"624":1}}],["高斯混合聚类",{"2":{"674":1}}],["高斯核函数",{"2":{"635":1}}],["高斯模型",{"2":{"621":1}}],["高斯",{"2":{"621":1,"640":1}}],["高斯分布有两个参数",{"2":{"620":1}}],["高次特征",{"2":{"560":1}}],["高维稀疏特征的场景下",{"2":{"502":1}}],["高效率",{"2":{"718":1}}],["高效的",{"2":{"464":1}}],["高效性",{"2":{"422":1}}],["高困惑度则反驳",{"2":{"423":1}}],["高频维度变化太快",{"2":{"422":1}}],["高",{"2":{"422":1,"546":2,"589":1}}],["高计算成本",{"2":{"422":1}}],["高级管道",{"2":{"293":1}}],["高级数据结构",{"2":{"106":1}}],["高可用基石",{"2":{"194":1}}],["高可�",{"2":{"188":1}}],["高层的指针越过的元素数量大于等于低层的指针",{"2":{"186":1}}],["高并发的情况下",{"2":{"134":1}}],["高位",{"2":{"83":1}}],["→",{"2":{"106":6,"422":6,"423":4,"845":4,"846":4,"847":3,"848":3}}],["初学者路径",{"2":{"106":1}}],["初始的聚类中心之间的相互距离要尽可能的远",{"2":{"676":1}}],["初始可以都为1",{"2":{"601":1}}],["初始值不同",{"2":{"544":1}}],["初始概率分布",{"2":{"525":1}}],["初始构造直方图是需要一次o",{"2":{"497":1}}],["初始点src的距离是0",{"2":{"59":1}}],["初始化为0",{"2":{"759":1}}],["初始化参数",{"2":{"543":1}}],["初始化",{"2":{"519":1}}],["初始化权重",{"2":{"431":1}}],["初始化训练样本的权值分布",{"2":{"427":1,"428":1}}],["初始化k个anchor",{"2":{"381":1}}],["初始化方法有",{"2":{"323":1}}],["初始化起始点s到所有的点的距离是inf",{"2":{"58":1}}],["初始化起始点的距离是0",{"2":{"58":1}}],["初始化我们要把sell设为0表示最初是sell状态且没有profit",{"2":{"26":1}}],["初始",{"2":{"13":1}}],["刷题练习",{"2":{"105":1}}],["实战模拟面试场景和练习方法",{"2":{"843":1}}],["实战练习",{"0":{"835":1}}],["实践中的一些注意点",{"2":{"730":1}}],["实质上对每一个样本中每一个词都进行负例采样",{"2":{"725":1}}],["实质上生成一颗带权路径最小的哈夫曼树",{"2":{"725":1}}],["实质上将原来的特征分成了100份",{"2":{"669":1}}],["实体的完整语义",{"2":{"714":1}}],["实体主体",{"2":{"246":1}}],["实体主体三部分组成",{"2":{"246":1}}],["实验组和对照组有显著差异",{"2":{"574":1}}],["实验组和对照组没有显著差异",{"2":{"574":1}}],["实验组和对照组的统计差异是由抽样误差引起的",{"2":{"571":1}}],["实验后分析数据",{"2":{"570":1}}],["实验室的小李需要在24小时后知道有毒的饮料是哪瓶",{"2":{"269":1}}],["实验室里有8瓶饮料",{"2":{"269":1}}],["实时更新",{"2":{"546":1}}],["实时访问动态或专业知识库",{"2":{"423":1}}],["实用",{"2":{"451":1}}],["实施快",{"2":{"423":1}}],["实行资源预先分配策略",{"2":{"297":1}}],["实际一般使用",{"2":{"713":1}}],["实际中一般还会有",{"2":{"689":1}}],["实际中不好用",{"2":{"279":1}}],["实际的模型的roc曲线则是一条上凸的曲线",{"2":{"591":1}}],["实际为负",{"2":{"591":1}}],["实际为正",{"2":{"591":1}}],["实际实现时是接近于0",{"2":{"548":1}}],["实际取值取决于数据样本",{"2":{"544":1}}],["实际使用梯度下降法时",{"2":{"544":1}}],["实际上就是让对应神经元的输出为0",{"2":{"566":1}}],["实际上很多叶子的分裂增益较低",{"2":{"466":1}}],["实际上是个",{"2":{"446":1}}],["实际上是一种服务的冗余",{"2":{"194":1}}],["实际上出现的概率可能非常低",{"2":{"198":1}}],["实际上",{"2":{"192":1,"573":1,"763":1}}],["实际应用中",{"2":{"651":1}}],["实际应用",{"2":{"105":1}}],["实例",{"2":{"185":2}}],["实现上可以做到并行",{"2":{"456":1}}],["实现简单用户个性化和上下文记忆",{"2":{"423":1}}],["实现亚秒级近似搜索",{"2":{"423":1}}],["实现子体间信息协同",{"2":{"423":1}}],["实现了",{"2":{"366":1}}],["实现了同时对多个",{"2":{"202":1}}],["实现通道升维",{"2":{"320":1}}],["实现跨通道的交互和信息整合",{"2":{"320":1}}],["实现流量控制",{"2":{"242":1}}],["实现快速的故障恢复",{"2":{"194":1}}],["实现有序集合",{"2":{"186":1}}],["实现",{"0":{"185":1},"2":{"423":1,"798":1}}],["实现思想",{"2":{"184":1}}],["实现的是读写不阻塞",{"2":{"174":1}}],["实现的�",{"2":{"133":1}}],["实现方式",{"2":{"173":1}}],["实现是不同的",{"2":{"162":1}}],["实现则是通过利用",{"2":{"139":1}}],["实现需要硬件层面的支持",{"2":{"135":1}}],["实现�",{"2":{"111":1,"133":1}}],["实现一�",{"0":{"111":1}}],["实现常用的多路归并排序",{"2":{"54":1}}],["实现多路归并排序",{"0":{"54":1}}],["能力提升",{"2":{"810":1}}],["能力越来越强最终达到稳态",{"2":{"352":1}}],["能做的就是将它们打包在一起�",{"2":{"800":1}}],["能做很多高效的辅助工作",{"2":{"422":1}}],["能列出每个查询的单词所有所在文档的列表的反向索引数据结构开发了出来",{"2":{"763":1}}],["能个处理多分类任务",{"2":{"626":1}}],["能增强推荐的覆盖度和效果",{"2":{"625":1}}],["能直接优化模型行为",{"2":{"423":1}}],["能显著提升模型判别能力",{"2":{"423":1}}],["能有效识别噪声和离群点",{"2":{"422":1}}],["能发现任意形状的簇",{"2":{"422":1}}],["能提示发送方降低发送的速率",{"2":{"241":1}}],["能促进标准化工作",{"2":{"233":1}}],["能够处理的有效模块",{"2":{"800":1}}],["能够去处理那些非",{"2":{"800":1}}],["能够提升模型表达能力",{"2":{"664":1}}],["能够大大简化模型和计算",{"2":{"641":1,"672":1}}],["能够在低维空间中直接算出高维内积",{"2":{"635":1}}],["能够在一定程度上提高检测模型对物体大小的鲁棒性",{"2":{"402":1}}],["能够基于泛化性能相当弱的的学习器构建出很强的集成",{"2":{"441":1}}],["能够对用户的上万张照片进行索引",{"2":{"423":1}}],["能够更好地利用",{"2":{"422":1}}],["能够更简洁的处理",{"2":{"218":1}}],["能够有效的减少神经网络的参数量和计算量",{"2":{"320":1}}],["能够看到所有已提交的事务结果",{"2":{"170":1}}],["能够准确分析算法的时间和空间复杂度",{"2":{"105":1}}],["能降低其系统开销",{"2":{"162":1}}],["能否装满",{"2":{"4":1}}],["理想情况下肯定是做到两者都高",{"2":{"589":1}}],["理想情况下这种方法给了我们足够的样本数",{"2":{"336":1}}],["理由如下",{"2":{"422":1}}],["理解客户需求和价值创�",{"0":{"840":1}}],["理解岗位要求和核心能力",{"2":{"833":1}}],["理解他人观点和需�",{"0":{"818":1}}],["理解句子的语义",{"2":{"422":1}}],["理解为计算量",{"2":{"394":1}}],["理解为计算速度",{"2":{"394":1}}],["理解指针操作",{"2":{"99":1}}],["理论基础",{"2":{"105":1}}],["层实现",{"2":{"422":1}}],["层和初始的表示空间中",{"2":{"422":1}}],["层进行分类和回归",{"2":{"366":1}}],["层进行空间池化使其所有特征图输出尺寸相同",{"2":{"366":1}}],["层归一化",{"2":{"307":1}}],["层",{"2":{"186":1,"367":1,"702":1}}],["层面的锁",{"2":{"139":2}}],["层面的互斥锁",{"2":{"137":1}}],["层序",{"2":{"103":1}}],["层次聚类",{"2":{"674":1}}],["层次模型",{"2":{"256":1}}],["层次化和网络化数据结构",{"2":{"99":1}}],["层次遍历的从右到左遍历等",{"2":{"86":1}}],["层次遍历的从下到上遍",{"2":{"86":1}}],["层次遍历的奇数层遍历",{"2":{"86":1}}],["层次遍历",{"2":{"85":1}}],["树级关系构成的栈递归",{"2":{"792":1}}],["树进行对比",{"2":{"790":1}}],["树和上一次的",{"2":{"790":1}}],["树",{"2":{"790":1}}],["树形结构为什么不需要归一化",{"0":{"608":1}}],["树生长策",{"2":{"514":1}}],["树2和树3",{"2":{"512":1}}],["树只需要一个节点就可以完美分割9990",{"2":{"502":1}}],["树只需要遍历叶结点中的链表",{"2":{"167":1}}],["树节点在进行分裂时",{"2":{"497":2,"513":1}}],["树模型对缺失值的敏感度低",{"2":{"508":1}}],["树模型的惩罚项通常为叶子节点数和深",{"2":{"502":1}}],["树模型的集成模型都是使用树作为基模型",{"2":{"490":1}}],["树模型则不一样",{"2":{"502":1}}],["树模型很容易优化出一个使用f1特征作为重要分裂节点的树",{"2":{"502":1}}],["树模型集成学",{"0":{"490":1}}],["树索引支持大于小于等于查找",{"2":{"167":1}}],["树索引和哈希索引的比�",{"2":{"167":1}}],["树需要中序遍历整个树",{"2":{"167":1}}],["树的算法",{"2":{"792":1}}],["树的中间结点只存放索引",{"2":{"167":1}}],["树的遍历",{"2":{"103":1}}],["树对�",{"2":{"167":1}}],["树实�",{"2":{"167":1}}],["树与图",{"2":{"99":1}}],["环境突变则会导致物种难以做出及时反应",{"2":{"564":1}}],["环境模拟",{"2":{"423":1}}],["环检测",{"2":{"103":1}}],["环形链表",{"0":{"68":1}}],["双编码器可离线预计算所有数据向量",{"2":{"423":1}}],["双编码器更受欢迎因为",{"2":{"423":1}}],["双线性插值是有两个变量的插值函数的线性插值扩展",{"2":{"369":1}}],["双非渣本后端三月逆袭字节",{"2":{"253":1}}],["双亲委派机制",{"0":{"156":1}}],["双指针",{"2":{"103":1}}],["双向节点",{"2":{"70":1}}],["数小于0",{"2":{"552":1}}],["数值特征域可以直接作为输入特征",{"2":{"734":1}}],["数值缩放不影响分裂点位置",{"2":{"608":1}}],["数值连续特征使用的最小均方误差",{"2":{"497":1}}],["数值型特征",{"2":{"451":1}}],["数学基础扎实",{"2":{"845":1}}],["数学之美",{"2":{"522":1,"529":1}}],["数学",{"2":{"423":1}}],["数",{"2":{"423":1,"527":1}}],["数字类型包含整数与浮点数",{"2":{"210":1}}],["数据分析师",{"0":{"848":1}}],["数据双向绑定",{"2":{"795":1}}],["数据",{"2":{"770":1,"795":1}}],["数据和代码如何存储",{"2":{"770":1}}],["数据仓库建设",{"2":{"767":1}}],["数据已经很少了",{"2":{"756":1}}],["数据更新",{"2":{"740":1}}],["数据应该如何进行预处理",{"2":{"731":1}}],["数据特征极强相关的数据集",{"2":{"680":1}}],["数据还是这么多",{"2":{"669":1}}],["数据多时",{"2":{"648":1}}],["数据是否集中",{"2":{"622":1}}],["数据集可分出来的簇密度不一",{"2":{"680":1}}],["数据集增强",{"2":{"561":1}}],["数据集中包含小目标的图片比较少",{"2":{"403":1}}],["数据并行",{"2":{"514":1}}],["数据敏感",{"2":{"501":1}}],["数据样本的扰动对于决策树的影响较大",{"2":{"460":1}}],["数据训练",{"2":{"423":1}}],["数据准备",{"2":{"423":1}}],["数据规模更大",{"2":{"423":1}}],["数据对象间距离的计算有很多种",{"2":{"396":1}}],["数据处理获得所有训练数据bounding",{"2":{"381":1}}],["数据没有进行归一化的操作",{"2":{"349":1}}],["数据不平衡的解决方法",{"0":{"336":1}}],["数据不一致性",{"2":{"193":1}}],["数据增强",{"2":{"325":1,"386":1}}],["数据清洗",{"2":{"307":1}}],["数据只能单向流动",{"2":{"293":1}}],["数据总额一致",{"2":{"255":1}}],["数据在传输过程中即使被截获",{"2":{"252":1}}],["数据报时",{"2":{"250":1}}],["数据渲染页面",{"2":{"235":1}}],["数据封装类对象",{"2":{"210":1}}],["数据存储",{"2":{"203":1}}],["数据压根还没读到",{"2":{"196":1}}],["数据库与网络",{"2":{"846":1}}],["数据库事务处理的四个基本要素",{"2":{"258":1}}],["数据库事务必须具备acid特性",{"2":{"258":1}}],["数据库三范式",{"0":{"257":1}}],["数据库模型编辑",{"0":{"256":1}}],["数据库",{"0":{"254":1},"1":{"255":1,"256":1,"257":1,"258":1},"2":{"259":1,"848":1}}],["数据库会将操作信息写入binlog日志当中",{"2":{"199":1}}],["数据库缓存一致�",{"0":{"195":1},"1":{"196":1,"197":1,"198":1,"199":1}}],["数据库索引的实现原理",{"0":{"167":1}}],["数据冗余",{"2":{"194":1}}],["数据的复制是单向的",{"2":{"194":1}}],["数据类型",{"2":{"186":1}}],["数据恢复",{"2":{"172":1}}],["数据都存在叶结点中",{"2":{"167":1}}],["数据保持⼀致",{"2":{"166":1}}],["数据�",{"0":{"158":1},"1":{"159":1,"160":1,"161":1,"162":1,"163":1,"164":1,"165":1,"166":1,"167":1,"168":1,"169":1,"170":1,"171":1,"172":1,"173":1,"174":1}}],["数据结构与算法",{"2":{"846":1}}],["数据结构",{"2":{"754":1,"764":1,"768":1}}],["数据结构中的客户�",{"2":{"185":1}}],["数据结构中是否包含客户端2�",{"2":{"185":1}}],["数据结构基础",{"2":{"106":1}}],["数据结构重点",{"0":{"103":1}}],["数目的空闲线程最大存活时间",{"2":{"129":1}}],["数组中�",{"2":{"800":1}}],["数组中有重复的值",{"2":{"40":1}}],["数组倒序",{"2":{"220":1}}],["数组排序",{"2":{"220":1}}],["数组+链表",{"2":{"118":2}}],["数组操作",{"2":{"103":1}}],["数组与字符串",{"2":{"99":1}}],["数组的每个元素应该是长度",{"2":{"81":1}}],["数组",{"0":{"39":1},"1":{"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1},"2":{"210":1}}],["数组从每个位置k分开",{"2":{"18":1}}],["搜索引擎",{"2":{"763":1}}],["搜索字典项目的方法为",{"2":{"762":1}}],["搜索业务",{"2":{"755":1}}],["搜索策略",{"2":{"104":1}}],["搜索算法",{"2":{"100":1}}],["搜狐",{"2":{"49":1}}],["掌握各种操作技巧",{"2":{"99":1}}],["📞",{"0":{"850":1}}],["📖",{"0":{"832":1},"1":{"833":1,"834":1,"835":1,"836":1}}],["🔍",{"0":{"828":1},"1":{"829":1,"830":1,"831":1}}],["💰",{"0":{"812":1}}],["💪",{"0":{"811":1,"820":1},"1":{"821":1,"822":1}}],["🚀",{"0":{"810":1,"837":1},"1":{"838":1,"839":1,"840":1}}],["🗣️",{"0":{"419":1}}],["👁️",{"0":{"418":1}}],["🗄️",{"0":{"264":1}}],["💻",{"0":{"262":1,"846":1}}],["📂",{"0":{"205":1,"261":1,"416":1,"745":1,"802":1,"806":1,"842":1},"1":{"206":1,"207":1,"262":1,"263":1,"264":1,"265":1,"417":1,"418":1,"419":1,"420":1,"421":1,"803":1,"804":1,"843":1}}],["🔗",{"0":{"106":1}}],["💡",{"0":{"105":1,"823":1},"1":{"824":1,"825":1,"826":1,"827":1},"2":{"106":1,"840":1,"850":1}}],["📊",{"0":{"101":1,"265":1,"420":1,"804":1,"848":1}}],["🔢",{"0":{"99":1}}],["📚",{"0":{"98":1,"808":1},"1":{"99":1,"100":1,"101":1,"809":1,"810":1,"811":1,"812":1}}],["前期准备",{"0":{"833":1}}],["前端",{"2":{"847":1}}],["前端框架熟练应用",{"2":{"847":1}}],["前端框架",{"2":{"803":1}}],["前端框架及常用工具",{"0":{"788":1},"1":{"789":1,"790":1,"791":1,"792":1,"793":1,"794":1,"795":1,"796":1,"797":1,"798":1,"799":1,"800":1}}],["前端开发工程师",{"0":{"847":1}}],["前端开发校招面试问题整理�",{"0":{"208":1,"772":1},"1":{"209":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1,"216":1,"217":1,"218":1,"219":1,"220":1,"221":1,"222":1,"223":1,"224":1,"225":1,"226":1,"227":1,"228":1,"229":1,"773":1,"774":1,"775":1,"776":1,"777":1,"778":1,"779":1}}],["前端开发还是数据分析师",{"2":{"97":1}}],["前面的条件如果包含了后面的条件",{"2":{"606":1,"609":1}}],["前面的树往往起到决定性的作用",{"2":{"497":1}}],["前半部分使用基础分类网络获取各层的feature",{"2":{"386":1}}],["前向分布算法是加法模型",{"2":{"493":1}}],["前向计算过程",{"2":{"373":1}}],["前向传播是取某特征区域的平均值进行输出",{"2":{"338":1}}],["前两行是预测的box关于anchor的offset与scales",{"2":{"372":1}}],["前者划分的空间没有重叠",{"2":{"648":1}}],["前者采用有向无环图来表达事件的因果关系",{"2":{"521":1}}],["前者拥有更少的参数",{"2":{"347":1}}],["前者是80",{"2":{"247":1}}],["前者称为主节点",{"2":{"194":1}}],["前一个值",{"2":{"220":1}}],["前缀指令实际上相当于一个内存屏障",{"2":{"143":1}}],["前缀指令�",{"2":{"143":1}}],["前缀和",{"2":{"103":1}}],["前序的第一个a是根节点",{"2":{"90":1}}],["前序遍历的结点a的前一个结",{"2":{"88":1}}],["前序遍历的第k个结",{"0":{"88":1}}],["前序遍历的迭代形式",{"2":{"85":1}}],["前序遍历",{"2":{"85":1}}],["前序",{"2":{"85":1,"90":1,"103":1}}],["后再画图",{"2":{"684":1}}],["后再微调",{"2":{"423":1}}],["后有",{"2":{"651":1}}],["后",{"2":{"635":1}}],["后验概率",{"0":{"613":1},"2":{"613":1,"631":1}}],["后剪枝",{"2":{"605":1}}],["后计算测试误差b",{"2":{"462":1}}],["后处理校验",{"2":{"422":1}}],["后回归bbox来检测微小目标",{"2":{"401":1}}],["后两行是真实box与anchor的offset与scales",{"2":{"372":1}}],["后面会提到",{"2":{"769":1}}],["后面还有机会对子节点继续选择特征a划分a1和a3",{"2":{"604":1}}],["后面查找特征分割点时重复使用",{"2":{"506":1}}],["后面的values",{"2":{"769":1}}],["后面的归并排",{"2":{"763":1}}],["后面的树",{"2":{"741":1}}],["后面的迭代中重复地使用这个结构",{"2":{"497":2,"505":1,"513":1}}],["后面的请求都会落到数据库上",{"2":{"188":1}}],["后面根据残差再预测",{"2":{"472":1}}],["后面就全部统称为激活函数",{"2":{"319":1}}],["后来的backbone设计采用了更高效的module",{"2":{"311":1}}],["后者划分的空间相互交叠",{"2":{"648":1}}],["后者采用无向图来表达变量间的相互作用",{"2":{"521":1}}],["后者是b",{"2":{"280":1}}],["后者是443",{"2":{"247":1}}],["后者称为从节点",{"2":{"194":1}}],["后可以防�",{"2":{"228":1}}],["后台线程",{"2":{"185":1}}],["后续事件处理阶�",{"2":{"778":1}}],["后续词元用特殊标签",{"2":{"423":1}}],["后续构建",{"2":{"423":1}}],["后续的日志会记录到新的文件�",{"2":{"173":1}}],["后续某个时间点再一次性将多个操作记录写到redo",{"2":{"173":1}}],["后访问的事务必须等前一个事务执行完�",{"2":{"170":1}}],["后端开发工程师",{"0":{"846":1}}],["后端开发",{"2":{"97":1}}],["后序遍历",{"2":{"85":1}}],["后序",{"2":{"85":1,"103":1}}],["即该属性新的参数值�",{"2":{"796":1}}],["即该广告的实际点击次数",{"2":{"593":1}}],["即当前盒子的子元素或兄弟元素",{"2":{"784":1}}],["即项目的排列方向",{"2":{"782":1}}],["即借助外部的文件进行排序",{"2":{"763":1}}],["即完成查找",{"2":{"762":1}}],["即便曝光少的广告",{"2":{"741":1}}],["即embedding向量",{"2":{"734":1}}],["即将评分矩阵分解为r=um",{"2":{"730":1}}],["即得评分矩阵rm",{"2":{"730":1}}],["即定性情况",{"2":{"730":1}}],["即前一层的输出",{"2":{"702":1}}],["即长短时记忆网络",{"2":{"697":1}}],["即对于每一个样本",{"2":{"668":1}}],["即对所有的t",{"2":{"531":1}}],["即先把特征线性求和",{"2":{"666":1}}],["即先全是之后全是这种方式",{"2":{"446":1}}],["即因变量服从正态分布",{"2":{"658":1}}],["即二者都用到了nn",{"2":{"651":1}}],["即求出它的y",{"2":{"651":1}}],["即感知机",{"2":{"642":1}}],["即拉格朗日函数",{"2":{"637":1}}],["即解决了以上两个问题",{"2":{"635":1}}],["即找到了问题的解",{"2":{"635":1}}],["即是对偶问题",{"2":{"635":1}}],["即是以代价",{"2":{"590":1}}],["即模型的稳定性",{"2":{"622":1}}],["即模型本身的精准度",{"2":{"622":1}}],["即出现为true没有出现为false",{"2":{"621":1}}],["即到底把这个样本划分到哪个结点里",{"2":{"601":1}}],["即这个类的概率最大",{"2":{"598":1}}],["即依次将每个样本划分为正",{"2":{"590":1}}],["即f1",{"2":{"589":1}}],["即floating",{"2":{"315":1}}],["即实",{"2":{"586":4}}],["即每一个样本判",{"2":{"585":1}}],["即每秒处理的图片数量或者处理每张图片所需的时间",{"2":{"393":1}}],["即避免环境改变时物种可能面临的灭绝",{"2":{"564":1}}],["即刻画了学习问题本身的难度",{"2":{"558":1}}],["即刻画了学习算法本身的拟合能力",{"2":{"558":1}}],["即刻画了数据扰动所造成的影响",{"2":{"558":1}}],["即m",{"2":{"552":1}}],["即module",{"2":{"112":1}}],["即控制增量的步长",{"2":{"549":1}}],["即可得到此结果",{"2":{"662":1}}],["即可",{"2":{"548":1}}],["即可查看",{"2":{"228":1}}],["即有",{"2":{"547":1}}],["即有方向有大小",{"2":{"541":1}}],["即梯度消失",{"2":{"527":1}}],["即用贪心法枚举所有可能的分割点",{"2":{"497":2,"513":1}}],["即variance",{"2":{"497":1}}],["即数据的扰动导致模型学习性能的变化",{"2":{"497":1}}],["即数据对象间的距离越小",{"2":{"396":1}}],["即bias",{"2":{"497":1}}],["即为所求",{"2":{"750":1}}],["即为特征矩阵v的第i列",{"2":{"729":1}}],["即为user特征矩阵u的第u行",{"2":{"729":1}}],["即为auc",{"2":{"591":1}}],["即为什么叫做gbdt",{"2":{"497":1}}],["即为叶子节点",{"2":{"484":1}}],["即为数据增加一个版本标识",{"2":{"133":1}}],["即不需写出w",{"2":{"635":1}}],["即不限制最大的叶子节点数",{"2":{"484":1}}],["即不断重试",{"2":{"134":1}}],["即参数max",{"2":{"470":1}}],["即所占权重",{"2":{"428":1}}],["即多次训练这类样本",{"2":{"403":1}}],["即存在有先验知识的训练数据集",{"2":{"396":1}}],["即待处理数据对象没有任何先验知识",{"2":{"396":1}}],["即根据相似性原则",{"2":{"396":1}}],["即认为两个对象的距离越近",{"2":{"382":1}}],["即inter",{"2":{"368":1}}],["即选择其中一个就ok了",{"2":{"337":1}}],["即导数",{"2":{"337":1}}],["即图首先被",{"2":{"334":1}}],["即图是运行时创建",{"2":{"334":1}}],["即计算时间与io时间占比",{"2":{"315":1}}],["即均值为0",{"2":{"306":1}}],["即全为顺时针方向或全为逆时针方向",{"2":{"281":1}}],["即从每排中选中一个c",{"2":{"275":1}}],["即最大化对数似然函数",{"2":{"631":1}}],["即最低位为1的1",{"2":{"269":1}}],["即最左优先",{"2":{"168":1}}],["即http下加入ssl层",{"2":{"247":1}}],["即空行",{"2":{"246":1}}],["即快重传",{"2":{"243":1}}],["即�",{"2":{"213":1}}],["即",{"2":{"210":1,"269":1,"315":1,"404":1,"430":1,"487":1,"730":1}}],["即写redis数据时应用连接主节点",{"2":{"194":1}}],["即在求解最大相似度的时候可以转为求解最小距离",{"2":{"730":1}}],["即在特征空间的内积等于它们在原始样本空间中通过核函",{"2":{"638":1}}],["即在",{"2":{"422":1}}],["即在rpn提取roi区域后",{"2":{"367":1}}],["即在模型训练开始前被赋予初值",{"2":{"314":1}}],["即在执行到内存屏障这句指令时",{"2":{"143":1}}],["即在链表长度达到一个阈值之后再转换为红黑树",{"2":{"120":1}}],["即使在现在这种分类器层出不穷的年代",{"2":{"625":1}}],["即使都是分类问题也不应该唯评价函数论",{"2":{"578":1}}],["即使丢失特定的线索",{"2":{"564":1}}],["即使有标注数据",{"2":{"422":1}}],["即使ti",{"2":{"372":1}}],["即使文件尾部破损",{"2":{"193":1}}],["即使数据库发⽣故障也不应该对其有任何影�",{"2":{"166":1}}],["即使此时线程池中存在空闲线�",{"2":{"130":1}}],["即使全部遍历",{"2":{"120":1}}],["即我们维护一个最大深度",{"2":{"93":1}}],["即sell",{"2":{"26":1}}],["时不会直接更新数据",{"2":{"793":1}}],["时不做转换",{"2":{"120":1}}],["时效性",{"2":{"546":1}}],["时引用这些结构化内容",{"2":{"423":1}}],["时钟等",{"2":{"301":1}}],["时钟算法使用环形链表",{"2":{"299":1}}],["时钟算法",{"2":{"299":1}}],["时对应0",{"2":{"279":1}}],["时传�",{"2":{"139":1}}],["时间管理",{"2":{"836":1}}],["时间控制",{"2":{"831":1}}],["时间",{"2":{"763":1}}],["时间o",{"2":{"756":1}}],["时间长",{"2":{"632":1}}],["时间序列通常会随着天",{"2":{"535":1}}],["时间效率上大大提高了",{"2":{"497":1}}],["时间进行查找",{"2":{"167":1}}],["时间单位",{"2":{"129":1}}],["时间复杂度就是从n个中过滤出来k个",{"2":{"756":1}}],["时间复杂度高",{"2":{"402":1}}],["时间复杂度也不会太高",{"2":{"120":1}}],["时间复杂度分析",{"2":{"101":1}}],["时间复杂度o",{"2":{"93":1,"756":1}}],["时间复杂度为o",{"2":{"26":1,"497":1}}],["时的概率已经非常小",{"2":{"120":1}}],["时",{"2":{"93":1,"110":2,"130":4,"144":1,"243":1,"422":1,"425":1,"532":1}}],["寻找跟目标user偏好既有大量相同的items",{"2":{"730":1}}],["寻找最优的决策树是一个np难的问题",{"2":{"607":1}}],["寻找划分点t",{"2":{"603":1}}],["寻找的是某个特征的最佳分裂点",{"2":{"508":1}}],["寻找树中最左下结点的",{"0":{"93":1}}],["寻找字母板网格中是否存在这个单词",{"2":{"36":1}}],["多进程处理划分或的文件",{"2":{"769":1}}],["多进程同时处理多个文档",{"2":{"769":1}}],["多层划分",{"2":{"754":1,"768":1}}],["多棵树正好满足lr每条训练样本可以通过gbdt映射成多个特征的需求",{"2":{"741":1}}],["多棵树的表达能力更强一些",{"2":{"741":1}}],["多对一",{"2":{"690":1}}],["多对多2",{"2":{"690":1}}],["多对多1",{"2":{"690":1}}],["多对多",{"2":{"662":2}}],["多分类问题一般将二分类推广到多分类的方式有三种",{"2":{"662":1}}],["多分类实时预",{"2":{"625":1}}],["多项式核函数",{"2":{"635":1}}],["多项式模型适用于离散特征情况",{"2":{"621":1}}],["多项式模型",{"2":{"621":1}}],["多项式",{"2":{"621":1}}],["多取一些值",{"2":{"544":1}}],["多数服从少数",{"2":{"497":1}}],["多次迭代",{"2":{"486":1}}],["多次随机初始化中心选经验上最适合的",{"2":{"677":1}}],["多次随机选择特征",{"2":{"476":1}}],["多次随机取属性",{"2":{"475":1}}],["多次随机取样",{"2":{"475":1}}],["多次有放回的随机取样",{"2":{"476":1}}],["多次采样",{"2":{"455":1,"458":1}}],["多次买卖",{"2":{"25":1}}],["多次买卖股票",{"2":{"25":1}}],["多角度的推理过程",{"2":{"423":1}}],["多样化训练样本",{"2":{"423":1}}],["多样性和安全性问题",{"2":{"423":1}}],["多样本插值",{"2":{"345":1}}],["多任务训练",{"2":{"423":1}}],["多任务的系统比较",{"2":{"423":1}}],["多任务损失",{"2":{"367":1}}],["多负例排序",{"2":{"423":2}}],["多模态理解",{"2":{"423":1}}],["多块召回",{"2":{"423":1}}],["多轮规划修正能力",{"2":{"423":1}}],["多工具调用",{"2":{"423":1}}],["多标签",{"2":{"422":1}}],["多查询注意力",{"2":{"422":2}}],["多查询注意力和分组查询",{"2":{"422":1}}],["多头注意力",{"2":{"422":1}}],["多头设计",{"2":{"422":1}}],["多头并行计算后拼接结果",{"2":{"422":1}}],["多尺度训练可以分为两个方面",{"2":{"402":1}}],["多尺度是提升精度最明显的技巧之一",{"2":{"402":1}}],["多尺度预测",{"2":{"378":1}}],["多卡并行的时候怎么实现参数共享",{"0":{"335":1}}],["多线程程序只要有一个线程崩溃",{"2":{"288":1}}],["多线程同步",{"2":{"109":1}}],["多媒体应用等",{"2":{"240":1}}],["多播",{"2":{"240":1}}],["多路复用模块的引入",{"2":{"202":1}}],["多路复用模块同时监听多个",{"2":{"202":1}}],["多路复用技�",{"2":{"202":1}}],["多级缓存",{"2":{"188":1}}],["多个文件的输入",{"2":{"769":1}}],["多个3",{"2":{"347":1}}],["多个事务对同⼀个数据读取的结果是相同的",{"2":{"166":1}}],["多个线程等待同一个锁时",{"2":{"136":1}}],["多走了很多无用路",{"2":{"92":1}}],["建模样本选取有误",{"2":{"559":1}}],["建立在归并操作上的一种排序算法",{"2":{"760":1}}],["建立一个bin容器",{"2":{"470":1}}],["建立照片特征的索引",{"2":{"423":1}}],["建立块与块之间的逻辑引用",{"2":{"423":1}}],["建立会话密钥",{"2":{"247":1}}],["建立连接时通过三次握手可以有效地避免历史错误连接的建立",{"2":{"237":1}}],["建立连接的过程叫做握手",{"2":{"236":1}}],["建立最大堆",{"2":{"52":1,"756":1}}],["建议反馈",{"2":{"849":1}}],["建议我们每一个map任务的输入数据16",{"2":{"770":1}}],["建议每天坚持刷题",{"2":{"106":1}}],["建议多熟练掌",{"2":{"90":1}}],["同样地",{"2":{"721":1}}],["同样",{"2":{"668":1}}],["同样可以给出分类边界以及达到预测目的",{"2":{"635":1}}],["同样有很多节假日",{"2":{"536":1}}],["同一硬件情况下",{"2":{"394":1}}],["同一数字与所在位置无关",{"2":{"355":1}}],["同一类线程共享代码和数据空间",{"2":{"288":1}}],["同理",{"2":{"268":1,"458":1}}],["同理可以确定",{"2":{"267":1}}],["同时可以采用梯度下降法",{"2":{"730":1}}],["同时可通过svd进行降维处理",{"2":{"730":1}}],["同时由于user和item的数量都比较多",{"2":{"730":1}}],["同时将记忆状态和输出状态合二为一",{"2":{"690":1}}],["同时检索它的右孩子",{"2":{"651":1}}],["同时检索它的左孩子",{"2":{"651":1}}],["同时在文本数据中",{"2":{"625":1}}],["同时用到了一阶和二阶导数",{"2":{"497":1}}],["同时迭代思路和adaboost也有所不同",{"2":{"493":1}}],["同时优化答案和推理过程匹配",{"2":{"423":1}}],["同时训练通用任务和领域任务",{"2":{"423":1}}],["同时最大化匹配图文对的相似度",{"2":{"423":1}}],["同时抑制在其他主题中的普遍词",{"2":{"422":1}}],["同时为了将",{"2":{"367":1}}],["同时神经网路将提取特征和分类融合在一个结构中",{"2":{"327":1}}],["同时也可以保证整个",{"2":{"202":1}}],["同时",{"2":{"202":1}}],["同时有请求a和请求b进行更新操作",{"2":{"196":1}}],["同时读缓存没读到数据",{"2":{"190":1}}],["同时查返回行较少",{"2":{"168":1}}],["同时叶子节点中存放的就是整张表的行记录数据",{"2":{"165":1}}],["同时仍保留空格和单词的初始顺序",{"2":{"77":1}}],["同学提出问题",{"2":{"85":2}}],["右孩子节",{"2":{"756":1}}],["右两个叶子结点的样本权重和",{"2":{"507":1}}],["右下角的min",{"2":{"390":1}}],["右上对应1",{"2":{"279":1}}],["右端重",{"2":{"270":2}}],["右",{"2":{"85":2}}],["根节",{"2":{"756":1}}],["根域名服务器返回gtld",{"2":{"249":1}}],["根",{"2":{"85":2}}],["根据反馈不断优�",{"2":{"835":1}}],["根据不同岗位调整重�",{"2":{"809":1}}],["根据需求写出map函数和reduce函数",{"2":{"769":1}}],["根据划分性质",{"2":{"763":1}}],["根据某个给定的条件",{"2":{"755":1}}],["根据现实业务进行设置",{"2":{"740":1}}],["根据加权之后的值进行排序",{"2":{"730":1}}],["根据加上正则项的结构风险最小化自下向上进行的剪枝操作",{"2":{"605":1}}],["根据马尔可夫性质",{"2":{"719":1}}],["根据条件概率公式与大数定律",{"2":{"718":1}}],["根据最大似然估计得到的模型的损失函数就是logloss",{"2":{"670":1}}],["根据sigmoid函数",{"2":{"670":1}}],["根据sigmoid的公式可以知道",{"2":{"394":1}}],["根据拉格朗日对偶性",{"2":{"635":1}}],["根据贝叶斯公式",{"2":{"631":1}}],["根据贝叶斯公式有",{"2":{"282":1}}],["根据极大化对数似然函数直接求出条件概率",{"2":{"627":1}}],["根据已有样本进行贝叶斯估计学习出先验概",{"2":{"627":1}}],["根据后验概率大小进行决策分类",{"2":{"615":1}}],["根据情况来选择或组合",{"2":{"605":1}}],["根据预测的结果和实际的标签可以把样本分为4",{"2":{"591":1}}],["根据学习器预测结果对样例进行排序",{"2":{"590":1}}],["根据费马定理",{"2":{"555":1}}],["根据多元函数泰勒公式",{"2":{"547":1}}],["根据具体算法定",{"2":{"546":1}}],["根据样本的数据",{"2":{"545":1}}],["根据每次分裂后产生的增益",{"2":{"510":1}}],["根据错误率赋予分类器权重",{"2":{"486":1}}],["根据该值对bin容器从小到大进行排序",{"2":{"470":1}}],["根据基学习器的表现对样本进行调整",{"2":{"456":1}}],["根据前向分布加法模型",{"2":{"433":1}}],["根据前面判断的该蛋是比较轻还是重可以判断天平上的其中一个蛋为要找的蛋",{"2":{"270":1}}],["根据误差改变权重就是adaboost的本质",{"2":{"431":1}}],["根据m=1",{"2":{"431":1}}],["根据时间",{"2":{"423":1}}],["根据用户或专家反馈持续优化模型输出质量",{"2":{"423":1}}],["根据用户反馈持续优化",{"2":{"423":1}}],["根据用户的查询高效地检索相关照片",{"2":{"423":1}}],["根据用户请求类型或上下文意图",{"2":{"423":1}}],["根据查询与文档间深层语义关系重新打分",{"2":{"423":1}}],["根据标题设定角色",{"2":{"423":1}}],["根据2中计算的iou去除重叠度高的",{"2":{"397":1}}],["根据2中的不等式",{"2":{"274":1}}],["根据输入image",{"2":{"368":1}}],["根据输入的开始点和末尾点",{"2":{"220":1}}],["根据i",{"2":{"301":1}}],["根据三个不等式得到排除概率1",{"2":{"274":1}}],["根据1中的所有条件",{"2":{"274":1}}],["根据1的位置不同确定a和b",{"2":{"43":1}}],["根据两边之和大于第三边",{"2":{"274":1}}],["根据key值得到想要的一切数据",{"2":{"258":1}}],["根据指定的key访问时",{"2":{"202":1}}],["根据过期时间的先后进行删除",{"2":{"200":1}}],["根据垂线从左到右遍历二叉",{"2":{"89":1}}],["根据对角线顺序遍历二叉树",{"2":{"89":1}}],["根据权重排序所有的边",{"2":{"59":1}}],["根据快速排序的思想",{"2":{"48":1}}],["根据未知旋转轴排序",{"2":{"41":1}}],["根据这个题目",{"2":{"21":1}}],["希尔排序",{"2":{"755":1}}],["希尔等算法",{"2":{"50":1}}],["希望大家要跳跃思维",{"2":{"266":1}}],["希望大家自行手写中序和后序的迭代代码",{"2":{"85":1}}],["存到文件里面就可以了",{"2":{"747":1}}],["存伪",{"2":{"574":1}}],["存放在内核中并由消息队列标识符标识",{"2":{"293":1}}],["存放在结果的第",{"2":{"83":1}}],["存取方式不同",{"2":{"244":1}}],["存在一个3阶交互",{"2":{"732":1}}],["存在users和items的互动",{"2":{"730":1}}],["存在类别不平衡问题",{"2":{"649":1}}],["存在无穷个分离超平面可以将两类数据正确分开",{"2":{"636":1}}],["存在的价值是什么",{"2":{"423":1}}],["存在的本地内存数据不一致",{"2":{"140":1}}],["存在",{"2":{"422":1}}],["存在就设置失败",{"2":{"184":1}}],["存储为block结构",{"2":{"510":1}}],["存储为块结构",{"2":{"504":1}}],["存储和文档数据库的优点",{"2":{"258":1}}],["存储大小不同",{"2":{"244":1}}],["存储在服务端",{"2":{"244":1}}],["存储在客户端",{"2":{"244":1}}],["存储在",{"2":{"244":1}}],["存储着修改之前的数据",{"2":{"174":1}}],["存储结果",{"2":{"34":1}}],["开根号",{"2":{"703":1}}],["开发技术",{"2":{"846":1,"847":1}}],["开发技�",{"0":{"801":1},"1":{"802":1,"803":1,"804":1}}],["开发各种产品",{"2":{"573":1}}],["开发和调试非常友好",{"2":{"202":1}}],["开源模型",{"2":{"423":1}}],["开销大",{"2":{"302":1}}],["开头的这样的序列p对应1",{"2":{"279":1}}],["开头的这样的序列p对应0",{"2":{"279":1}}],["开始",{"2":{"388":1}}],["开始时两个模型都没有训练",{"2":{"352":1}}],["开始行",{"2":{"246":1}}],["开始执行拥塞避免算法",{"2":{"243":2}}],["开",{"2":{"83":1}}],["或全部",{"2":{"786":1}}],["或有很多离群值",{"2":{"680":1}}],["或近似线性可分",{"2":{"635":1}}],["或依赖关系的影响能相互抵消",{"2":{"617":1}}],["或达到指定的迭代次数",{"2":{"555":1}}],["或是解码",{"2":{"519":1}}],["或平均",{"2":{"459":1}}],["或等效h100",{"2":{"423":1}}],["或等效算力如h100",{"2":{"423":1}}],["或忽略",{"2":{"423":1}}],["或摘要传递",{"2":{"423":1}}],["或限制字数等",{"2":{"422":1}}],["或",{"2":{"422":3,"689":1}}],["或block",{"2":{"311":1}}],["或进程",{"2":{"301":1}}],["或被操作系统及有终止权的进程所终止时所处的状态",{"2":{"292":1}}],["或出现无法克服的错误而异常终止",{"2":{"292":1}}],["或�",{"2":{"199":1}}],["或直接将输入转换为整数来处理",{"2":{"83":1}}],["或者不能一次性读入内存中",{"2":{"768":1}}],["或者发现user之间的相关性",{"2":{"727":1}}],["或者超出规定的时间",{"2":{"651":1}}],["或者说是假设成立的条件实际并不成立",{"2":{"559":1}}],["或者说是每经过一个往返时间rtt",{"2":{"243":1}}],["或者线性回归",{"2":{"497":1,"504":1,"513":1}}],["或者求取树预测的平均值",{"2":{"489":1}}],["或者到达迭代次数",{"2":{"486":1}}],["或者对于回归问题选择线性回归",{"2":{"438":1}}],["或者很宽的目标",{"0":{"403":1}}],["或者其他网络",{"2":{"373":1}}],["或者锚点和标注的重叠区域指标",{"2":{"367":1}}],["或者叫做模型复杂度惩罚项",{"2":{"330":1}}],["或者消失",{"2":{"323":1}}],["或者是非等概率硬币",{"2":{"278":1}}],["或者",{"2":{"244":1}}],["或者写在内层但是没有用",{"2":{"214":1}}],["或者更长时间生成一次",{"2":{"192":1}}],["或者甚至数�",{"2":{"192":1}}],["或者fast",{"2":{"68":1}}],["或者优先队列",{"2":{"54":1}}],["案例库和事实知识",{"2":{"423":1}}],["案例",{"2":{"82":1}}],["被误分的情况",{"2":{"730":1}}],["被广泛应用",{"2":{"625":1}}],["被densenet发扬光大",{"2":{"318":1}}],["被打�",{"2":{"188":1}}],["被其修饰的变量在每次使用之前都从主内存刷新",{"2":{"140":1}}],["被",{"2":{"81":1}}],["替换",{"2":{"134":1,"710":1}}],["替换一个字",{"2":{"5":1}}],["替代",{"2":{"81":4}}],["括号生成",{"0":{"80":1}}],["也希望这份资料能同样帮助到你",{"2":{"765":1}}],["也即pos",{"2":{"721":1}}],["也即所有中心词的词集",{"2":{"719":1}}],["也即maxp",{"2":{"719":1,"722":1}}],["也有的实现会把前一时刻的隐层和当前时刻的输入分开",{"2":{"699":1}}],["也有一种特殊的情况",{"2":{"301":1}}],["也叫",{"2":{"689":1}}],["也叫k均值或k平均",{"2":{"675":1}}],["也称bin",{"2":{"651":1}}],["也称为周期性的变化",{"2":{"535":1}}],["也要有足够大的确信度将他们分开",{"2":{"635":1}}],["也得看出现的次数",{"2":{"621":1}}],["也支持回归问题",{"2":{"597":1}}],["也好像不是不行",{"2":{"515":1}}],["也好控制模型复杂度",{"2":{"466":1}}],["也会放弃此次分裂",{"2":{"507":1}}],["也会在以下几种情况下选择零样本分类",{"2":{"422":1}}],["也限制了模型对长依赖的建模能力",{"2":{"422":1}}],["也可能是多个",{"2":{"654":2}}],["也可能不是极值点",{"2":{"551":1}}],["也可享受大尺寸和多尺寸带来的增益",{"2":{"402":1}}],["也可以便于划分",{"2":{"770":1}}],["也可以基于数据范围用",{"2":{"755":1}}],["也可以进行离散化进行one",{"2":{"734":1}}],["也可以是主观观点得出",{"2":{"613":1}}],["也可以由背景常识得出",{"2":{"613":1}}],["也可以做分类",{"2":{"600":1}}],["也可以通过人工设置的方式来指定时间序列的变点",{"2":{"537":1}}],["也可以支",{"2":{"511":1}}],["也可以支决策树",{"2":{"511":1}}],["也可以一定程度上防止过拟合",{"2":{"307":1}}],["也可以使用图像增强",{"2":{"307":1}}],["也可以使用公式",{"2":{"131":1}}],["也可以不使用",{"2":{"246":1}}],["也许也有使用平均值进行更新",{"2":{"381":1}}],["也只是说每个单元格最多只预测一个目标",{"2":{"378":1}}],["也只有当前正在运行的代码",{"2":{"301":1}}],["也跟具体算子的计算密集程度",{"2":{"315":1}}],["也不存在过拟合的现象",{"2":{"487":1}}],["也不考虑上下文",{"2":{"422":1}}],["也不清楚面试出这种题目的意义",{"2":{"266":1}}],["也不会影响客户端的读�",{"2":{"193":1}}],["也不会把前面的指令排到内存屏障的后面",{"2":{"143":1}}],["也实现了流量控制",{"2":{"242":1}}],["也易修�",{"2":{"193":1}}],["也将聚集索引的叶子节点称为数据页",{"2":{"165":1}}],["也成内存栅栏",{"2":{"143":1}}],["也就意味着它能学习更为全局",{"2":{"309":1}}],["也就是1",{"2":{"793":1}}],["也就是给定中心词",{"2":{"722":1}}],["也就是给定上下文词",{"2":{"719":1}}],["也就是和分类最相关的少数点",{"2":{"641":1,"672":1}}],["也就是函数间隔为1",{"2":{"635":1}}],["也就是值的变异情况",{"2":{"583":1}}],["也就是当前最陡峭的位置向下走一步",{"2":{"542":1}}],["也就是垂直切分",{"2":{"514":1}}],["也就是",{"2":{"422":1,"502":1}}],["也就是通道的信息交互整合的过程",{"2":{"320":1}}],["也就是信息加密的等级",{"2":{"247":1}}],["也就是我们平时所说的原型链的概念�",{"2":{"212":1}}],["也就是只有一个请求可以设置成功",{"2":{"184":1}}],["也就是行的系统版本号小于或等于事务的系统版本�",{"2":{"162":1}}],["也就是说高偏差而低方差",{"2":{"622":1}}],["也就是说它的重要程度比较高",{"2":{"483":1}}],["也就是说描述图像本身的特征数",{"2":{"392":1}}],["也就是说",{"2":{"26":1,"493":1,"497":1,"508":1,"651":1,"739":1,"784":1}}],["也就�",{"2":{"109":1}}],["也是我们之前提到过的partition处理",{"2":{"769":1}}],["也是roc曲线的横纵坐标",{"2":{"591":1}}],["也是轮询+遍历",{"2":{"302":1}}],["也是一样的情况",{"2":{"278":1}}],["也是一个有效答案",{"2":{"79":1}}],["也是为了实现可靠传输的",{"2":{"241":1}}],["也是使用类似的递归思想",{"2":{"87":1}}],["本属性定义如果一条轴线排不下",{"2":{"782":1}}],["本来就是用梯度拟合",{"2":{"515":1}}],["本轮迭代找到决策树",{"2":{"493":1}}],["本质",{"2":{"657":1}}],["本质上",{"2":{"800":1}}],["本质上是基于全局语料进行svd矩阵分解",{"2":{"725":1}}],["本质上也是簇间距离和簇内距离之比",{"2":{"684":1}}],["本质上就是事先对已知样本点进行剪辑",{"2":{"651":1}}],["本质上决策树是通过一系列规则对数据进行分类的过程",{"2":{"597":1}}],["本质上来说是因为这个地方可画多条切线",{"2":{"337":1}}],["本质是搜索局部极大值",{"2":{"397":1}}],["本题可以将鸡蛋分成三份",{"2":{"270":1}}],["本题中",{"2":{"76":1}}],["本地读取优化和加载平衡的细节",{"2":{"769":1}}],["本地域名服务器缓存解析结果",{"2":{"249":1}}],["本地的hosts文件和向本地dns服务器进行查询",{"2":{"235":1}}],["本地",{"2":{"188":1}}],["本身以及它后面的字符称之�",{"2":{"798":1}}],["本身方差就不大",{"2":{"461":1}}],["本身的表示",{"2":{"422":1}}],["本身都是创建对象",{"2":{"224":1}}],["本身并不需要占用太多的资源",{"2":{"109":1}}],["本身",{"2":{"83":1}}],["本身就是回文",{"2":{"7":1}}],["验证逻辑",{"2":{"795":1}}],["验证和测试集",{"2":{"741":1}}],["验证错误是34",{"0":{"482":1}}],["验证模型零样本能力",{"2":{"423":1}}],["验证文章是否由",{"2":{"423":1}}],["验证损失最小即为最优迭代次数",{"2":{"325":1}}],["验证它是否是回文串",{"2":{"76":1}}],["验证回文",{"0":{"76":1}}],["验证是否已经满足条件",{"2":{"35":1}}],["左孩子节",{"2":{"756":1}}],["左右节点存在",{"2":{"756":1}}],["左右各一半",{"2":{"56":1}}],["左上角的点",{"2":{"390":1}}],["左上角纵坐标",{"2":{"381":1}}],["左上角横坐标",{"2":{"381":1}}],["左下对应0",{"2":{"279":1}}],["左端重",{"2":{"270":2}}],["左边看到的二叉树结点",{"0":{"95":1}}],["左",{"2":{"85":2}}],["左括号必须以正确的顺序闭合",{"2":{"75":1}}],["左括号必须用相同类型的右括号闭合",{"2":{"75":1}}],["为媒介元素",{"2":{"776":1}}],["为线性复杂复杂度o",{"2":{"735":1}}],["为这样可以让频率高的词先学习",{"2":{"725":1}}],["为零则无法计算",{"2":{"618":1}}],["为反",{"2":{"613":1}}],["为正向",{"2":{"613":1}}],["为参数",{"2":{"602":1}}],["为残差平方和的均",{"2":{"583":1}}],["为在x0",{"2":{"555":1}}],["为状态空间中经过从一个状态到另一个状态的转换的随机过程",{"2":{"525":1}}],["为什",{"0":{"638":1},"2":{"498":1}}],["为什么想加入我们�",{"0":{"827":1}}],["为什么我们对每一步进行一个取名字",{"2":{"769":1}}],["为什么建树采用gbdt而非rf",{"2":{"741":1,"742":1}}],["为什么建树采用ensemble决策树",{"2":{"741":1}}],["为什么迭代次数后会收敛",{"0":{"682":1}}],["为什么在计算k",{"0":{"679":1}}],["为什么在模型训练开始会有warm",{"0":{"346":1}}],["为什么逻辑回归比线性回归要好",{"0":{"666":1}}],["为什么svm对缺失数据敏",{"0":{"639":1}}],["为什么采用间隔最大化",{"0":{"636":1}}],["为什么说朴素贝叶斯是高偏差低方差",{"0":{"622":1}}],["为什么属性独立性假设在实际情况中很难成立",{"0":{"617":1}}],["为什么朴素贝叶斯如此朴素",{"0":{"614":1}}],["为什么l1比l2更容易获得稀疏解",{"0":{"563":1}}],["为什么参数越小代表模型越简单",{"0":{"562":1}}],["为什么会出现这个现象",{"0":{"559":1}}],["为什么不使用三阶或者更高梯度信息",{"2":{"497":1}}],["为什么不用全样本训练",{"0":{"478":1}}],["为什么adaboost方式能够提高整体模型的学习精度",{"0":{"433":1}}],["为什么",{"0":{"459":1,"550":1},"2":{"423":1}}],["为什么双编码器在大规模相似度搜索中更受欢迎",{"2":{"423":1}}],["为什么提示词中需要描述角色定义",{"2":{"422":1}}],["为什么提出旋转的提议框呢",{"2":{"404":1}}],["为什么提出anchor",{"2":{"367":1}}],["为什么能提升推理速度",{"2":{"422":1}}],["为什么注意力机制需要多个头",{"2":{"422":1}}],["为什么它是指输入和输出的总长度",{"2":{"422":1}}],["为什么使用不同尺寸和不同长宽比",{"2":{"367":1}}],["为什么要将求",{"0":{"637":1}}],["为什么要拟合负梯",{"2":{"498":1}}],["为什么要随机特征",{"0":{"479":1}}],["为什么要在向量相似度检索前",{"2":{"423":1}}],["为什么要把文档划分成多个块进行索引",{"2":{"423":1}}],["为什么要做bounding",{"2":{"372":1}}],["为什么要反向传播",{"0":{"340":1}}],["为什么要对网络进行初始化",{"0":{"323":1}}],["为什么max",{"0":{"339":1}}],["为什么还能用",{"0":{"337":1}}],["为什么神经网络种常用relu作为激活函数",{"0":{"328":1}}],["为什么需要同时最大化匹配图文对的相似度和最小化非匹配图文对的相似度",{"2":{"423":1}}],["为什么需要重排序模型",{"2":{"423":1}}],["为什么需要做特征归一化",{"0":{"305":1}}],["为什么需要四次挥手",{"0":{"239":1}}],["为什么需要三次握手",{"0":{"237":1}}],["为什么这么快",{"0":{"202":1}}],["为什么新生代用标�",{"0":{"154":1}}],["为什么链表长度为8要转化为红黑�",{"0":{"120":1}}],["为基学习器的gbdt框架",{"2":{"444":1}}],["为何",{"0":{"440":1}}],["为何不直接将视觉编码器的输出连接到语言模型",{"2":{"423":1}}],["为后续sft和rlhf提供初始化权重",{"2":{"423":1}}],["为兼顾特定领域知识和通用能力",{"2":{"423":1}}],["为解决语义检索与关键词匹配的矛盾",{"2":{"423":1}}],["为解决分块后的上下文缺失问题",{"2":{"423":1}}],["为选择用yolov3",{"0":{"413":1}}],["为",{"2":{"388":1,"631":1,"689":1}}],["为64",{"2":{"357":1}}],["为要找的蛋",{"2":{"270":1}}],["为表述方便",{"2":{"270":1}}],["为公平锁",{"2":{"139":1}}],["为空默�",{"2":{"139":1}}],["为非公平�",{"2":{"139":1}}],["为非负整数",{"2":{"32":1}}],["为了替代正向索引的每个文档的单词列表",{"2":{"763":1}}],["为了提升广告整体投放效果",{"2":{"741":1}}],["为了提升线性分类器的准确度",{"2":{"739":1}}],["为了提高查找的效率",{"2":{"186":1}}],["为了能够得到真实值",{"2":{"654":1}}],["为了能够找到查询点q在数据集合中的最近邻点",{"2":{"651":1}}],["为了能够让kd",{"2":{"651":1}}],["为了使问题变得易于处理",{"2":{"637":1}}],["为了弥补这个缺陷",{"2":{"628":1}}],["为了解决knn算法计算量过大的问题",{"0":{"651":1}}],["为了解决零概率的问题",{"2":{"618":1}}],["为了解决这个问题",{"2":{"397":1,"619":1}}],["为了均衡两个指标",{"2":{"589":1}}],["为了保证数据的新鲜性",{"2":{"740":1}}],["为了保证量纲一致性",{"2":{"581":1}}],["为了保证原子性",{"2":{"140":1}}],["为了减少特征取值的影响",{"2":{"544":1}}],["为了后续推导的统一",{"2":{"516":1}}],["为了给后面的训练留出更多的学习空",{"2":{"507":1}}],["为了是相乘之后最小",{"2":{"497":1}}],["为了应对大方差",{"2":{"459":1}}],["为了求上式的最小化",{"2":{"430":1}}],["为了尽可能防止提示词注入",{"2":{"422":1}}],["为了得到更大的交并比",{"2":{"367":1}}],["为了性能更快",{"2":{"199":1}}],["为了方便",{"2":{"112":1}}],["为了运用这种思想",{"2":{"74":1}}],["算法是用来更新并且渲�",{"2":{"792":1}}],["算法导论",{"2":{"764":1}}],["算法的查找效率很高",{"2":{"651":1}}],["算法的增长策略构建树",{"2":{"471":1}}],["算法思想较简单",{"2":{"649":1}}],["算法思想重点",{"0":{"104":1}}],["算法测试由后验分布给出的全局最值最可能出现的位置的点",{"2":{"628":1}}],["算法也比较简",{"2":{"626":1}}],["算法复杂度",{"2":{"546":1}}],["算法运行时间长",{"2":{"544":1}}],["算法迭代步长α选择",{"2":{"544":1}}],["算法中需要用到样本的地方全部以内积形式出现",{"2":{"635":1}}],["算法中",{"2":{"533":1}}],["算法即可对其自动进行处理",{"2":{"497":1}}],["算法十问",{"0":{"497":1}}],["算法会建立在最大叶子节点数内最优的决策树",{"2":{"484":1}}],["算法可以允许一小部分的冲突",{"2":{"468":1}}],["算法面试题",{"0":{"429":1},"1":{"430":1,"431":1,"432":1,"433":1,"434":1,"435":1,"436":1,"437":1,"438":1,"439":1,"440":1,"441":1}}],["算法流程",{"0":{"428":1},"2":{"455":1,"456":1,"475":1}}],["算法详解",{"0":{"426":1},"1":{"427":1,"428":1}}],["算法详细的流程描述如下",{"2":{"396":1}}],["算法介绍",{"0":{"424":1},"1":{"425":1,"426":1,"427":1,"428":1,"429":1,"430":1,"431":1,"432":1,"433":1,"434":1,"435":1,"436":1,"437":1,"438":1,"439":1,"440":1,"441":1,"442":1}}],["算法工程师",{"0":{"845":1},"2":{"422":1}}],["算法简单",{"2":{"422":1}}],["算法简单易实现",{"2":{"396":1}}],["算法进行",{"2":{"376":1}}],["算法在图片上预取",{"2":{"366":2}}],["算法后使检测任务可以由神经网络端到端地完成",{"2":{"365":1}}],["算法筛选设置了过期时间的键值对",{"2":{"200":2}}],["算法涉及到三个操作",{"2":{"134":1}}],["算法设计",{"2":{"106":1}}],["算法优化策略",{"2":{"101":1}}],["算法基础需要大量练习才能熟练掌握",{"2":{"106":1}}],["算法基础是所有技术岗位面试的核心内容",{"2":{"97":1}}],["算法基础",{"0":{"97":1},"1":{"98":1,"99":1,"100":1,"101":1,"102":1,"103":1,"104":1,"105":1,"106":1},"2":{"845":1,"846":1,"847":1,"848":1}}],["算法就会返回最终答案的lcp",{"2":{"74":1}}],["算法就结束了",{"2":{"74":1}}],["算法要依次遍历字符",{"2":{"74":1}}],["算法",{"2":{"74":1,"110":1,"243":1,"651":1,"792":1}}],["示例引导",{"2":{"422":1}}],["示例",{"2":{"74":2,"75":5,"76":2,"77":1,"78":3,"79":2,"81":3,"83":2,"423":1}}],["编程之美",{"2":{"764":1}}],["编程任务",{"2":{"423":1}}],["编程",{"2":{"423":1}}],["编程语言",{"0":{"204":1},"1":{"205":1,"206":1,"207":1},"2":{"845":1,"846":1,"847":1,"848":1}}],["编码成一个固定长度的序列",{"2":{"422":1}}],["编码后的0",{"2":{"269":1}}],["编译",{"2":{"334":1}}],["编译器会对代码指令重排序",{"2":{"140":1}}],["编写一个函数来查找字符串数组中的最长公共前缀",{"2":{"74":1}}],["编辑距离",{"0":{"5":1}}],["题意",{"2":{"72":1,"73":1}}],["题目中没有说明坏的蛋是比好的蛋重还是轻",{"2":{"270":1}}],["题目中4只出现一次",{"2":{"268":1}}],["题目",{"2":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"61":1,"72":1,"85":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"92":1,"93":1,"94":1,"95":1,"267":1,"268":1,"269":1,"270":1,"271":1,"274":1,"275":1,"276":1,"277":1,"278":1,"279":1,"280":1,"281":1,"282":1,"283":1,"747":1,"748":1,"749":1,"750":1,"751":1,"752":1}}],["两阶段预训练",{"2":{"713":1}}],["两层",{"2":{"707":1}}],["两层循环的顺序不能改变",{"2":{"497":1}}],["两种加速方案",{"2":{"725":1}}],["两种算法的结果是很接近的",{"2":{"641":1,"672":1}}],["两种方式结合",{"2":{"423":1}}],["两种方案的差别不大",{"2":{"369":1}}],["两类错误是什么",{"0":{"574":1}}],["两点马尔可夫性质",{"2":{"527":1}}],["两矩形面积之和",{"2":{"390":1}}],["两人玩游戏",{"2":{"267":1}}],["两次整数化",{"2":{"368":1}}],["两次握手",{"2":{"237":1}}],["两次b",{"2":{"165":1}}],["两者殊途同归均能用于推荐系统",{"2":{"730":1}}],["两者都可以理解为整合特征图信息",{"2":{"392":1}}],["两者的区别在于分母上",{"2":{"730":1}}],["两者的区别",{"2":{"330":1}}],["两者均可并发执行",{"2":{"288":1}}],["两者共同进行管理的�",{"2":{"110":1}}],["两者不同的地方是",{"2":{"110":1}}],["两者各有优劣",{"2":{"109":1}}],["两个相邻的块级盒子的垂直外边距会产生折叠",{"2":{"784":1}}],["两个相同维度的feature",{"2":{"318":1}}],["两个盒子之间的垂直的间隙是由它们的",{"2":{"784":1}}],["两个模型",{"2":{"725":1}}],["两个模型都是降低方差和偏差",{"2":{"439":1}}],["两个变量之间的关系不是一次函数关系的图象不是直线",{"2":{"654":1}}],["两个变量之间的关系是一次函数关系的图象是直线",{"2":{"654":1}}],["两个方法都可以增加不同的正则化项",{"2":{"641":1,"672":1}}],["两个box没有重叠区域",{"2":{"390":1}}],["两个矩形的宽之和减去组合后的矩形的宽就是重叠矩形的宽",{"2":{"390":1}}],["两个网络共享相同的卷积层",{"2":{"373":1}}],["两个控制信息",{"2":{"237":1}}],["两个单列查询返回行较多",{"2":{"168":1}}],["两个或更多个列上的索引被称作复合索引",{"2":{"168":1}}],["两个关键字也可以实现可见性",{"2":{"140":1}}],["两个节点a和b的最近距",{"2":{"92":1}}],["两个链表合并为一个升序链表",{"0":{"71":1}}],["两s=nums",{"2":{"18":1}}],["快速学习新技术的能力",{"0":{"838":1}}],["快速学�",{"2":{"815":1}}],["快速排",{"0":{"757":1}}],["快速排序是对冒泡排序的改进",{"2":{"757":1}}],["快速排序",{"0":{"51":1},"2":{"754":1,"755":1,"768":1}}],["快速部署",{"2":{"423":1}}],["快速迭代和调试模型基本能力",{"2":{"423":1}}],["快速迭代基本能力",{"2":{"423":1}}],["快恢复",{"2":{"243":1}}],["快重传",{"2":{"243":1}}],["快照文件",{"2":{"194":1}}],["快照数据文件生成的时候",{"2":{"192":1}}],["快排",{"2":{"104":1}}],["快",{"2":{"65":1}}],["有逻辑的组织语言",{"0":{"831":1}}],["有hadoop和couchdb等",{"2":{"769":1}}],["有m多个query日志文件记录",{"2":{"769":1}}],["有最大堆和最小堆",{"2":{"756":1}}],["有10个文件",{"2":{"748":1}}],["有1−yj",{"2":{"635":1}}],["有三种不同用法",{"2":{"702":1}}],["有三种状态",{"2":{"217":1}}],["有很多特征高度相关也不会影响分类器的效果",{"2":{"669":1}}],["有以下特性",{"2":{"668":1}}],["有明显的前期训练过程",{"2":{"651":1}}],["有没有什么好的解决方式",{"0":{"650":1}}],["有这么个观点",{"2":{"622":1}}],["有这个特性是因为泰勒二阶展开",{"2":{"511":1}}],["有关",{"2":{"574":1}}],["有先验的好处就是可以在较小的数据集中有良好的泛化性能",{"2":{"568":1}}],["有时会导致迭代速度过快",{"2":{"544":1}}],["有时根据经验将步长初始化为1",{"2":{"544":1}}],["有时候不一定最好",{"2":{"163":1}}],["有可能是一个局部的最优解",{"2":{"542":1}}],["有可能我们不能走到山脚",{"2":{"542":1}}],["有向图模",{"2":{"525":1}}],["有向图判环",{"0":{"61":1}}],["有人声称一篇文章是用",{"2":{"423":1}}],["有何不同",{"2":{"422":1}}],["有了user特征信息和item特征信息",{"2":{"730":1}}],["有了相似度测量后",{"2":{"730":1}}],["有了强大的生成式大模型",{"2":{"422":1}}],["有了",{"2":{"422":1}}],["有试过其他的方法吗",{"0":{"403":1}}],["有两种模式",{"2":{"798":1}}],["有两种方法进行特征变换",{"2":{"739":1}}],["有两种方法可以计算属性的类条件概率",{"2":{"620":1}}],["有两种方法",{"2":{"390":1}}],["有两个大创新",{"2":{"387":1}}],["有利于大物体和超大物体检测",{"2":{"388":1}}],["有的尝试取得了成功",{"2":{"378":1}}],["有的时候在模型接近分类器的末端使用全局平均池化还可以代替flatten操作",{"2":{"339":1}}],["有助于防止过拟合",{"2":{"513":1}}],["有助于保持模型深层的稳定性",{"2":{"346":1}}],["有助于减缓模型在初始阶段对mini",{"2":{"346":1}}],["有哪些改进",{"2":{"423":1}}],["有哪些优点缺点",{"0":{"385":1}}],["有哪些初始化的方法",{"0":{"323":1}}],["有哪些经典的卷积类型",{"0":{"316":1}}],["有哪些防止过拟合的策略",{"0":{"307":1}}],["有些比较复杂的关系",{"2":{"607":1}}],["有些没有bn的层可能有偏置bias",{"2":{"314":1}}],["有些功能会在不同的层次中重复出现",{"2":{"233":1}}],["有名管道也是半双工的通信方式",{"2":{"293":1}}],["有名管道",{"2":{"293":1}}],["有0",{"2":{"276":2}}],["有一个1g大小的一个文件",{"2":{"749":1}}],["有一个重要的操作步骤",{"2":{"651":1}}],["有一个需要注意的地方",{"2":{"628":1}}],["有一个特殊的软中断是yield调用",{"2":{"301":1}}],["有一个是坏的",{"2":{"270":1}}],["有一苹果两个人抛硬币来决定谁吃这个苹果先抛到正面者吃",{"2":{"280":1}}],["有一条有向边",{"2":{"61":1}}],["有十二个鸡蛋",{"2":{"270":1}}],["有",{"2":{"251":1,"555":1}}],["有什么不足",{"0":{"694":1}}],["有什么不同",{"0":{"109":1}}],["有什么好处",{"0":{"693":1}}],["有什么优点",{"2":{"422":1}}],["有什么作用",{"0":{"368":1}}],["有什么缺陷",{"0":{"368":1}}],["有什么理论解释么",{"2":{"346":1}}],["有什么数据增强的方式",{"0":{"345":1}}],["有什么区别",{"0":{"224":2},"2":{"307":1,"422":1}}],["有正负号�",{"2":{"210":1}}],["有序",{"2":{"756":1}}],["有序接收",{"2":{"242":1}}],["有序性",{"2":{"140":1}}],["有序性和一致�",{"2":{"140":1}}],["有序链表",{"2":{"55":1}}],["有自己的作用域",{"2":{"112":1}}],["有效的阻止过拟合",{"2":{"564":1}}],["有效的括",{"0":{"75":1}}],["有效保留关键权重信息",{"2":{"423":1}}],["有效提升模型中文表现",{"2":{"423":1}}],["有效期不同",{"2":{"244":1}}],["有效字符串需满足",{"2":{"75":1}}],["有环",{"2":{"68":1}}],["抄写",{"2":{"59":1}}],["更重要的是如何在改进现有的技术",{"2":{"769":1}}],["更重要的是更具有",{"2":{"330":1}}],["更为直接",{"2":{"725":1}}],["更容易收敛",{"2":{"700":1}}],["更贴近人类思维",{"2":{"607":1}}],["更加鲁棒",{"2":{"605":1}}],["更加快�",{"2":{"192":1}}],["更具普适性",{"2":{"515":1}}],["更像微信聊天",{"2":{"423":1}}],["更高控制力",{"2":{"423":1}}],["更高效的硬件利用",{"2":{"422":1}}],["更符合预期的语气和风格回答问题",{"2":{"422":1}}],["更有意义",{"2":{"422":1}}],["更有利于小目标的检测",{"2":{"403":1}}],["更有利信息传递到下一个模块进行特征提取",{"2":{"339":1}}],["更适合离线带偏好数据的优化",{"2":{"423":1}}],["更适合复杂对话和文本生成",{"2":{"422":1}}],["更适合生成任务",{"2":{"422":1}}],["更适合处理计算密集型的任务�",{"2":{"109":1}}],["更多尺寸的图片进行训练",{"2":{"402":1}}],["更多的体现在信息的完整传递这个维度上",{"2":{"339":1}}],["更精确的rpn",{"2":{"374":1}}],["更精准些",{"2":{"369":1}}],["更好的基础分类网络",{"2":{"378":1}}],["更好的roi分类方法",{"2":{"374":1}}],["更好的特征网络resnet等",{"2":{"374":1}}],["更好避免数据丢失",{"2":{"193":1}}],["更能把稀疏的特征传递下去",{"2":{"339":1}}],["更合适",{"0":{"339":1}}],["更易调试pytorch代码",{"2":{"334":1}}],["更新视图但不重新请求页面",{"2":{"798":2}}],["更新",{"2":{"796":3}}],["更新的时机是",{"2":{"793":1}}],["更新页面的时候",{"2":{"792":1}}],["更新�",{"2":{"790":1}}],["更新门和重置门",{"2":{"690":1}}],["更新门",{"2":{"690":1,"697":1}}],["更新簇中心坐标为当前簇内节点的坐标平均值",{"2":{"675":1}}],["更新了现在所谓的后验概率",{"2":{"613":1}}],["更新样本权重",{"2":{"431":1}}],["更新训练数据集的权值分布",{"2":{"428":1}}],["更新数据库数�",{"2":{"199":2}}],["更新所有点的距离",{"2":{"58":1}}],["更准确的说�",{"2":{"109":1}}],["更优惠",{"2":{"26":1}}],["图片广告",{"2":{"593":1}}],["图片来源百面机器学习",{"2":{"558":1}}],["图中绿色线是tpr",{"2":{"592":1}}],["图中的顶点代表随机变量",{"2":{"519":1}}],["图模型的引入使得人们在处理复杂概率问题时",{"2":{"521":1}}],["图文对齐的结构化摘要或关键信息片段",{"2":{"423":1}}],["图像描述",{"2":{"423":1}}],["图像或文本的单模态特征",{"2":{"423":1}}],["图像金字塔",{"2":{"402":2}}],["图像模糊",{"2":{"401":1}}],["图像的内插",{"2":{"369":1}}],["图像和标签都进行线性插值",{"2":{"345":1}}],["图结构的创建是静态的",{"2":{"334":1}}],["图结构的创建是动态的",{"2":{"334":1}}],["图的创建及调试不同",{"2":{"334":1}}],["图的表示",{"2":{"103":1}}],["图论算法",{"2":{"106":1}}],["图论算法基础",{"2":{"99":1}}],["图论",{"2":{"99":1}}],["图常用的表示方法有两种",{"2":{"57":1}}],["图",{"0":{"57":1},"1":{"58":1,"59":1,"60":1,"61":1}}],["各存放50亿个url",{"2":{"747":1}}],["各种分类场景",{"2":{"667":1}}],["各种梯度下降法性能比较",{"0":{"546":1}}],["各种排序算法的原理和实现",{"2":{"100":1}}],["各项参数指标不能一步就达到理想状态",{"2":{"544":1}}],["各个特征变量取值是相互独立的",{"2":{"632":1}}],["各个特征变量取值是相互独立",{"2":{"627":1}}],["各个决策树趋于相同",{"2":{"478":1}}],["各个学习器之间相互独立",{"2":{"425":1}}],["各个面出现的概率不同",{"2":{"279":1}}],["各自有什么优缺点",{"2":{"423":1}}],["各有什么特点",{"0":{"412":1}}],["各有什么优势",{"2":{"330":1}}],["各点坐标输入图片大小大小各点坐标输入图片大小",{"2":{"368":1}}],["各握了几次手",{"2":{"268":1}}],["各层之间是独立的",{"2":{"233":1}}],["各并发事务之间数据库是独⽴�",{"2":{"166":1}}],["各取一半",{"2":{"56":1}}],["各大公司",{"2":{"40":1}}],["先把熟词建一棵树",{"2":{"763":1}}],["先把拥塞窗口cwnd",{"2":{"243":1}}],["先无序",{"2":{"651":1}}],["先验概率和后验概率是相对的",{"2":{"613":1}}],["先验概率",{"0":{"613":1},"2":{"613":1}}],["先验就是优化的起跑线",{"2":{"568":1}}],["先验性的认为生男生女的自然概率相同",{"2":{"276":1}}],["先回到标准的模型即没有dropout",{"2":{"564":1}}],["先计算样本量少的节点的样本索引",{"2":{"514":1}}],["先计算长度n",{"2":{"56":1}}],["先从顶到底建立树直到最大深度",{"2":{"507":1}}],["先看一个例子",{"2":{"502":1}}],["先看该特征下划分出的bin容器的个数",{"2":{"470":1}}],["先说",{"2":{"502":1}}],["先使用袋外错误率",{"2":{"462":1}}],["先扔一轮骰子",{"2":{"446":1}}],["先蒸馏基础能力",{"2":{"423":1}}],["先用小型句子嵌入模型生成文本向量",{"2":{"423":1}}],["先用imagenet做预训练",{"2":{"401":1}}],["先对整本小说生成一份结构化摘要",{"2":{"423":1}}],["先思考后回答",{"2":{"422":1}}],["先分成两部分进行排序",{"2":{"769":1}}],["先分割",{"2":{"401":1}}],["先分析天平平衡的情况",{"2":{"270":1}}],["先进行离散化bin",{"2":{"739":1}}],["先进行过滤",{"2":{"470":1}}],["先进行",{"2":{"388":1}}],["先进先出置换算法",{"2":{"299":1}}],["先通过1×1卷积对通道数进行降通道",{"2":{"320":1}}],["先抛者a吃苹果",{"2":{"280":1}}],["先写数据�",{"2":{"199":1}}],["先写日志",{"2":{"173":1}}],["先删�",{"2":{"199":1}}],["先删除缓存",{"0":{"197":1}}],["先更新数据库",{"0":{"196":1,"198":1}}],["先将样本按距离分解成组",{"2":{"651":1}}],["先将数据集写入临时文件",{"2":{"192":1}}],["先将记录写入redo",{"2":{"173":1}}],["先找出学生中年龄18岁的学生",{"2":{"163":1}}],["先查询学生表中姓名为",{"2":{"163":1}}],["先检查该语句是否有权限",{"2":{"163":1}}],["先插入再扩容",{"2":{"118":1}}],["先扩容再插入",{"2":{"118":1}}],["先加低位判断是否有新的进",{"2":{"83":1}}],["先低价买入",{"2":{"24":1}}],["单页路由的",{"2":{"798":1}}],["单项预训练模型",{"2":{"711":1}}],["单变量离散化为n个后",{"2":{"664":1}}],["单次迭代样本数",{"2":{"546":1}}],["单边梯度算法过滤掉梯度小的样本",{"2":{"471":1}}],["单边梯度采样",{"2":{"464":1}}],["单样本像素内容变换",{"2":{"345":1}}],["单样本几何变换",{"2":{"345":1}}],["单个样本",{"2":{"546":1}}],["单个进程具有处理多个",{"2":{"302":1}}],["单个",{"2":{"244":1,"690":1}}],["单个hash槽内元素个数�",{"2":{"120":1}}],["单线�",{"2":{"202":1}}],["单线程异步非阻塞",{"2":{"109":1}}],["单例模式�",{"0":{"141":1,"144":1},"1":{"142":1,"143":1,"144":1}}],["单链表的归并排序",{"2":{"56":1}}],["单链表的插入排序",{"2":{"55":1}}],["单链表归并排序",{"0":{"56":1}}],["单链表插入排序",{"0":{"55":1}}],["单词",{"0":{"749":1}}],["单词可以由按顺序的相邻单元的字母组成",{"2":{"36":1}}],["单词搜索",{"0":{"36":1}}],["单词接龙",{"0":{"35":1}}],["全称",{"2":{"690":2}}],["全样本训练忽视了局部样本的规律",{"2":{"478":1}}],["全连接层的参数量",{"2":{"395":1}}],["全连接层的flops",{"2":{"394":1}}],["全连接层是卷积层的特例",{"2":{"329":1}}],["全连接层是全局连接",{"2":{"329":1}}],["全大写",{"2":{"394":1}}],["全部=2",{"2":{"281":1}}],["全部完成",{"2":{"217":1}}],["全部由",{"2":{"186":1}}],["全局极小值",{"2":{"554":1}}],["全局摘要生成",{"2":{"423":1}}],["全局池化",{"2":{"394":1}}],["全局作用域",{"2":{"214":1}}],["全局变量",{"2":{"52":1,"756":1}}],["全量复制",{"2":{"194":1}}],["全排",{"0":{"29":1}}],["下来我们把线性回归的输出",{"2":{"660":1}}],["下溢问题",{"2":{"619":1}}],["下一步就是把这5000个文件进行归并",{"2":{"749":1}}],["下一层要将上一层的用户打散",{"2":{"572":1}}],["下一个时刻的观测只与其相对应的状态有",{"2":{"527":1}}],["下一个状态的概率分布只与当前状态有",{"2":{"527":1}}],["下图为偏差和方差示意图",{"2":{"558":1}}],["下表简单对比随机梯度下降",{"2":{"546":1}}],["下面给出几种排序算法的简单介绍图",{"2":{"755":1}}],["下面来具体介绍下",{"2":{"603":1}}],["下面介绍能结合两种方法优点的小批量梯度下降法",{"2":{"545":1}}],["下面通过介绍两种梯度下降法的求解思路",{"2":{"545":1}}],["下面分析第一次天平不平衡的情况",{"2":{"270":1}}],["下",{"2":{"473":1}}],["下降最快",{"2":{"515":1}}],["下降",{"2":{"346":1}}],["下采样的过程是一个信息损失的过程",{"2":{"313":1}}],["下采样的方式主要有两种",{"2":{"313":1}}],["下采样的作用是什么",{"0":{"313":1}}],["下采样层有两个作用",{"2":{"313":1}}],["下标",{"2":{"221":1}}],["下标从1开始",{"2":{"52":1}}],["下次使用标记",{"2":{"36":1}}],["阿泽的文章",{"2":{"473":1}}],["阿里实习",{"0":{"383":1}}],["阿里java实习生一面",{"2":{"253":1}}],["阿里",{"2":{"52":1}}],["阿�",{"2":{"44":1}}],["某现在一天广告赚1000w+的新闻app排序基线是lr",{"2":{"667":1}}],["某电商的购物搭配推荐用了大量lr",{"2":{"667":1}}],["某电商搜索排序",{"2":{"667":1}}],["某搜索引擎厂的广告ctr预估基线版是lr",{"2":{"667":1}}],["某个词",{"2":{"618":2}}],["某一步生成不佳时",{"2":{"423":1}}],["某金融公司",{"2":{"51":1}}],["某创业公�",{"2":{"46":1}}],["爱奇艺",{"2":{"51":1}}],["俗称押题",{"2":{"50":1}}],["冒泡排序",{"2":{"755":1}}],["冒泡阶段�",{"2":{"226":1}}],["冒泡",{"2":{"50":1}}],["交互界面",{"2":{"795":1}}],["交互a",{"2":{"756":1}}],["交互式双向语言建模",{"2":{"713":1}}],["交换",{"2":{"756":1}}],["交换a",{"2":{"756":2}}],["交换最后一个位�",{"2":{"48":1}}],["交集为空",{"2":{"572":1}}],["交给强文本模型处理",{"2":{"423":1}}],["交叉轴的中点对齐",{"2":{"782":1}}],["交叉轴的终点对齐",{"2":{"782":1}}],["交叉轴的起点对齐",{"2":{"782":1}}],["交叉验证剪枝",{"2":{"605":1}}],["交叉验证",{"2":{"561":1}}],["交叉编码器需每次对查询和候选项一起编码",{"2":{"423":1}}],["交叉熵",{"2":{"331":1}}],["交叉字符",{"0":{"13":1}}],["交数据的版本数据与数据库表对应记录的当前版本信息进行比对",{"2":{"133":1}}],["超出了模型的上下文限制",{"2":{"423":1}}],["超出训练长度后",{"2":{"422":1}}],["超出范围",{"2":{"23":1}}],["超时都会失效",{"2":{"244":1}}],["超时失效时会话结束",{"2":{"244":1}}],["超时重传",{"2":{"241":1}}],["超详细版本2",{"2":{"235":1}}],["超详细版本1",{"2":{"235":1}}],["超过该时间则自动释放锁",{"2":{"184":1}}],["超过窗口大小",{"2":{"47":1}}],["构成上下文窗口",{"2":{"423":1}}],["构成一个统一的网络",{"2":{"373":1}}],["构建和使用堆",{"2":{"764":1}}],["构建倒排索引",{"2":{"761":1}}],["构建数据索引clipping和overlapping两种",{"2":{"648":1}}],["构建决策树",{"2":{"597":1}}],["构建多个",{"2":{"475":1}}],["构建下一棵树分为两个阶段",{"2":{"449":1}}],["构建文章对",{"2":{"423":1}}],["构建高质量难负例的方法",{"2":{"423":1}}],["构建",{"2":{"423":1}}],["构建向量索引",{"2":{"423":1}}],["构建基础表示模型",{"2":{"422":1}}],["构建一个分类系统",{"2":{"422":1}}],["构建dom树",{"2":{"235":1}}],["构建乘积数组",{"0":{"46":1}}],["构造都是通过虚拟",{"2":{"790":1}}],["构造并求解约束最优化问题",{"2":{"635":2}}],["构造lagrange函数",{"2":{"635":1}}],["构造一个分类能力很强的强分类器",{"2":{"487":1}}],["构造输入",{"2":{"423":1}}],["构造输出回文串",{"2":{"79":1}}],["构造二叉树",{"0":{"90":1},"2":{"90":1}}],["构造图",{"2":{"61":2}}],["构造最小支撑树",{"2":{"22":1}}],["构造辅助数",{"2":{"11":1}}],["二分查找之前也要求数据有",{"2":{"755":1}}],["二分类模型",{"2":{"634":2}}],["二分类损失+smoothl1损失",{"2":{"367":1}}],["二是选定了划分属性",{"2":{"601":1}}],["二是因为距离越长模型参数越多",{"2":{"527":1}}],["二是增大感受野",{"2":{"313":1}}],["二阶信息可以描述梯度变化方向是如何变化的",{"2":{"516":1}}],["二阶信息能够让梯度收敛的更快",{"2":{"516":1}}],["二阶泰勒展开可以近似大量损失函数",{"2":{"513":1}}],["二阶可导",{"2":{"504":1,"511":1}}],["二阶导数是1",{"2":{"470":1}}],["二者都是要训练很多棵决策树",{"2":{"489":1}}],["二者都是bootstrap自助法选取样本",{"2":{"489":1}}],["二面",{"0":{"369":1,"390":2,"397":1}}],["二",{"0":{"363":1},"1":{"364":1,"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1,"377":1,"378":1,"379":1,"380":1,"381":1,"382":1,"383":1,"384":1,"385":1,"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1,"396":1,"397":1,"398":1,"399":1,"400":1,"401":1,"402":1,"403":1,"404":1,"405":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1},"2":{"270":1}}],["二维表结构表示逻辑世界的相对的概念",{"2":{"258":1}}],["二维数组中的查找",{"0":{"45":1}}],["二级索引中保存的",{"2":{"165":1}}],["二级索引需要两次索引查找",{"2":{"165":1}}],["二叉树的最长连续子序列",{"0":{"94":1}}],["二叉树的最大宽度是使用层次遍历",{"2":{"87":1}}],["二叉树的最大高",{"2":{"87":2}}],["二叉树的镜像",{"2":{"91":1}}],["二叉树的对角线遍",{"0":{"89":1}}],["二叉树的z型遍",{"0":{"86":1},"2":{"86":1}}],["二叉树的遍历",{"0":{"85":1}}],["二叉树介绍",{"2":{"84":1}}],["二叉树是面试中最容易被问道的问题",{"2":{"84":1}}],["二叉树",{"0":{"84":1},"1":{"85":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"92":1,"93":1,"94":1,"95":1,"96":1},"2":{"84":1,"754":1,"768":1}}],["二进制串个数",{"0":{"12":1}}],["\\t其中",{"2":{"428":1}}],["\\t写一个缓存刷新页面",{"2":{"190":1}}],["\\t系统上线后",{"2":{"190":1}}],["\\tconsole",{"2":{"112":1}}],["\\tif",{"2":{"82":2}}],["\\tint",{"2":{"43":1,"54":1,"82":4}}],["\\ttnode",{"2":{"82":3}}],["\\twhile",{"2":{"54":1}}],["\\t\\tcnt",{"2":{"82":3}}],["\\t\\t\\tans",{"2":{"82":1}}],["\\t\\t\\tt",{"2":{"82":1}}],["\\t\\t\\tcnt",{"2":{"82":1}}],["\\t\\t\\t",{"2":{"54":1}}],["\\t\\t\\t\\tbreak",{"2":{"54":1}}],["\\t\\t\\t\\tvec",{"2":{"54":1}}],["\\t\\t\\t\\tindex",{"2":{"54":1}}],["\\t\\t\\tif",{"2":{"54":1}}],["\\t\\t\\tq",{"2":{"54":2}}],["\\t\\tfor",{"2":{"54":1}}],["\\t\\tresult",{"2":{"54":1}}],["\\t\\tq",{"2":{"54":1}}],["\\t\\tint",{"2":{"54":2}}],["\\t\\tif",{"2":{"54":2,"82":2}}],["\\t\\t",{"2":{"54":3,"82":2}}],["\\t\\tvec",{"2":{"54":1}}],["\\t\\tvector",{"2":{"54":1}}],["\\t\\tans",{"2":{"43":1}}],["\\tvector",{"2":{"54":1}}],["\\tpriority",{"2":{"54":1}}],["\\treturn",{"2":{"43":1,"54":1,"82":1}}],["\\t",{"2":{"43":2,"54":3,"82":5,"220":17}}],["\\tfor",{"2":{"43":1,"54":2,"82":3}}],["^t$$",{"2":{"730":1}}],["^4",{"2":{"275":1,"735":1}}],["^=",{"2":{"43":2}}],["^",{"2":{"43":5,"496":3,"536":1,"635":21,"730":2,"735":2}}],["落单的数",{"0":{"43":1}}],["京�",{"2":{"42":1}}],["请介绍一个你最有成就感的项�",{"0":{"825":1}}],["请介绍一下faster",{"0":{"365":1}}],["请最多使",{"2":{"763":1}}],["请将所有的女性放到男性的前面",{"2":{"757":1}}],["请描述下协同过滤的优缺点",{"2":{"731":1}}],["请谈谈你对协同过滤中特征学习的理解",{"2":{"731":1}}],["请思",{"2":{"497":1}}],["请解释为什么",{"0":{"461":1}}],["请比较以下三种方案在医疗领域文本分类任务上的优缺点",{"2":{"423":1}}],["请仅使用以下词汇表中的单词作答",{"2":{"423":1}}],["请仅输出以下",{"2":{"422":1}}],["请考虑多种可能情况",{"2":{"422":1}}],["请验证你的答案是否与前提一致",{"2":{"422":1}}],["请一步步思考再作答",{"2":{"422":1}}],["请同时利用有标签和无标签的数据",{"2":{"422":1}}],["请叙述一下yolov3中k",{"0":{"381":1}}],["请简单介绍一下自�",{"0":{"824":1}}],["请简单说明其中two",{"0":{"367":1}}],["请简述一下虚�",{"0":{"790":1}}],["请简述一下",{"0":{"782":1}}],["请简述一�",{"0":{"114":1,"791":1,"792":1,"796":1,"797":1,"798":1}}],["请简要叙述一下",{"0":{"366":1}}],["请问用天平最少称几次",{"2":{"270":1}}],["请问",{"2":{"269":1}}],["请求中",{"2":{"798":1}}],["请求与保持条件",{"2":{"296":1}}],["请求报文",{"2":{"246":2}}],["请求缓存刚好失效",{"2":{"198":1}}],["请求a将查到的旧值写入缓�",{"2":{"198":1}}],["请求a将新值写入数据库",{"2":{"197":1}}],["请求a查询数据库",{"2":{"198":1}}],["请求a进行写操作",{"2":{"197":1}}],["请求b删除缓存",{"2":{"198":1}}],["请求b将新值写入数据库",{"2":{"198":1}}],["请求b将旧值写入缓�",{"2":{"197":1}}],["请求b去数据库查询得到旧�",{"2":{"197":1}}],["请求b查询发现缓存不存�",{"2":{"197":1}}],["请注意",{"2":{"78":1}}],["请你按最早出现的顺序写出所有不在熟词表中的生词",{"2":{"763":1}}],["请你写出一个函数",{"2":{"80":1}}],["请你找出其中不含有重复字符",{"2":{"78":1}}],["请你判断一个",{"2":{"61":1}}],["请判断一个链表是否为回文链表",{"2":{"64":1}}],["请找出这个数字�",{"2":{"42":1}}],["请大家自行补上哈夫曼树",{"2":{"21":1}}],["主动发现问题和机会",{"2":{"821":1}}],["主动�",{"2":{"821":1}}],["主动进行",{"2":{"423":1}}],["主轴为垂直方向",{"2":{"782":2}}],["主轴为水平方向",{"2":{"782":2}}],["主机",{"2":{"769":1}}],["主题是评分矩阵潜在特征",{"2":{"730":1}}],["主题下的所有文档的集合",{"2":{"422":1}}],["主线剧情",{"2":{"423":1}}],["主控调度器",{"2":{"423":1}}],["主键约束",{"2":{"257":1}}],["主节点会将这�",{"2":{"194":1}}],["主进程只�",{"2":{"192":1}}],["主�",{"2":{"188":1}}],["主从架构的主从异步复制导�",{"2":{"185":1}}],["主从复制还是哨兵和集群能够实施的基础",{"2":{"194":1}}],["主从复制实现了数据的热备份",{"2":{"194":1}}],["主从复制原理",{"0":{"194":1}}],["主从复制",{"2":{"172":1,"194":1}}],["主要目的是将相同的key的数据映射到同一个reduce工作的节点",{"2":{"769":1}}],["主要目的是将一个大问题分成多个小问题进行求解",{"2":{"769":1}}],["主要用于大规模数据集合的并行计算",{"2":{"769":1}}],["主要用于线性不可分的情形",{"2":{"640":1}}],["主要用于线性可分的情形",{"2":{"640":1}}],["主要面向的是如何在海量数据情况下使用排序方法",{"2":{"755":1}}],["主要体现的是经过前n颗树",{"2":{"741":1}}],["主要将",{"2":{"690":1}}],["主要通过对原始的",{"2":{"690":1}}],["主要通过以下几种方式提升推理速度",{"2":{"422":1}}],["主要需要解决的是两个问题",{"2":{"601":1}}],["主要看以下两个方面",{"2":{"575":1}}],["主要因为是memm只在局部做归一化",{"2":{"520":1}}],["主要为例合理地处理类别型特",{"2":{"444":1}}],["主要优化推理阶段",{"2":{"422":1}}],["主要分为三种",{"2":{"393":1}}],["主要针对",{"2":{"389":1}}],["主要包括深度学习相关的特征抽取模型",{"2":{"688":1}}],["主要包括",{"2":{"386":1}}],["主要的特点是可以把更新流程拆分成一个一个的小的单元进行更新",{"2":{"792":1}}],["主要的有三个",{"2":{"574":1}}],["主要的原因是对于每个特征",{"2":{"495":1}}],["主要的不同的是顺序不同",{"2":{"439":1}}],["主要的参考文献",{"0":{"358":1}}],["主要的方式就是接收方返回的",{"2":{"242":1}}],["主要作为进程间以及同一进程内不同线程之间的同步手段",{"2":{"293":1}}],["主要是为了削弱每棵树的影响",{"2":{"513":1}}],["主要是为了寻找一种时间和空间的平衡",{"2":{"120":1}}],["主要是指非关系型",{"2":{"258":1}}],["主要存储的是逻辑日志",{"2":{"174":1}}],["主要有两种方法定义k",{"2":{"677":1}}],["主要有两个原因",{"2":{"367":1}}],["主要有两个作用",{"2":{"174":1}}],["主要有三个原因",{"2":{"423":1}}],["主要有三大类",{"2":{"308":1}}],["主要有以下三项",{"2":{"136":1}}],["主要这个时",{"2":{"92":1}}],["主要原则数组可以随机读取",{"2":{"39":1}}],["主元�",{"0":{"42":1}}],["去学习分类器",{"2":{"641":1,"672":1}}],["去掉了全连接层",{"2":{"378":1}}],["去掉前导0",{"2":{"83":1}}],["去掉重复项后为1",{"2":{"66":1}}],["去掉其重复项",{"2":{"66":1}}],["去掉三个�",{"2":{"42":1}}],["去除无关或重复内容",{"2":{"423":1}}],["去除问题数据",{"2":{"307":1}}],["去除",{"2":{"40":1}}],["去消耗其他的猫",{"2":{"27":1}}],["要诚实",{"2":{"840":1}}],["要定义或修改的属性的名称�",{"2":{"796":1}}],["要在其上定义属性的对象�",{"2":{"796":1}}],["要在a的范围之内",{"2":{"756":1}}],["要悠久的多",{"2":{"690":1}}],["要注意空簇可能导致的程序bug",{"2":{"685":1}}],["要优化的参数",{"2":{"657":1}}],["要优于链表�",{"2":{"120":2}}],["要给它分类",{"2":{"651":1}}],["要引入核函数",{"0":{"638":1}}],["要考虑独占域和分享域问题",{"2":{"572":1}}],["要求得到top",{"2":{"769":1}}],["要求找出中位数",{"2":{"763":1}}],["要求你按照query的频度排序",{"2":{"748":1}}],["要求数据具有一定的稠密度",{"2":{"730":1}}],["要求映射到高维空间后要近似线性可分",{"2":{"634":1}}],["要求模型参数估计的越精确",{"2":{"521":1}}],["要求与web服务器建立ssl连接",{"2":{"247":1}}],["要让样本的损失尽量变得更小",{"2":{"493":1}}],["要让模型快速忘记某个特定知识",{"2":{"422":1}}],["要让输入的分布尽可能地接近模型预训练的分布",{"2":{"401":1}}],["要更常用",{"0":{"339":1}}],["要追求一个原则",{"2":{"338":1}}],["要好一些",{"2":{"244":1}}],["要么学习使用tfdbg调试器",{"2":{"334":1}}],["要么不执行",{"2":{"255":1}}],["要么执行",{"2":{"255":1}}],["要么全不执行",{"2":{"166":1}}],["要么是事务自身插入或者修改过的�",{"2":{"162":1}}],["要么是在事务开始前已经存在的",{"2":{"162":1}}],["要么随机唤醒一个线程要么唤醒全部线�",{"2":{"136":1}}],["要寻找一种时间和空间的平衡",{"2":{"120":1}}],["要时刻注意一个数组中有两列数",{"2":{"39":1}}],["要记录老字符",{"2":{"35":1}}],["�2",{"2":{"422":1}}],["�",{"0":{"48":1,"109":1,"136":1,"146":1,"157":1,"161":1,"201":1,"213":2,"217":1,"218":3,"220":1,"221":1,"224":2},"1":{"137":1,"138":1,"139":1},"2":{"39":1,"40":1,"43":1,"46":1,"109":3,"110":8,"121":2,"130":1,"131":1,"133":1,"134":2,"136":1,"137":1,"139":2,"140":7,"142":1,"162":1,"163":1,"185":2,"186":2,"189":1,"190":3,"192":2,"202":1,"210":1,"211":3,"213":3,"217":1,"218":3,"220":1,"224":2,"226":2,"228":1,"422":1,"776":3,"792":5,"796":1,"798":1,"800":2}}],["栈等",{"2":{"39":1}}],["队列",{"2":{"39":1}}],["第六章",{"2":{"764":1}}],["第次迭代的代价函数里包含了前面次迭代的预测值",{"2":{"513":1}}],["第t次迭代的代价函数里包含了前面t",{"2":{"497":2,"505":1}}],["第个i基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第i个特征值",{"2":{"458":1}}],["第四",{"2":{"446":1}}],["第四次挥手",{"2":{"239":1}}],["第8章",{"2":{"442":1}}],["第k个基学习器根据前k",{"2":{"435":1}}],["第k�",{"0":{"48":1}}],["第三层是softmax输出层",{"2":{"718":1}}],["第三类输入为",{"2":{"472":1}}],["第三棵树针对样本",{"2":{"472":1}}],["第三",{"2":{"446":1}}],["第三范式建立第一第二范式上",{"2":{"257":1}}],["第三范式",{"2":{"257":1}}],["第三次用天平",{"2":{"270":3}}],["第三次挥手",{"2":{"239":1}}],["第三次握手",{"2":{"237":1}}],["第三种方案",{"2":{"222":1}}],["第一行在下方",{"2":{"782":1}}],["第一行在上方",{"2":{"782":1}}],["第一层是映射层",{"2":{"718":1}}],["第一节中介绍的算法",{"2":{"651":1}}],["第一种方法",{"2":{"620":1}}],["第一种方案",{"2":{"222":1}}],["第一类参数",{"2":{"507":1}}],["第一类输入为",{"2":{"472":1}}],["第一棵树包含3个叶节点",{"2":{"739":1}}],["第一棵树针对样本",{"2":{"472":1}}],["第一棵树的一个叶子节点内所有样本的label的均值就是这个棵树的预测值",{"2":{"472":1}}],["第一部分",{"2":{"394":1,"395":1}}],["第一范式",{"2":{"257":1}}],["第一次",{"2":{"270":1,"274":1,"280":1}}],["第一次挥手",{"2":{"239":1}}],["第一次握手",{"2":{"237":1}}],["第一次遍历哈希表",{"2":{"82":1}}],["第一个词元标签复制到所有拆分词元",{"2":{"423":1}}],["第一个函数执行结束后",{"2":{"217":1}}],["第一个完成或失败后调用方�",{"2":{"217":1}}],["第一步",{"2":{"274":1}}],["第一步写数据库成功",{"2":{"198":1}}],["第一步建立最大堆",{"2":{"52":1}}],["第一步暴力解法",{"2":{"39":1}}],["第二棵树包含2个叶节点",{"2":{"739":1}}],["第二棵树输入针对样本",{"2":{"472":1}}],["第二层是一个激活函数为tanh的隐含层",{"2":{"718":1}}],["第二类参数",{"2":{"507":1}}],["第二类输入为",{"2":{"472":1}}],["第二部分",{"2":{"394":1,"395":1}}],["第二种方法",{"2":{"390":1,"620":1}}],["第二种方案",{"2":{"222":1}}],["第二",{"2":{"357":1,"446":1}}],["第二范式建立在第一范式上",{"2":{"257":1}}],["第二范式",{"2":{"257":1}}],["第二次机会的时候要将这个页面从链表头移到链表尾",{"2":{"299":1}}],["第二次机会算法",{"2":{"299":1}}],["第二次是y",{"2":{"279":1}}],["第二次",{"2":{"274":1,"280":1}}],["第二次右端重可知",{"2":{"270":1}}],["第二次用天平",{"2":{"270":1}}],["第二次挥手",{"2":{"239":1}}],["第二次握手",{"2":{"237":1}}],["第二次遍历数组",{"2":{"82":1}}],["第二步",{"2":{"274":1}}],["第二步删除缓存失败",{"2":{"198":1}}],["第二步是否可以排序",{"2":{"39":1}}],["第二个指针从表头与第一个指针同时向后移动",{"2":{"72":1}}],["都包含这样的过程",{"2":{"651":1}}],["都有",{"2":{"634":1}}],["都有f",{"2":{"554":1}}],["都要用到训练集所有的数据",{"2":{"545":1}}],["都存在有效率的算法可供演算",{"2":{"519":1}}],["都需要重新读取整个已有上下文作为输入",{"2":{"422":1}}],["都需要掌握扎实的算法基础",{"2":{"97":1}}],["都会被编译到你指定的输出路径的文件夹中",{"2":{"800":1}}],["都会重新构建整个",{"2":{"790":1}}],["都会求解当前位置的梯度",{"2":{"542":1}}],["都会与序列中其他",{"2":{"422":1}}],["都会回收它的内�",{"2":{"122":1}}],["都能在一次计算中捕捉到",{"2":{"422":1}}],["都进行各自的",{"2":{"388":1}}],["都映射成大小固定",{"2":{"368":1}}],["都整合在了一个网络中",{"2":{"365":1}}],["都再次计算写入缓存的值",{"2":{"196":1}}],["都是将连续的特征离散化",{"2":{"604":1}}],["都是由多棵树组成",{"2":{"501":1}}],["都是基于单棵树计算每个特征的重要性",{"2":{"462":1}}],["都是前项分布加法模型的一种",{"2":{"436":1}}],["都是有一个问题",{"2":{"279":1}}],["都是0",{"2":{"276":1}}],["都是一种引用",{"2":{"210":1}}],["都是私有的",{"2":{"112":1}}],["都是先根据条件进行排序",{"2":{"17":1}}],["都可以归类到梯度提升决策树算法系列",{"2":{"497":1}}],["都可以简单地看做是只需要对每个值算一次",{"2":{"394":1}}],["都可以使用这个代码进行变",{"2":{"86":1}}],["都可以解决",{"2":{"50":1}}],["都不是直观看到的那样",{"2":{"39":1}}],["变革推动",{"2":{"819":1,"839":1}}],["变得更加美观",{"2":{"798":1}}],["变点的选择",{"0":{"533":1}}],["变化较明显",{"2":{"306":1}}],["变化下一",{"2":{"35":1}}],["变量",{"2":{"211":3}}],["变成了",{"2":{"317":1}}],["变成",{"2":{"41":1}}],["变换但是还想要开",{"2":{"787":1}}],["变换",{"2":{"787":1}}],["变换的单词是否在字典",{"2":{"35":1}}],["变换过程中的中间单词必须在字典中出现",{"2":{"35":1}}],["变换规则如下",{"2":{"35":1}}],["进入入口起点后",{"2":{"800":1}}],["进入环境",{"2":{"110":1}}],["进一步引入非线性",{"2":{"664":1}}],["进一步压",{"2":{"502":1}}],["进一步提高效",{"2":{"497":1}}],["进一步提高计算效率",{"2":{"468":1}}],["进一步在决策树的训练过程中引入了随机属性选择",{"2":{"492":1}}],["进一步加深了网络结构",{"2":{"378":1}}],["进而推广到非线性分类问题",{"2":{"637":1}}],["进而计算后验概率",{"2":{"632":1}}],["进而求出联合分布概",{"2":{"627":1}}],["进而减轻梯度估计的偏差",{"2":{"448":1}}],["进而导致模型产生过拟合的问题",{"2":{"448":1}}],["进而解决预测偏移的问题",{"2":{"445":1}}],["进而提高算法的准确性和泛化能力",{"2":{"444":1}}],["进程或许会被挂起直到i",{"2":{"301":1}}],["进程可在任何时刻提出资源申请",{"2":{"297":1}}],["进程已获得的资源",{"2":{"296":1}}],["进程号为1",{"2":{"294":1}}],["进程的亲缘关系通常是指父子进程关系",{"2":{"293":1}}],["进程的状态",{"0":{"290":1},"1":{"291":1,"292":1}}],["进程间通信方式",{"0":{"293":1}}],["进程完成任务到达正常结束点",{"2":{"292":1}}],["进程是系统进行资源分配和调度的基本单位",{"2":{"288":1}}],["进程和线程的区别",{"0":{"288":1}}],["进程与线程",{"2":{"262":1}}],["进阶路径",{"2":{"106":1}}],["进阶",{"2":{"40":1,"81":1}}],["进",{"2":{"35":1}}],["进行改造",{"2":{"793":1}}],["进行开发时所有的",{"2":{"790":1}}],["进行排序",{"2":{"763":1}}],["进行分开使用位图",{"2":{"763":1}}],["进行划分小文件的方法",{"2":{"751":1}}],["进行处理后作为输入特征",{"2":{"734":1}}],["进行推荐",{"2":{"727":1}}],["进行优化",{"2":{"725":1}}],["进行索引和查找时",{"2":{"651":1}}],["进行迭代",{"2":{"555":1}}],["进行建模",{"2":{"521":1}}],["进行剪枝",{"2":{"507":1}}],["进行多轮迭代",{"2":{"428":1}}],["进行混合训练",{"2":{"423":1}}],["进行交互",{"2":{"422":1}}],["进行",{"2":{"366":1,"388":4,"497":1,"751":1,"790":1}}],["进行计算",{"2":{"274":1}}],["进行中",{"2":{"217":1}}],["进行删除缓存操作",{"2":{"199":1}}],["进行锁释放",{"2":{"184":1}}],["进行回滚",{"2":{"174":1}}],["进行权限校验",{"2":{"163":1}}],["进行管理",{"2":{"110":1}}],["进行比较的开销小很多�",{"2":{"790":1}}],["进行比较的�",{"2":{"134":1}}],["进行比较即可",{"2":{"92":1}}],["进行比较",{"2":{"92":1}}],["进行遍历",{"2":{"29":1}}],["进行dfs搜索",{"2":{"26":1}}],["遍历从递归改为循环�",{"2":{"792":1}}],["遍历文件b",{"2":{"747":1}}],["遍历文件a",{"2":{"747":1}}],["遍历两类树到叶子节点",{"2":{"741":1}}],["遍历每一个候选区域",{"2":{"369":1}}],["遍历数组",{"0":{"221":1}}],["遍历",{"2":{"85":1}}],["遍历abba型的回文串",{"2":{"79":1}}],["遍历tmp的所有的字符",{"2":{"35":1}}],["遍历所有以p开",{"2":{"31":1}}],["遍历所有可能的",{"2":{"31":1}}],["对技术的兴趣和追�",{"0":{"838":1}}],["对工作结果负责的态度",{"2":{"821":1}}],["对它们进行处理�",{"2":{"800":1}}],["对服务器端完全无用",{"2":{"798":1}}],["对属性设置一�",{"2":{"796":1}}],["对不同的属性操作",{"2":{"786":1}}],["对不同的树的训练结果也没有做进一步的优化提升",{"2":{"480":1}}],["对的格式",{"2":{"769":1}}],["对r1",{"2":{"748":1}}],["对r树了解很少",{"2":{"648":1}}],["对原始特征进行映射",{"2":{"741":1}}],["对原始变量梯度为0",{"2":{"635":1}}],["对余下的物品进行评分与相似度加权",{"2":{"730":1}}],["对负样本进行随机采样",{"2":{"721":1}}],["对负样本区分能力较弱",{"2":{"423":1}}],["对上文词的词向量进行了拼接",{"2":{"718":1}}],["对上式变形",{"2":{"547":1}}],["对文本进行特征提取",{"2":{"689":1}}],["对文章文本计算困惑度",{"2":{"423":1}}],["对奇异点敏感",{"2":{"676":1}}],["对模型中自变量多重共线性较为敏感",{"2":{"663":1}}],["对模型其他功能干扰更小",{"2":{"422":1}}],["对离群点不敏感",{"2":{"649":1}}],["对未知实例的泛化能力最强",{"2":{"636":1}}],["对未来的预估",{"0":{"534":1}}],["对偶问题往往更易求解",{"2":{"637":1}}],["对偶互补松弛",{"2":{"635":1}}],["对偶算法",{"2":{"635":1}}],["对输入数据的表达形式很敏",{"2":{"626":1}}],["对输入的特征图进行压缩",{"2":{"339":1}}],["对小规模的数据表现很好",{"2":{"626":1}}],["对小目标检测的改进可以从下面几个方面考虑",{"2":{"385":1}}],["对缺失值不敏感",{"2":{"630":1}}],["对缺失值的处理方式如下",{"2":{"508":1}}],["对缺失值的处理",{"2":{"497":1}}],["对缺失数据不太敏感",{"2":{"626":1}}],["对乘积结果取自然对数",{"2":{"619":1}}],["对部分未知的状态用主观概率估计",{"2":{"615":1}}],["对部分特征缺失不敏感",{"2":{"485":1}}],["对树模型的结构不造成影响",{"2":{"608":1}}],["对树中的每个非叶子结点",{"2":{"504":1}}],["对大数据量的处理性能较好",{"2":{"607":1}}],["对相邻的特征取值ai与ai+1",{"2":{"603":1}}],["对相似度分数应用softmax",{"2":{"422":1}}],["对a的取值进行从小到大排序得到",{"2":{"603":1}}],["对没有缺失特征值a的数据集d~",{"2":{"601":1}}],["对这棵树进行先序遍历即可",{"2":{"763":1}}],["对这个文件排序",{"2":{"763":1}}],["对这个文件进行排序",{"2":{"763":1}}],["对这个问题进行了校正",{"2":{"599":1}}],["对这三个量使用拉普拉斯平滑的计算方法如下",{"2":{"618":1}}],["对这些相似文本自动赋予伪标签",{"2":{"423":1}}],["对这些default",{"2":{"385":1}}],["对取值多的特征加上的惩罚",{"2":{"599":1}}],["对收",{"2":{"590":1}}],["对目标函数在x0",{"2":{"555":1}}],["对其进行比较",{"2":{"545":1}}],["对其他文件不可见",{"2":{"112":1}}],["对梯度下降法调优主要体现在以下几个方面",{"2":{"544":1}}],["对比预排序的exact",{"2":{"514":1}}],["对比学习",{"2":{"423":1}}],["对结果影响不大",{"2":{"514":1}}],["对损失函数进行了二阶泰勒展开",{"2":{"513":1}}],["对损失函数做了二阶泰勒展开",{"2":{"504":1}}],["对特征本身来说的话",{"2":{"669":1}}],["对特征排序后仅选择常数个候选分裂位置作为候选分裂点",{"2":{"510":1}}],["对特征值进行排",{"2":{"510":1}}],["对寻找最佳分割点的影响不是很大",{"2":{"508":1}}],["对异常值不敏感",{"2":{"501":1,"629":1}}],["对异常样本比较敏感",{"2":{"441":1}}],["对公",{"2":{"497":1}}],["对样本分布较为敏感的分类器更适用于bagging",{"2":{"461":1}}],["对训练集进行第t次随机采样",{"2":{"455":1,"475":1}}],["对α求导并等于0",{"2":{"430":1}}],["对话或任务执行数据",{"2":{"423":1}}],["对话生成等任务",{"2":{"423":1}}],["对所有的错误的节点重新执行",{"2":{"770":1}}],["对所有串建立字典树",{"2":{"763":1}}],["对所有类都是相同的",{"2":{"631":1}}],["对所有基模型预测的结果进行综合产生最终的预测结果",{"2":{"455":1}}],["对所有照片进行去重",{"2":{"423":1}}],["对所有预测框的置信度降序排序",{"2":{"397":1}}],["对齐语义空间",{"2":{"423":1}}],["对用户输入的话进行改写",{"2":{"423":1}}],["对用户是透明的",{"2":{"300":1}}],["对早期对话进行摘要压缩",{"2":{"423":1}}],["对重复关键词做过滤或降权处理",{"2":{"422":1}}],["对参数引入拉普拉斯先验等价于",{"2":{"568":1}}],["对参数引入高斯正态先验分布相当于l2正则化",{"2":{"568":1}}],["对参数",{"2":{"422":1}}],["对初始质心敏感",{"2":{"422":1}}],["对位置敏感",{"2":{"422":1}}],["对全局信息进行加权聚合",{"2":{"422":1}}],["对硬件内存要求比较低",{"2":{"394":1}}],["对",{"2":{"388":1,"619":1,"716":1,"729":1,"748":1,"769":1,"786":1}}],["对代码运行流程描述为",{"2":{"388":1}}],["对网络结构的设计进行了改进",{"2":{"378":1}}],["对每个桶分别进行排序",{"2":{"758":1}}],["对每个小文件",{"2":{"749":1}}],["对每个词x",{"2":{"749":1}}],["对每个词元单独标注",{"2":{"423":1}}],["对每个url求取",{"2":{"747":1}}],["对每个参数",{"2":{"545":1}}],["对每个线程分配一个连续的buffer",{"2":{"506":1}}],["对每个类别训练m个分类器",{"2":{"497":1}}],["对每个子体使用结构化提示+嵌入指令压缩技术",{"2":{"423":1}}],["对每个sections进行max",{"2":{"368":1}}],["对每一个桶分别进行排序",{"2":{"758":1}}],["对每一个符合条件的bin容器进行公式计算",{"2":{"470":1}}],["对每一个单元边界进行整数化",{"2":{"368":1}}],["对每一个层以此处理",{"2":{"35":1}}],["对提取的特征进行检测分类",{"2":{"361":1}}],["对可能包含物体的区域进行特征提取",{"2":{"361":1}}],["对学习率进行调节",{"2":{"354":1}}],["对已获得的资源保持不放",{"2":{"296":1}}],["对应值是包含该属性的文档的id或者文化的位置",{"2":{"761":1}}],["对应",{"2":{"759":1}}],["对应设置为1",{"2":{"759":1}}],["对应为1的位置表示这个数字存在",{"2":{"759":1}}],["对应权重调节为2",{"2":{"601":1}}],["对应于用平行于坐标轴的平面对空间的划分",{"2":{"597":1}}],["对应于进程被创建时的状态",{"2":{"292":1}}],["对应通道的特征图语义类似",{"2":{"392":1}}],["对应1",{"2":{"279":1}}],["对应0",{"2":{"279":1}}],["对应的集合中可以保留出现的次数等信息",{"2":{"761":1}}],["对应的样",{"2":{"635":1}}],["对应的样时",{"2":{"635":1}}],["对应的长度分别是x",{"2":{"274":1}}],["对应的顶点",{"2":{"61":1}}],["对nosql",{"2":{"258":1}}],["对数值比较敏感",{"2":{"730":1}}],["对数似然函数最大化得到似然函数的代数表达式为",{"2":{"661":1}}],["对数据没有假设",{"2":{"649":1}}],["对数据的训练快",{"2":{"626":1}}],["对数据的改变就是永久的",{"2":{"255":1}}],["对数据做缩放和变换",{"2":{"354":1}}],["对数组每一项运行一次某函数",{"2":{"220":5}}],["对称树是平衡的",{"2":{"450":1}}],["对称加密具有更高的加解密速度",{"2":{"252":1}}],["对称加密算法种类及其他相关信息返回客户端",{"2":{"252":1}}],["对称加密算法",{"2":{"252":1}}],["对称加密和非对称加密在https的应用",{"0":{"252":1}}],["对称二叉",{"0":{"91":1}}],["对外点更不敏感",{"2":{"372":1}}],["对外面函数的变量进行修改�",{"2":{"215":1}}],["对外提供的读写服务",{"2":{"192":1}}],["对内存很友好",{"2":{"201":1}}],["对业务线代码造成大量的侵入",{"2":{"199":1}}],["对写�",{"2":{"189":1}}],["对某�",{"2":{"185":1}}],["对同行记录",{"2":{"170":1}}],["对此版本号加一",{"2":{"133":1}}],["对象�",{"2":{"796":1}}],["对象模型",{"2":{"256":1}}],["对象中的变量将不会丢失",{"2":{"244":1}}],["对象中如果既有基本类型",{"2":{"223":1}}],["对象中如果均为基本类�",{"2":{"223":1}}],["对象存储特定用户会话所需的属性及配置信息",{"2":{"244":1}}],["对象上注册事件名称�",{"2":{"226":1}}],["对象的区别",{"0":{"221":1}}],["对象的方法�",{"2":{"213":1}}],["对象罢了�",{"2":{"218":1}}],["对象提供了如下四种方法",{"2":{"217":1}}],["对象代表一个异步操作",{"2":{"217":1}}],["对象调用",{"2":{"213":1}}],["对象应用",{"2":{"213":1}}],["对象",{"2":{"210":1,"218":2}}],["对象只有在同步块或同步方法中才能调用",{"2":{"139":1}}],["对象来完成",{"2":{"139":1}}],["对象可以同时绑定对个对象",{"2":{"136":1}}],["对象晋升的条件主要有两个�",{"2":{"110":1}}],["对象最开始都会先被分配到新生代",{"2":{"110":1}}],["对一个有向无环图",{"2":{"60":1}}],["对于流畅度问题",{"2":{"792":1}}],["对于那些没有并行计算和分布式处理经验的程序员",{"2":{"769":1}}],["对于那些需要花费一些时间去处理的进程",{"2":{"301":1}}],["对于想用使用mapreduce的程序员来说",{"2":{"769":1}}],["对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数",{"2":{"763":1}}],["对于两路输入来说",{"2":{"392":1}}],["对于top",{"2":{"756":1}}],["对于任意的节点",{"2":{"756":1}}],["对于任意的α",{"2":{"430":1}}],["对于曝光充分训练样本充足的广告",{"2":{"741":1}}],["对于离散特征",{"2":{"739":1}}],["对于离散值可能会有多个划分阈值",{"2":{"470":1}}],["对于bin边界的学习非常重要",{"2":{"739":1}}],["对于bin容器较多的情况",{"2":{"470":1}}],["对于我们需要预测的样本",{"2":{"721":1}}],["对于sigmoid函数",{"2":{"668":1}}],["对于sell",{"2":{"26":1}}],["对于线性可分的数据集来说",{"2":{"642":1}}],["对于后来的soft",{"2":{"634":1}}],["对于贝叶斯优化算法",{"2":{"628":1}}],["对于文本相关的多分类实时预测",{"2":{"625":1}}],["对于朴素贝叶斯了",{"2":{"622":1}}],["对于部分数据预测效果不好",{"2":{"622":1}}],["对于复杂模型",{"2":{"622":1}}],["对于复合索引",{"2":{"168":1}}],["对于分类任务来说",{"2":{"617":1}}],["对于分辨率很低的小目标",{"2":{"403":1}}],["对于异常点的容错能力好",{"2":{"607":1}}],["对于决策树进行约束",{"2":{"605":1}}],["对于在该属性上缺失特征的样本的处理",{"2":{"601":1}}],["对于二分类问题",{"2":{"591":1}}],["对于二分类问",{"2":{"586":1}}],["对于共享域",{"2":{"572":1}}],["对于可行解x∗",{"2":{"554":1}}],["对于总数为m个样本的数据",{"2":{"545":1}}],["对于预测的数据模型使用poisson分布找到新增的变点",{"2":{"534":1}}],["对于已知的时间序列",{"2":{"534":1}}],["对于要处理的一段文本",{"2":{"527":1}}],["对于概率图模型",{"2":{"521":1}}],["对于马尔科夫随机场",{"2":{"521":1}}],["对于上面这种case",{"2":{"502":1}}],["对于上一棵树分错的样本",{"2":{"489":1}}],["对于类别特征的处理",{"2":{"497":1}}],["对于类别型特征的处理需要大量的内存和时间",{"2":{"451":1}}],["对于特征的值有缺失的样本",{"2":{"497":1,"513":1}}],["对于多分类任务",{"2":{"497":1}}],["对于大数据时代的大样本训练速度有优势",{"2":{"485":1}}],["对于随机森林中的每一颗决策树",{"2":{"483":1}}],["对于模型的泛化能力是有害的",{"2":{"478":1}}],["对于连续特征",{"2":{"470":1,"739":1}}],["对于",{"2":{"455":1,"475":1,"575":1,"785":1}}],["对于小红书和知乎两种类型的网站",{"2":{"423":1}}],["对于小物体",{"2":{"378":1}}],["对于指定的词表",{"2":{"422":1}}],["对于第二类问题",{"2":{"403":1}}],["对于第i个bounding",{"2":{"381":1}}],["对于数据中的类别特征",{"2":{"497":1}}],["对于数据量较小的情形可以使用小型的数据类型来保存训练数据",{"2":{"497":1}}],["对于数据集中含有小目标图片较少的情况",{"2":{"403":1}}],["对于数组",{"2":{"221":1}}],["对于检测结果来说很重要",{"2":{"401":1}}],["对于检测图片中大目标物体时",{"2":{"369":1}}],["对于缩放后坐标不能刚好为整数的情况",{"2":{"368":1}}],["对于每个类yi",{"2":{"620":1}}],["对于每个锚点",{"2":{"367":1}}],["对于每一个特征域",{"2":{"734":1}}],["对于每一个样本单独训练一个模型",{"2":{"447":1}}],["对于每一天",{"2":{"26":1}}],["对于不平衡的类别",{"2":{"336":1}}],["对于某些设备",{"2":{"301":1}}],["对于单处理机系统",{"2":{"291":1}}],["对于一批文档",{"2":{"761":1}}],["对于一般数据",{"2":{"640":1}}],["对于一颗树",{"2":{"462":1}}],["对于一个样本",{"2":{"739":1}}],["对于一个固定词表",{"2":{"422":1}}],["对于一个完整的https请求过程",{"2":{"252":1}}],["对于一道判断题",{"2":{"282":1}}],["对于对象",{"2":{"221":1}}],["对于同一份数据",{"2":{"193":1}}],["对于有等值查询的列和范围查询的列",{"2":{"168":1}}],["对于innodb",{"2":{"165":1}}],["对于边数相对顶点较少的图",{"2":{"57":1}}],["对于其他的猫",{"2":{"27":1}}],["utf",{"2":{"796":1}}],["util",{"2":{"82":1,"133":1,"136":1,"139":1}}],["ui",{"2":{"792":2}}],["ul>�",{"2":{"774":1}}],["u012289441",{"2":{"753":1}}],["u014297722",{"2":{"743":1}}],["u010352603",{"2":{"743":1}}],["u010398493",{"2":{"499":1}}],["u010665216",{"2":{"517":1}}],["u中每一列表示电影的一种主题成分",{"2":{"730":1}}],["u2适用于二元情况",{"2":{"730":1}}],["u2",{"2":{"730":10}}],["u1",{"2":{"730":7}}],["u的偏好",{"2":{"729":1}}],["u的偏差",{"2":{"729":1}}],["u+∑j∈si",{"2":{"729":1}}],["u++",{"2":{"60":1}}],["u|c",{"2":{"721":3}}],["using",{"2":{"690":1}}],["use",{"2":{"34":1,"114":3,"422":1,"800":2}}],["user",{"2":{"34":1,"422":1,"727":1,"729":2}}],["upsampling",{"2":{"312":1}}],["up",{"0":{"346":1},"2":{"253":1,"303":1,"312":1,"346":1}}],["update",{"2":{"174":2}}],["url",{"2":{"246":1,"747":1,"798":6}}],["udp报文或用户数据报",{"2":{"240":1}}],["udp",{"2":{"240":1}}],["uuid",{"2":{"184":2}}],["u=0",{"2":{"60":1}}],["u",{"2":{"58":21,"59":10,"60":8,"721":18,"729":7,"730":19}}],["unpooling",{"2":{"312":1}}],["unauthorized",{"2":{"245":1}}],["unsqueeze",{"2":{"390":6}}],["unshift",{"2":{"220":1}}],["unsubscribe",{"2":{"111":3}}],["undefined",{"2":{"210":2,"211":1,"796":2}}],["undo",{"0":{"171":1,"174":1},"1":{"172":1,"173":1,"174":1},"2":{"174":6}}],["uncommitted",{"2":{"170":1}}],["units",{"2":{"319":1,"690":1}}],["unit",{"2":{"139":1}}],["union",{"2":{"22":2,"59":2}}],["unlock",{"2":{"137":1,"139":1}}],["unordered",{"2":{"31":1,"35":1}}],["相信自己的能力和价�",{"2":{"834":1}}],["相关�",{"2":{"830":1}}],["相关技",{"0":{"754":1},"1":{"755":1,"756":1,"757":1,"758":1,"759":1,"760":1,"761":1,"762":1,"763":1}}],["相关框架",{"0":{"113":1},"1":{"114":1}}],["相互作用作为各自特征潜向量的内积进行j建模",{"2":{"735":1}}],["相互作用外",{"2":{"735":1}}],["相加与分别",{"2":{"705":1}}],["相似性",{"2":{"730":1}}],["相似单词的词向量彼此接近",{"2":{"718":1}}],["相似",{"2":{"651":1}}],["相似度越高",{"2":{"730":1}}],["相似度越小",{"2":{"730":1}}],["相似度与距离之间的关系",{"2":{"730":1}}],["相似度检索",{"2":{"423":1}}],["相似度计算可预计算",{"2":{"730":1}}],["相似度计算",{"2":{"422":1}}],["相同url",{"0":{"747":1}}],["相同数据量",{"2":{"497":1}}],["相同之处",{"2":{"489":1}}],["相同点",{"2":{"436":1,"501":1,"725":1}}],["相同时间内",{"2":{"394":1}}],["相应的分类决策函数",{"2":{"635":1}}],["相应的算法如下",{"2":{"431":1}}],["相应的位标为1",{"2":{"269":1}}],["相比批量梯度下降对应所有的训练样本",{"2":{"545":1}}],["相比而言",{"2":{"545":1}}],["相比xgb不需要遍历一个特征值就需要计算一次分裂的增益",{"2":{"465":1}}],["相比xgb不需要额外存储预排序",{"2":{"465":1}}],["相比于神经网络之类的黑盒分类模型",{"2":{"607":1}}],["相比于xgboost",{"0":{"445":1}}],["相比于v1的改进",{"2":{"378":1}}],["相比有什么优缺点",{"2":{"423":1}}],["相比",{"2":{"423":2,"725":1}}],["相比交叉编码器",{"2":{"423":1}}],["相比之下",{"2":{"422":1}}],["相比yolo",{"2":{"378":1}}],["相比v1提高了训练图像的分辨率",{"2":{"378":1}}],["相当于学习这些规则的权重",{"2":{"739":1}}],["相当于学习速率",{"2":{"513":1}}],["相当于",{"2":{"730":1}}],["相当于f这个特征完全无效",{"2":{"679":1}}],["相当于为模型引入了非线性",{"2":{"664":1}}],["相当于该特征在模型中发挥了两次作",{"2":{"624":1}}],["相当于消耗了两倍的内存",{"2":{"513":1}}],["相当于带",{"2":{"513":1}}],["相当于预剪枝",{"2":{"504":1}}],["相当于加了一个先验",{"2":{"392":1}}],["相当于选取离目标点最近的点",{"2":{"368":1}}],["相当于一个前版本",{"2":{"174":1}}],["相对提升了与分类最相关的数据点的权重",{"2":{"641":1,"672":1}}],["相对而言",{"2":{"527":1}}],["相对于boosting系列的adaboost和gbdt",{"2":{"485":1}}],["相对于非对称加密",{"2":{"252":1}}],["相对简单",{"2":{"423":1}}],["相对位置",{"2":{"422":1}}],["相对�",{"2":{"192":1}}],["相�",{"2":{"136":1}}],["相反可能会得到比单独使用更差的效果",{"2":{"567":1}}],["相反rf使用了随机采样",{"2":{"497":1}}],["相反",{"2":{"110":1,"309":1,"427":1}}],["相邻",{"2":{"33":1}}],["相等的字符串",{"2":{"32":1}}],["将已有知识应用到新场景的能�",{"2":{"815":1}}],["将被定义或修改的属性描述符�",{"2":{"796":1}}],["将底层更新单元的数据结构改成了链表结构",{"2":{"792":1}}],["将当前整�",{"2":{"790":1}}],["将占满整个容器的高度",{"2":{"782":1}}],["将结果写入临时文件",{"2":{"769":1}}],["将每个文件作为一路排序",{"2":{"763":1}}],["将单个文件读入内存",{"2":{"763":1}}],["将单词拆成多个词元时",{"2":{"423":1}}],["将单词拆分成多个词元时",{"2":{"423":1}}],["将k+1个桶中读取内容",{"2":{"763":1}}],["将d划分到每一个桶",{"2":{"758":1}}],["将一组无序的集合",{"2":{"755":1}}],["将排序好的query和对应的query",{"2":{"748":1}}],["将update",{"2":{"741":1}}],["将u所到达的所有顶点v",{"2":{"60":1}}],["将无法被推荐",{"2":{"730":1}}],["将下文单词也纳入训练环境",{"2":{"718":1}}],["将向量映射到",{"2":{"718":1}}],["将one",{"2":{"718":1}}],["将概率全部分配给最大值对应的",{"2":{"703":1}}],["将记忆状态和输出状态合并为一个状态",{"2":{"700":1}}],["将输入的句子映射为一个",{"2":{"689":1}}],["将输出作为最后的输入特征",{"2":{"458":1}}],["将不同",{"2":{"689":1}}],["将不同簇的数据点用不同颜色表示",{"2":{"684":1}}],["将不是相互独立的特征用一条边连接起来",{"2":{"468":1}}],["将数据进行分类",{"2":{"683":1}}],["将数据点映射到更高维度再分群",{"2":{"680":1}}],["将数组元素和对应的频次存入哈希",{"2":{"82":1}}],["将sigmoid函数作用于线性回归的输出得到输出结果",{"2":{"665":1}}],["将s切分成每一个子串都是回文串",{"2":{"38":1}}],["将n个类别两两配对",{"2":{"662":1}}],["将样本点特征x映射到新的特征空间",{"2":{"635":1}}],["将极大改为极小",{"2":{"635":1}}],["将以上两式代入拉格朗日函数中消去",{"2":{"635":1}}],["将分类阈值依次设为每个样本的预测",{"2":{"590":1}}],["将目标函数近似成二次函数",{"2":{"555":1}}],["将时间序列分成季节项st",{"2":{"531":1}}],["将风险降到最小",{"2":{"527":1}}],["将b通过gbdt得到update",{"2":{"741":1}}],["将b通过gbdt得到所有对应叶子节点的下标进行one",{"2":{"741":1}}],["将block划分到不同硬盘来提高吞吐",{"2":{"506":1}}],["将b连接到a后面",{"2":{"220":1}}],["将连续数据离散化为直方图的形式",{"2":{"497":1}}],["将上述式子的两项都看做是向量",{"2":{"497":1}}],["将上述式子化简",{"2":{"430":1}}],["将其变成有序的方法就是排序",{"2":{"755":1}}],["将其中一个文件中的url使用bloom",{"2":{"747":1}}],["将其称为bagging算法",{"2":{"480":1}}],["将其取值范围变为",{"2":{"469":1}}],["将其作为该anchor",{"2":{"381":1}}],["将属于该箱子的样本数据更新为箱子的值",{"2":{"465":1}}],["将浮点数的范围均分成若干区间",{"2":{"465":1}}],["将t个学习器加权结合",{"2":{"456":1}}],["将多个较弱的模型集成模型组",{"2":{"453":1}}],["将多有入度为0的点",{"2":{"61":1}}],["将训练",{"2":{"635":1}}],["将训练映射",{"2":{"635":1}}],["将训练好的所有基模型对训练集进行预测",{"2":{"458":1}}],["将训练好的弱分类器集成为一个强分类器",{"2":{"427":1}}],["将训练数据统一resize到固定尺寸",{"2":{"386":1}}],["将长文拆成合理长度的段落或问答对",{"2":{"423":1}}],["将企业知识库转成适合sft的数据集",{"2":{"423":1}}],["将通用语料和领域语料按一定比例混合训练",{"2":{"423":1}}],["将通道分成m份",{"2":{"348":1}}],["将用户查询转换为语义向量",{"2":{"423":1}}],["将用户输入限制在变量",{"2":{"422":1}}],["将阶段一输出连同原始问题一并输入强大的文本模型",{"2":{"423":1}}],["将小数的乘法操作转化为取对数后的加法操作",{"2":{"619":1}}],["将小说按章节或段落分块",{"2":{"423":1}}],["将小物体在图片中复制多分",{"2":{"403":1}}],["将语义强相关的内容聚为一块",{"2":{"423":1}}],["将文档划分为多个块是为了提高召回精度和效率",{"2":{"423":1}}],["将文件描述符放入一个集合中",{"2":{"302":1}}],["将大规模的数据放在了直方图中",{"2":{"465":1}}],["将大智能体按功能划分为多个子智能体",{"2":{"423":1}}],["将大模型用于分类任务时",{"2":{"422":1}}],["将历史对话存入向量数据库",{"2":{"423":1}}],["将对话转为结构化格式存入外部",{"2":{"423":1}}],["将非词表内词替换或拒答",{"2":{"423":1}}],["将具有较高相异度的数据对象划分至不同类簇",{"2":{"396":1}}],["将具有较高相似度的数据对象划分至同一类簇",{"2":{"396":1}}],["将新",{"2":{"388":1}}],["将从骨干网络",{"2":{"388":1}}],["将imagenet分类数据集和coco检测数据集同时对模型训练",{"2":{"378":1}}],["将ip包中目标ip与路由表进行匹配",{"2":{"250":1}}],["将检测和分类问题做成了一个统一的框架",{"2":{"378":1}}],["将整张图作为网络的输入",{"2":{"378":1}}],["将整数化后的边界区域平均分割成",{"2":{"368":1}}],["将候选区域分割成kxk个单元",{"2":{"369":1}}],["将映射后的区域划分为相同大小的sections",{"2":{"368":1}}],["将roi映射到feature",{"2":{"368":1}}],["将越来越偏的分布拉回到标准化的分布",{"2":{"351":1}}],["将更有助于分类",{"2":{"327":1}}],["将这些用户所喜欢的物品提取出来并过滤掉目标用户已经喜欢的物品",{"2":{"730":1}}],["将这些",{"2":{"422":1}}],["将这些feature",{"2":{"373":1}}],["将这些候选框信息送入到fast",{"2":{"373":1}}],["将这些信息发送至消息队列",{"2":{"199":1}}],["将这个集合从用户空间拷贝到内核空间",{"2":{"302":1}}],["将系统中的所有资源统一编号",{"2":{"297":1}}],["将另一个程序当做一个新的进程在当前程序进程中启动",{"2":{"293":1}}],["将寄存器上下文和栈保存到其他地方",{"2":{"289":1}}],["将铅笔折两次",{"2":{"274":1}}],["将鸡蛋编号为1到12",{"2":{"270":1}}],["将8个瓶子进行如下编码",{"2":{"269":1}}],["将会在24小时后毒发身亡",{"2":{"269":1}}],["将待发送数据用公钥加密",{"2":{"252":1}}],["将得到的ip地址到硬件地址的映射写入arp高速缓存",{"2":{"250":1}}],["将重发这个报文段",{"2":{"241":1}}],["将丢弃这个报文段和不确认收到此报文段",{"2":{"241":1}}],["将保持它首部和数据的检验和",{"2":{"241":1}}],["将需要删除的key发送至消息队列",{"2":{"199":1}}],["将相�",{"2":{"190":1}}],["将提",{"2":{"133":1}}],["将此版本号一同读出",{"2":{"133":1}}],["将7作为一个分水岭",{"2":{"120":1}}],["将存活对象向一侧移动",{"2":{"110":1}}],["将内存平均分为两块",{"2":{"110":1}}],["将内存分为两个生代",{"2":{"110":1}}],["将层数作为key",{"2":{"89":1}}],["将cur的后一个节点的prev指向cur的前一个节",{"2":{"70":1}}],["将cur的前一个节点的next指向cur的后一个节",{"2":{"70":1}}],["将cur插入到sorted中",{"2":{"55":1}}],["将",{"2":{"70":1,"185":1,"388":2,"423":1,"700":1}}],["将第二个节点的prev设置为none",{"2":{"70":1}}],["将所有类型的文件",{"2":{"800":1}}],["将所有存在的值对应的位置设置",{"2":{"759":1}}],["将所有弱分类器的结果加权求和",{"2":{"486":1}}],["将所有的数据根据",{"2":{"763":1}}],["将所有的特征视为图的各个顶点",{"2":{"468":1}}],["将所有的bounding",{"2":{"381":1}}],["将所有的偶数排列奇数的前面�",{"2":{"49":1}}],["将所有数据看做key",{"2":{"258":1}}],["将所有可能存在的数据哈希到一个足够大�",{"2":{"189":1}}],["将所有入度为0的点",{"2":{"61":1}}],["将改变后的a加入到候选队列中",{"2":{"32":1}}],["将矩阵进行求和压缩到一维形",{"2":{"10":1}}],["返",{"2":{"32":1,"83":1}}],["返回结果",{"2":{"769":1}}],["返回频数最高的100个词",{"2":{"749":1}}],["返回当前的最近邻结点和距离",{"2":{"651":1}}],["返回路径",{"2":{"519":1}}],["返回相关照片",{"2":{"423":1}}],["返回张量元素个数",{"2":{"397":1}}],["返回这个链表",{"2":{"302":1}}],["返回icmp",{"2":{"250":1}}],["返回index",{"2":{"220":2}}],["返回解析结果给用户",{"2":{"249":1}}],["返回返回值的数组",{"2":{"220":1}}],["返回返回值为true的项的数�",{"2":{"220":1}}],["返回true",{"2":{"220":2}}],["返回数组长�",{"2":{"220":2}}],["返回数组的新长度",{"2":{"81":1}}],["返回�",{"2":{"218":1}}],["返回函数",{"2":{"211":7}}],["返回引擎的执行结果",{"2":{"163":1}}],["返回",{"2":{"82":2,"211":10,"651":1}}],["返回4",{"2":{"81":1}}],["返回1",{"2":{"81":1}}],["返回6",{"2":{"81":1}}],["返回空字符",{"2":{"74":1}}],["返回所有可能的结果",{"2":{"38":1}}],["返回所有有可能的句子",{"2":{"31":1}}],["返回所需的最少补齐数",{"2":{"23":1}}],["返回其所有可能的子集",{"2":{"30":1}}],["返回其所有可能的排列",{"2":{"29":1}}],["返回其最大和",{"2":{"18":1}}],["返回可以获得的最大利润",{"2":{"26":1}}],["返回lcs的长度",{"2":{"2":1}}],["中为当前最大的元素",{"2":{"756":1}}],["中为什么用",{"0":{"705":1}}],["中心词和上下文词",{"2":{"725":1}}],["中心词",{"2":{"719":1}}],["中心极限定理",{"2":{"571":1}}],["中首次被提出",{"2":{"690":1}}],["中被提出",{"2":{"690":1}}],["中常用的距离度量",{"0":{"681":1}}],["中位",{"2":{"763":1}}],["中位数代替平均值作为簇中心",{"2":{"676":1}}],["中位�",{"0":{"44":1}}],["中就得到了逻辑回归的假设函数",{"2":{"660":1}}],["中没有出现过",{"2":{"618":1}}],["中没�",{"2":{"218":1}}],["中取值所产生的划分结果相同",{"2":{"603":1}}],["中显式要求模型列出推理过程",{"2":{"422":1}}],["中指定模型身份和行为范围",{"2":{"422":1}}],["中兴",{"0":{"383":1}}],["中进行特征提取",{"2":{"366":1}}],["中许多项变成零",{"2":{"330":1}}],["中断代码本身也可以被其他的硬中断中断",{"2":{"301":1}}],["中断请求",{"2":{"301":1}}],["中随机取数",{"2":{"283":1}}],["中会包含自己的接收窗口的大小",{"2":{"242":1}}],["中设�",{"2":{"228":1}}],["中什么是闭包�",{"0":{"215":1}}],["中作用域你是如何理解的",{"0":{"214":1}}],["中如何判断一个对象是什么类型",{"0":{"211":1}}],["中提出",{"2":{"186":1}}],["中哪里用到了跳表",{"0":{"186":1}}],["中默认的引擎�",{"2":{"167":1}}],["中有时也称辅助索引为二级索引�",{"2":{"165":1}}],["中一�",{"0":{"163":1}}],["中对应的缓存行无�",{"2":{"143":1}}],["中对应的关键字就�",{"2":{"140":1}}],["中的数学原理详解",{"2":{"725":1}}],["中的数据",{"2":{"192":1}}],["中的梯度消失或梯度爆炸问题",{"0":{"698":1}}],["中的操作",{"2":{"651":1}}],["中的boosting$算法类别",{"2":{"503":1}}],["中的分块量化如何解决普通量化导致的信息损失问题",{"2":{"423":1}}],["中的所有数据",{"2":{"192":1}}],["中的",{"2":{"140":2,"422":1,"635":1}}],["中的两个小写字母精确地交换位",{"2":{"32":1}}],["中可以使�",{"2":{"140":1}}],["中要配合使用",{"2":{"135":1}}],["中每个中间件的执行顺序�",{"2":{"114":1}}],["中",{"2":{"110":1,"130":1,"140":2,"189":1,"258":1,"270":2,"367":1,"389":1,"422":2,"423":3,"537":1,"705":1,"747":2,"748":1,"749":1,"784":4,"798":1,"800":1}}],["中旬",{"2":{"90":1}}],["中旬的遍历的第k个结",{"2":{"88":1}}],["中序遍历",{"2":{"85":1}}],["中序",{"2":{"85":1,"103":1}}],["中最长的回文子串",{"2":{"79":1}}],["中某几个数字的和来表示即可",{"2":{"23":1}}],["中某几个数字的和来表示",{"2":{"23":1}}],["之所以可以用这个表达式来作为相应特征的重要性的度量值是因为",{"2":{"483":1}}],["之间取值范围的数s",{"2":{"659":1}}],["之间的",{"2":{"670":1}}],["之间的误差",{"2":{"622":1}}],["之间的关系曲线",{"2":{"590":1}}],["之间",{"2":{"131":1,"670":1}}],["之和时",{"2":{"129":1}}],["之前只访问过深度小于depth的节点",{"2":{"93":1}}],["之前",{"2":{"30":1}}],["之后最简单的使用就是提供map函数和reduce函数即可",{"2":{"769":1}}],["之后进行合并结果",{"2":{"769":1}}],["之后进行遍历",{"2":{"20":1}}],["之后在合并",{"2":{"769":1}}],["之后合并结果",{"2":{"769":1}}],["之后对每个文件进行排序",{"2":{"763":1}}],["之后归并结果",{"2":{"763":1}}],["之后剩下的k个一定是top",{"2":{"756":1}}],["之后再传给输出层神经元",{"2":{"566":1}}],["之后求αm∗",{"2":{"430":1}}],["之后使用原图上采样得到的图像来做微调",{"2":{"401":1}}],["之后使用一维数组的最大子段和进行计算",{"2":{"10":1}}],["之后",{"2":{"267":1}}],["之后更新时",{"2":{"133":1}}],["之后fast和slow一起走",{"2":{"72":1}}],["之后基于贪心策略得到最优结果",{"2":{"17":1}}],["子树分支所在的区域",{"2":{"651":1}}],["子树删除",{"2":{"605":1}}],["子采",{"2":{"507":1}}],["子任务网络一个负责目标分类",{"2":{"387":1}}],["子进程来执行",{"2":{"192":1}}],["子线程",{"2":{"192":1}}],["子串",{"2":{"78":1}}],["子集",{"0":{"30":1}}],["子数组使得它们的和最大",{"2":{"18":1}}],["回流+重绘",{"2":{"786":3}}],["回到聚类的定义",{"2":{"684":1}}],["回答原则",{"0":{"830":1}}],["回答技巧和策略",{"0":{"828":1},"1":{"829":1,"830":1,"831":1}}],["回答准确且符合人类期望",{"2":{"423":1}}],["回答",{"2":{"423":1}}],["回归系数衰减太慢",{"2":{"657":1}}],["回归和排序问题应该选择不同的评价函",{"2":{"578":1}}],["回归问题是取平均",{"2":{"501":2}}],["回归问题",{"2":{"497":1,"504":1,"513":1}}],["回归树数量",{"2":{"462":1}}],["回归再加上mask预测的损失之和",{"2":{"375":1}}],["回归损失函数利用的是fast",{"2":{"372":1}}],["回归",{"0":{"579":1},"1":{"580":1,"581":1,"582":1,"583":1},"2":{"366":1,"459":1,"472":1,"649":1,"654":1,"657":2}}],["回归等任务",{"2":{"340":1}}],["回调函数将就绪的描述符添加到一个链表中",{"2":{"302":1}}],["回调方�",{"2":{"217":1}}],["回调方法",{"2":{"217":1}}],["回车",{"2":{"246":1}}],["回滚和多版本控�",{"2":{"174":1}}],["回收完成后",{"2":{"110":1}}],["回文链表",{"0":{"64":1}}],["回文划分",{"0":{"7":1}}],["回溯检查总是从优先级最高",{"2":{"651":1}}],["回溯等搜索策略",{"2":{"100":1}}],["回溯其他可能组合",{"2":{"30":1}}],["回溯",{"2":{"29":1,"651":1}}],["则就叫称为重绘",{"2":{"786":1}}],["则读取附在该结点上的信息",{"2":{"762":1}}],["则∂l∂θu=d",{"2":{"721":1}}],["则一般选择置信度最大的",{"2":{"662":1}}],["则一定是最优解",{"2":{"544":1}}],["则误差平方为",{"2":{"656":1}}],["则把他的右孩子加入到队列中",{"2":{"651":1}}],["则设定两者距离为无穷大",{"2":{"651":1}}],["则我们说d0和d1线性可分",{"2":{"634":1}}],["则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响",{"2":{"617":1}}],["则停止切分",{"2":{"605":1}}],["则a同时划分入a1",{"2":{"601":1}}],["则平均每一次训练有3个神经元失活",{"2":{"566":1}}],["则需要某种策略来选择一个替补质心",{"2":{"685":1}}],["则需要减少正则化参数",{"2":{"560":1}}],["则需要用户去手动释放锁",{"2":{"139":1}}],["则",{"2":{"554":1,"668":1}}],["则情况不定",{"2":{"551":1}}],["则为",{"2":{"796":2}}],["则为极大值点",{"2":{"551":1}}],["则为函数的极小值点",{"2":{"551":1}}],["则取值有效",{"2":{"544":1}}],["则不是极值点",{"2":{"552":1}}],["则不分裂",{"2":{"507":1}}],["则不会继续再尝试选择最优特征来进行划分",{"2":{"484":1}}],["则对此没有要",{"2":{"627":1}}],["则对应类别为最终结果",{"2":{"662":1}}],["则对应坐标为",{"2":{"590":2}}],["则对应的通道数也为n",{"2":{"348":1}}],["则对闭区间",{"2":{"496":1}}],["则会和兄弟节点一起被剪枝",{"2":{"484":1}}],["则会识别成一个bbox",{"2":{"397":1}}],["则说明这个特征对于样本的分类结果影响很大",{"2":{"483":1}}],["则t个弱学习器投出最多票数的类别或者类别之一为最终类别",{"2":{"455":1,"475":1}}],["则每个样本的权值为1n",{"2":{"427":1}}],["则偏好标签为",{"2":{"423":1}}],["则文章不太可能是该模型用该提示词生成",{"2":{"423":1}}],["则提示最近可用时间段",{"2":{"423":1}}],["则是对于那些包含小物体的图像",{"2":{"403":1}}],["则是左边看到",{"2":{"95":1}}],["则它们越有可能在同一个类簇",{"2":{"396":1}}],["则它们的相似性越高",{"2":{"396":1}}],["则它算是当前程序的子进程",{"2":{"293":1}}],["则优先选择roialign",{"2":{"369":1}}],["则其梯度更新值非常小",{"2":{"328":1}}],["则权重参数呈指数级增长",{"2":{"326":1}}],["则权重参数呈指数级减小",{"2":{"326":1}}],["则神经网络的输出结果等于各层权重参数的积再与输入数据集相乘",{"2":{"326":2}}],["则该过程重复多次",{"2":{"685":1}}],["则该节点不再生成子节点",{"2":{"484":1}}],["则该结构对平台运行的内存要求越高",{"2":{"314":1}}],["则该值的引用次数�",{"2":{"110":1}}],["则称x∗为局部极小值",{"2":{"554":1}}],["则称此进程处于就绪状态",{"2":{"291":1}}],["则称该进程处于运行状态",{"2":{"291":1}}],["则公式3的结果是",{"2":{"282":1}}],["则有对应的",{"2":{"635":1}}],["则有当全部约束满足",{"2":{"635":1}}],["则有混淆矩阵",{"2":{"591":1}}],["则有",{"2":{"282":2,"547":1}}],["则s",{"2":{"276":1}}],["则slow和fast总会在某一点相遇",{"2":{"68":1}}],["则4号蛋为要找的蛋",{"2":{"270":2}}],["则8号蛋为要找的蛋",{"2":{"270":1}}],["则剩下的蛋",{"2":{"270":1}}],["则可以降低特征数量",{"2":{"468":1}}],["则可以中断",{"2":{"139":1}}],["则可能会出现内存爆表和局部最优的情况",{"2":{"333":1}}],["则可知重量不同的蛋在9",{"2":{"270":1}}],["则12号蛋为重量不同的蛋",{"2":{"270":1}}],["则重量不同的蛋在剩下的4个中",{"2":{"270":1}}],["则发送arp请求广播报文获取下一跳的mac",{"2":{"250":1}}],["则将kd树的根节点加入到优先级队列中",{"2":{"651":1}}],["则将数据路由到相应的出口",{"2":{"250":1}}],["则将其标记为",{"2":{"110":1}}],["则丢弃",{"2":{"250":1}}],["则执行任务",{"2":{"792":1}}],["则执行",{"2":{"184":1}}],["则即可以选公平锁也可以选非公平锁",{"2":{"139":1}}],["则予以更新",{"2":{"133":1}}],["则和",{"2":{"123":1}}],["则这个对象直接晋升到老生代中",{"2":{"110":1}}],["则这个值的引用次数�",{"2":{"110":1}}],["则这个值的引用次数就是",{"2":{"110":1}}],["则返回该值本身�",{"2":{"218":1}}],["则返回",{"2":{"82":1}}],["则fast会先为空",{"2":{"68":1}}],["则没有环",{"2":{"61":1}}],["则u在线性序列中出现在v之前",{"2":{"60":1}}],["则表示满足要",{"2":{"34":1}}],["则次数就",{"2":{"33":1}}],["则结果是经过多轮消耗之后变",{"2":{"27":1}}],["则经过多次消耗之后",{"2":{"27":1}}],["则移除这个不满足的区间",{"2":{"20":1}}],["就不会多出一�",{"2":{"798":1}}],["就不会影响浏览器的渲染等工作",{"2":{"792":1}}],["就等到下一帧的空闲时间再去执行�",{"2":{"792":1}}],["就容易出现掉帧的现象",{"2":{"792":1}}],["就比如是我们上篇文章中提到的top",{"2":{"769":1}}],["就结束",{"2":{"763":1}}],["就选择基于user的方式",{"2":{"730":1}}],["就面临着维数灾难",{"2":{"651":1}}],["就把x的label设为c",{"2":{"651":1}}],["就从数据集中",{"2":{"651":1}}],["就都求出来了",{"2":{"635":1}}],["就低",{"2":{"589":1}}],["就要分析哪里出现了问题",{"2":{"575":1}}],["就需要我们进行埋点设计",{"2":{"575":1}}],["就这样一步步地走下去",{"2":{"542":1}}],["就这样使用贪心算法生成combinations",{"2":{"446":1}}],["就适当提高",{"2":{"422":1}}],["就越低",{"2":{"422":1}}],["就能处理比训练时更长的文本",{"2":{"422":1}}],["就能处理更多的图片",{"2":{"394":1}}],["就必须截断或者做缓存处理",{"2":{"422":1}}],["就用负样本补充",{"2":{"370":1}}],["就绪进程可以按多个优先级来划分队列",{"2":{"291":1}}],["就绪",{"2":{"291":1}}],["就先在其",{"2":{"250":1}}],["就知道接收方确实没有收到报文段",{"2":{"243":1}}],["就变成了",{"2":{"185":1}}],["就会推荐给你",{"2":{"727":1}}],["就会得到空簇",{"2":{"685":1}}],["就会增加",{"2":{"651":1}}],["就会因为每个区间内训练记录太少而不能对p",{"2":{"620":1}}],["就会导致树结构的剧烈改变",{"2":{"607":1}}],["就会",{"2":{"422":1}}],["就会抛异常�",{"2":{"218":1}}],["就会丢失最近未持久化的数据",{"2":{"192":1}}],["就会不断的延长�",{"2":{"185":1}}],["就会回收这些对象的内存",{"2":{"122":1}}],["就是事件冒泡�",{"2":{"778":1}}],["就是事件捕获�",{"2":{"778":1}}],["就是将大文件分成多个小文件进行统计",{"2":{"769":1}}],["就是将数据划分成两部分进行处理",{"2":{"760":1}}],["就是两个用户都对这个物品有评价",{"2":{"730":1}}],["就是对每个类都训练出一个分类器",{"2":{"643":1}}],["就是对称的二叉树",{"2":{"91":1}}],["就是一个单词有没有在一个文档中出现",{"2":{"621":1}}],["就是一个递归的选择内部节点",{"2":{"597":1}}],["就是一种符合内存模型规范的",{"2":{"140":1}}],["就是这一层中的每个神经元都有p的概率失活",{"2":{"566":1}}],["就是只考虑前一个单词的一阶马尔科夫链模型",{"2":{"527":1}}],["就是所求的最终的某类别的ap值",{"2":{"393":1}}],["就是重叠矩形的宽",{"2":{"390":1}}],["就是上述的不同尺寸的feature",{"2":{"386":1}}],["就是在页面第一次加载的时候",{"2":{"786":1}}],["就是在原来",{"2":{"330":1}}],["就是在大型主机上是有硬件通道的",{"2":{"301":1}}],["就是异步的意思",{"2":{"218":1}}],["就是可以不使用锁机制实现线程间的同步",{"2":{"134":1}}],["就是",{"2":{"134":1,"212":1}}],["就直接在内存中进行读取�",{"2":{"112":1}}],["就可用uuvi对目标用户进行评分预测",{"2":{"730":1}}],["就可查出其对应的硬件地址",{"2":{"250":1}}],["就可以来实现前端路�",{"2":{"798":2}}],["就可以",{"2":{"787":1}}],["就可以swap",{"2":{"756":1}}],["就可以得到最大堆",{"2":{"756":1}}],["就可以很方便很好的实现上面我们说的这种非线性和tuple特征变换",{"2":{"739":1}}],["就可以进行分类了",{"2":{"659":1}}],["就可以直接定义损失函数了",{"2":{"516":1}}],["就可以随机的改变样本在特征x处的值",{"2":{"483":1}}],["就可以调用返回值函数",{"2":{"215":1}}],["就可以构成一个对象的序列",{"2":{"212":1}}],["就可以将其占用的内存空间回收回来",{"2":{"110":1}}],["就可以将中序分成左右两个子树",{"2":{"90":1}}],["就可能导致死锁现象",{"2":{"139":1}}],["就可能会用到它们",{"2":{"110":1}}],["就将这个变量标记为",{"2":{"110":1}}],["就加入这个边",{"2":{"59":1}}],["就离开了",{"2":{"27":1}}],["就进行一次买卖",{"2":{"25":1}}],["当浏览器跳转到新状态时",{"2":{"798":1}}],["当属性值修改时",{"2":{"796":1}}],["当属于某个簇的样本数过多",{"2":{"676":1}}],["当属于某个簇的样本数过少时把这个簇去除",{"2":{"676":1}}],["当访问该属性时",{"2":{"796":1}}],["当页面中某个",{"2":{"787":1}}],["当页面中的一些元素需要更新属性",{"2":{"786":1}}],["当页面中的一部分",{"2":{"786":1}}],["当页面触发一个事件的时候",{"2":{"778":1}}],["当处理完成事件后",{"2":{"778":1}}],["当处理大量数据时",{"2":{"321":1}}],["当事件被触发",{"2":{"778":1}}],["当事件发生时",{"2":{"227":1}}],["当你输入前半部分",{"2":{"762":1}}],["当ad曝光不充分不足以训练树时",{"2":{"741":1}}],["当幸福来敲门的时候",{"2":{"727":1}}],["当k取较小的常数时",{"2":{"725":1}}],["当p值小于0",{"2":{"684":1}}],["当有一个新的样本来的时候",{"2":{"643":1}}],["当样本在原始空间线性不可分",{"2":{"638":1}}],["当样本相应的特征值缺失时",{"2":{"508":1}}],["当存在约束不满足",{"2":{"635":1}}],["当存在约束不满足θα",{"2":{"635":1}}],["当全部约束满足+∞",{"2":{"635":1}}],["当朴素贝叶斯算法数据的属性为连续型变量时",{"2":{"620":1}}],["当数据改变了就会来触发这个函数",{"2":{"796":1}}],["当数据的属性是连续型变量时",{"0":{"620":1}}],["当数据无法一次载入内存或者在分布式情况下",{"2":{"497":2,"513":1}}],["当值越小时",{"2":{"536":1}}],["当值越大时",{"2":{"536":1}}],["当n=2的时候",{"2":{"527":1}}],["当正负样本比例为1",{"2":{"509":1}}],["当引入一次分裂后",{"2":{"507":1}}],["当在",{"2":{"502":1}}],["当基函数为基本分类器时",{"2":{"493":1}}],["当基函数是分类器时",{"2":{"430":1}}],["当训练数据线性可分时",{"2":{"636":1}}],["当训练完毕以后",{"2":{"472":1}}],["当训练集损失持续下降",{"2":{"307":1}}],["当使用离散特征进行分裂时",{"2":{"470":1}}],["当这个模型用在对一个未曾见过的数据集进行测试的时候",{"2":{"459":1}}],["当这个值的引用次数变成",{"2":{"110":1}}],["当需要组合的categorical",{"2":{"446":1}}],["当标注数据少时",{"2":{"423":1}}],["当负样本难以采集或训练资源有限",{"2":{"423":1}}],["当单一智能体的提示词过长",{"2":{"423":1}}],["当单次模型调用生成效果不佳时",{"2":{"423":1}}],["当两个目标靠的非常近时",{"2":{"397":1}}],["当卷积层的局部连接是全局连接时",{"2":{"329":1}}],["当神经网络层数越多时",{"2":{"327":1}}],["当模型在训练集和测试集上精度都很差时",{"2":{"307":1}}],["当模型在训练集上精度很高",{"2":{"307":1}}],["当文件描述符的数量增加时",{"2":{"302":1}}],["当文件大小大于给定值后",{"2":{"173":1}}],["当中断产生的时候",{"2":{"301":1}}],["当进程由i",{"2":{"291":1}}],["当一条样本x进来之后",{"2":{"741":1}}],["当一个进程开始运行之前",{"2":{"297":1}}],["当一个进程由于时间片用完而进入就绪状态时",{"2":{"291":1}}],["当一个进程获得了除处理机以外的一切所需资源",{"2":{"291":1}}],["当一个进程在处理机上运行时",{"2":{"291":1}}],["当一只猫的萌系数变成0它就会离开你",{"2":{"27":1}}],["当x属于",{"2":{"279":1}}],["当主机a欲向本局域网上的某个主机",{"2":{"250":1}}],["当主节点出现问题时",{"2":{"194":1}}],["当客户端关闭会话",{"2":{"244":1}}],["当用户在应用程序的",{"2":{"244":1}}],["当发送端收到连续三个重复的确认时",{"2":{"243":1}}],["当拥塞窗口的大小达到慢开始门限",{"2":{"243":1}}],["当网络拥塞时",{"2":{"241":1}}],["当接收方来不及处理发送方的数据",{"2":{"241":1}}],["当服务端收到fin报文时",{"2":{"239":1}}],["当我们调用",{"2":{"792":1}}],["当我们寻找约束存在时的最优点的时候",{"2":{"637":1}}],["当我们确定了需要分析的具体指标之后",{"2":{"575":1}}],["当我们访问一个对象的属性时",{"2":{"212":1}}],["当我们第一次访问一个深度为depth的节点x",{"2":{"93":1}}],["当新的merge后的日志文件准备好时",{"2":{"193":1}}],["当加锁次数�",{"2":{"185":1}}],["当写到结尾时",{"2":{"173":1}}],["当最左侧字段是常量引用时",{"2":{"168":1}}],["当最后一个中间件执行完毕后",{"2":{"114":1}}],["当涉及到多个变量的时�",{"2":{"135":1}}],["当且仅�",{"2":{"134":1}}],["当提交任务数超过",{"2":{"130":1}}],["当提交任务数超�",{"2":{"129":1}}],["当线程池中超�",{"2":{"130":1}}],["当线程池达到",{"2":{"130":1}}],["当线程池小于",{"2":{"130":1}}],["当内存空间不足时",{"2":{"122":1}}],["当要�",{"2":{"110":1}}],["当满足晋升条件时对象会从新生代晋升到老生代�",{"2":{"110":1}}],["当垃圾收集器下次再运行时",{"2":{"110":1}}],["当声明了一个变量并将一个引用类型值赋给该变量时",{"2":{"110":1}}],["当然我们需要设置一个好的hash函数",{"2":{"770":1}}],["当然我也可以选择多路归并排序",{"2":{"760":1}}],["当然可能会有一些优化",{"2":{"769":1}}],["当然还有其他的功能",{"2":{"769":1}}],["当然还有其他的很多应用",{"2":{"769":1}}],["当然中的很多问题我都没有提出来",{"2":{"769":1}}],["当然受限于笔者的自身水平",{"2":{"765":1}}],["当然这只是转换之后的格式",{"2":{"769":1}}],["当然这是在先验分布是接近真实分布的情况下得到的了",{"2":{"568":1}}],["当然这样走下去",{"2":{"542":1}}],["当然必须在同一硬件条件下进行比较",{"2":{"393":1}}],["当然同时也增加了一定的计算量",{"2":{"313":1}}],["当然",{"2":{"110":1,"193":1,"542":1,"572":1,"690":1,"699":1}}],["当然希望每个人都能研究每一个题目",{"2":{"50":1}}],["当变量进入环境",{"2":{"110":1}}],["当遍历到一个点的深度大于最大深度时",{"2":{"93":1}}],["当遍历到第",{"2":{"74":1}}],["当前宏任务结束后",{"2":{"793":1}}],["当前帧先执行浏览器的渲染等任务",{"2":{"792":1}}],["当前的节点数",{"2":{"605":1}}],["当前的长度是上一层的个数",{"2":{"85":1,"86":1}}],["当前层filter",{"2":{"315":1}}],["当前值",{"2":{"220":1}}],["当前插入节点是最小的值",{"2":{"55":1}}],["当",{"2":{"74":1,"202":1,"241":1,"423":2,"532":1}}],["当第一个指针指向空节点时",{"2":{"72":1}}],["当第一个指针扫描到第k个结点后",{"2":{"72":1}}],["当猫a的萌系数不变",{"2":{"27":1}}],["h6>",{"2":{"775":1}}],["h6>�",{"2":{"774":1}}],["h5>",{"2":{"775":1}}],["h4>",{"2":{"775":1}}],["h3>",{"2":{"775":1}}],["h2>",{"2":{"775":1}}],["h1>",{"2":{"774":1,"775":1}}],["hbase",{"2":{"767":1}}],["hs为什么用霍夫曼树而不用其他二叉树",{"2":{"725":1}}],["hw",{"2":{"721":2}}],["hw=",{"2":{"721":1}}],["hw+",{"2":{"721":1}}],["hwtθu",{"2":{"721":18}}],["hθ",{"2":{"545":5,"657":4,"661":4}}],["hmm在处理nlp词性标注和实体识别任务中的局限",{"2":{"527":1}}],["hmm为什么是生成模型",{"2":{"527":1}}],["hmm模型是对转移概率",{"2":{"520":1}}],["hmm",{"0":{"520":1,"523":1},"1":{"524":1,"525":1,"526":1,"527":1,"528":1,"529":1}}],["hua111hua",{"2":{"686":1}}],["huazhongkejidaxuezpp",{"2":{"284":1}}],["hugxnyksq3rgdmla",{"2":{"517":1}}],["human",{"2":{"423":1}}],["h组k",{"2":{"422":1}}],["h=",{"2":{"382":1}}],["h=32",{"2":{"357":1}}],["h分别为bbox的中心点坐标",{"2":{"372":1}}],["h∗",{"2":{"372":1}}],["hot或者multi",{"2":{"734":1}}],["hot模型的缺点",{"2":{"725":1}}],["hot模型与word2vec模型比较",{"2":{"725":1}}],["hot向量转化为词向量",{"2":{"718":1}}],["hot",{"2":{"705":1,"734":1}}],["hot编码",{"2":{"739":1,"741":1}}],["hot编码后作为输入特征",{"2":{"734":1}}],["hot编码向量",{"2":{"446":1}}],["hot编码方法将特征转为数值型",{"2":{"446":1}}],["hochreiter",{"2":{"690":1}}],["holidays",{"0":{"536":1},"2":{"536":1,"537":1}}],["hout∗wout∗cout∗4",{"2":{"394":1}}],["hout∗wout∗cout",{"2":{"394":1}}],["houbb",{"2":{"203":1}}],["hog",{"2":{"361":1}}],["hystrix",{"2":{"188":1}}],["hadoop生态",{"2":{"804":1}}],["hadoop",{"2":{"767":1}}],["hall",{"2":{"684":1}}],["harabasz",{"2":{"684":1}}],["harmonic",{"2":{"589":1}}],["hard",{"2":{"423":1}}],["ha",{"2":{"372":2}}],["ha在训练rpn时需要准备好目标t",{"2":{"367":1}}],["hat",{"2":{"496":3}}],["hatw∗=log⁡",{"2":{"372":1}}],["hatw∗=w∗",{"2":{"367":1}}],["hatw=log⁡",{"2":{"372":1}}],["hatw=w",{"2":{"367":1}}],["hatx∗=x∗−xa",{"2":{"367":1}}],["handshake",{"2":{"253":1}}],["handler",{"2":{"111":7}}],["hasownproperty",{"2":{"111":3}}],["hascycle",{"2":{"68":1}}],["hashchange",{"2":{"798":1}}],["hashcode",{"0":{"124":1},"2":{"124":1}}],["hash映射",{"2":{"754":1,"768":1}}],["hashmap默认",{"2":{"120":1}}],["hashmap",{"0":{"118":1},"1":{"119":1,"120":1},"2":{"82":3,"754":1,"768":1}}],["hash",{"2":{"40":19,"185":3,"747":1,"748":1,"749":1,"770":1,"798":9}}],["history的改变添加监听事件",{"2":{"798":1}}],["history",{"2":{"798":4}}],["histogram",{"2":{"361":1}}],["hidden",{"2":{"786":1}}],["hive",{"2":{"767":1}}],["hierarchial",{"2":{"725":1}}],["hierarchical",{"0":{"720":1,"723":1},"2":{"725":3}}],["hinton",{"2":{"703":1}}],["hinge损失",{"2":{"331":1}}],["hi=∂y^",{"2":{"496":1}}],["hi++",{"2":{"79":2}}],["hi",{"2":{"79":10}}],["high",{"2":{"45":4}}],["highlight",{"2":{"26":1}}],["ht",{"2":{"602":1}}],["htm",{"2":{"303":1,"743":1}}],["htmlwebpackplugin",{"2":{"800":2}}],["html>",{"2":{"796":2}}],["html5",{"0":{"776":1},"2":{"798":1}}],["htmls",{"2":{"253":1}}],["html",{"0":{"772":1,"773":1,"774":1,"777":1,"778":1},"1":{"773":1,"774":2,"775":2,"776":2,"777":1,"778":2,"779":2},"2":{"62":1,"96":1,"203":3,"253":1,"259":1,"272":1,"284":2,"303":1,"499":1,"517":1,"522":1,"591":1,"595":1,"652":1,"656":1,"666":1,"671":1,"725":2,"774":1,"796":2,"798":1,"800":2,"803":1}}],["http协议",{"2":{"263":1}}],["http的连接很简单",{"2":{"247":1}}],["http和https使用的是完全不同的连接方式",{"2":{"247":1}}],["http是超文本传输协议",{"2":{"247":1}}],["http与https的区别",{"0":{"247":1}}],["http版本",{"2":{"246":1}}],["http报文都由开始行",{"2":{"246":1}}],["http报文有请求报文和响应报文两种",{"2":{"246":1}}],["http报文",{"0":{"246":1}}],["http状态码",{"0":{"245":1}}],["httponly",{"2":{"228":1}}],["http",{"2":{"96":1,"114":1,"244":1,"246":1,"247":1,"253":1,"284":1,"303":1,"442":1,"522":1,"658":1,"670":1,"671":1,"743":1,"798":2}}],["https中同时使用了对称加密算法和非对称加密算法",{"2":{"252":1}}],["https协议是由ssl+http协议构建的可进行加密传输",{"2":{"247":1}}],["https协议需要到ca申请证书",{"2":{"247":1}}],["https则是具有安全性的ssl加密传输协议",{"2":{"247":1}}],["https的安全基础是ssl",{"2":{"247":1}}],["https",{"2":{"16":2,"26":1,"62":2,"85":2,"96":3,"203":10,"247":1,"253":7,"259":3,"272":3,"284":4,"303":3,"414":22,"473":4,"499":4,"517":5,"522":1,"538":1,"556":2,"558":1,"563":1,"564":1,"567":1,"568":1,"577":1,"591":1,"595":3,"644":3,"652":6,"656":1,"664":1,"665":1,"666":1,"686":1,"725":6,"743":2,"753":2}}],["hessian",{"2":{"552":4,"553":1,"555":1}}],["height计算出的anchor",{"2":{"382":1}}],["height",{"2":{"229":1,"784":1}}],["hello",{"2":{"218":1}}],["helper",{"2":{"94":4}}],["head>",{"2":{"796":2}}],["head进行最终的预测",{"2":{"362":1}}],["header>",{"2":{"775":1}}],["header",{"2":{"228":1,"776":1}}],["head指向第二个节",{"2":{"70":1}}],["head",{"2":{"55":3,"56":15,"64":10,"65":3,"66":5,"67":17,"68":3,"69":16,"70":4,"71":3,"72":7,"73":3,"186":1,"362":1}}],["heapsort",{"2":{"52":2,"756":1}}],["heapsize=n",{"2":{"52":1,"756":1}}],["heapsize",{"2":{"52":4,"756":1}}],["here",{"2":{"34":1,"94":1}}],["h",{"2":{"27":10,"61":2,"315":3,"317":3,"368":1,"372":2,"379":1,"394":1,"536":1,"660":1,"668":1}}],["所添加记录的url",{"2":{"798":1}}],["所添加记录的标�",{"2":{"798":1}}],["所描完事后",{"2":{"751":1}}],["所要求解的对偶问题的求解中",{"2":{"638":1}}],["所擅长处理的nlp任务也不同",{"2":{"521":1}}],["所",{"2":{"513":1}}],["所需的偏好数据",{"2":{"423":1}}],["所谓海量数据处理",{"2":{"768":1}}],["所谓聚类",{"2":{"396":1}}],["所谓的正则化",{"2":{"330":1}}],["所包含的信息越高级",{"2":{"311":1}}],["所收养",{"2":{"294":1}}],["所给出的条件慢慢分析",{"2":{"266":1}}],["所有master节点是一个管理节点负责调度",{"2":{"770":1}}],["所有在使用的时候",{"2":{"769":1}}],["所有在再整个建立过程是串行处理的",{"2":{"497":1}}],["所有的曝光的实例",{"2":{"740":1}}],["所有的这些条件都具备的概率基本并不大",{"2":{"198":1}}],["所有对于lr进行在线学习和更新",{"2":{"740":1}}],["所有簇内差异之和",{"2":{"684":1}}],["所有变量几乎不可能满足两两之间的条件",{"2":{"614":1}}],["所有变量的联合概率分布为",{"2":{"526":1}}],["所有样本按照评分排序",{"2":{"592":1}}],["所有样本中随机选择k个子样本选择最优属性来划分",{"2":{"497":1}}],["所有训练数据只用一次",{"2":{"546":1}}],["所有可能相同的url都在对应的小文件",{"2":{"747":1}}],["所有可能观测的集合",{"2":{"525":1}}],["所有可能状态的集合",{"2":{"525":1}}],["所有每次都是拟合的负梯",{"2":{"497":1}}],["所有树组合在一起",{"2":{"477":1}}],["所有回归树中通过特征i分裂后平方损失的减少值的和",{"2":{"462":1}}],["所有头共享k",{"2":{"422":1}}],["所有类的ap值平均值",{"2":{"393":1}}],["所有以",{"2":{"279":2}}],["所有颜色全不同的概率是6",{"2":{"277":1}}],["所有颜色全相同的概率是3",{"2":{"277":1}}],["所有8个饮料最多用三个小白鼠",{"2":{"269":1}}],["所有一对夫妇握手的次数和一定是8",{"2":{"268":1}}],["所有操作全部执行完以前其它会话不能看到过程",{"2":{"255":1}}],["所有浏览器支持",{"2":{"226":1}}],["所有函数都执行结束后",{"2":{"217":1}}],["所有函数操作完成后调用方法",{"2":{"217":1}}],["所有引擎都可以使用",{"2":{"173":1}}],["所有字符都有一个ascii值在",{"2":{"81":1}}],["所有输入只包含小写字母",{"2":{"74":1}}],["所有连接点",{"2":{"60":1}}],["所有顶点的起始指针",{"2":{"60":1}}],["所有我们将r扩大一倍",{"2":{"23":1}}],["所以当用户刷新页面之类的操作时",{"2":{"798":1}}],["所以我们只要将一些需要更新的方法放在这里面就可以实现",{"2":{"796":1}}],["所以我们的损失函数最小化可以转化",{"2":{"497":1}}],["所以倾向于推荐较为流行的items",{"2":{"730":1}}],["所以前期数据比较少",{"2":{"730":1}}],["所以推荐不准确",{"2":{"730":1}}],["所以上面的输出会有",{"2":{"689":1}}],["所以上下文的切换非常快",{"2":{"289":1}}],["所以最终簇内的平方误差和",{"2":{"682":1}}],["所以最后得出的拟合曲线不再是线性的了",{"2":{"657":1}}],["所以支持向量机只有很少的重要的训练样本决定",{"2":{"635":1}}],["所以这个模型被叫做支持向量机",{"2":{"635":1}}],["所以这个模型仍然能够工作得很好",{"2":{"614":1}}],["所以很容易陷入局部最优值",{"2":{"628":1}}],["所以很显然",{"2":{"109":1}}],["所以会带来一些准确率上的损失",{"2":{"626":1}}],["所以会对噪点较为敏感",{"2":{"471":1}}],["所以朴素贝叶斯算法应先处理特征",{"2":{"624":1}}],["所以其十分适合增量计算",{"2":{"623":1}}],["所以其长度",{"2":{"78":3}}],["所以加法平滑也叫做拉普拉斯平滑",{"2":{"618":1}}],["所以就是求max",{"2":{"612":1}}],["所以埋点中这些参数必须要有",{"2":{"575":1}}],["所以原假设是统计者想要拒绝的假设",{"2":{"571":1}}],["所以原作者在选择链表元素个数时选择�",{"2":{"120":1}}],["所以输出层每个神经元只有3个输入",{"2":{"566":1}}],["所以按每个参数",{"2":{"545":1}}],["所以只能摸索着根据直觉",{"2":{"542":1}}],["所以只能先回复一个ack报文",{"2":{"239":1}}],["所以是回归问题",{"2":{"654":1}}],["所以是判别模型",{"2":{"527":1}}],["所以是不会对数据上锁的",{"2":{"133":1}}],["所以它们都属于生成式模型",{"2":{"521":1}}],["所以它的计算量也是指的前向推理过程中乘加运算的次数",{"2":{"315":1}}],["所以要进行归一化才能成为一个有效的概率分布",{"2":{"521":1}}],["所以将目标函数进行二阶泰勒展开",{"2":{"516":1}}],["所以说成是拟合梯度",{"2":{"515":1}}],["所以访问梯度是连续的",{"2":{"514":1}}],["所以构建一次直方图就够",{"2":{"514":1}}],["所以每一层都要重新构建直方图",{"2":{"514":1}}],["所以每次分裂只需计算分裂后样本数较少的子节点的直方图然后通过做差的方式获得另一个子节点的直方图",{"2":{"497":1}}],["所以每次查询的效率都差不多",{"2":{"167":1}}],["所以需要进行校准",{"2":{"740":1,"741":1}}],["所以需要对最大深度做限制",{"2":{"514":1}}],["所以需要更多的卷积核来进行学习",{"2":{"311":1}}],["所以时间复杂度是o",{"2":{"497":1}}],["所以时间复杂度并不会增加多少",{"2":{"402":1}}],["所以xgboost还提出了一种可并行的近似直方图算法",{"2":{"497":2}}],["所以iterative",{"2":{"439":1}}],["所以在很多实验中",{"2":{"641":1,"672":1}}],["所以在做文本分类时",{"2":{"422":1}}],["所以在买卖股票时候取max能保证最优性不",{"2":{"26":1}}],["所以模型更容易捕捉词和词之间的距离关系",{"2":{"422":1}}],["所以如果总长度超过了模型的最大支持范围",{"2":{"422":1}}],["所以参数量为0",{"2":{"395":1}}],["所以结果为",{"2":{"394":1}}],["所以同一硬件处理相同图片所需的flops越小",{"2":{"394":1}}],["所以图片的尺寸需固定大小输入到cnn中",{"2":{"378":1}}],["所以神经元激活值为负时",{"2":{"350":1}}],["所以提取的是全局信息",{"2":{"329":1}}],["所以提取的是局部信息",{"2":{"329":1}}],["所以具体设定也是一个调参的过程",{"2":{"311":1}}],["所以共有2的3次方种可能",{"2":{"281":1}}],["所以四个人在不同的概率是",{"2":{"275":1}}],["所以可知这个蛋比其余的蛋重",{"2":{"270":1}}],["所以不可能将其完全加载到内存中处理",{"2":{"747":1}}],["所以不会有梯度弥散现象",{"2":{"350":1}}],["所以不会被压缩",{"2":{"81":1}}],["所以不需要使用更多的通信次数传输相同的信息",{"2":{"237":1}}],["所以速度极快",{"2":{"202":1}}],["所以没有任何磁盘寻址的开销",{"2":{"193":1}}],["所以通过二级索引查找行",{"2":{"165":1}}],["所以一张表可以有多个辅助索引",{"2":{"165":1}}],["所以又称为非阻塞同步",{"2":{"134":1}}],["所以",{"2":{"120":1,"140":1,"188":1,"270":1,"276":1,"739":1}}],["所以返",{"2":{"94":2}}],["所以先right后left",{"2":{"85":1}}],["所以k要减去左边丢弃的数的个数",{"2":{"48":1}}],["比基分类器的方差小",{"2":{"461":1}}],["比起这片区域的平均值来",{"2":{"339":1}}],["比http协议安全",{"2":{"247":1}}],["比�",{"2":{"192":1,"796":1}}],["比较lr和gbdt",{"0":{"502":1}}],["比较一下catboost",{"2":{"497":1}}],["比较两者的优缺点",{"0":{"439":1}}],["比较两个二叉树是否互为镜",{"2":{"91":1}}],["比较fasterrcnn在rcnn系列中的改进点",{"0":{"376":1}}],["比较训练损失和验证损失曲线",{"2":{"325":1}}],["比较容易遭到不法获取",{"2":{"244":1}}],["比较",{"2":{"134":1}}],["比较和替换是一个原子操�",{"2":{"134":1}}],["比较交换",{"2":{"134":1}}],["比较的次�",{"2":{"124":1}}],["比较的是地址",{"2":{"123":1}}],["比较的是值",{"2":{"123":1}}],["比较地址",{"2":{"123":1}}],["比较卖出持有股是否能得到更多的利润",{"2":{"26":1}}],["比",{"0":{"339":1},"2":{"83":1}}],["比如压缩打包",{"2":{"800":1}}],["比如改变浏览器大小",{"2":{"786":1}}],["比如改变",{"2":{"786":1}}],["比如电影片段或其他视频流�",{"2":{"776":1}}],["比如章节",{"2":{"776":1}}],["比如是map或者reduce任务",{"2":{"770":1}}],["比如外排序",{"2":{"763":1}}],["比如模1000",{"2":{"750":1}}],["比如ascii码值求和",{"2":{"747":1}}],["比如a2和a1",{"2":{"604":1}}],["比如喜欢搞笑的程度",{"2":{"730":1}}],["比如搞笑",{"2":{"730":1}}],["比如看电影的评分矩阵划分后",{"2":{"730":1}}],["比如评分场景",{"2":{"730":1}}],["比如乐天派一般评分范围一般会高于悲观的人",{"2":{"730":1}}],["比如买或者没买",{"2":{"730":1}}],["比如你非常喜欢电影",{"2":{"727":1}}],["比如你有位朋友看电影的爱好跟你类似",{"2":{"727":1}}],["比如你的网络层数",{"2":{"394":1}}],["比如一个特征是年龄",{"2":{"664":1}}],["比如如果对用户年龄离散化",{"2":{"664":1}}],["比如垃圾邮件识别",{"2":{"625":1}}],["比如文本分类问题里面",{"2":{"621":1}}],["比如异或",{"2":{"607":1}}],["比如某个节点小于100个样本",{"2":{"605":1}}],["比如缺失特征a的样本a之前权重为1",{"2":{"601":1}}],["比如长度",{"2":{"600":1}}],["比如实验组和对照组分流的流量是否均匀",{"2":{"575":1}}],["比如核svm",{"2":{"560":1}}],["比如搜索广告的点击率",{"2":{"546":1}}],["比如离散为256个bin时",{"2":{"514":1}}],["比如损失函数进行了二阶泰勒展开",{"2":{"503":1}}],["比如均方误差",{"2":{"497":1}}],["比如选择简单的逻辑回归",{"2":{"438":1}}],["比如表格",{"2":{"422":1}}],["比如判断情感",{"2":{"422":1}}],["比如新增类别",{"2":{"422":1}}],["比如裁剪图像进行重叠",{"0":{"403":1}}],["比如引入fpn结构",{"2":{"400":1}}],["比如s3fd中使用更低的conv3",{"2":{"385":1}}],["比如ssd或者faster",{"2":{"321":1}}],["比如roi分别在conv4和conv5上做roi",{"2":{"374":1}}],["比如说densenet中的模块之间的连接大多采用average",{"2":{"339":1}}],["比如说",{"2":{"336":1}}],["比如把01映射为0",{"2":{"278":1}}],["比如我们有很多性别",{"2":{"757":1}}],["比如我们要",{"2":{"174":1}}],["比如我�",{"2":{"218":1}}],["比如关键词是否正确等等",{"2":{"163":1}}],["比如提取上面这个语句是查�",{"2":{"163":1}}],["比如在数组中很简单的题目转换成链表就有很大的变动",{"2":{"63":1}}],["比如",{"2":{"57":1,"227":1,"301":1,"422":2,"469":1,"521":1,"574":1,"727":1,"776":1,"786":2}}],["比碍事j个数组合s的个",{"2":{"15":1}}],["用具体的例子和数据支撑",{"2":{"830":1}}],["用过mapreduce的思想了",{"2":{"769":1}}],["用字典树",{"2":{"763":1}}],["用哈希",{"2":{"763":1}}],["用位图表示",{"2":{"759":1}}],["用最小堆过滤n",{"2":{"756":1}}],["用最少的参数拓宽网络通道",{"2":{"320":1}}],["用公式表示如下",{"2":{"719":1,"722":1}}],["用相似度函数重新定义内积运算",{"2":{"635":1}}],["用反证法我们可以得到至少有一",{"2":{"635":1}}],["用朴素贝叶斯也通常能取得很好的效果",{"2":{"625":1}}],["用贝叶斯公式表达如下",{"2":{"614":1}}],["用白盒模型",{"2":{"607":1}}],["用一个大小为k的最大堆",{"2":{"763":1}}],["用一个简单的模型训练出一个连续的词向量",{"2":{"718":1}}],["用一个hash函数将用户的唯一标识进行hash取模",{"2":{"572":1}}],["用一个集合mstset维护已经满足要求的顶点",{"2":{"59":1}}],["用迭代公式进行迭代",{"2":{"547":1}}],["用普通的bgd算法",{"2":{"546":1}}],["用图模式",{"2":{"521":1}}],["用残差去拟合",{"2":{"515":1}}],["用float",{"2":{"514":1}}],["用for循环每次算一个卷积",{"2":{"357":1}}],["用int",{"2":{"514":1}}],["用采样集dt训练第t个决策树模型gt",{"2":{"475":1}}],["用采样集dt训练第t个弱学习器gt",{"2":{"455":1}}],["用调整后的样本",{"2":{"456":1}}],["用丰富多元的创意或战略案例扩充训练集",{"2":{"423":1}}],["用r1生成并人工筛选",{"2":{"423":1}}],["用rlhf优化模型生成的推理路径和答案质量",{"2":{"423":1}}],["用低学习率微调模型",{"2":{"423":1}}],["用低成本提升英文主导嵌入模型的中文能力",{"2":{"423":1}}],["用",{"2":{"423":1}}],["用扩增数据微调简单的分类器",{"2":{"423":1}}],["用特殊词元",{"2":{"423":1}}],["用余弦相似度损失更简单高效",{"2":{"423":1}}],["用注意力机制从视觉特征中提取关键信息",{"2":{"423":1}}],["用户根据需求设置的map函数",{"2":{"769":1}}],["用户背后的特征交互非常的复杂",{"2":{"732":1}}],["用户性别和年龄",{"2":{"732":1}}],["用户经常在饭点下载送餐app",{"2":{"732":1}}],["用户a",{"2":{"729":1}}],["用户一般可以设置以下四种参数",{"2":{"537":1}}],["用户个性化记忆",{"2":{"423":1}}],["用户更喜欢a",{"2":{"423":1}}],["用户反馈",{"2":{"423":1}}],["用户用语和文档表述方式可能不同",{"2":{"423":1}}],["用户查询可能简短或模糊",{"2":{"423":1}}],["用户输入",{"2":{"423":1}}],["用户提问时检索相关历史片段",{"2":{"423":1}}],["用户分段处理",{"2":{"422":1}}],["用初始模型对部分高置信度的无标签数据打标签",{"2":{"422":1}}],["用这$c",{"2":{"643":1}}],["用这k个分类器来测试",{"2":{"643":1}}],["用这",{"2":{"422":1}}],["用这个来训练rpn",{"2":{"367":1}}],["用这个节点来更新答案",{"2":{"93":1}}],["用这个节点更新ans",{"2":{"93":1}}],["用的就是掩码语言建模",{"2":{"422":1}}],["用的端口也不一样",{"2":{"247":1}}],["用零样本不用重新训练",{"2":{"422":1}}],["用更少的内存完成等价计算",{"2":{"422":1}}],["用归一化权重对值向量",{"2":{"422":1}}],["用查询向量",{"2":{"422":1}}],["用稍低一点的分数来代替原有的分数",{"2":{"397":1}}],["用处",{"2":{"397":1}}],["用逻辑回归替代softmax作为分类器",{"2":{"378":1}}],["用第二步的fast",{"2":{"373":1}}],["用双线性内插的方法计算出这四个位置的值",{"2":{"369":1}}],["用小的随机数初始化权重",{"2":{"354":1}}],["用可靠的模型诊断工具对模型进行诊断",{"2":{"354":1}}],["用stride为2的可学习卷积层来代替pooling可以得到更好的效果",{"2":{"313":1}}],["用在数据分化比较大的场景",{"2":{"306":1}}],["用私钥解密",{"2":{"252":1}}],["用于访问内置插件",{"2":{"800":1}}],["用于面试与复习",{"2":{"765":1}}],["用于发现曝光充分的id对应有区分性的特征",{"2":{"741":1}}],["用于增加随机性",{"2":{"507":1}}],["用于直接控制模型的复杂度",{"2":{"507":1}}],["用于防止过拟合",{"2":{"504":1}}],["用于高效地生成候选的分割点",{"2":{"497":2,"513":1}}],["用于控制模型的复杂度",{"2":{"497":1,"513":1}}],["用于下一轮",{"2":{"428":1}}],["用于后续模型微调和提升检索效果",{"2":{"423":1}}],["用于回答",{"2":{"423":1}}],["用于检测小物体",{"2":{"388":1}}],["用于检测大物体",{"2":{"388":1}}],["用于生成region",{"2":{"373":1}}],["用于通知接收进程某个事件已经发生",{"2":{"293":1}}],["用于从www服务器传输超文本到本地浏览器的传输协议",{"2":{"247":1}}],["用于大多数应用",{"2":{"240":1}}],["用于表示函数是一个异步函数�",{"2":{"218":1}}],["用法",{"0":{"226":1}}],["用现成api",{"2":{"222":1}}],["用另一个对象替换当前对象",{"2":{"213":2}}],["用二进制压缩文件",{"2":{"192":1}}],["用来学习高阶特征交互",{"2":{"736":1}}],["用来控制节假日的灵活度",{"2":{"537":1}}],["用来控制季节项的灵活度",{"2":{"537":1}}],["用来衡量词在文档中的重要性",{"2":{"422":1}}],["用来抑制检测时冗余的框",{"2":{"397":1}}],["用来回滚的相反操作日志",{"2":{"174":1}}],["用来实现分组唤醒需要唤醒的线程们",{"2":{"136":1}}],["用关键字",{"2":{"164":1}}],["用哪个关键字",{"0":{"164":1}}],["用我们上面提到的层次遍历",{"2":{"95":1}}],["用前一天own状态转移",{"2":{"26":1}}],["用own和sell分别保留这两种状态到目前为止所拥有的最大利润",{"2":{"26":1}}],["用m",{"2":{"11":1}}],["状态调�",{"2":{"836":1}}],["状态转移概率分布",{"2":{"525":1}}],["状态转移方程",{"2":{"104":1}}],["状态码组成",{"2":{"246":1}}],["状态定义",{"2":{"104":1}}],["状态",{"2":{"26":1}}],["状态和已经售出股票",{"2":{"26":1}}],["如底部对齐",{"2":{"784":1}}],["如今互联网产生的数据量已经达到pb级别",{"2":{"768":1}}],["如今的查询能通过立即的单词标示迅速获取结果",{"2":{"763":1}}],["如您在阅读过程中发现问题",{"2":{"765":1}}],["如年龄等",{"2":{"734":1}}],["如性别和地区",{"2":{"734":1}}],["如性别",{"2":{"734":1}}],["如上图所示",{"2":{"689":1}}],["如对会员作分群以后",{"2":{"684":1}}],["如按各自分割超平面",{"2":{"651":1}}],["如按照尾号的奇数或者偶数将其分为两组",{"2":{"572":1}}],["如k",{"2":{"648":1}}],["如l1",{"2":{"641":1,"672":1}}],["如下图所示",{"2":{"733":1}}],["如下主要分析user",{"2":{"727":1}}],["如下",{"2":{"586":1,"730":1}}],["如分到100个或1000个桶中",{"2":{"572":1}}],["如图所示",{"2":{"559":1}}],["如图像的语义分割",{"2":{"312":1}}],["如否",{"2":{"543":1}}],["如同马尔可夫随机场",{"2":{"519":1}}],["如自然语言文字或是生物序列",{"2":{"519":1}}],["如cart",{"2":{"497":1}}],["如随机森林",{"2":{"459":1}}],["如随机输出",{"2":{"423":1}}],["如50",{"2":{"423":1}}],["如创意写作或战略分析",{"2":{"423":1}}],["如数学",{"2":{"423":1}}],["如过程一致性损失",{"2":{"423":1}}],["如r树",{"2":{"648":1}}],["如rlhf",{"2":{"423":1}}],["如resnet",{"2":{"423":1}}],["如知识蒸馏",{"2":{"423":1}}],["如基于句向量的轻量模型",{"2":{"423":1}}],["如使用clip文本编码器或其他文本嵌入模型",{"2":{"423":1}}],["如faiss",{"2":{"423":2}}],["如某人物对白",{"2":{"423":1}}],["如人物关系",{"2":{"423":1}}],["如memory模块",{"2":{"423":1}}],["如max",{"2":{"313":1}}],["如日期",{"2":{"423":1}}],["如用户的浏览历史",{"2":{"734":1}}],["如用户目标",{"2":{"423":1}}],["如用户鉴权校验",{"2":{"189":1}}],["如加上",{"2":{"422":1}}],["如输出系统不允许的内容",{"2":{"422":1}}],["如文本",{"2":{"422":1}}],["如写作",{"2":{"422":1}}],["如翻译对",{"2":{"423":1}}],["如翻译",{"2":{"422":1}}],["如语法",{"2":{"422":1}}],["如冻结特定注意力头或lora微调",{"2":{"422":1}}],["如主谓一致",{"2":{"422":1}}],["如重叠",{"2":{"399":1}}],["如y",{"2":{"306":1}}],["如信号两",{"2":{"293":1}}],["如所有进程都在阻塞状态",{"2":{"291":1}}],["如此循环",{"2":{"466":1}}],["如此连续抽取3次",{"2":{"277":1}}],["如此反复",{"2":{"212":1}}],["如最低老鼠1死了",{"2":{"269":1}}],["如表格模型数据excel",{"2":{"256":1}}],["如匹配路由表不成功",{"2":{"250":1}}],["如是则解封装并将ip包移动到路由器内部",{"2":{"250":1}}],["如不是则丢弃",{"2":{"250":1}}],["如没有",{"2":{"250":2}}],["如有需要",{"2":{"423":1}}],["如有则重新封装出去",{"2":{"250":1}}],["如有",{"2":{"250":1}}],["如保持用户的登录状态",{"2":{"244":1}}],["如�",{"2":{"184":1,"185":1,"218":2,"792":1}}],["如",{"2":{"131":1,"211":1,"240":2,"422":9,"423":6,"613":1,"787":1}}],["如何更新",{"2":{"796":2}}],["如何开启",{"0":{"787":1}}],["如何清除浮动",{"0":{"785":1}}],["如何换行",{"2":{"782":1}}],["如何阻止元素默认行为�",{"0":{"779":1}}],["如何阻止事件冒泡",{"0":{"779":1}}],["如何shuffle",{"2":{"770":1}}],["如何编写map和reduce函数",{"2":{"769":1}}],["如何编写一个智能体",{"2":{"423":1}}],["如何想到使用计数排序或者在海量数据处理方面使用计数排序的思想呢",{"2":{"759":1}}],["如何根据gbdt建的两类树",{"2":{"741":1}}],["如何求解funk",{"2":{"731":1}}],["如何通过相似度计算设计协同过滤推荐系统",{"2":{"731":1}}],["如何选择协同过滤算法是基于user还是基于item",{"2":{"730":1}}],["如何选取好的iou",{"2":{"401":1}}],["如何简单计算user偏差以及item偏差",{"2":{"730":1}}],["如何比较",{"2":{"684":1}}],["如何进行高效的匹配查找",{"0":{"648":1}}],["如何采用二分法对连续特征离散化",{"2":{"603":1}}],["如何分组才能更好地避免混淆呢",{"0":{"572":1}}],["如何分步生成",{"2":{"423":1}}],["如何理解knn中的k的取值",{"0":{"647":1}}],["如何理解高方差与低偏差",{"0":{"558":1}}],["如何理解concat和add这两种常见的feature",{"0":{"392":1}}],["如何对k",{"0":{"684":1}}],["如何对梯度下降法进行调优",{"0":{"544":1}}],["如何对中文分词问题用hmm模型进行建模的训练",{"2":{"528":1}}],["如何控制",{"0":{"437":1}}],["如何将协同过滤用于推荐系统",{"2":{"731":1}}],["如何将这一方法扩展到更主观的领域",{"2":{"423":1}}],["如何将其转化为",{"2":{"423":1}}],["如何将其转换成适合",{"2":{"423":1}}],["如何将其拆分为多个智能体",{"2":{"423":1}}],["如何尽可能保留",{"2":{"423":1}}],["如何防止模型收敛到单一类型的高奖励回答",{"2":{"423":1}}],["如何防止模型在微调数据集以外的问题上泛化能力下降",{"2":{"423":1}}],["如何微调一个",{"2":{"423":1}}],["如何证实或证伪这个说法",{"2":{"423":1}}],["如何用较低的继续预训练成本提升其中文能力",{"2":{"423":1}}],["如何在数据量不断增大的情况下",{"2":{"768":1}}],["如何在特征值缺失的情况下进行划分特征的选择",{"2":{"601":1}}],["如何在保证模型获得特定领域知识的同时",{"2":{"423":1}}],["如何在系统层面检测提示词注入攻击",{"2":{"422":1}}],["如何扩增训练数据的数量",{"2":{"423":1}}],["如何构建训练数据集",{"2":{"423":1}}],["如何构建高质量的难负例",{"2":{"423":1}}],["如何构建一个",{"2":{"423":1}}],["如何生成负例以提升模型性能",{"2":{"423":1}}],["如何结合两者的能力来回答与多模态相关的问题",{"2":{"423":1}}],["如何解决",{"0":{"618":1,"698":1},"2":{"527":1,"528":1}}],["如何解决标签对齐问题",{"2":{"423":1}}],["如何解决这对矛盾",{"2":{"423":1}}],["如何解决文档分块后内容上下文缺失的问题",{"2":{"423":1}}],["如何处理跨片段的依赖关系",{"2":{"423":1}}],["如何确保系统在面对不完整或矛盾的信息时仍能提供合理建议",{"2":{"423":1}}],["如何确保其输出的语言始终限定在指定的词汇表中",{"2":{"422":1}}],["如何保证输出是合法",{"2":{"422":1}}],["如何保证其输出一定是几个类别之一",{"2":{"422":1}}],["如何保证模型的输出一定是合法的",{"2":{"422":1}}],["如何让模型",{"2":{"422":1}}],["如何让模型先思考后回答",{"2":{"422":1}}],["如何设计提示词模板",{"2":{"422":1}}],["如何设计�",{"2":{"168":1}}],["如何使用随机森林对特征重要性进行评估",{"0":{"483":1}}],["如何使用本章介绍的技术来提高主题之间的区分度",{"2":{"422":1}}],["如何使�",{"0":{"228":1,"229":1}}],["如何改进这个问题",{"2":{"497":1}}],["如何改进k",{"0":{"382":1}}],["如何改进",{"0":{"374":1},"2":{"385":1}}],["如何查看",{"0":{"164":1}}],["如何实现线程安全�",{"0":{"148":1}}],["如何判断是否可以回�",{"2":{"110":1}}],["如何优化呢",{"2":{"26":1}}],["如果页面元素很多",{"2":{"792":1}}],["如果的确能够显著提高性能",{"2":{"787":1}}],["如果的已经排序的结果中",{"2":{"60":1}}],["如果项目未设置高度或设为",{"2":{"782":1}}],["如果能将数据均匀分配",{"2":{"758":1}}],["如果能将决策树用于回归的话可以扩大它的使用范围",{"2":{"600":1}}],["如果允许有一定的错误率",{"2":{"747":1}}],["如果用户在分界点",{"2":{"730":1}}],["如果用户跟模型对话轮次过多",{"2":{"423":1}}],["如果目标用户包含在所计算的特征矩阵里面的话",{"2":{"730":1}}],["如果中心词是生僻词",{"2":{"725":1}}],["如果训练样本的中心词是一个很生僻的词",{"2":{"721":1}}],["如果所有的点在指派步骤都未分配到某个簇",{"2":{"685":1}}],["如果维数不多也可以做一定的降维处理",{"2":{"684":1}}],["如果我希望能把常客与其他顾客区别开来",{"2":{"679":1}}],["如果我们知道所有的数字只出现一次",{"2":{"759":1}}],["如果我们只是想得到词向量",{"2":{"718":1}}],["如果我们设置概率阈值为0",{"2":{"659":1}}],["如果我们能够找到一种函数",{"2":{"635":1}}],["如果我们需要求解损失函数的最大值",{"2":{"540":1}}],["如果我们需要生成小说的标题",{"2":{"423":1}}],["如果我们要自己蒸馏一个较小的垂直领域模型",{"2":{"423":1}}],["如果这种情况发生",{"2":{"685":1}}],["如果这是一家奢侈品商店",{"2":{"679":1}}],["如果这个数字出现怎对应的位置就是1",{"2":{"759":1}}],["如果这个对象内部不存在这个属性",{"2":{"212":1}}],["如果这个",{"2":{"184":1}}],["如果label=",{"0":{"668":1}}],["如果特征没有离散化",{"2":{"664":1}}],["如果特征很多",{"0":{"606":1,"609":1}}],["如果查找点在切分维坐标小于当前点的切分维坐标",{"2":{"651":1}}],["如果kd树非空",{"2":{"651":1}}],["如果总词数为n",{"2":{"621":1}}],["如果粒度太粗",{"2":{"620":1}}],["如果粒度太细",{"2":{"620":1}}],["如果属性间依赖对所有类别影响相同",{"2":{"617":1}}],["如果以后还有新的信息引入",{"2":{"613":1}}],["如果把这个条件拿出来也是可以帮助分析数据",{"2":{"606":1,"609":1}}],["如果下一次切分没有降低误差",{"2":{"605":1}}],["如果模型是随机的",{"2":{"591":1}}],["如果相差太大",{"2":{"575":1}}],["如果50",{"2":{"573":1}}],["如果失活概率为0",{"2":{"566":1}}],["如果将梯度向量简写为g",{"2":{"555":1}}],["如果将所有数据复制一倍放入训练数据集",{"2":{"497":1}}],["如果存在",{"2":{"756":1}}],["如果存在n维向量w和实数b",{"2":{"634":1}}],["如果存在其δ邻域",{"2":{"554":1}}],["如果存在返回下标",{"2":{"41":1}}],["如果对原始数据进行降噪训练",{"2":{"629":1}}],["如果对n个计数都加上lambda",{"2":{"618":1}}],["如果对可行域内所有点x都有f",{"2":{"554":1}}],["如果对长字符串列进行索引",{"2":{"169":1}}],["如果令δx=−∇f",{"2":{"547":1}}],["如果忽略一次以上的项",{"2":{"547":1}}],["如果样本数据很大",{"2":{"545":1}}],["如果取值无效",{"2":{"544":1}}],["如果损失函数在变小",{"2":{"544":1}}],["如果损失函数是凸函数",{"2":{"542":1,"544":1}}],["如果只考虑前n",{"2":{"527":1}}],["如果只能修改rpn网络的话",{"0":{"400":1}}],["如果您有100个观察值",{"2":{"512":1}}],["如果任一个叶子结点的样本权重低于某一个阈值",{"2":{"507":1}}],["如果分裂后目标函数的增益小于该阈值",{"2":{"507":1}}],["如果加了限制",{"2":{"484":1}}],["如果某个量x",{"2":{"618":1}}],["如果某个样本该特征值缺失",{"2":{"504":1}}],["如果某些特征的样本比例过大",{"2":{"607":1}}],["如果某些样本缺失的特征值缺失",{"2":{"508":1}}],["如果某节点的不纯度",{"2":{"484":1}}],["如果某节点的样本数少于min",{"2":{"484":1}}],["如果某叶子节点数目小于样本数",{"2":{"484":1}}],["如果它被分类错误",{"2":{"427":1}}],["如果它没有和最小支撑顶点形成环",{"2":{"59":1}}],["如果一个数据实例缺失了一个属性的数值",{"2":{"630":1}}],["如果一个人有多个账号",{"0":{"576":1}}],["如果一个样本被准确分类",{"2":{"427":1}}],["如果一个对象具有强引用",{"2":{"122":1}}],["如果一个对象是第二次经历从",{"2":{"110":1}}],["如果一共有n个样本",{"2":{"427":1}}],["如果要堆a升序排序",{"2":{"756":1}}],["如果要在一个非推理型模型的基础上通过强化学习",{"2":{"423":1}}],["如果要定义全局变量",{"2":{"112":1}}],["如果困惑度高",{"2":{"423":1}}],["如果标注的训练数据很少",{"2":{"423":1}}],["如果需要我们可以堆这k进行任何排序",{"2":{"756":1}}],["如果需要根据某长篇小说的内容回答问题",{"2":{"423":1}}],["如果需要通过修改尽可能少的参数值",{"2":{"422":1}}],["如果单一智能体的提示词过长",{"2":{"423":1}}],["如果开发一个学习英语的应用",{"2":{"422":1}}],["如果iou阈值较低",{"2":{"401":1}}],["如果iou阈值过高",{"2":{"401":1}}],["如果正样本不足",{"2":{"370":1}}],["如果过大",{"2":{"333":1}}],["如果网络层的输出爆炸或者消失",{"2":{"323":1}}],["如果网络断开了连接",{"2":{"194":1}}],["如果子进程退出",{"2":{"294":1}}],["如果结果是01则产生0",{"2":{"278":1}}],["如果结果是00或11就丢弃重来",{"2":{"278":1}}],["如果都是3次都是红色概率则是",{"2":{"277":1}}],["如果选择y作为一条边肯定不满足",{"2":{"274":1}}],["如果x=1",{"2":{"267":1}}],["如果实在不行就",{"2":{"266":1}}],["如果在随机采样的情况下",{"2":{"669":1}}],["如果在损失函数最终收敛的情况下",{"2":{"669":1}}],["如果在网络初始化时给网络赋予0的权重",{"0":{"322":1}}],["如果在浏览器缓存中没有找到ip",{"2":{"249":1}}],["如果在不同的子网",{"2":{"235":1}}],["如果收到段的检验和有差错",{"2":{"241":1}}],["如果想要禁止用",{"0":{"228":1}}],["如果想继续持有",{"2":{"185":1}}],["如果业务中有置顶的需求",{"2":{"200":1}}],["如果再严谨点",{"2":{"199":1}}],["如果再次import",{"2":{"112":1}}],["如果你的项目进度落后了",{"2":{"826":1}}],["如果你的上级给你安排了一个不合理的任务",{"0":{"826":1}}],["如果你需要在短时间内学习一门新技术",{"2":{"826":1}}],["如果你发现同事的工作有问题",{"2":{"826":1}}],["如果你写入数据库的值",{"2":{"196":1}}],["如果你是一个写数据库场景比较多",{"2":{"196":1}}],["如果你最多只允许完成一次交",{"2":{"24":1}}],["如果数据文件特别大",{"2":{"192":1}}],["如果数组有序可以使用搞笑的折半查找",{"2":{"50":1}}],["如果采用这种方案",{"2":{"185":1}}],["如果客户�",{"2":{"185":2}}],["如果因为某些原因导致事务失败或回滚了",{"2":{"174":1}}],["如果联合索引列的前置列与索引单列一致",{"2":{"168":1}}],["如果检查没问题就执行下一�",{"2":{"163":1}}],["如果有的文件超过了1m大小",{"2":{"749":1}}],["如果有多个空簇",{"2":{"685":1}}],["如果有多个",{"2":{"662":1}}],["如果有多个分组并行进行的情况的话",{"2":{"572":1}}],["如果有k类",{"2":{"643":1}}],["如果有很多的特征高度相关或者说有一个特征重复了100遍",{"0":{"669":1}}],["如果有很大一部分的特征遗失",{"2":{"485":1}}],["如果有很长",{"0":{"403":1}}],["如果有标注数据",{"2":{"422":1}}],["如果有n个类别",{"2":{"397":1}}],["如果有直接缓存",{"2":{"163":1}}],["如果有权限就会调用数据库引擎接口",{"2":{"163":1}}],["如果有权限",{"2":{"163":1}}],["如果有环",{"2":{"68":1}}],["如果提交的数据",{"2":{"133":1}}],["如果复写了则根据复写的判断方式",{"2":{"123":1}}],["如果内存空间不足了",{"2":{"122":1}}],["如果内存空间足够",{"2":{"122":1}}],["如果扩容因子过低",{"2":{"119":1}}],["如果扩容因子过高",{"2":{"119":1}}],["如果占比过高",{"2":{"110":1}}],["如果新生代内存空间不够",{"2":{"110":1}}],["如果包含对这个值引用的变量又取得了另外一个值",{"2":{"110":1}}],["如果同一个值又被赋给另一个变量",{"2":{"110":1}}],["如果为1则返",{"2":{"82":1}}],["如果不归一化就算k",{"2":{"679":1}}],["如果不是",{"2":{"252":1}}],["如果不能及时收到一个确认",{"2":{"241":1}}],["如果不采用给缓存设置过期时间策略",{"2":{"197":1}}],["如果不包含则会获得一个返回的数字",{"2":{"185":1}}],["如果不存在",{"2":{"82":1}}],["如果不存在公共前缀",{"2":{"74":1}}],["如果不使",{"2":{"34":1}}],["如果链表只有这一个节",{"2":{"70":1}}],["如果首节点的元素即是要删除的元素",{"2":{"70":1}}],["如果没有这样的索引",{"2":{"165":1}}],["如果没有定义主键",{"2":{"165":1}}],["如果没有",{"2":{"163":1,"796":2}}],["如果没有权限就会返回错误信息",{"2":{"163":1}}],["如果没有权限",{"2":{"163":1}}],["如果没有手动释放锁",{"2":{"139":1}}],["如果没有复写",{"2":{"123":1}}],["如果没有发现指定模块",{"2":{"112":1}}],["如果没有环",{"2":{"68":1}}],["如果没股票",{"2":{"26":1}}],["如果是00变01",{"2":{"751":1}}],["如果是则更新最近邻点和最近邻距离",{"2":{"651":1}}],["如果是连续值还有大量的排序运算",{"2":{"600":1}}],["如果是回归算法",{"2":{"455":1,"475":1}}],["如果是分类算法预测",{"2":{"455":1,"475":1}}],["如果是通道数相同且后面带卷积的话",{"2":{"392":1}}],["如果是右端重也是一样的",{"2":{"270":1}}],["如果是首次连接",{"2":{"194":1}}],["如果是写操作",{"2":{"143":1}}],["如果是引用数据类型",{"2":{"123":1}}],["如果是基本数据类型",{"2":{"123":1}}],["如果是",{"2":{"61":1,"252":1,"747":2}}],["如果使用n阶展开就要求损失函数n阶可导",{"2":{"497":1}}],["如果使用",{"2":{"34":1}}],["如果两",{"2":{"33":1}}],["如果可以已经使用的特征a和特征b可以提点特征c",{"2":{"606":1,"609":1}}],["如果可以通过",{"2":{"32":1}}],["如果可能贪心一般都可以使用动态规划解决",{"2":{"17":1}}],["如果bin容器的数量小于4",{"2":{"470":1}}],["如果b",{"2":{"27":2}}],["如果其他的猫萌系数变",{"2":{"27":1}}],["如果满足prices",{"2":{"25":1}}],["如果当前帧已经没有空闲时间",{"2":{"792":1}}],["如果当前帧还有空闲时间",{"2":{"792":1}}],["如果当前等级大于最大等",{"2":{"95":1}}],["如果当前位置",{"2":{"33":1}}],["如果当前有股票",{"2":{"26":1}}],["如果当前",{"2":{"23":1}}],["如果发现不满足条件",{"2":{"20":1}}],["如果sum",{"2":{"763":1}}],["如果s",{"2":{"18":1}}],["如果",{"2":{"7":1,"110":1,"134":1,"211":1,"218":2,"235":1,"502":1,"508":1,"640":2}}],["考虑采取分而治之的方法",{"2":{"747":1}}],["考虑不同用户的评价范围不一样",{"2":{"730":1}}],["考虑到",{"2":{"725":1}}],["考虑到算法中如果不需写出分离超平面",{"2":{"635":1}}],["考虑函数间隔与几何间隔的关系式",{"2":{"635":1}}],["考虑a和任意一个categorical",{"2":{"446":1}}],["考虑使用categorical",{"2":{"446":1}}],["考虑bias",{"2":{"394":2,"395":2}}],["考虑连续产生两个随机数",{"2":{"278":1}}],["考虑每一天同时维护两种状态",{"2":{"26":1}}],["考虑购买或者跳过",{"2":{"26":1}}],["考虑出售或者保留",{"2":{"26":1}}],["而原因就�",{"2":{"792":1}}],["而被广泛使用",{"2":{"739":1}}],["而deepfm的wide部分采用fm模型",{"2":{"738":1}}],["而depthwiseconvolution大概只需要1秒",{"2":{"357":1}}],["而数值特征无需进行embedding",{"2":{"734":1}}],["而协同过滤是不考虑内容直接分析items之间的关系或者users之间的关系",{"2":{"730":1}}],["而如果没有人进行评分",{"2":{"730":1}}],["而如果是图片中有较多小目标物体需要检测",{"2":{"369":1}}],["而修正的余弦系数则采用两个用户各自的评分集",{"2":{"730":1}}],["而word2vec是基于上下文局部语料计算共现概率",{"2":{"725":1}}],["而negative",{"2":{"725":1}}],["而负样本为除了w之外的所有词",{"2":{"721":1}}],["而模型的计算瓶颈主要在第二步",{"2":{"718":1}}],["而簇间相似度尽可能地小",{"2":{"684":1}}],["而sigmoid能够把它映射到",{"2":{"670":1}}],["而svm的理解和优化相对来说复杂一些",{"2":{"641":1,"672":1}}],["而分类范围",{"2":{"666":1}}],["而分类过程为有监督过程",{"2":{"396":1}}],["而逻辑回归则是似然函数",{"2":{"666":1}}],["而逻辑回归通过非线性映射",{"2":{"641":1,"672":1}}],["而中间概率的变化很大",{"2":{"663":1}}],["而岭回归也正则化的不够",{"2":{"657":1}}],["而只需要知道其核函数",{"2":{"638":1}}],["而只有较大的参数值才能产生较大的导数",{"2":{"562":1}}],["而引入这样的映射后",{"2":{"638":1}}],["而对于不是我们需要的样本",{"2":{"721":1}}],["而对于所有属于d1的点",{"2":{"634":1}}],["而对于own",{"2":{"26":1}}],["而目标是确定新数据点将归属到哪个类中",{"2":{"634":1}}],["而利用则是根据后验分布在最可能出现全局最值的区域进行采样",{"2":{"628":1}}],["而lr则对此没有要求",{"2":{"632":1}}],["而lr为判别模",{"2":{"632":1}}],["而lr适用于大规模数据集",{"2":{"627":1,"632":1}}],["而lightgbm和catboost则是在xgboost基础上做了进一步的优化",{"2":{"497":1}}],["而lightgbm则是计算将样本离散化为直方图后的直方图切割位置的增益即可",{"2":{"497":1}}],["而垃圾文本过",{"2":{"625":1}}],["而由于对部分数据的过度拟合",{"2":{"622":1}}],["而具体的p",{"2":{"612":1}}],["而采取随机选择的方式避免过度拟合",{"2":{"605":1}}],["而决策树的这些规则是通过训练样本自动学习得到的",{"2":{"597":1}}],["而得分s",{"2":{"591":1}}],["而在千万级甚至更大的数据集上",{"2":{"718":1}}],["而在很多情况下",{"2":{"614":1}}],["而在测试时",{"2":{"565":1}}],["而在未知数据上表现差",{"2":{"559":1}}],["而在正负饱和区域的梯度趋向于0",{"2":{"350":1}}],["而实际测试时是不会有dropout的",{"2":{"566":1}}],["而实际上数据库的写操作会比读操作慢得多",{"2":{"198":1}}],["而实现",{"2":{"548":1}}],["而online",{"2":{"546":1}}],["而order为",{"2":{"397":1}}],["而最大熵模型是直",{"2":{"521":1}}],["而直方图算法在建立完直方图后",{"2":{"514":1}}],["而为每个节点增加了一个缺省方向",{"2":{"508":1}}],["而为了消除残差",{"2":{"497":1}}],["而我们都知道",{"2":{"502":1}}],["而其他类似logloss这样的目标函数不能表示成这样形式",{"2":{"516":1}}],["而其他的bin容器就是另一个many集合",{"2":{"470":1}}],["而其",{"2":{"502":1}}],["而catboost使用了对称树结构",{"2":{"497":1}}],["而concat是通道数的合并",{"2":{"392":1}}],["而损失函数的定义就决定了在子区域内各个步长",{"2":{"497":1}}],["而弱分类器的训练时间往往很长",{"2":{"487":1}}],["而这在计算机的表示下就是词向量",{"2":{"725":1}}],["而这些属性只是影响元素的外观",{"2":{"786":1}}],["而这些梯度的获取顺序是按照特征的大小顺序的",{"2":{"514":1}}],["而这些样本的特征",{"2":{"502":1}}],["而这正是随机森林独特的优点",{"2":{"484":1}}],["而这个",{"2":{"422":1}}],["而这个t",{"2":{"367":1}}],["而随机森林仅仅考虑一个特征子集",{"2":{"481":1}}],["而后面的分类器为了达到较低的带权分类误差",{"2":{"440":1}}],["而要引入",{"2":{"423":1}}],["而小说的长度远远超出了上下文限制",{"2":{"423":1}}],["而非共现概率",{"2":{"520":1}}],["而非逐轮堆叠原始对话",{"2":{"423":1}}],["而非一次",{"2":{"165":1}}],["而零样本分类方式获得了",{"2":{"422":1}}],["而传统中文分词是为了符合人类语义理解习惯",{"2":{"422":1}}],["而",{"2":{"422":2}}],["而roc曲线下的面积",{"2":{"591":1}}],["而rf的核心就是自采样",{"2":{"497":1}}],["而rf每次都是独立的随机采样",{"2":{"497":1}}],["而rrpn的提议框带有旋转角度",{"2":{"404":1}}],["而rrpn可以检测任意方向的文本",{"2":{"404":1}}],["而relu在大于0的部分梯度为常数",{"2":{"350":1}}],["而relu没有饱和区",{"2":{"328":1}}],["而位置信息又是主要在网络的低层",{"2":{"401":1}}],["而adaboost算法是前向分布加法算法的特例",{"2":{"493":1}}],["而add形式则将对应的特征图相加",{"2":{"392":1}}],["而a8握了别家的所有人的手",{"2":{"268":1}}],["而每一特征下的信息是没有增加",{"2":{"392":1}}],["而每次交易都必须付手续费",{"2":{"26":1}}],["而提出一种级联",{"2":{"389":1}}],["而有的尝试并没有提升模型性能",{"2":{"378":1}}],["而有时我们需要将图像恢复到原来的尺寸以便进行进一步的计算",{"2":{"312":1}}],["而batchnormalization的作用是通过规范化的手段",{"2":{"351":1}}],["而深度学习里的卷积网络可实现对局部区域信息的提取",{"2":{"327":1}}],["而池化层是不可学习的",{"2":{"313":1}}],["而验证集损失不再下降时",{"2":{"307":1}}],["而内核主要负责对需要运行的任何其他的进程进行调度",{"2":{"301":1}}],["而磁盘i",{"2":{"301":1}}],["而它的一个或多个子进程还在运行",{"2":{"294":1}}],["而父进程并没有调用wait或waitpid获取子进程的状态信息",{"2":{"294":1}}],["而暂时停止运行",{"2":{"291":1}}],["而又要晚于写操作删除缓存",{"2":{"198":1}}],["而读操作必需在写操作前进入数据库操作",{"2":{"198":1}}],["而读数据场景比较少的业务需求",{"2":{"196":1}}],["而客户端1也以为自己成功加了锁",{"2":{"185":1}}],["而同时查询a",{"2":{"168":1}}],["而是会直接将其挂到更新队列中�",{"2":{"793":1}}],["而是直接",{"2":{"635":1}}],["而是他做了什么",{"2":{"576":1}}],["而是到了某一个局部的山势低处",{"2":{"542":1}}],["而是所有feature共享一个直方图",{"2":{"514":1}}],["而是特征维度的并",{"2":{"505":1}}],["而是特征维度的并行",{"2":{"504":1}}],["而是设定了一个搜索bin容器数量的上限值",{"2":{"470":1}}],["而是边读边计算最大值与加权和",{"2":{"422":1}}],["而是从不同子空间学习多样化的关联模式",{"2":{"422":1}}],["而是需要手工设置",{"2":{"385":1}}],["而是由它们计算得到的偏移量",{"2":{"367":1}}],["而是在整个用户会话中一直存在下去",{"2":{"244":1}}],["而是执行快恢复算法fr",{"2":{"243":1}}],["而是要经过一系列复杂的计算再写入缓存",{"2":{"196":1}}],["而是行的主键值",{"2":{"165":1}}],["而是主键值",{"2":{"165":1}}],["而是系统版本�",{"2":{"162":1}}],["而没有阻塞",{"2":{"131":1}}],["而当变量离开环境时",{"2":{"110":1}}],["而多线程同步",{"2":{"109":1}}],["而与多线程同�",{"2":{"109":1}}],["而不同的网络产生不同的过拟合",{"2":{"564":1}}],["而不仅仅是局部归一化",{"2":{"520":1}}],["而不需要使用过采样的方法来调整样本权重",{"2":{"460":1}}],["而不会影响布局的",{"2":{"786":1}}],["而不会输出无关内容",{"2":{"422":1}}],["而不会产生过拟合",{"2":{"378":1}}],["而不大关心这个object位置在哪",{"2":{"339":1}}],["而不是基于推荐目标当前的相似item",{"2":{"730":1}}],["而不是",{"0":{"705":1}}],["而不是硬的二分类",{"2":{"703":1}}],["而不是事物真实的值",{"2":{"654":1}}],["而不是人",{"2":{"576":1}}],["而不是小于0",{"2":{"574":1}}],["而不是所有的特征都去作为拆分特征",{"2":{"489":1}}],["而不是直接拟合残",{"0":{"515":1}}],["而不是直接将视觉编码器输出接入语言模型",{"2":{"423":1}}],["而不是直接置零",{"2":{"397":1}}],["而不是固定的位置编号",{"2":{"422":1}}],["而不是知道这�",{"2":{"220":1}}],["而不是像",{"2":{"136":1,"422":1}}],["而不",{"2":{"94":1}}],["而且它会减少移动端设备的电池寿命",{"2":{"787":1}}],["而且每一个数都小于等于n",{"2":{"763":1}}],["而且进行了非线性的组合变换",{"2":{"739":1}}],["而且一般items的量非常多",{"2":{"730":1}}],["而且对最难分的点",{"2":{"635":1}}],["而且不同的国家有着不同的假期",{"2":{"536":1}}],["而且特征已经被存储为一个个block结构",{"2":{"505":1}}],["而且树模型很容易过拟合",{"2":{"502":1}}],["而且只能在具有亲缘关系的进程间使用",{"2":{"293":1}}],["而且出现的次数相同",{"2":{"279":1}}],["而且两人的数字相差1",{"2":{"267":1}}],["而且还要锁表",{"2":{"198":1}}],["而且并发着有一个写操作",{"2":{"198":1}}],["而且",{"2":{"197":1}}],["而且描述起来很麻烦",{"2":{"57":1}}],["而且没有访问",{"2":{"33":1}}],["而且你不能持有超",{"2":{"26":1}}],["只重绘",{"2":{"786":1}}],["只根据用户行为",{"2":{"730":1}}],["只用到一阶泰勒展开",{"2":{"513":1}}],["只针对了学习一棵树且是回归问题的情况",{"2":{"470":1}}],["只是效率问题",{"2":{"769":1}}],["只是一种思想并不代表业界的技术策略",{"2":{"754":1,"768":1}}],["只是重复的次数比较多而已",{"2":{"748":1}}],["只是可能中间很多特征的值正负相消了",{"2":{"669":1}}],["只是这个条件在这棵树中是无用的",{"2":{"606":1,"609":1}}],["只是目标函数是均方误差的一种特殊情况",{"2":{"515":1}}],["只是用梯度去拟合",{"2":{"515":1}}],["只是为了便于理解",{"2":{"470":1}}],["只是每一维下的信息量在增加",{"2":{"392":1}}],["只让子集合较大的bin容器参加划分阈值计算",{"2":{"470":1}}],["只考虑选择一个特征",{"2":{"446":1}}],["只考虑字母和数字字符",{"2":{"76":1}}],["只给第一个词元贴标签",{"2":{"423":1}}],["只需函数支持一阶和二阶求导",{"2":{"513":1}}],["只需取一个向量",{"2":{"423":1}}],["只需要给定具体的核函数即可",{"2":{"638":1}}],["只需要知道属于哪个类的概率最大即可",{"2":{"631":1}}],["只需要对每个特征遍历直方图即可",{"2":{"514":1}}],["只需要用8位整形就可以保存一个样本被映射为哪个bin",{"2":{"514":1}}],["只需要其一阶",{"2":{"511":1}}],["只需要新的损失函数二阶可导",{"2":{"504":1}}],["只需要计算k次",{"2":{"465":1}}],["只需要在上面接一个简单的分类器",{"2":{"422":1}}],["只需要在卖出时支",{"2":{"26":1}}],["只需要选取当recall",{"2":{"393":1}}],["只需要o",{"2":{"202":1}}],["只允许从以下选项中选择一个",{"2":{"422":1}}],["只允许进程在没有占用资源的时候才能申请资源",{"2":{"297":1}}],["只看见对方的",{"2":{"267":2}}],["只要提map和reduce函数",{"2":{"769":1}}],["只要利用全部有评价的信息",{"2":{"730":1}}],["只要训练复杂度高于o",{"2":{"662":1}}],["只要各类别的条件概率排序正确",{"2":{"617":1}}],["只要没有到达梯度为0的点",{"2":{"547":1}}],["只要二阶可导即可",{"2":{"516":1}}],["只要损失函数一阶",{"2":{"504":1}}],["只要函数可一阶和二阶求导",{"2":{"497":1}}],["只要数据样本对应的bin容器编号在这些阈值对应的bin集合之中",{"2":{"470":1}}],["只要角度公式支持",{"2":{"422":1}}],["只要格式规范",{"2":{"422":1}}],["只要是对象就有原�",{"2":{"212":1}}],["只要垃圾回收器没有回收它",{"2":{"122":1}}],["只会查找版本早于当前事务版本的数据行",{"2":{"162":1}}],["只不过实现方式不同",{"2":{"140":1}}],["只能将大文件分成几个小文件",{"2":{"763":1}}],["只能表示维度数量的单词",{"2":{"725":1}}],["只能找到球状群",{"2":{"676":1}}],["只能发现球形类簇",{"2":{"396":1}}],["只能选x作为一个边",{"2":{"274":1}}],["只能根据两边只差＞第三边进行排除",{"2":{"274":1}}],["只能根据",{"2":{"266":1}}],["只能保存",{"2":{"244":1}}],["只能由主节点到从节�",{"2":{"194":1}}],["只能借助",{"2":{"135":1}}],["只能在结尾是0的后面加1",{"2":{"12":1}}],["只具有弱引用的对象拥有更短暂的生命周期",{"2":{"122":1}}],["只有在内容超�",{"2":{"774":1}}],["只有大量的评分之后",{"2":{"730":1}}],["只有局部语义",{"2":{"694":1}}],["只有活跃的描述符才会触发回调函数",{"2":{"302":1}}],["只有自己是2的时候",{"2":{"267":1}}],["只有y=2的时候",{"2":{"267":1}}],["只有当发送方发送并收到确认之后",{"2":{"242":1}}],["只有当访问一个key时",{"2":{"201":1}}],["只有等到我服务端所有的报文都发送完了",{"2":{"239":1}}],["只有一个自变量的情况称为简单回归",{"2":{"654":1}}],["只有一个请求能获得锁",{"2":{"184":1}}],["只有一个数出现了一次",{"2":{"43":1}}],["只有进行递归即可",{"2":{"90":1}}],["只包含数",{"2":{"83":1}}],["代入w∗和样本点",{"2":{"635":1}}],["代开",{"2":{"621":2}}],["代开发票发票代开发票p",{"2":{"621":1}}],["代价越低",{"2":{"590":1}}],["代价函数不一定就小",{"2":{"515":1}}],["代价函数除了loss还有正则项",{"2":{"515":1}}],["代表这个anchor中是否存在物体",{"2":{"386":1}}],["代表这个锁",{"2":{"185":1}}],["代表的是ground",{"2":{"367":1}}],["代表数据库",{"2":{"258":2}}],["代表着服务器和客户端一次会话的过程",{"2":{"244":1}}],["代表超过了范围的数",{"2":{"210":1}}],["代表非数字",{"2":{"210":1}}],["代表生成括号的对数",{"2":{"80":1}}],["代表了交易手续费",{"2":{"26":1}}],["代码抽象",{"2":{"769":1}}],["代码执行",{"2":{"423":1}}],["代码执行完后系统会自动让线程释放对锁的占用",{"2":{"139":1}}],["代码库",{"2":{"423":1}}],["代码中则会判断该锁",{"2":{"185":1}}],["代码实现一下深拷贝对象�",{"0":{"223":1}}],["代码实现一下展平数组",{"0":{"222":1}}],["代码实现",{"2":{"105":1}}],["代码",{"2":{"22":1}}],["然而基于user的会给推荐目标带来惊喜",{"2":{"730":1}}],["然而要求评分矩阵元素不能为空",{"2":{"730":1}}],["然而当kd",{"2":{"651":1}}],["然而整个",{"2":{"440":1}}],["然而",{"2":{"198":1,"301":1,"484":1}}],["然后你就可以利用",{"2":{"800":1}}],["然后仅仅将需要变化的部分进行实际的浏览器",{"2":{"790":1}}],["然后读入文章进行比较",{"2":{"763":1}}],["然后按照该值存到5000个小文件",{"2":{"749":1}}],["然后按出现次数做快速",{"2":{"748":1}}],["然后挨个读取另外一个文件的url",{"2":{"747":1}}],["然后遍历另一个小文件的每个url",{"2":{"747":1}}],["然后我们只要求出1000对小文件中相同的url即可",{"2":{"747":1}}],["然后根据所取得的值将url分别存储到1000个小文件",{"2":{"747":1}}],["然后根据该值去聚簇索引找到对应行�",{"2":{"165":1}}],["然后把它添加�",{"2":{"800":1}}],["然后把bin的编号作为离散型特征",{"2":{"739":1}}],["然后把所提取的特征输入到",{"2":{"366":1}}],["然后进行推荐",{"2":{"730":1}}],["然后进行最大池化操作",{"2":{"369":1}}],["然后最近新上了",{"2":{"727":1}}],["然后最大化它的几何间隔",{"2":{"634":1}}],["然后带动其他词的学习",{"2":{"725":1}}],["然后建立二叉树节点",{"2":{"604":1}}],["然后对这些绝对值取最大值即得此评分模型的k",{"2":{"592":1}}],["然后对于每个anchor",{"2":{"381":1}}],["然后计算完users之间的相似度后",{"2":{"730":1}}],["然后计算未知样本到各质心的距离",{"2":{"651":1}}],["然后计算这两组数据的差异和确定该差异是否存在统计上的显著性",{"2":{"571":1}}],["然后计算pr曲线下面积作为ap值",{"2":{"393":1}}],["然后用相应的离散区间替换连续属性值",{"2":{"620":1}}],["然后用贝叶斯公式对发生概率进行修正",{"2":{"615":1}}],["然后用下面的公式进行迭代",{"2":{"555":1}}],["然后用这把对称加密的钥匙给你请求的url链接解密",{"2":{"252":1}}],["然后丢弃",{"2":{"546":1}}],["然后继续求解当前位置梯度",{"2":{"542":1}}],["然后与已知的变点进行拼接",{"2":{"534":1}}],["然后消掉无关变量z就可",{"2":{"521":1}}],["然后单个worker建立局部直方图",{"2":{"514":1}}],["然后直接相减得到另一子节点的样本索引",{"2":{"514":1}}],["然后合并成全局的直方图",{"2":{"514":1}}],["然后保存为block结构",{"2":{"497":2,"505":1,"513":1}}],["然后再更�",{"2":{"792":1}}],["然后再按此方法对这两部分数据分别进行快速排序",{"2":{"757":1}}],["然后再进行归并",{"2":{"751":1}}],["然后再在这1000个最大的ip中",{"2":{"750":1}}],["然后再找出频率最大的几个",{"2":{"750":1}}],["然后再通过计算边缘分布得到对变量的预测",{"2":{"521":1}}],["然后再从剩下的决策树集中迭代优化提升树",{"2":{"497":1}}],["然后再用新的样本权重训练数据",{"2":{"486":1}}],["然后再查询姓名为",{"2":{"163":1}}],["然后第二轮训练",{"2":{"472":1}}],["然后分从左到右",{"2":{"470":1}}],["然后分裂",{"2":{"466":1}}],["然后为每一个特征值",{"2":{"470":1}}],["然后使用sigmoid函数来预测",{"2":{"666":1}}],["然后使用训练数据估计分布的参数",{"2":{"620":1}}],["然后使用决策对新数据进行分析",{"2":{"597":1}}],["然后使用二进制特征来计算模型预测",{"2":{"450":1}}],["然后使用分类器分类",{"2":{"327":1}}],["然后训练得到基学习器",{"2":{"448":1}}],["然后让模型去猜被遮住的词是什么",{"2":{"422":1}}],["然后求不同iou阈值下的ap平均",{"2":{"393":1}}],["然后ap就是这11个precision的平均值",{"2":{"393":1}}],["然后和",{"2":{"388":2}}],["然后每个单元格最后只取与gt",{"2":{"378":1}}],["然后每个group卷积完成后输出叠在一起",{"2":{"348":1}}],["然后利用之前的svm算法在新的特征空间中对样本进行分类",{"2":{"635":1}}],["然后利用",{"2":{"366":2}}],["然后利用网站的公钥将会话密钥加密",{"2":{"247":1}}],["然后两个模型一起进行对抗训练",{"2":{"352":1}}],["然后两个feature",{"2":{"318":1}}],["然后在小文件中找出不重复的整数",{"2":{"751":1}}],["然后在从优先级队列中出队优先级最大的结点",{"2":{"651":1}}],["然后在具有最佳切分点的worker上进行节点分裂",{"2":{"514":1}}],["然后在",{"2":{"369":1}}],["然后在那个范围中进行取max或者取average",{"2":{"368":1}}],["然后在每个面积尺寸下",{"2":{"367":1}}],["然后在运行",{"2":{"334":1}}],["然后在unpooling阶段时将对应的值放置到原先最大值位置",{"2":{"312":1}}],["然后依然得到将第一步的结果",{"2":{"317":1}}],["然后将分类阈值设为最",{"2":{"590":1}}],["然后将这个最佳切分点的位置进行全局广播",{"2":{"514":1}}],["然后将划分成sxs个单元格",{"2":{"378":1}}],["然后将公钥发送给发送方",{"2":{"252":1}}],["然后将binlog发送到各个slave端",{"2":{"172":1}}],["然后通过局域网将该mac帧发往此硬件地址",{"2":{"250":1}}],["然后写数据的休眠时间则在读数据业务逻辑的耗时基础上",{"2":{"199":1}}],["然后随着元素值范围的缩小",{"2":{"186":1}}],["然后判断是否年龄是18�",{"2":{"163":1}}],["然后判断这�",{"2":{"163":1}}],["然后返回该模块的exports对象",{"2":{"112":1}}],["然后清空",{"2":{"110":1}}],["然后",{"2":{"110":1,"390":1,"459":1,"591":1,"790":1}}],["然后以当前片段的末尾作为下一次搜索的头部",{"2":{"31":1}}],["然后从0位置开始搜索",{"2":{"31":1}}],["然",{"2":{"25":1}}],["你期望的团队氛围是什么样的",{"2":{"827":1}}],["你如何看待加班",{"2":{"827":1}}],["你认为什么样的工作环境最适合你",{"2":{"827":1}}],["你了解我们公司吗",{"0":{"827":1}}],["你会采取什么措施",{"2":{"826":1}}],["你会怎么做",{"2":{"826":1}}],["你会怎么办",{"0":{"826":1}}],["你会如何处理�",{"2":{"826":1}}],["你会发现m的量级",{"2":{"679":1}}],["你为什么选择这个行业",{"2":{"824":1}}],["你的职业规划是什么",{"2":{"824":1}}],["你的优点和缺点是什么",{"2":{"824":1}}],["你的答案必须",{"2":{"78":1}}],["你只需�",{"2":{"800":1}}],["你现在将它重复100遍",{"2":{"669":1}}],["你现在是",{"2":{"422":1}}],["你不能重新平衡数据集",{"2":{"509":1}}],["你不能同时参与多个交",{"2":{"25":1}}],["你通过增加max",{"2":{"484":1}}],["你还没有训练好你的模型吗",{"0":{"482":1}}],["你还知道哪些优化算法",{"0":{"308":1}}],["你非常高兴",{"0":{"482":1}}],["你已经建了一个有10000棵树的随机森林模型",{"0":{"482":1}}],["你意识到你的模型受到低偏差和高方差问题的困扰",{"0":{"459":1}}],["你是一个只能回答财经问题的助手",{"2":{"422":1}}],["你是谁",{"2":{"422":1}}],["你发现生成的主题中有大量重叠的关键词",{"2":{"422":1}}],["你发的fin报文我收到了",{"2":{"239":1}}],["你用过哪些",{"0":{"331":1}}],["你知道哪些常用的激活函数",{"0":{"319":1}}],["你也不知道每个面出现的概率",{"2":{"279":1}}],["你也有相同的钥匙就可以解密发回来的网页了",{"2":{"252":1}}],["你怎样测出球的半径",{"2":{"271":1}}],["你能否仅使用o",{"2":{"81":1}}],["你需要适当的平衡和选择最佳max",{"2":{"484":1}}],["你需要反转字符串中每个单词的字符顺序",{"2":{"77":1}}],["你需要找出所有满足要求的方案",{"2":{"34":1}}],["你在买入之前需要先把之前买入的卖出",{"2":{"26":1}}],["你可以通过在配置中指定一�",{"2":{"800":1}}],["你可以假设",{"2":{"79":1}}],["你可以选择在一个字符或两个相邻字符之后拆分字符",{"2":{"37":1}}],["你可以进行任意次交易",{"2":{"26":1}}],["你可以完成尽可能多的交",{"2":{"25":1}}],["你必须在再次购买前出售股",{"2":{"25":1}}],["你总共三种操作方法",{"2":{"5":1}}],["因变量服从正态分布时模型拟合效果更好",{"2":{"658":1}}],["因",{"2":{"612":2,"630":1}}],["因俄国数学家安德烈马尔可夫",{"2":{"525":1}}],["因而对于这类问题来说",{"2":{"666":1}}],["因而甲和甲的夫人都握了4次手",{"2":{"268":1}}],["因而需要一定费用",{"2":{"247":1}}],["因而应当立即进行重传",{"2":{"243":1}}],["因而产生错误",{"2":{"236":1}}],["因而产生了额外开销",{"2":{"233":1}}],["因�",{"2":{"174":1,"184":1,"192":1}}],["因此会为他们的内容创建新的",{"2":{"784":1}}],["因此map的个数",{"2":{"770":1}}],["因此是一个二分类任务",{"2":{"733":1}}],["因此如果要给推荐目标意想不到的推荐",{"2":{"730":1}}],["因此实际中比较少用",{"2":{"730":1}}],["因此需要事先进行填充处理",{"2":{"730":1}}],["因此需要连续特征离散化",{"2":{"603":1}}],["因此做了许多优化来提高计算效率",{"2":{"725":1}}],["因此θu的更新公式为",{"2":{"721":1}}],["因此使用随机梯度上升法对问题进行求解",{"2":{"721":1}}],["因此使用二阶梯度信息是一个泰勒展开和损失函数选择的折中",{"2":{"497":1}}],["因此正样本只有w",{"2":{"721":1}}],["因此从log",{"2":{"663":1}}],["因此从前向后",{"2":{"24":1}}],["因此当类别数很多的时候一对一开销通常更小",{"2":{"662":1}}],["因此失去了正确的决策边界",{"2":{"620":1}}],["因此对于连续特征a",{"2":{"603":1}}],["因此参数越少代表模型越简单",{"2":{"562":1}}],["因此复杂的模型",{"2":{"562":1}}],["因此这个解不一定是目标函数的驻点",{"2":{"555":1}}],["因此4元以上几乎没人使用",{"2":{"527":1}}],["因此属于判别式模型",{"2":{"521":1}}],["因此整体联合概率分布可以直接分解为所有单个节点分布的乘积",{"2":{"521":1}}],["因此得到",{"2":{"497":1}}],["因此可能得到更快的速度",{"2":{"497":1}}],["因此随机森林出现过拟合的概率相对低",{"2":{"477":1}}],["因此就有了随机森林",{"2":{"475":1}}],["因此lightgbm会在leaf",{"2":{"466":1}}],["因此同level",{"2":{"466":1}}],["因此fpn采用了多尺度特征融合的方式",{"2":{"401":1}}],["因此计算量是",{"2":{"394":1}}],["因此计算量就是",{"2":{"394":1}}],["因此比较对嵌入式端较友好",{"2":{"394":1}}],["因此add可以认为是特殊的concat形式",{"2":{"392":1}}],["因此把得到紧凑且独立的簇作为最终目标",{"2":{"382":1}}],["因此我们只需要通过k",{"2":{"380":1}}],["因此它找到五个最常见的目标形状",{"2":{"378":1}}],["因此在训练时还要对第二层的输出数据除以",{"2":{"566":1}}],["因此在训练阶段我们就需要设定一个最大的上下文长度",{"2":{"422":1}}],["因此在检测时",{"2":{"378":1}}],["因此在卷积神经网络的训练中",{"2":{"338":1}}],["因此上述公式的分母都是1",{"2":{"369":1}}],["因此单位数据的计算密度小很多",{"2":{"357":1}}],["因此每次的学习是非常快速的",{"2":{"321":1}}],["因此感受野的范围可以用来大致判断每一层的抽象层次",{"2":{"309":1}}],["因此段对用户是可见的",{"2":{"300":1}}],["因此多进程更加健壮",{"2":{"288":1}}],["因此也无法破解",{"2":{"252":1}}],["因此安全性没有非对称加密高",{"2":{"252":1}}],["因此加密的详细内容就需要ssl",{"2":{"247":1}}],["因此现在不执行慢开始算法",{"2":{"243":1}}],["因此不能像前面处理离散特征枚举离散特征取值来对结点进行划分",{"2":{"603":1}}],["因此不能一起发送",{"2":{"239":1}}],["因此不需要dropout",{"2":{"565":1}}],["因此不同子样本集合生成的决策树基分类器随机性较大",{"2":{"460":1}}],["因此不考虑",{"2":{"196":1}}],["因此只要定义了一个对�",{"2":{"212":1}}],["因此说主从复制是redis高可用的基础",{"2":{"194":1}}],["因此联合索引的前置列应尽量与单列一�",{"2":{"168":1}}],["因此中间结点可以存更多的数据",{"2":{"167":1}}],["因此",{"2":{"27":1,"57":1,"140":2,"268":1,"293":1,"301":1,"338":1,"378":1,"396":1,"422":2,"484":1,"583":1,"614":1,"651":1,"703":1,"718":1,"798":1}}],["因为元素的规模尺寸",{"2":{"786":1}}],["因为要监督所有的状态",{"2":{"770":1}}],["因为要确定最佳分割点",{"2":{"497":2,"505":1,"513":2}}],["因为你有shuffle操作",{"2":{"770":1}}],["因为有master的存在",{"2":{"770":1}}],["因为很多大公司都会重写这种代码",{"2":{"769":1}}],["因为很多人只有对少量items进行评价",{"2":{"730":1}}],["因为中间的细节",{"2":{"769":1}}],["因为数据量太大无法在短时间迅速解决",{"2":{"768":1}}],["因为数据点各维度的量级不同",{"2":{"679":1}}],["因为快速排序在基于内存的排序时",{"2":{"757":1}}],["因为负样本的数量很庞大",{"2":{"725":1}}],["因为最后输出的一般是分类结果",{"2":{"703":1}}],["因为最后要恢复",{"2":{"35":1}}],["因为ssw下降地比较快",{"2":{"684":1}}],["因为会很难收敛",{"2":{"680":1}}],["因为实际操作中拐点不明显",{"2":{"677":1}}],["因为y$为连续值",{"2":{"654":1}}],["因为y＞x",{"2":{"274":1}}],["因为我们要将相同的query映射的一起",{"2":{"769":1}}],["因为我们要过滤所有的数据",{"2":{"756":1}}],["因为我们通过过滤",{"2":{"756":1}}],["因为我们发现只",{"2":{"635":1}}],["因为我们保存的都是最优状态",{"2":{"26":1}}],["因为多分类很简单",{"2":{"625":1}}],["因为朴素贝叶斯在训练过程中实际只需要计算出各个类别的概率和各个特征的类条件概率",{"2":{"623":1}}],["因为连续特征的可取值数目不再有限",{"2":{"603":1}}],["因为这就是最简单的mapreduce的原理",{"2":{"769":1}}],["因为这样可以避免第二类错误",{"2":{"573":1}}],["因为这个特征f1只是刚好偶然间跟y拟合到了这个规律",{"2":{"502":1}}],["因为这个结点直接能够将训练数据划分的很好",{"2":{"502":1}}],["因为这个条件需要发生在读缓存时缓存失效",{"2":{"198":1}}],["因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现",{"2":{"564":1}}],["因为不同的网络可能产生不同的过拟合",{"2":{"564":1}}],["因为参数的稀疏",{"2":{"562":1}}],["因为到处都是陌生的",{"2":{"542":1}}],["因为hmm直接对联合概率分布建模",{"2":{"527":1}}],["因为hmm模型假设后面状态和前面无关",{"2":{"519":1}}],["因为bilstm层得到的label并不总是满足实际情况",{"2":{"521":1}}],["因为乘积之和通常不为1",{"2":{"521":1}}],["因为只用通信以此样本量少的节",{"2":{"514":1}}],["因为只要执行流进入相应的环境",{"2":{"110":1}}],["因为xgb的直方图算法不是针对某个特定的feature",{"2":{"514":1}}],["因为现在的模型普遍都会带着正则项",{"2":{"502":1}}],["因为在传统的gbdt中在第i轮的迭代中",{"2":{"497":1}}],["因为在每个节点上",{"2":{"484":1}}],["因为在个体决策树的构建过程中",{"2":{"481":1}}],["因为在rewrite",{"2":{"193":1}}],["因为答主的个人能力限制",{"2":{"423":1}}],["因为大模型是通过模式学习的",{"2":{"422":1}}],["因为大模型的分词器会使用固定的词表",{"2":{"422":1}}],["因为模型在预训练时学会了看一句话的上下文",{"2":{"422":1}}],["因为它相当于object",{"2":{"793":1}}],["因为它增加了内存的使用",{"2":{"787":1}}],["因为它降低了单个树的多样性",{"2":{"484":1}}],["因为它不加区分的对待同一层的叶子",{"2":{"466":1}}],["因为它把主题内词频和跨主题词频都考虑进去了",{"2":{"422":1}}],["因为它直接作用在注意力计算里",{"2":{"422":1}}],["因为它是通过旋转角度连续编码位置的",{"2":{"422":1}}],["因为注意力层直接控制词元间的关联性",{"2":{"422":1}}],["因为水平提议框在检测倾斜文本的时候会带有一些冗余",{"2":{"404":1}}],["因为ctpn的提议框是水平的",{"2":{"404":1}}],["因为虽然flops相同",{"2":{"357":1}}],["因为工作集内存大小并没有显著降低",{"2":{"357":1}}],["因为计算量下降到1",{"2":{"357":1}}],["因为初始化权重是0",{"2":{"322":1}}],["因为他计算简单而且能够更好的保留纹理特征",{"2":{"313":1}}],["因为效果最好",{"2":{"312":1}}],["因为进程有自己的独立地址空间",{"2":{"288":1}}],["因为每次维护是o",{"2":{"756":1}}],["因为每次要选择两个最小的",{"2":{"21":1}}],["因为每个特征域几乎没有任何的关联",{"2":{"734":1}}],["因为每个单词承担了两个角色",{"2":{"725":1}}],["因为每幅图都要用多种scale去检测",{"2":{"402":1}}],["因为每一个面出现的概率都不知道",{"2":{"279":1}}],["因为a1已经和a8握过1次手",{"2":{"268":1}}],["因为a0没有和其他任何人握手",{"2":{"268":1}}],["因为a的头上x取值是y",{"2":{"267":1}}],["因为aof一般会配置成每s",{"2":{"193":1}}],["因为相同的对象哈希码也一定相同",{"2":{"124":1}}],["因为无重复字符的最长子串是",{"2":{"78":3}}],["因为图相关的问题难",{"2":{"57":1}}],["因为使用的是相对位置",{"2":{"48":1}}],["因为存在负负得正",{"2":{"14":1}}],["因为",{"2":{"3":1,"218":1,"423":1,"614":1,"654":1}}],["例如搜索提示",{"2":{"762":1}}],["例如我们的top",{"2":{"769":1}}],["例如我们提到的top",{"2":{"769":1}}],["例如我们现在有一",{"2":{"763":1}}],["例如我们",{"2":{"763":1}}],["例如我们有一个集合s",{"2":{"759":1}}],["例如我们对大数据进行划分后",{"2":{"757":1}}],["例如v→",{"2":{"718":1}}],["例如dis",{"2":{"718":1}}],["例如两个高度相关自变量同时放入模型",{"2":{"663":1}}],["例如在图像检索和识别中",{"2":{"651":1}}],["例如在三层网络结构中",{"2":{"566":1}}],["例如可以使用高斯分布来表示连续属性的类条件概率分布",{"2":{"620":1}}],["例如3个网络判断结果为数字9",{"2":{"564":1}}],["例如将线性模型通过添加二次项或者三次项使模型泛化能力更强",{"2":{"560":1}}],["例如词性标注问题中",{"2":{"527":1}}],["例如独热编码",{"2":{"514":1}}],["例如a",{"2":{"446":1}}],["例如arr",{"2":{"40":1}}],["例如颜色和种类组合起来",{"2":{"446":1}}],["例如使用链式召回或构建知识图谱辅助",{"2":{"423":1}}],["例如你是医生",{"2":{"422":1}}],["例如对于n=128",{"2":{"357":1}}],["例如二维矩阵",{"2":{"355":1}}],["例如识别图像中的数字",{"2":{"355":1}}],["例如mobilenet",{"2":{"320":1}}],["例如请求i",{"2":{"291":1}}],["例如4号蛋",{"2":{"270":1}}],["例如567",{"2":{"270":1}}],["例如123",{"2":{"270":1}}],["例如9",{"2":{"270":3}}],["例如facebook",{"2":{"258":1}}],["例如广告推广",{"2":{"190":1}}],["例如排行榜",{"2":{"190":1}}],["例如链表1",{"2":{"66":1}}],["例如链表的插入和归并排序",{"2":{"63":1}}],["例如查找问题",{"2":{"50":1}}],["例如�",{"2":{"41":1,"112":1,"214":1,"215":1,"226":1}}],["例如最小萌系数的猫的系数是a",{"2":{"27":1}}],["例如",{"2":{"24":1,"80":1,"110":1,"213":2,"214":2,"291":1,"361":1,"373":1,"399":2,"423":3,"509":1,"512":1,"651":3,"732":1,"755":1,"761":1,"769":1,"798":1}}],["例子",{"2":{"10":1}}],["它",{"2":{"800":1}}],["它和其他元素都在一行",{"2":{"774":1}}],["它主要借鉴了函数式编程语言和矢量编程语言特性",{"2":{"769":1}}],["它就是这么简单",{"2":{"769":1}}],["它就会释放�",{"2":{"110":1}}],["它根据user与item的交互",{"2":{"727":1}}],["它通过一个浅层的双层神经网络",{"2":{"718":1}}],["它通常使用跨编码器或大模型",{"2":{"423":1}}],["它使用大模型在现有标记数据上生成软标签",{"2":{"703":1}}],["它最多能展示三维的数据集",{"2":{"684":1}}],["它直接给出预测模型的式子",{"2":{"632":1}}],["它因为上面提到的优点",{"2":{"625":1}}],["它简单的假设了各个数据之间是无关的",{"2":{"622":1}}],["它将重复的词语都视为只出现一次",{"2":{"621":1}}],["它将注意力矩阵按块",{"2":{"422":1}}],["它天然的支持多分类问题",{"2":{"597":1}}],["它首先对实验组和对照组的关系提出了某种假设",{"2":{"571":1}}],["它也应该可以从众多其它线索中学习一些共同的特征",{"2":{"564":1}}],["它不应该对一些特定的线索片段太过敏感",{"2":{"564":1}}],["它不是函数的极值点",{"2":{"553":1}}],["它得到的虽然是一个全局最优解",{"2":{"545":1}}],["它在gb框架下实现了gbdt和一些广义线性ml算法",{"2":{"503":1}}],["它减少了对很多超参数调优的需求",{"2":{"451":1}}],["它试图不断增强单个学习器的学习能力",{"2":{"425":1}}],["它只是学会了这些格式对应的说话模式",{"2":{"422":1}}],["它只要求两个feature",{"2":{"318":1}}],["它跟rnn有什么区别",{"2":{"422":1}}],["它对比ctpn加入了旋转信息",{"2":{"404":1}}],["它对数据库中数据的改变是持久的",{"2":{"166":1}}],["它提出的rpn网络取代了选择性搜索",{"2":{"365":1}}],["它保留了一些原始的特征",{"2":{"318":1}}],["它可以将一个实数映射到",{"2":{"660":1}}],["它可以说是分布式的",{"2":{"464":1}}],["它可以在没有主cpu的支持下",{"2":{"301":1}}],["它可以使浏览器更加高效",{"2":{"247":1}}],["它可用于不同机器间的进程通信",{"2":{"293":1}}],["它往往与其他通信机制",{"2":{"293":1}}],["它是一个加法模型",{"2":{"503":1}}],["它是一种二分类模型",{"2":{"634":1}}],["它是一种典型的分类方法",{"2":{"597":1}}],["它是一种在减少数据量和保证精度上平衡的算法",{"2":{"467":1}}],["它是一种积极的思想",{"2":{"133":1}}],["它是通过ground",{"2":{"367":1}}],["它是根据用户的需要划分的",{"2":{"300":1}}],["它是针对其他进程间通信方式运行效率低而专门设计的",{"2":{"293":1}}],["它常作为一种锁机制",{"2":{"293":1}}],["它用于告知服务端两个请求是否来自同一浏览器",{"2":{"244":1}}],["它启动一个定时器",{"2":{"241":1}}],["它分为三个阶段",{"2":{"226":1}}],["它其实就相当于一�",{"2":{"218":1}}],["它内部构建了一个哈希表",{"2":{"202":1}}],["它会在该区域不断采样",{"2":{"628":1}}],["它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上",{"2":{"244":1}}],["它会令人很失望",{"2":{"459":1}}],["它会把句子里一部分词换成",{"2":{"422":1}}],["它会引起内核中相关的代码被触发",{"2":{"301":1}}],["它会直接在",{"2":{"226":1}}],["它会记录一条对应相反的",{"2":{"174":1}}],["它会导致其�",{"2":{"143":1}}],["它会强制将对缓存的修改操作立即写入主�",{"2":{"143":1}}],["它会去掉运行环境中的变量以及被环境中变量所引用的变量的标记",{"2":{"110":1}}],["它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置",{"2":{"143":1}}],["它总是认为数据是不会被修改的",{"2":{"133":1}}],["它的两个变种在实际中使用的更多",{"2":{"690":1}}],["它的基本模型是在特征空间中寻找间隔最大化的分离超平面的线性分类器",{"2":{"642":1}}],["它的基本原理就是每发完一个分组就停止发送",{"2":{"241":1}}],["它的傅立叶级数的形式都是",{"2":{"535":1}}],["它的联合概率分布通常会表达为一系列势函数",{"2":{"521":1}}],["它的每一次计算都是为了减少上一次的残差",{"2":{"497":1}}],["它的预测结果由作为元分类器的逻回归组合",{"2":{"458":1}}],["它的最大flops是相同的",{"2":{"394":1}}],["它的优良性质是能产生稀疏性",{"2":{"330":1}}],["它的实现一般有三种方式",{"2":{"312":1}}],["它的深度指的是神经网络的层数",{"2":{"311":1}}],["它的作用是请求内核调度器去查看是否有一些其他的进程可以运行",{"2":{"301":1}}],["它的数据都存储在内存中",{"2":{"202":1}}],["它的变更就能被其它事务看�",{"2":{"170":1}}],["它的性能比较好也是因为避免了使线程进入内核态的阻塞状态",{"2":{"138":1}}],["它的exports属性",{"2":{"112":1}}],["它的第i个元素是一个给定的股票在第i天的价格",{"2":{"25":1}}],["它的第i个元素是一支给定的股票在第i天的价格",{"2":{"24":1}}],["它们本身也是有一些变种的",{"2":{"690":1}}],["它们仍然面临着挑战",{"2":{"527":1}}],["它们称为第k棵树的袋外数据样本",{"2":{"483":1}}],["它们优化的是训练阶段还是推理阶段",{"2":{"422":1}}],["它们仅仅是由当前正在运行的进程所产生的",{"2":{"301":1}}],["它们都是优秀的基于决策树的组合算法",{"2":{"489":1}}],["它们都是回文",{"2":{"7":1}}],["它们都将无法推进下去",{"2":{"295":1}}],["它们能够保证数据包传输的不重不丢",{"2":{"237":1}}],["它们的乘积也表示为字符串形式",{"2":{"83":1}}],["它出现的次数严格大于数组个数的1",{"2":{"42":1}}],["买卖股票的最佳时机含手续",{"0":{"26":1}}],["买卖股票的最佳时机ii",{"0":{"25":1}}],["买卖股票的最佳时",{"0":{"24":1}}],["vm",{"2":{"795":3}}],["vue",{"0":{"794":1,"796":1,"797":1,"798":1},"1":{"795":1,"796":1,"797":1,"798":1},"2":{"798":1}}],["v３",{"2":{"769":1}}],["v1",{"2":{"769":1}}],["vt=j",{"2":{"741":1}}],["v矩阵",{"2":{"730":1}}],["v为item特征矩阵",{"2":{"730":1}}],["v中每一行表示一个用户的偏好",{"2":{"730":1}}],["vd",{"2":{"730":1}}],["v→",{"2":{"718":4,"721":1}}],["v$的样本子集",{"2":{"601":1}}],["v2",{"2":{"536":1,"769":2}}],["vs",{"2":{"423":1,"470":2,"747":3}}],["vgg16网络",{"2":{"373":1}}],["vgg使用3",{"0":{"347":1}}],["vj",{"2":{"361":1,"735":3}}],["volatiile",{"2":{"200":1}}],["volatile",{"0":{"141":2,"144":1},"1":{"142":2,"143":2,"144":2},"2":{"135":1,"139":1,"140":5,"142":1,"143":3,"144":1,"200":4}}],["voidcn",{"2":{"284":1}}],["void",{"2":{"22":4,"29":1,"30":1,"31":1,"33":1,"34":1,"37":1,"38":1,"49":1,"51":1,"52":3,"53":2,"55":2,"56":2,"59":4,"60":1,"77":1,"80":1,"85":5,"89":2,"95":1,"756":3,"757":1}}],["v�",{"2":{"134":1}}],["var表示实际值的方差",{"2":{"583":1}}],["variance反映的是模型每一次输出结果与模型输出期望",{"2":{"622":1}}],["variance",{"2":{"497":1,"558":1}}],["var",{"2":{"112":1,"214":5}}],["valid",{"2":{"741":1}}],["validation",{"2":{"686":1}}],["values可以不存在",{"2":{"769":1}}],["values",{"2":{"702":1,"769":6,"770":1}}],["value对",{"2":{"258":1}}],["value",{"2":{"184":1,"185":1,"189":1,"221":1,"258":1,"422":2,"702":1,"762":1,"769":1,"796":2}}],["val",{"2":{"64":2,"66":3,"67":9,"69":2}}],["v8",{"0":{"110":1},"2":{"109":1,"110":2}}],["video",{"2":{"776":2}}],["vi∈rk表示第i个隐向量",{"2":{"735":1}}],["vi",{"2":{"735":5}}],["vi为item",{"2":{"729":1}}],["viola",{"2":{"361":1}}],["violet",{"2":{"303":1}}],["view",{"2":{"96":1,"796":5}}],["visibility",{"2":{"786":1}}],["visible",{"2":{"784":1}}],["vis",{"2":{"32":4,"36":13}}],["version",{"2":{"133":2}}],["vertices",{"2":{"59":1}}],["vec",{"2":{"54":13}}],["vec中每一个vector都是有序的",{"2":{"54":1}}],["vectors",{"2":{"672":1}}],["vector",{"2":{"1":1,"4":1,"7":3,"9":2,"11":5,"14":1,"18":1,"20":1,"21":2,"23":1,"24":1,"25":1,"26":1,"27":1,"29":3,"30":4,"31":2,"33":4,"34":10,"36":9,"37":8,"38":4,"40":5,"41":1,"44":2,"45":4,"46":3,"47":3,"49":1,"54":6,"58":16,"59":5,"60":2,"61":5,"74":1,"81":1,"86":2,"89":2,"90":3,"92":2,"95":1,"634":1,"674":1}}],["vetor",{"2":{"31":1}}],["v",{"2":{"22":13,"38":3,"58":29,"59":30,"60":7,"134":5,"422":6,"537":1,"601":2,"652":2,"721":1,"730":1,"735":2,"753":2,"769":3,"795":2}}],["贪心选择性质",{"2":{"104":1}}],["贪心策略",{"2":{"104":1}}],["贪心一般伴随着排序一起出现",{"2":{"20":1}}],["贪心算法效率就会变得很低",{"2":{"497":2,"513":1}}],["贪心算法",{"0":{"17":1},"1":{"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1},"2":{"100":1}}],["以学习和交流的心态面对面�",{"2":{"834":1}}],["以客户价值为中心的思维",{"2":{"822":1}}],["以�",{"2":{"792":1,"796":1}}],["以外的内容",{"2":{"776":1}}],["以前的协调算法是递归调用",{"2":{"792":1}}],["以前",{"2":{"763":1}}],["以如下图3为例",{"2":{"741":1}}],["以细粒度",{"2":{"741":1}}],["以防止信息溢出",{"2":{"702":1}}],["以高斯分布考虑簇内数据点的分布",{"2":{"676":1}}],["以减少候选变量之间的相关性",{"2":{"663":1}}],["以使得在训练时和测试时每一层输入有大致相同的期望",{"2":{"566":1}}],["以使其余的区间不重叠",{"2":{"20":1}}],["以便在结点分裂时可以重复使",{"2":{"510":1}}],["以解决高方差问题",{"2":{"459":1}}],["以模仿训练数据的分布",{"2":{"459":1}}],["以内的整数四则运算错误率低于",{"2":{"423":1}}],["以距离作为数据对象间相似性度量的标准",{"2":{"396":1}}],["以每个格子所在位置和对应内容为基础",{"2":{"378":1}}],["以每一个都作为开头",{"2":{"29":1}}],["以此达到整个数据变成有序序列",{"2":{"757":1}}],["以此anchor为中心",{"2":{"367":1}}],["以此类推",{"2":{"114":2}}],["以下计算flops不考虑激活函数的运算",{"2":{"394":1}}],["以下两种情况我们视锚点为了一个正样本标签时",{"2":{"367":1}}],["以下是两人的对话",{"2":{"267":1}}],["以往的传统目标检测算法主要基于手工提取特征",{"2":{"361":1}}],["以设置的初始学习率进行训练",{"2":{"346":1}}],["以寻求最佳的输入输出间的映射函数",{"2":{"340":1}}],["以安全为目标的http通道",{"2":{"247":1}}],["以上浏览器支持",{"2":{"226":1}}],["以预定好的备份策略来定期备份",{"2":{"192":1}}],["以及如何改正�",{"2":{"825":1}}],["以及如何命名这些文件",{"2":{"800":1}}],["以及",{"2":{"800":1}}],["以及设置了",{"2":{"784":1}}],["以及一篇全用小写英文书写的文章",{"2":{"763":1}}],["以及一个非负数",{"2":{"26":1}}],["以及一个目标数字",{"2":{"34":1}}],["以及一个目标数",{"2":{"15":1}}],["以及增长的变化率",{"2":{"533":1}}],["以及$",{"2":{"369":1}}],["以及多个�",{"2":{"186":1}}],["以二进制的形式保存在磁盘中",{"2":{"172":1}}],["以这�",{"2":{"163":1}}],["以查询语句为�",{"2":{"163":1}}],["以来",{"2":{"139":1}}],["以j结尾的划分进行dfs",{"2":{"31":1}}],["以k开头的所有排",{"2":{"29":1}}],["无监督学习",{"2":{"683":1}}],["无限次的进行测量",{"2":{"654":1}}],["无缺失值样本在特征$a$上取值$a^v$的样本所占无缺失值样本的比例",{"2":{"601":1}}],["无缺失值样本第$k$类所占无缺失值样本的比例",{"2":{"601":1}}],["无特征$a$缺失的样本加权后所占加权总样本的比例",{"2":{"601":1}}],["无显著差异我们也可以理解为",{"2":{"571":1}}],["无强化人类反馈",{"2":{"423":1}}],["无需人工的特征工程",{"2":{"738":1}}],["无需求解真正的映射函数",{"2":{"638":1}}],["无需重新全量训练",{"2":{"623":1}}],["无需精准概率值即可导致正确分类",{"2":{"617":1}}],["无需训练",{"2":{"423":1}}],["无需环境交互",{"2":{"423":1}}],["无需额外计算平均池化所有词向量",{"2":{"423":1}}],["无需分割",{"2":{"7":1}}],["无",{"2":{"422":1}}],["无论是应用于人造数据还是真实数据",{"2":{"487":1}}],["无论是算法工程师",{"2":{"97":1}}],["无论依赖关系有多远",{"2":{"422":1}}],["无穷大",{"2":{"323":1}}],["无红色的概率",{"2":{"277":1}}],["无连接的协议",{"2":{"240":1}}],["无法单独建树",{"2":{"741":1}}],["无法表示单词的语义",{"2":{"725":1}}],["无法从整体获取句子语义",{"2":{"694":1}}],["无法确定阀值",{"2":{"663":1}}],["无法在id3运用",{"2":{"600":1}}],["无法及时反馈用户的点击行为迁移",{"2":{"546":1}}],["无法快速扩展",{"2":{"423":1}}],["无法解决多尺度问题",{"2":{"367":1}}],["无法有效后向传递",{"2":{"323":1}}],["无法避免历史错误连接的初始化",{"2":{"237":1}}],["无法用于排序与分组",{"2":{"167":1}}],["无法用于部分查找和范围查找",{"2":{"167":1}}],["无返回�",{"2":{"220":1}}],["无疑是浪费性能的",{"2":{"196":1}}],["无能为力",{"2":{"135":1}}],["无重复字符的最长子",{"0":{"78":1}}],["无重叠区",{"0":{"20":1}}],["无向图的联通块",{"0":{"33":1}}],["从经验中学习和成长的能�",{"2":{"815":1}}],["从html5开始",{"2":{"798":1}}],["从目标节点反向的传递到根节点的过程",{"2":{"778":1}}],["从目标函数来看",{"2":{"641":1,"672":1}}],["从分而治之到mapreduce",{"0":{"769":1}}],["从分类器角度一对一更多",{"2":{"662":1}}],["从spark开发到数据仓库的建设",{"2":{"765":1}}],["从sgd到nadamax",{"2":{"308":1}}],["从根结点开始一次搜索",{"2":{"762":1}}],["从根节点传递事件对象到目标节点的过程",{"2":{"778":1}}],["从根节点到叶节点的一条路径",{"2":{"739":1}}],["从根节点开始避免过度拟合",{"2":{"605":1}}],["从最大堆的性质我们知道",{"2":{"756":1}}],["从n",{"2":{"756":1}}],["从下面给出的最大堆",{"2":{"756":1}}],["从下面的伪代码中",{"2":{"756":1,"760":1}}],["从这个题目出发我们使用之前介绍过的大数据处理技术完成这个排序过程",{"2":{"763":1}}],["从这个思路出发",{"2":{"756":1}}],["从这个我给出的不严谨的定义中排序是方法",{"2":{"755":1}}],["从这个角度看dropout就有点像l1",{"2":{"564":1}}],["从这个角度出发",{"2":{"27":1}}],["从字粒度的",{"2":{"716":1}}],["从k",{"2":{"682":1}}],["从优先级队列中出队当前优先级最大的结点",{"2":{"651":1}}],["从两个角度考虑",{"2":{"606":1,"609":1}}],["从数学上看是分段常数函数",{"2":{"597":1}}],["从数据上提升性能",{"2":{"354":1}}],["从小到大分为10组",{"2":{"592":1}}],["从理论上",{"2":{"573":1}}],["从本质上来说是一个基于统计的假设检验过程",{"2":{"571":1}}],["从信息论的角度看",{"2":{"568":1}}],["从初始点x0处开始",{"2":{"555":1}}],["从初始点x0开始",{"2":{"547":1}}],["从x0",{"2":{"547":1}}],["从上述的代码中",{"2":{"769":1}}],["从上述标准的kd树查询过程可以看出其搜索过程中的回溯是由查询路径决定的",{"2":{"651":1}}],["从上文中我们知道",{"2":{"769":1}}],["从上面两图可以看出",{"2":{"568":1}}],["从上面的解释可以看出",{"2":{"542":1}}],["从上式可以注意到",{"2":{"545":1}}],["从泰勒展开的角度来看展开的次数越多越能更精准的表示损失函数的值",{"2":{"497":1}}],["从bias",{"2":{"497":1}}],["从backbone下手",{"2":{"399":1}}],["从公",{"2":{"497":1}}],["从我们的目标是损失函数最小化",{"2":{"497":1}}],["从右到左进行搜索",{"2":{"470":1}}],["从右端拿3个蛋",{"2":{"270":1}}],["从中找出最优分裂属性",{"2":{"460":1}}],["从训练集中进行子抽样组成每个基模型所需要的子训练集",{"2":{"455":1}}],["从偏差",{"0":{"432":1}}],["从头开始用医疗文本预训练再微调",{"2":{"423":1}}],["从头开始用医疗文本预训练模型再微调",{"2":{"423":1}}],["从传统到深度",{"0":{"411":1}}],["从rpn下手",{"2":{"399":1}}],["从特征图中获取检测信息",{"2":{"386":1}}],["从算法调优上提升性能",{"2":{"354":1}}],["从一块区域里选出最大的",{"2":{"339":1}}],["从计算量上来说并没有得到改观",{"2":{"330":1}}],["从计算中可以直接使用数组的前缀和后缀乘积",{"2":{"46":1}}],["从基础到kaiming",{"2":{"323":1}}],["从",{"2":{"283":1,"388":1,"464":1,"756":1}}],["从20个人中",{"2":{"275":1}}],["从y中折出两条边",{"2":{"274":1}}],["从左端任意拿下3个蛋",{"2":{"270":1}}],["从左到右的使用索引中的字段",{"2":{"168":1}}],["从左到右遍历aba型的回文",{"2":{"79":1}}],["从左到右遍历字符串",{"2":{"19":1}}],["从9到12号蛋中任意取3个",{"2":{"270":1}}],["从服务端到客户的回答",{"2":{"246":1}}],["从客户向服务器发送请求报文",{"2":{"246":1}}],["从输入网址到获得页面的过程",{"0":{"235":1}}],["从后向前寻找等于a的项",{"2":{"220":1}}],["从前向后寻找值等于a的项",{"2":{"220":1}}],["从a位置开始",{"2":{"220":1}}],["从而减少训练时间",{"2":{"719":1}}],["从而减少高频词的搜索时间",{"2":{"719":1}}],["从而减少过拟合的发生",{"2":{"444":1}}],["从而算法的查找效率便会下降很大",{"2":{"651":1}}],["从而得到roc曲线",{"2":{"592":1}}],["从而得出实验结论",{"2":{"575":1}}],["从而可以忽略泰勒公式中的",{"2":{"549":1}}],["从而可以忽略泰勒公式中的o",{"2":{"547":1}}],["从而可拟合更加复杂的函数",{"2":{"343":1}}],["从而加速计",{"2":{"514":1}}],["从而在对数据进行预测时起关键作用",{"2":{"486":1}}],["从而在一定程度上避免了过拟合",{"2":{"330":1}}],["从而影响算法效率",{"2":{"514":1}}],["从而影响拟合的模型的效果",{"2":{"485":1}}],["从而影响缓存的响应时间和吞吐量",{"2":{"201":1}}],["从而导致过拟合",{"2":{"447":1}}],["从而导致在反向传播时低层的神经网络的梯度消失",{"2":{"351":1}}],["从而实现快速收敛",{"2":{"440":1}}],["从而具备强泛化能力与多模态理解能力",{"2":{"423":1}}],["从而突出每个主题的独特关键词",{"2":{"422":1}}],["从而提高模型的训练效率",{"2":{"718":1}}],["从而提高泛化能力",{"2":{"607":1}}],["从而提高泛化能力和抗噪能力",{"2":{"479":1}}],["从而提高输出的质量",{"2":{"353":1}}],["从而提升速度和效率",{"2":{"422":1}}],["从而更好地对小目标进行检测",{"2":{"400":1}}],["从而两个目标靠的非常近时会被识别成一个bbox",{"2":{"397":1}}],["从而对应的特征图共享一个卷积核",{"2":{"392":1}}],["从而使得训练速度加快",{"2":{"725":1}}],["从而使得模型在训练时对于噪音不敏感",{"2":{"507":1}}],["从而使得模型在训练时更注重于难分类的样本",{"2":{"387":1}}],["从而使梯度变大",{"2":{"351":1}}],["从而降低了隐含元的维度",{"2":{"718":1}}],["从而降低了模型的复杂性",{"2":{"459":1}}],["从而降低了物体检测的定位准确性",{"2":{"378":1}}],["从而降低数据的维度",{"2":{"353":1}}],["从而做到了高效",{"2":{"378":1}}],["从而将整个特征聚集过程转化为一个连续的操作",{"2":{"369":1}}],["从而产生梯度弥散的现象",{"2":{"350":1}}],["从而代替下采样和上采样",{"2":{"306":1}}],["从而",{"2":{"276":1,"721":2}}],["从而不会被清除",{"2":{"201":1}}],["从而避免梯度估计的偏差",{"2":{"445":1}}],["从而避免了对底层存储系统的查询压力",{"2":{"189":1}}],["从而避免出现数据脏读的现象�",{"2":{"142":1}}],["从节点实时同步这些数据",{"2":{"194":1}}],["从缓存取不到的数据",{"2":{"189":1}}],["从逻辑上讲",{"2":{"110":1}}],["从该数字中移除掉k个数位",{"2":{"19":1}}],[">array",{"2":{"757":1}}],[">a",{"2":{"756":2}}],[">key",{"2":{"91":2,"92":2}}],[">second",{"2":{"89":2}}],[">start",{"2":{"20":1}}],[">right",{"2":{"85":7,"86":2,"87":3,"88":1,"89":1,"90":1,"91":2,"92":2,"93":2,"94":2,"95":1}}],[">left",{"2":{"85":7,"86":2,"87":3,"88":1,"89":1,"90":1,"91":2,"92":2,"93":2,"94":2,"95":1}}],[">1",{"2":{"69":1,"87":1}}],[">null",{"2":{"69":2}}],[">next",{"2":{"55":8,"56":11}}],[">5",{"2":{"69":1}}],[">4",{"2":{"69":2}}],[">3",{"2":{"69":2}}],[">2",{"2":{"69":2}}],[">data",{"2":{"55":4,"56":3,"85":5,"86":2,"89":1,"94":3,"95":1}}],[">>",{"2":{"43":1}}],[">>k",{"2":{"43":1}}],[">weight",{"2":{"22":2,"59":2}}],[">edge",{"2":{"22":4,"59":4}}],[">e",{"2":{"22":2,"59":2}}],[">end",{"2":{"20":1}}],[">val",{"2":{"93":1,"94":4}}],[">v",{"2":{"22":2,"59":2}}],[">",{"2":{"18":1,"21":1,"22":2,"25":1,"29":1,"31":2,"34":1,"36":5,"38":1,"40":3,"41":2,"44":4,"45":3,"48":2,"49":1,"52":3,"54":2,"55":1,"58":6,"59":2,"66":1,"69":1,"78":1,"80":2,"82":1,"85":8,"86":1,"89":1,"111":1,"390":4,"397":1,"760":1,"796":5}}],[">=x",{"2":{"48":1}}],[">=0",{"2":{"10":1,"36":1}}],[">=",{"2":{"7":1,"31":1,"33":2,"36":1,"37":1,"41":1,"42":1,"45":1,"47":1,"52":1,"78":1,"80":1,"83":2,"756":1}}],["和连续的数值特征域",{"2":{"734":1}}],["和m",{"2":{"679":1}}],["和min",{"2":{"385":1}}],["和最终的",{"2":{"800":1}}],["和最小化12∥w∥2是等价的",{"2":{"635":1}}],["和最短距离数组",{"2":{"58":1}}],["和条件概",{"2":{"627":1}}],["和情感分",{"2":{"625":1}}],["和累计坏样本数占总坏样本数比",{"2":{"592":1}}],["和判",{"2":{"585":1}}],["和身份证是不是同一个无关",{"2":{"576":1}}],["和噪声",{"2":{"558":1}}],["和online",{"2":{"546":1}}],["和批量梯度下降",{"2":{"545":1}}],["和批归一化rnn",{"2":{"307":1}}],["和观察序列的长度",{"2":{"527":1}}],["和马尔科夫随机场",{"2":{"521":1}}],["和表现概率",{"2":{"520":1}}],["和权值向量w",{"2":{"519":1}}],["和属性随机",{"2":{"497":1}}],["和为1",{"2":{"428":1}}],["和多少训练时长",{"2":{"423":2}}],["和强化学习",{"2":{"423":1}}],["和加权求和是独立计算的",{"2":{"422":1}}],["和完整的编码器",{"2":{"422":1}}],["和新融合后的",{"2":{"388":1}}],["和分类器",{"2":{"378":1}}],["和定位准确性等方面都有大大提升",{"2":{"378":1}}],["和two",{"2":{"378":1}}],["和ti∗分别为网络的预测值和回归的目标",{"2":{"367":1}}],["和a",{"2":{"756":3}}],["和anchor",{"2":{"367":1}}],["和addition不同的是",{"2":{"318":1}}],["和参数量",{"2":{"315":1}}],["和该算子底层优化的程度有关",{"2":{"315":1}}],["和该事务在启动时看到的数据一致�",{"2":{"170":1}}],["和中心化",{"2":{"305":1}}],["和超过1的个数",{"0":{"283":1}}],["和80",{"2":{"282":1}}],["和y",{"2":{"267":1}}],["和缓存雪崩不同的是",{"2":{"190":1}}],["和老生代",{"2":{"110":1}}],["和从root到b的路",{"2":{"92":1}}],["和num2的第j位相乘的结果在乘积中的位置是",{"2":{"83":1}}],["和上一个类似",{"2":{"43":1}}],["和一个记忆层使其在长文本上表现更佳",{"2":{"690":1}}],["和一个目标值target",{"2":{"40":1}}],["和一个字典",{"2":{"35":1}}],["和",{"0":{"226":1,"568":1,"700":1,"784":1},"2":{"18":1,"56":1,"237":1,"246":2,"334":1,"367":1,"388":2,"422":6,"423":2,"702":2,"713":1,"725":2,"763":1}}],["和b进行比较",{"2":{"32":1}}],["和b",{"2":{"12":1}}],["不回流",{"2":{"786":1}}],["不换行",{"2":{"782":1}}],["不用关心细节",{"2":{"769":1}}],["不用对特征进行筛选",{"2":{"487":1}}],["不加也不影响结果",{"2":{"769":1}}],["不一定满足最大堆的性质",{"2":{"756":1}}],["不一定再保持简单的线性结构",{"2":{"422":1}}],["不对应的小文件不可能有相同的url",{"2":{"747":1}}],["不以细粒度的id建树",{"2":{"741":1}}],["不得不考虑长尾广告",{"2":{"741":1}}],["不足以表达多个有区分性的特征组合",{"2":{"741":1}}],["不再拼接",{"2":{"725":1}}],["不再重复",{"2":{"270":1}}],["不完全的双向预训练",{"2":{"708":1}}],["不归一化就做不到",{"2":{"679":1}}],["不平衡的样本可以给knn的预测结果造成哪些问题",{"0":{"650":1}}],["不算大也不算小",{"2":{"640":1}}],["不等式约束乘子非",{"2":{"635":1}}],["不适用于有隐变量的情况",{"2":{"632":1}}],["不适合直接输入语言模型",{"2":{"423":1}}],["不关心样本中类别的比例及类别下出现特征的概率",{"2":{"632":1}}],["不影响最终结果",{"2":{"630":1}}],["不影响类条件概率的计算",{"2":{"630":1}}],["不光看词语是否在文本中出现",{"2":{"621":1}}],["不稳定",{"2":{"546":2}}],["不断优化和提升的意�",{"2":{"815":1}}],["不断循环求梯度",{"2":{"542":1}}],["不断的降低模型的方差",{"2":{"501":1}}],["不知道下山的路",{"2":{"542":1}}],["不易过拟合",{"2":{"501":1}}],["不易调试要么从会话请求检查变量",{"2":{"334":1}}],["不必像预排序一样保留额外的对特征值进行预排序的信",{"2":{"497":1}}],["不过主要的思想依然是mapreduce模式",{"2":{"769":1}}],["不过可以筛选出来",{"2":{"739":1}}],["不过此时的解有无穷多个",{"2":{"636":1}}],["不过这里只涉及到加和操",{"2":{"497":1}}],["不过默认的方法是对特征预排序",{"2":{"497":1}}],["不过岭回归并不具有产生稀疏解的能力",{"2":{"330":1}}],["不允许有浮动对象",{"2":{"785":1}}],["不允许右边有浮动对象",{"2":{"785":1}}],["不允许左边有浮动对象",{"2":{"785":1}}],["不允许先把某一个类别的m颗树学习完",{"2":{"497":1}}],["不允许分割",{"2":{"166":1}}],["不建议自己生成one",{"2":{"446":1}}],["不容易过拟合",{"2":{"450":1,"466":1}}],["不容易发生过拟合",{"2":{"441":1}}],["不容易被在所有主题中都出现的高频词干扰",{"2":{"422":1}}],["不管是分类问题还是回归问题",{"2":{"431":1}}],["不管当前内存空间足够与否",{"2":{"122":1}}],["不计算损失",{"2":{"423":1}}],["不仅更能帮助我们写出更优的代码",{"2":{"769":1}}],["不仅要讲正负类样本分开",{"2":{"635":1}}],["不仅与它本身以及它前一个词的标注有关",{"2":{"527":1}}],["不仅和单个观测状态相关",{"2":{"527":1}}],["不仅需要存储特征值",{"2":{"513":1}}],["不仅支持",{"2":{"513":1}}],["不仅能降低过拟合",{"2":{"497":1,"513":1}}],["不仅学习最终答案",{"2":{"423":1}}],["不仅限于语义相似度",{"2":{"423":1}}],["不仅记录�",{"2":{"174":1}}],["不合法时触发二次问答或重新生成",{"2":{"422":1}}],["不合法则重试生成或触发",{"2":{"422":1}}],["不添加任何解释",{"2":{"422":1}}],["不太适合超大规模数据",{"2":{"422":1}}],["不依赖上下文",{"2":{"422":1}}],["不需要领域知识",{"2":{"730":1}}],["不需要就空置进行处理",{"2":{"730":1}}],["不需要计算准确的概率值",{"2":{"631":1}}],["不需要提前归一化",{"2":{"607":1}}],["不需要预先指定簇数",{"2":{"422":1}}],["不需要模型训练",{"2":{"422":1}}],["不需要大型模型推理",{"2":{"422":1}}],["不需要用户去手动释放锁",{"2":{"139":1}}],["不论是max",{"2":{"394":1}}],["不考虑剩余的block块即可",{"2":{"507":1}}],["不考虑bias",{"2":{"394":2,"395":1}}],["不考虑feature的通道个数",{"2":{"385":1}}],["不变的情况下",{"2":{"320":1}}],["不损失分辨率",{"2":{"320":1}}],["不同岗位的行为面试重�",{"0":{"837":1},"1":{"838":1,"839":1,"840":1}}],["不同问题不同分析",{"2":{"578":1}}],["不同的问题应该不同对",{"2":{"578":1}}],["不同的任务应该选择不同的评价指",{"2":{"578":1}}],["不同的节假日可以看成相互独立的模型",{"2":{"536":1}}],["不同域之间的用户相互独立",{"2":{"572":1}}],["不同模型的理论不同",{"2":{"521":1}}],["不同在于根据全局直方图进行各个worker上的节点分裂时会单独计算子节点的样本索引",{"2":{"514":1}}],["不同之处",{"2":{"489":1}}],["不同随机数的设定对于模型预测结果有一定的影响",{"2":{"451":1}}],["不同点",{"2":{"436":1,"501":1,"725":1}}],["不同网络",{"2":{"394":1}}],["不同数据集的某类别的ap计算方法大同小异",{"2":{"393":1}}],["不同级采用不同",{"2":{"389":1}}],["不同尺度feature",{"2":{"385":1}}],["不同尺寸和不同长宽比",{"2":{"367":1}}],["不同于现在的卷积神经网络可以自动提取高效特征进行图像表示",{"2":{"361":1}}],["不同于图像分类任务",{"2":{"360":1}}],["不同归一化方法的比较",{"2":{"307":1}}],["不同存储引擎的",{"2":{"162":1}}],["不剥夺条件",{"2":{"296":1}}],["不相撞概率=不相撞",{"2":{"281":1}}],["不相撞有有2种可能",{"2":{"281":1}}],["不满足p序列的要求",{"2":{"279":1}}],["不妨假设左端重",{"2":{"270":1}}],["不提供acid",{"2":{"258":1}}],["不会重新加载页面�",{"2":{"798":1}}],["不会详述每一种排序方法的原理",{"2":{"755":1}}],["不会因为一个用户年龄长了一岁就变成一个完全不同的人",{"2":{"664":1}}],["不会因为网络传输的问题发生混乱",{"2":{"237":1}}],["不会碎片",{"2":{"251":1}}],["不使用流量控制和拥塞控制",{"2":{"240":1}}],["不兼容低版本的浏览�",{"2":{"222":1}}],["不可靠传输",{"2":{"240":1}}],["不可控",{"2":{"192":1}}],["不可重入的优�",{"2":{"185":1}}],["不可�",{"2":{"121":1}}],["不存在就进行加锁",{"2":{"185":1}}],["不存在返回",{"2":{"41":1}}],["不包括查�",{"2":{"172":1}}],["不包含所有的顶点",{"2":{"58":1}}],["不要随意使用",{"2":{"787":1}}],["不要让二路归并排序限制我们的思想",{"2":{"760":1}}],["不要建立无意义的索引",{"2":{"169":1}}],["不要在索引列上面做任何操�",{"2":{"169":1}}],["不支持多播",{"2":{"240":1}}],["不支持事务",{"2":{"161":1}}],["不支持外键",{"2":{"161":1}}],["不为",{"2":{"144":1}}],["不安�",{"2":{"121":1}}],["不能影响其他元素",{"2":{"785":1}}],["不能处理的大问题",{"2":{"763":1}}],["不能将数据同时读入内存",{"2":{"755":1}}],["不能够很好地拟合数据",{"2":{"559":1}}],["不能很快的收敛到局部最优解",{"2":{"545":1}}],["不能很好处理非凸形簇或噪声数据",{"2":{"422":1}}],["不能",{"2":{"322":1,"461":1,"550":1}}],["不能强行剥夺",{"2":{"296":1}}],["不能逆序",{"2":{"94":1}}],["不能使用索引中范围条件右边的�",{"2":{"169":1}}],["不能使用任何标准库的大数类型",{"2":{"83":1}}],["不能使用2",{"2":{"8":1}}],["不是无用的",{"2":{"606":1,"609":1}}],["不是极值点",{"2":{"550":1}}],["不是说每棵树可以并行训练",{"2":{"505":1}}],["不是一次性对整行做归一化",{"2":{"422":1}}],["不是物理地址的指针",{"2":{"165":1}}],["不是对称",{"2":{"91":1}}],["不是",{"2":{"81":1}}],["不是子串",{"2":{"78":1}}],["不重复的整数",{"0":{"751":1}}],["不重复",{"2":{"81":1}}],["不重",{"2":{"18":1}}],["一切文件都是模块",{"2":{"800":1}}],["一篇",{"2":{"690":1}}],["一种思想是将输出改为一个霍夫曼树",{"2":{"719":1}}],["一种是用上下文预测中心词",{"2":{"718":1}}],["一种方法是选择一个距离当前任何质心最远的点",{"2":{"685":1}}],["一种基于树模型的bagging的优化版本",{"2":{"475":1}}],["一共训练出c",{"2":{"643":1}}],["一对一",{"2":{"643":1,"662":2,"690":1}}],["一对多",{"2":{"643":1,"662":2,"690":1}}],["一部分是有特征值a的数据",{"2":{"601":1}}],["一部分是分通道卷积",{"2":{"394":1,"395":1}}],["一周以后发现总收入下降了20",{"2":{"573":1}}],["一是在样本某些特征缺失的情况下选择划分的属性",{"2":{"601":1}}],["一是因为距离太远的词与当前词关系不大",{"2":{"527":1}}],["一是减少计算量",{"2":{"313":1}}],["一阶信息描述梯度变化方向",{"2":{"516":1}}],["一阶段ssd",{"0":{"409":1}}],["一类是以boosting",{"2":{"425":1}}],["一类是以bagging",{"2":{"425":1}}],["一句话总结贝叶斯算",{"0":{"631":1}}],["一句话的分词方式是唯一的",{"2":{"422":1}}],["一句话是不是只有唯一的分词方式",{"2":{"422":1}}],["一次性就可以加入到内存了",{"2":{"748":1}}],["一次特征提取产生多个feature",{"2":{"402":1}}],["一次买卖股",{"2":{"24":1}}],["一面",{"0":{"365":2,"368":1,"374":1,"378":1,"383":3,"385":2,"390":1,"396":2,"397":3,"399":1,"404":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1},"2":{"367":1,"385":1}}],["一位算法工程师经历30+场cv面试后总结的常见问题合集",{"2":{"358":1}}],["一位算法工程师经历",{"2":{"358":1}}],["一文详解卷积神经网络的演变历程",{"2":{"342":1}}],["一文详解数学原理及优缺点",{"2":{"319":1}}],["一方面数据变成了高维空间中线性可分的数据",{"2":{"638":1}}],["一方面耗时较长",{"2":{"546":1}}],["一方面要保留feature",{"2":{"339":1}}],["一方面进行特征压缩",{"2":{"339":1}}],["一方面使特征图变小",{"2":{"339":1}}],["一些关于词向量的问题",{"2":{"725":1}}],["一些互为反向的拟合相互抵消就可以达到整体上减少过拟合",{"2":{"564":1}}],["一些新的目标检测的backbone有哪些",{"0":{"412":1}}],["一些内核允许设备驱动的一些部分存在于用户空间",{"2":{"301":1}}],["一些看似复杂的问题当数据有序的时候就变的简单",{"2":{"50":1}}],["一道题对或者错的概率是0",{"2":{"282":1}}],["一定要注意",{"2":{"787":1}}],["一定要牢记",{"2":{"785":1}}],["一定满足最大堆的性质",{"2":{"756":1}}],["一定满足三边只和大于第三边",{"2":{"274":1}}],["一定最小",{"2":{"682":1}}],["一定是最大值",{"2":{"756":1}}],["一定是向量之间的异",{"2":{"497":1}}],["一定是从y中的两个边之差＞x",{"2":{"274":1}}],["一定会保证当前操作之后剩下的数字最小",{"2":{"19":1}}],["一把长度大约是球的直径2",{"2":{"271":1}}],["一",{"0":{"360":1},"1":{"361":1,"362":1},"2":{"270":1,"519":1}}],["一旦找到了一个局部最优值",{"2":{"628":1}}],["一旦得到处理机即可运行",{"2":{"291":1}}],["一旦事务提交",{"2":{"255":1}}],["一旦发现了只具有弱引用的对象",{"2":{"122":1}}],["一二三面面经",{"2":{"253":1}}],["一条记录时",{"2":{"174":1}}],["一条数据了",{"2":{"174":1}}],["一致性",{"2":{"166":1,"255":1}}],["一�",{"2":{"136":1,"192":1}}],["一直走到我们觉得已经到了山脚",{"2":{"542":1}}],["一直迭代",{"2":{"472":1}}],["一直失败",{"2":{"134":1}}],["一直全速运�",{"2":{"131":1}}],["一样",{"2":{"123":1}}],["一棵树的表达能力很弱",{"2":{"741":1}}],["一棵树的生成肯定还是不如多棵树",{"2":{"475":1}}],["一棵树中每个结点在分裂时",{"2":{"508":1}}],["一棵二叉树中每个节点的两个子树的深度相差不会超",{"2":{"87":1}}],["一棵高度平衡的二叉树的定义是",{"2":{"87":1}}],["一个浮动元素会尽量向左或向右移动",{"2":{"785":1}}],["一个mapreduce的程序主要有两部分组成",{"2":{"769":1}}],["一个搜索引擎执行的目标就是优化查询的速度",{"2":{"763":1}}],["一个在线尝试word2vec的小demo",{"2":{"725":1}}],["一个产物",{"2":{"725":1}}],["一个异常数据年龄300岁会给模型造成很大的干扰",{"2":{"664":1}}],["一个简单的改进思路就是将查询路径上的结点进行排序",{"2":{"651":1}}],["一个节点是a2对应的样本",{"2":{"604":1}}],["一个节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到",{"2":{"514":1}}],["一个词被标注为",{"2":{"527":1}}],["一个结点",{"2":{"502":1}}],["一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到",{"2":{"465":1}}],["一个灵活的模型没有泛化能力",{"2":{"459":1}}],["一个专业的提示词",{"2":{"422":1}}],["一个专业的提示词模板由哪几部分构成",{"2":{"422":1}}],["一个头可能捕捉语法结构",{"2":{"422":1}}],["一个负责bbox回归",{"2":{"387":1}}],["一个窗口只能检测一个目标",{"2":{"367":1}}],["一个roi",{"2":{"367":1}}],["一个中断通常只能中断一颗cpu",{"2":{"301":1}}],["一个资源每次只能被一个进程使用",{"2":{"296":1}}],["一个父进程退出",{"2":{"294":1}}],["一个进程因请求资源而阻塞时",{"2":{"296":1}}],["一个进程使用fork创建子进程",{"2":{"294":1}}],["一个进程正在等待某一事件发生",{"2":{"291":1}}],["一个进程至少有一个线程",{"2":{"288":1}}],["一个三角形",{"2":{"281":1}}],["一个y",{"2":{"274":1}}],["一个球",{"2":{"271":1}}],["一个帧到达路由器后",{"2":{"250":1}}],["一个子进程",{"2":{"192":1}}],["一个一定不存在的数据会被这�",{"2":{"189":1}}],["一个是归并操作",{"2":{"760":1}}],["一个是递归划分",{"2":{"760":1}}],["一个是使用残差模型",{"2":{"378":1}}],["一个是内存中的日志缓冲",{"2":{"173":1}}],["一个是标记整理",{"2":{"110":1}}],["一个是标记清除",{"2":{"110":1}}],["一个事务启动时",{"2":{"170":1}}],["一个事务执行过程中看到的数据",{"2":{"170":1}}],["一个事务提交后",{"2":{"170":1}}],["一个事务还没提交",{"2":{"170":1}}],["一个查询可以只使用索引中的一部份",{"2":{"168":1}}],["一个保存的是行的删除时间",{"2":{"162":1}}],["一个步长为2进行遍历",{"2":{"68":1}}],["一个步长为1",{"2":{"68":1}}],["一个最大值和最小",{"2":{"14":1}}],["一列是给定的数组的值",{"2":{"39":1}}],["一般来书我们的输入文件都是文件",{"2":{"769":1}}],["一般来说参数量越低的网络",{"2":{"394":1}}],["一般来说目标检测中的速度评价指标有",{"2":{"393":1}}],["一般来说",{"2":{"333":1}}],["一般应用在快速查询中",{"2":{"762":1}}],["一般应用于金融风控领域",{"2":{"592":1}}],["一般我们都是使用二路归并",{"2":{"760":1}}],["一般query的总量是有限的",{"2":{"748":1}}],["一般情况有很多学习率更新的方法",{"2":{"740":1}}],["一般情况下是一个自旋操作",{"2":{"134":1}}],["一般情况下贪心和排序一起出现",{"2":{"17":1}}],["一般推荐比较流行的items",{"2":{"730":1}}],["一般会对其进行缩放",{"2":{"703":1}}],["一般会得到5个不同的结果",{"2":{"564":1}}],["一般要用kernal",{"2":{"680":1}}],["一般用kd树来实现nn",{"2":{"651":1}}],["一般用最大似然估计",{"2":{"631":1}}],["一般假设样本服从正态分布",{"2":{"631":1}}],["一般都是单独事件发生的概率",{"2":{"613":1}}],["一般这种关系可以换神经网络分类方法来解决",{"2":{"607":1}}],["一般到80",{"2":{"573":1}}],["一般",{"2":{"546":3,"730":1}}],["一般讲",{"2":{"521":1}}],["一般不会直接使用",{"2":{"757":1}}],["一般不会考到图相关的问题",{"2":{"57":1}}],["一般不推荐改动默认值1e",{"2":{"484":1}}],["一般的弱分类器可以是决策树",{"2":{"453":1}}],["一般的常用评价指标有",{"2":{"393":1}}],["一般认为决策树表现良好",{"2":{"438":1}}],["一般使用最小二乘法",{"2":{"656":1}}],["一般使用有限个测试样例绘制roc曲线",{"2":{"590":1}}],["一般使用缩减因子对每棵树进行降权",{"2":{"497":1}}],["一般使用earlystopping进行控制迭代次数",{"2":{"437":1}}],["一般使用梯度的负方向替代偏差进行计算",{"2":{"436":1}}],["一般使用的是双线性插值",{"2":{"312":1}}],["一般选择多个相差较大的模型进行bagging",{"2":{"432":1}}],["一般池化",{"2":{"394":1}}],["一般默认是0",{"2":{"337":1}}],["一般value的格式是json或者文本等",{"2":{"258":1}}],["一般在形式上是一个二维数组",{"2":{"256":1}}],["一般免费证书较少",{"2":{"247":1}}],["一般是先训练gbdt在训练lr",{"2":{"741":1}}],["一般是",{"2":{"246":1}}],["一般是通过为数据库表增加一�",{"2":{"133":1}}],["一般失效时间较短",{"2":{"244":1}}],["一般aof每隔1s",{"2":{"193":1}}],["一般通过lock",{"2":{"139":1}}],["一般为高维映射",{"2":{"635":1}}],["一般为",{"2":{"131":1}}],["一般遇到数组相关的题目",{"2":{"39":1}}],["g的数据文件",{"2":{"763":1}}],["global",{"2":{"686":1,"740":1}}],["gb",{"2":{"763":1}}],["gb表示梯度提升",{"2":{"497":1}}],["gbm",{"2":{"464":1}}],["gbdt与lr融合方案",{"2":{"741":1}}],["gbdt与boosting区别较大",{"2":{"497":1}}],["gbdt每棵树都在学习前面棵树尚存的不足",{"2":{"741":1}}],["gbdt+lr如何训练",{"2":{"741":1}}],["gbdt+lr是facebook提出在线广告模型",{"2":{"739":1}}],["gbdt特征的重要性是如何评估的",{"2":{"741":1}}],["gbdt可以每天或者几天更新一次",{"2":{"740":1}}],["gbdt本来中的g代表grandient",{"2":{"515":1}}],["gbdt本轮迭代只需拟合当前模型的残差",{"2":{"493":1}}],["gbdt只用了一阶导数信息",{"2":{"504":1}}],["gbdt只能顺序生成",{"2":{"501":1}}],["gbdt$的实现也有学习速率",{"2":{"513":1}}],["gbdt$进行了一系列优化",{"2":{"503":1}}],["gbdt$",{"2":{"502":1}}],["gbdt容易过拟",{"2":{"501":1}}],["gbdt不断的降低模型的偏差",{"2":{"501":1}}],["gbdt对异常值比较敏",{"2":{"501":1}}],["gbdt对异常值敏感吗",{"2":{"498":1}}],["gbdt对异常值非常敏感",{"2":{"497":1}}],["gbdt如何防止过拟合",{"2":{"497":1}}],["gbdt没有任何改变",{"2":{"497":1}}],["gbdt应用在多分类问题",{"2":{"497":1}}],["gbdt使用的一阶梯度的泰勒展开式",{"2":{"497":1}}],["gbdt使用的是加法模型和前向分布算法",{"2":{"493":1}}],["gbdt使用基学习器是cart树",{"2":{"497":1}}],["gbdt为什么用负梯度代表残差",{"2":{"497":1}}],["gbdt格式化损失函",{"2":{"496":1}}],["gbdt的拟合值残差为什么用负梯度代替",{"0":{"515":1}}],["gbdt的区别",{"2":{"502":1}}],["gbdt的第m轮的扶梯度公",{"2":{"496":1}}],["gbdt的前向分布公",{"2":{"496":1}}],["gbdt也是迭代",{"2":{"493":1}}],["gbdt中的gradient",{"2":{"480":1}}],["gbdt用到的是boosting算法",{"2":{"480":1}}],["gbdt是非线性模型",{"2":{"502":1}}],["gbdt是加权融",{"2":{"501":1}}],["gbdt是采用boosing方法",{"2":{"497":1}}],["gbdt是训练过程如何选择特征",{"2":{"497":1}}],["gbdt是前向加法模型",{"2":{"497":1}}],["gbdt是一个非常流行的机器学习算法",{"2":{"495":1}}],["gbdt是如何做回归和分类的",{"0":{"472":1}}],["gbdt是根据前m",{"2":{"436":1}}],["gbdt和rf的特征重要性计算方法是相同的",{"2":{"462":1}}],["gbdt和rf如何计算特征重要性",{"0":{"462":1}}],["gbdt计算方法",{"2":{"462":1}}],["gbdt",{"0":{"480":1,"493":1,"739":1},"2":{"420":1,"456":1,"490":1,"497":3,"501":1,"503":1,"513":2}}],["gift",{"2":{"496":3}}],["gil+gir",{"2":{"462":1}}],["github",{"2":{"85":2,"203":2,"253":1,"303":1,"522":1,"556":1,"591":1,"725":1,"850":1}}],["g∑i=1nexp",{"2":{"430":1}}],["gmm",{"2":{"676":1}}],["gm∗=argming∑i=1nw^mii",{"2":{"430":1}}],["gm",{"2":{"430":1}}],["gpu需求",{"2":{"423":2}}],["gpu",{"0":{"787":1},"2":{"422":3,"423":2,"787":5}}],["gpt的缺点",{"0":{"711":1}}],["gpt",{"0":{"709":1},"1":{"710":1,"711":1},"2":{"422":3,"711":1}}],["gpt类",{"2":{"422":1}}],["g组k",{"2":{"422":1}}],["gqa",{"2":{"422":2}}],["gated",{"2":{"690":1}}],["gaussian",{"2":{"568":1,"635":1,"674":1}}],["gain",{"2":{"512":1,"601":1,"603":1}}],["gamma$",{"2":{"635":1}}],["gamma=",{"2":{"635":1}}],["gamma",{"2":{"507":1,"635":5}}],["gaoyi135",{"2":{"414":1}}],["gan用一个生成模型和一个判别模型",{"2":{"352":1}}],["gan网络的思想",{"0":{"352":1}}],["gd算法可以实时的依据网民的点击行为进行迁移",{"2":{"546":1}}],["gd在互联网领域用的较多",{"2":{"546":1}}],["gd于mini",{"2":{"546":1}}],["gd的区别",{"2":{"546":1}}],["gdbt的做法是采用一对多的策略也就是说",{"2":{"497":1}}],["gd",{"2":{"308":1,"546":4}}],["gn和sn",{"2":{"307":1}}],["gn都是什么",{"2":{"307":1}}],["go等后端语言",{"2":{"846":1}}],["google公司设计mapreduce的初衷主要是为了解决其搜索引擎中大规模网页数据的并行化处理",{"2":{"769":1}}],["good3",{"2":{"111":3}}],["good2",{"2":{"111":3}}],["good",{"2":{"111":6,"592":1}}],["goss对要进行分裂的特征按照绝对值大小进行排序",{"2":{"467":1}}],["goss算法从减少样本的角度出发",{"2":{"467":1}}],["goss",{"0":{"467":1},"2":{"464":1,"495":1}}],["got",{"2":{"218":2}}],["gc",{"0":{"153":1}}],["gcd",{"2":{"27":4}}],["geq",{"2":{"635":1}}],["geqslant",{"2":{"602":1}}],["generation",{"2":{"110":2,"423":1}}],["generate",{"2":{"80":4}}],["generateparenthesis",{"2":{"80":1}}],["getter",{"2":{"796":2}}],["getelementbyid",{"2":{"226":1,"796":2}}],["getinstance",{"2":{"144":1}}],["getheight",{"2":{"87":5}}],["get",{"2":{"82":2,"796":2}}],["geeksforgeeks",{"2":{"16":1,"62":1,"96":2}}],["g",{"2":{"60":1,"422":1,"428":1,"496":1,"532":1,"651":1,"763":1}}],["g进行拓扑排序",{"2":{"60":1}}],["gru",{"0":{"699":1,"700":1},"2":{"690":1,"698":1,"700":3}}],["greedy对每个特征都需要遍历一遍数据",{"2":{"514":1}}],["greedy算法来说",{"2":{"514":1}}],["greater",{"2":{"21":1,"54":1}}],["group=512的卷积跑100次",{"2":{"357":1}}],["gram模型",{"0":{"722":1},"1":{"723":1,"724":1}}],["gram",{"2":{"718":1,"725":1}}],["gram神经网络模型",{"2":{"718":1}}],["grams",{"2":{"527":1}}],["gradient",{"2":{"464":1,"495":1,"497":1}}],["gradients",{"2":{"361":1}}],["grandyang",{"2":{"96":1}}],["graph简称dag",{"2":{"60":1}}],["graph",{"0":{"57":1},"1":{"58":1,"59":1,"60":1,"61":1},"2":{"22":16,"58":7,"59":21,"60":2,"61":4,"62":1}}],["grid",{"2":{"33":16}}],["gtld服务器接收请求并返回name",{"2":{"249":1}}],["gt",{"0":{"365":1,"368":1,"369":1,"374":1,"378":1,"383":1,"385":1,"389":1,"390":1,"396":1,"397":1,"399":1,"404":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1,"600":2},"2":{"6":1,"18":1,"23":2,"25":1,"58":3,"66":8,"67":8,"89":3,"267":7,"271":1,"274":8,"279":1,"367":2,"385":1,"390":1,"393":1,"397":1,"422":2,"428":5,"430":1,"567":1,"591":1,"632":2,"634":1,"635":3,"638":1,"664":1,"697":14,"756":2,"769":2,"776":12,"795":2}}],["参照",{"2":{"472":1}}],["参�",{"0":{"203":1}}],["参考论文",{"2":{"770":1}}],["参考见",{"2":{"725":1}}],["参考文",{"0":{"644":1}}],["参考资",{"0":{"538":1}}],["参考资料",{"0":{"442":1,"473":1,"556":1,"577":1,"610":1,"686":1},"2":{"305":1,"306":1,"307":1,"308":1,"312":1,"313":1,"315":1,"318":1,"319":1,"320":1,"323":1,"326":1,"330":1,"333":1,"334":1,"335":1,"338":1,"339":1,"343":1,"345":1,"346":1,"558":1,"656":1,"658":1,"664":1,"665":1,"666":1,"670":1,"671":1,"725":1}}],["参考tinyzero在verl框架下的配置",{"2":{"423":1}}],["参考代码",{"2":{"390":1,"397":1}}],["参考答案",{"2":{"342":1,"356":1}}],["参考链接",{"0":{"253":1,"303":1,"414":1},"2":{"563":1,"564":1,"567":1,"568":1}}],["参考",{"0":{"62":1,"259":1,"272":1,"284":1,"743":1,"753":1,"771":1},"2":{"298":1,"591":1}}],["参考哈夫曼树的构造",{"2":{"21":1}}],["参数更新不需要继续传播",{"2":{"703":1}}],["参数更少",{"2":{"700":1}}],["参数共享",{"2":{"693":1}}],["参数多",{"2":{"640":1}}],["参数少",{"2":{"640":1}}],["参数调优",{"0":{"628":1}}],["参数太多",{"2":{"559":1}}],["参数的初始值选择",{"2":{"544":1}}],["参数可能过拟合领域数据",{"2":{"423":1}}],["参数冻结",{"2":{"423":1}}],["参数选择困难",{"2":{"422":1}}],["参数与flops中一致",{"0":{"395":1}}],["参数为3",{"2":{"357":3}}],["参数为两个int数组",{"2":{"61":1}}],["参数量2",{"2":{"395":1}}],["参数量2=",{"2":{"395":1}}],["参数量1",{"2":{"395":1}}],["参数量参数量1=k2∗cin",{"2":{"395":1}}],["参数量paras计算",{"0":{"395":1}}],["参数量",{"2":{"394":1,"395":1}}],["参数量的计算方式",{"2":{"314":1}}],["参数量越大",{"2":{"314":1}}],["参数量指的是网络中可学习变量的数量",{"2":{"314":1}}],["参数",{"0":{"537":1,"699":1},"2":{"129":1,"422":1,"507":1,"515":1}}],["参数有哪些",{"0":{"128":1},"1":{"129":1,"130":1,"131":1}}],["参数dist和path需要初始化大小",{"2":{"58":1}}],["参",{"0":{"16":1,"96":1,"499":1,"517":1,"522":1,"529":1,"595":1,"652":1,"764":1}}],["个人品质",{"0":{"820":1},"1":{"821":1,"822":1}}],["个人价值与公司发展的结�",{"2":{"810":1}}],["个人觉得这是的最主要的优点",{"2":{"485":1}}],["个性化",{"2":{"809":1}}],["个新的方法",{"2":{"798":1}}],["个小文件",{"2":{"763":1}}],["个参数",{"2":{"699":1}}],["个输出通道",{"2":{"689":1}}],["个分类器",{"2":{"643":1}}],["个类",{"2":{"618":1}}],["个子样本来迭代",{"2":{"545":1}}],["个要素",{"2":{"525":1}}],["个label的得分",{"2":{"521":1}}],["个体学习器是串行序列化生成的",{"2":{"425":1}}],["个",{"2":{"422":1,"689":1}}],["个尺度的最终输出",{"2":{"388":1}}],["个单元",{"2":{"368":1}}],["个proposals",{"2":{"367":1}}],["个左右",{"2":{"366":2}}],["个字节的固定长度",{"2":{"251":1}}],["个字节的可变长度",{"2":{"251":1}}],["个字符应该是",{"2":{"81":3}}],["个字符组成的子串本身就是回文",{"2":{"7":1}}],["个字符最少分割多少次可以使得到的都是回文子串",{"2":{"7":1}}],["个请求一定会有一个请求重新对这个",{"2":{"184":1}}],["个请求打过来的话",{"2":{"184":1}}],["个功能",{"2":{"143":1}}],["个线程的线程�",{"2":{"131":1}}],["个点",{"2":{"61":1}}],["个数的和等于目标数字",{"2":{"15":1}}],["个数",{"2":{"15":1,"533":1,"763":1}}],["个数里面找出",{"2":{"15":1}}],["个不同的正整数",{"2":{"15":1}}],["每当数据变化时",{"2":{"790":1}}],["每当被判定属于某一类的时候",{"2":{"643":1}}],["每种下游任务都要特定的设计",{"2":{"708":1}}],["每种尺度预测3个box",{"2":{"378":1}}],["每回迭代都会用簇内点的平均值去更新簇中心",{"2":{"682":1}}],["每张图像通常用一个几百维的向量来表示",{"2":{"651":1}}],["每张表只能拥有一个聚簇索引",{"2":{"165":1}}],["每天更新一次",{"2":{"546":1}}],["每天都有两种操作",{"2":{"26":1}}],["每走到一个位置的时候",{"2":{"542":1}}],["每棵树训练前需要等前面的树训练完成才能开始训练",{"2":{"505":1}}],["每棵树的权重和错误率有关",{"2":{"489":1}}],["每轮计算可以不使用全部样本",{"2":{"507":1}}],["每轮的训练是在上一轮的训练的残差基础之上进行训练的",{"2":{"497":1}}],["每轮构建",{"2":{"472":1}}],["每轮训练结束后",{"2":{"440":1}}],["每轮训练一直存在分类错误的问题",{"0":{"440":1}}],["每步可加入人工或规则约束",{"2":{"423":1}}],["每生成一个新",{"2":{"422":1}}],["每6次作为一个事件",{"2":{"279":1}}],["每排5个人",{"2":{"275":1}}],["每份四只",{"2":{"270":1}}],["每经过一个传输轮次",{"2":{"243":1}}],["每收到一个新的确认报文之后",{"2":{"243":1}}],["每隔一定的时间",{"2":{"201":1}}],["每隔5分钟",{"2":{"192":1}}],["每s一次fsync",{"2":{"193":1}}],["每秒同步一�",{"2":{"193":1}}],["每开始一个新的事务",{"2":{"162":1}}],["每个页面至少需要一次回流",{"2":{"786":1}}],["每个盒子的布局由以下因素决定",{"2":{"784":1}}],["每个数分配2bit",{"2":{"751":1}}],["每个url各占64字节",{"2":{"747":1}}],["每个会员分别有r",{"2":{"679":1}}],["每个变量有单独的权重",{"2":{"664":1}}],["每个worker上的数据先建立起局部的直方图",{"2":{"514":1}}],["每个worker进行切分即可",{"2":{"514":1}}],["每个worker寻找局部最佳切分点",{"2":{"514":1}}],["每个样本设置一个权重",{"2":{"601":1}}],["每个样本的权重是二阶",{"2":{"514":1}}],["每个样本都有大量候选框参与训练",{"2":{"321":1}}],["每个特征点的局部特征用一个高维向量来表征",{"2":{"651":1}}],["每个特征同等重要",{"2":{"616":1}}],["每个特征采用常数个分位点作为候选分割点",{"2":{"506":1}}],["每个特征按特征值对样本进行预排序",{"2":{"505":1}}],["每个新的模型的建立是为了使得之前的模型的残差往梯度下降的方法",{"2":{"497":1}}],["每个叶子节点上输出的score的l2模的平方和",{"2":{"497":1}}],["每个叶子节点的索引可以被编码为长度等于树深度的二进制向量",{"2":{"450":1}}],["每个训练样本的权值相同",{"2":{"428":1}}],["每个训练样本的权值应该相等",{"2":{"427":1}}],["每个小块单独计算缩放因子",{"2":{"423":1}}],["每个子体负责单一任务",{"2":{"423":1}}],["每个头独立计算q",{"2":{"422":1}}],["每个注意力头并不只关注一个词元",{"2":{"422":1}}],["每个注意力头只关注一个词元吗",{"2":{"422":1}}],["每个",{"2":{"422":1}}],["每个bbox的面积",{"2":{"397":1}}],["每个输入都需要经历4次运算",{"2":{"394":1}}],["每个采样点的特征值由其相邻的4个整型特征点的像素值通过双线性差值得到",{"2":{"369":1}}],["每个group对应n",{"2":{"348":1}}],["每个module是由多个卷积层组成",{"2":{"311":1}}],["每个设备或设备集都有它自己的irq",{"2":{"301":1}}],["每个设置过期时间的key都需要创建一个定时器",{"2":{"201":1}}],["每个独立的进程有程序运行的入口",{"2":{"288":1}}],["每个线程都有自己独立的运行栈和程序计数器",{"2":{"288":1}}],["每个进程都有独立的代码和数据空间",{"2":{"288":1}}],["每个蚂蚁在方向的选择上有且只有2种可能",{"2":{"281":1}}],["每个家庭的女孩数目为",{"2":{"276":1}}],["每个家庭都有且只有一个儿子",{"2":{"276":1}}],["每个首部行在结束地方都有",{"2":{"246":1}}],["每个首部行都是由",{"2":{"246":1}}],["每个事件都会先由根传到目标元素",{"2":{"226":1}}],["每个对象都会在其内部初始化一个属性",{"2":{"212":1}}],["每个文件的query都可能重复",{"2":{"748":1}}],["每个文件的每一行存放的都是用户的query",{"2":{"748":1}}],["每个文件1g",{"2":{"748":1}}],["每个文件都代表了某时�",{"2":{"192":1}}],["每个文件就是一个模块",{"2":{"112":1}}],["每个模块内部",{"2":{"112":1}}],["每个import的js文件都是单例",{"2":{"112":1}}],["每个单元格只预测2个bbox",{"2":{"378":1}}],["每个单元的边界也不做量化",{"2":{"369":1}}],["每个单元中的字母最多只能使用一次",{"2":{"36":1}}],["每个单词由单个空格分隔",{"2":{"77":1}}],["每个顶点的相邻的点",{"2":{"59":1}}],["每个物品的大小为a",{"2":{"4":1}}],["每一行代表一个数据",{"2":{"769":1}}],["每一行有一",{"2":{"763":1}}],["每一次改�",{"2":{"798":1}}],["每一次将一个例作为正例",{"2":{"662":1}}],["每一次使用新的采样点来测试目标函数时",{"2":{"628":1}}],["每一次的数据分布都不同",{"2":{"435":1}}],["每一次合并两个最小的数",{"2":{"21":1}}],["每一对夫妇一定会有一个人和其他夫妇握手",{"2":{"268":1}}],["每一层对应的节点作为vector",{"2":{"89":1}}],["每一修改一个字符",{"2":{"35":1}}],["每一个盒子的左外边缘会触碰到容器的左边缘",{"2":{"784":1}}],["每一个工作节点",{"2":{"769":1}}],["每一个单词的概率用其路径上的权重乘积来表示",{"2":{"719":1}}],["每一个特征都是原来特征权重值的百分之一",{"2":{"669":1}}],["每一个叶子节点都是通过多个条件之后的划分空间",{"2":{"598":1}}],["每一个划分阈值对应着一个bin容器编号",{"2":{"470":1}}],["每一个人都可能和其他人握手",{"2":{"268":1}}],["每一个网络连接其实都对应一个文件描述符",{"2":{"202":1}}],["每一个你可以选择任意一只猫a去消耗另外一只猫b的萌系数",{"2":{"27":1}}],["每一个猫都有一个初始化的萌系数",{"2":{"27":1}}],["每次弹出一个最大值",{"2":{"763":1}}],["每次维护堆的性质",{"2":{"756":1}}],["每次迭代都将数据集中的各个点划分到距离它最近的簇内",{"2":{"675":1}}],["每次迭代都学习一棵cart树来拟合之前",{"2":{"503":1}}],["每次使用yes",{"2":{"497":1}}],["每次建树样本个数随机选择",{"2":{"492":1}}],["每次建树特征个数随机选择",{"2":{"492":1}}],["每次传入的不同数据得到的结果是相同的",{"2":{"322":1}}],["每次只处理一部分",{"2":{"422":1}}],["每次只随机选取一个样本来更新模型参数",{"2":{"321":1}}],["每次只能改变一个字母",{"2":{"35":1}}],["每次只能选择两个数a",{"2":{"21":1}}],["每次都是提高前一次分错了的数据集的权值",{"2":{"456":1}}],["每次都要复制",{"2":{"302":1}}],["每次都取红球的概率是1",{"2":{"277":1}}],["每次任意取一个又放回",{"2":{"277":1}}],["每次写入数据库后",{"2":{"196":1}}],["每次有数据修改发生时都会同�",{"2":{"193":1}}],["每次�",{"2":{"192":1}}],["每次对数据结构中的加锁次�",{"2":{"185":1}}],["每次查询都需要从根结点到叶结点",{"2":{"167":1}}],["每次等概率随机返回一个元",{"2":{"73":1}}],["每次选择一个入度为0的顶点u",{"2":{"60":1}}],["每次去掉三个数",{"2":{"42":1}}],["每次去掉两个数",{"2":{"42":1}}],["每次怕判断是够使用第i个",{"2":{"34":1}}],["每次改变a的一个字",{"2":{"32":1}}],["每次给当前片段加上空格",{"2":{"31":1}}],["每次合并需要消耗a+b的能量",{"2":{"21":1}}],["每次更新最大最小",{"2":{"14":1}}],["overflow",{"2":{"784":1}}],["oversample",{"2":{"403":1}}],["ol>�",{"2":{"774":1}}],["oldstate",{"2":{"793":1}}],["old",{"2":{"110":1}}],["oldc",{"2":{"35":2}}],["o6if0f1treyia",{"2":{"556":1}}],["omega$求导数并另其等于0",{"2":{"496":1}}],["other方式",{"2":{"470":1}}],["otherwise",{"2":{"372":1,"532":1}}],["otherwise其中",{"2":{"367":1}}],["oob",{"2":{"462":1,"483":1}}],["ohnm",{"2":{"370":1}}],["operatorname",{"2":{"635":4,"730":1}}],["operating",{"2":{"590":1}}],["operation",{"2":{"318":1}}],["operations的缩写",{"2":{"394":1}}],["operations",{"2":{"315":1,"394":1}}],["openai",{"2":{"422":1,"423":1}}],["optimization",{"2":{"423":2}}],["opt",{"2":{"299":1}}],["o的方式是相同",{"2":{"301":1}}],["o的请求",{"2":{"301":1}}],["o可以在进程之间产生并且调度过程通常和磁盘i",{"2":{"301":1}}],["o完成",{"2":{"301":1}}],["o完成等",{"2":{"291":1}}],["o模型的不同",{"2":{"301":1}}],["o请求通常可以排队并且可以稍后处理",{"2":{"301":1}}],["o请求需要被立即处理",{"2":{"301":1}}],["o发生的程序",{"2":{"301":1}}],["o而等待i",{"2":{"291":1}}],["o操作完成而进入就绪状态时",{"2":{"291":1}}],["obj2",{"2":{"224":6}}],["obj1",{"2":{"224":6}}],["obj",{"2":{"223":1,"496":1,"796":6}}],["object",{"0":{"124":1,"224":1},"2":{"64":1,"68":1,"69":3,"70":2,"71":2,"72":1,"73":1,"123":1,"210":1,"211":7,"223":1,"224":2,"796":2}}],["online",{"2":{"546":3}}],["only",{"2":{"258":1}}],["only模式追加�",{"2":{"193":1}}],["one",{"2":{"378":1,"464":1,"495":1,"705":1,"725":2}}],["onclick",{"2":{"226":1}}],["once",{"2":{"111":2}}],["onxxx",{"0":{"226":1},"2":{"226":1}}],["on",{"2":{"192":1,"686":1}}],["odds",{"2":{"663":2}}],["oddevensort",{"2":{"49":1}}],["odps",{"2":{"192":1}}],["offsets",{"2":{"372":2}}],["of",{"0":{"221":1},"2":{"89":1,"90":5,"221":2,"361":1,"375":1,"497":1,"511":1,"651":1,"674":1,"682":1,"684":2,"686":1,"769":1}}],["o",{"2":{"82":1,"120":2,"167":1,"202":2,"301":1,"302":7,"549":1,"725":2,"787":1}}],["outliers",{"2":{"680":1}}],["outlook",{"2":{"518":1}}],["out",{"2":{"511":1}}],["outpre",{"2":{"67":4}}],["output�",{"2":{"800":1}}],["output层",{"0":{"737":1}}],["output",{"2":{"3":1,"6":1,"38":1,"95":2,"223":5,"422":1,"702":1,"800":3}}],["outervar",{"2":{"214":2}}],["outer",{"2":{"66":6,"67":10,"214":2}}],["oriented",{"2":{"361":1}}],["oracle",{"2":{"258":1}}],["or",{"2":{"67":1,"497":1,"730":1}}],["ordered则是对ordered",{"2":{"449":1}}],["ordered和plain",{"2":{"449":1}}],["order",{"2":{"60":4,"397":12}}],["org",{"2":{"16":1,"62":1,"96":2}}],["own=max",{"2":{"26":1}}],["own",{"2":{"26":3}}],["ok",{"2":{"13":1,"245":1}}],["是扁平化的链表的数据存储结构",{"2":{"792":1}}],["是大量的同步计算任务阻塞了浏览器�",{"2":{"792":1}}],["是使�",{"2":{"790":1}}],["是使用同一个学习器在不同的数据分布上进行学习",{"2":{"435":1}}],["是什么",{"0":{"784":2}}],["是每一个人都会关心的问题",{"2":{"768":1}}],["是每次只考虑当前最优",{"2":{"17":1}}],["是我们面临的问题",{"2":{"768":1}}],["是最常用的方法",{"2":{"757":1}}],["是2010年rendle提出的一个强大的非线性分类模型",{"2":{"735":1}}],["是去掉svd的σ成分",{"2":{"730":1}}],["是o",{"2":{"725":1}}],["是分开的",{"2":{"708":1}}],["是分类器所预测正确的正样本占所有正样本的比例",{"2":{"588":1}}],["是分类器预测的正样本中预测正确的比例",{"2":{"587":1}}],["是因为点积的方差是",{"2":{"703":1}}],["是因为从泰勒展开式来看",{"2":{"497":1}}],["是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析",{"2":{"654":1}}],["是杂乱无章的",{"2":{"651":1}}],["是由smo算法解出来的",{"2":{"635":1}}],["是模型数据的可视化呈现",{"2":{"795":1}}],["是模型在测试数据上变现良好",{"2":{"605":1}}],["是模型整个结构中的非线性扭曲力",{"2":{"319":1}}],["是样本集d基于划分点t二分之后的信息增益",{"2":{"603":1}}],["是互联网广告常用的术",{"2":{"593":1}}],["是互相影响的",{"2":{"589":1}}],["是函数的驻点",{"2":{"552":1}}],["是两种主要梯度下降法",{"2":{"545":1}}],["是自然语言处理的重要技术",{"2":{"527":1}}],["是随机场的一种",{"2":{"519":1}}],["是给定一组输入随机变量条",{"2":{"519":1}}],["是gbdt的损失函数",{"2":{"497":1}}],["是k个树的加权平均",{"2":{"497":1}}],["是进行分类问题的时候",{"2":{"497":1}}],["是的每棵树不容易过拟合",{"2":{"497":1}}],["是常数",{"2":{"496":2}}],["是bagging的一个扩展变体",{"2":{"492":1}}],["是为解决gbdt训练速度慢",{"2":{"464":1}}],["是为了减少神经元对部分上层神经元的依赖",{"2":{"565":1}}],["是为了保证能够忽略泰勒公式中的高阶无穷小项",{"2":{"555":1}}],["是为了实现多模态对齐和区分",{"2":{"423":1}}],["是为了管理主存的方便而划分的",{"2":{"300":1}}],["是如何把",{"2":{"423":1}}],["是如何实现增量计算",{"2":{"422":1}}],["是医疗领域主流选择",{"2":{"423":1}}],["是针对一个",{"2":{"422":1}}],["是针对单个文档计算词频和逆文档频率",{"2":{"422":1}}],["是靠在输入里加明确的角色标记",{"2":{"422":1}}],["是floating",{"2":{"394":2}}],["是predicted",{"2":{"367":1}}],["是该物体或不是",{"2":{"367":1}}],["是属于multi",{"2":{"360":1}}],["是dilation",{"2":{"306":2}}],["是普通的卷积过程",{"2":{"306":1}}],["是事件b",{"2":{"282":1}}],["是事件a",{"2":{"282":1}}],["是c",{"2":{"275":1}}],["是建立在关系模型基础上的数据库",{"2":{"258":1}}],["是无状态的",{"2":{"247":1}}],["是用来说明浏览器",{"2":{"246":1}}],["是干什么的",{"2":{"220":1}}],["是持久化之外的一种数据冗余方�",{"2":{"194":1}}],["是指基于海量数据的存储",{"2":{"768":1}}],["是指将一台redis服务器的数据",{"2":{"194":1}}],["是指缓存和数据库中都没有的数据",{"2":{"189":1}}],["是单线程的吗",{"0":{"202":1}}],["是单线程的",{"2":{"184":1}}],["是通过索引来获取的",{"2":{"514":1}}],["是通过在每行记录后面保存两个隐藏的列来实现的",{"2":{"162":1}}],["是通过保存数据在某个时间点的快照来实现�",{"2":{"162":1}}],["是解决由于多线程通过共享内存进行通信时",{"2":{"140":1}}],["是不是应该使用下mapreduce",{"2":{"752":1}}],["是不是自身互为镜",{"2":{"91":1}}],["是不同的",{"2":{"394":1}}],["是不可中断类型的锁",{"2":{"139":1}}],["是从",{"2":{"139":1}}],["是",{"2":{"139":1,"423":1,"525":1,"615":1,"689":1}}],["是能保证单个变量的操作是原子性的",{"2":{"135":1}}],["是一步步传递信息",{"2":{"422":1}}],["是一�",{"2":{"224":1}}],["是一种非线性模型",{"2":{"597":1,"631":1}}],["是一种鉴别式机率模型",{"2":{"519":1}}],["是一种随机化的数据",{"2":{"186":1}}],["是一种多版本并发控制机制",{"2":{"162":1}}],["是一种规范",{"2":{"140":1}}],["是一种很出名的无锁的算法",{"2":{"134":1}}],["是一个模块打包工具",{"2":{"800":1}}],["是一个动态的环境",{"2":{"740":1}}],["是一个被严重简化了的模型",{"2":{"622":1}}],["是一个衡量cpa广告效果的指标",{"2":{"594":1}}],["是一个衡量硬件性能的指标",{"2":{"394":1}}],["是一个客户端和服务器端请求和应答的标准",{"2":{"247":1}}],["是一个子序列",{"2":{"78":1}}],["是一个空串的时候",{"2":{"74":1}}],["是根据概率统计而选择的",{"2":{"120":1}}],["是时间和空间成本上寻求的一种折中选择",{"2":{"119":1}}],["是对wide",{"2":{"732":1}}],["是对锁只能加一次",{"2":{"185":1}}],["是对1中如何设置有效期的优�",{"2":{"185":1}}],["是对外的接口",{"2":{"112":1}}],["是对称的",{"2":{"91":1}}],["是将g中所有顶点排成一个线性序列",{"2":{"60":1}}],["是相邻的",{"2":{"33":1}}],["是否运行结束",{"2":{"770":1}}],["是否完成",{"2":{"302":1}}],["是否公平�",{"2":{"139":1}}],["是否原子性",{"0":{"132":1},"1":{"133":1,"134":1,"135":1}}],["是否可中�",{"2":{"139":1}}],["是否可手动释放",{"2":{"139":1}}],["是否可变",{"2":{"121":1}}],["是否可以使用数据结构",{"2":{"39":1}}],["是否可以二分",{"2":{"39":1}}],["是否在字典中",{"2":{"31":1}}],["是否能够组成s3",{"2":{"13":1}}],["是回文串",{"2":{"7":1}}],["在压力下保持高效工�",{"2":{"821":1}}],["在不确定性下做出决策的能�",{"2":{"816":1}}],["在不考虑采样的情况下",{"2":{"669":1}}],["在哪里输出它所创建�",{"2":{"800":1}}],["在哪些场景下",{"2":{"423":1}}],["在配置时主要有如下常用属性",{"2":{"800":1}}],["在监听事件中",{"2":{"798":1}}],["在页面元素很多",{"2":{"792":1}}],["在构�",{"2":{"790":1}}],["在构建模型的过程中",{"2":{"307":1}}],["在写函数的时候只需要注意key和value怎么设置",{"2":{"769":1}}],["在公司中或者个人的使用的时候",{"2":{"769":1}}],["在解决海量数据的问题的时候",{"2":{"768":1}}],["在解决海量数据的问题的时候使用的技术",{"2":{"754":1}}],["在某个结点处",{"2":{"762":1}}],["在某些点上不能求导",{"2":{"580":1}}],["在某些噪音比较大的样本集上",{"2":{"485":1}}],["在相应的子树上",{"2":{"762":1}}],["在相同的机器资源里面",{"2":{"109":1}}],["在内存中和文件上如何分配",{"2":{"761":1}}],["在内存中查询是否有结果",{"2":{"163":1}}],["在改变之前",{"2":{"756":1}}],["在改进的情况下可以处理多分类问题",{"2":{"672":1}}],["在堆的数据结构进行增删改查的过程中",{"2":{"756":1}}],["在top",{"2":{"756":1}}],["在2",{"2":{"751":1}}],["在时间t内被点击设置为label=1",{"2":{"740":1}}],["在时间步向前执行完后才开始输出结果序列",{"2":{"690":1}}],["在时间步向前执行完后输出单个结果",{"2":{"690":1}}],["在时间步向前时同时输出结果序列",{"2":{"690":2}}],["在协同过滤中",{"2":{"730":1}}],["在语言模型训练的过程中",{"2":{"725":1}}],["在cbow模型中",{"2":{"721":1}}],["在百万级的数据集上需要耗时数周才能得到相对不错的结果",{"2":{"718":1}}],["在知识蒸馏过程中",{"2":{"703":1}}],["在效果没有明显下降的同时",{"2":{"690":1}}],["在长文本上有梯度消失和梯度爆炸的问题",{"2":{"690":1}}],["在长上下文外推时的挑战",{"2":{"422":1}}],["在长上下文外推时会面临什么挑战",{"2":{"422":1}}],["在输入句子序列上平滑移动",{"2":{"689":1}}],["在两棵树种分别落入叶子节点2和叶子节点1",{"2":{"739":1}}],["在两端随着log",{"2":{"663":1}}],["在两者中间还插入了一个",{"2":{"367":1}}],["在其已有的样本进行一个加权拟合",{"2":{"657":1}}],["在原始kd",{"2":{"651":1}}],["在原图中最近得像素点赋值给新的像素点",{"2":{"369":1}}],["在介绍bbf算法前",{"2":{"651":1}}],["在x附近找离它最近的k个数据点",{"2":{"651":1}}],["在x∈",{"2":{"306":1}}],["在knn的样本搜索中",{"0":{"648":1}}],["在应用中",{"2":{"647":1}}],["在应用程序中",{"2":{"199":1}}],["在实现贝叶斯分类器时",{"2":{"631":1}}],["在实际的使用中也经常使用",{"2":{"618":1}}],["在预测时",{"2":{"630":1}}],["在预测新数据时",{"2":{"489":1}}],["在建模时将被忽略",{"2":{"630":1}}],["在建树的阶段",{"2":{"449":1}}],["在算法的建模时和预测时数据的属性都是单独处理的",{"2":{"630":1}}],["在算法参数初始化时",{"2":{"544":1}}],["在测试一个新点时",{"2":{"628":1}}],["在测试集上精度很差时",{"2":{"307":1}}],["在已知分类y的条件下",{"2":{"627":1,"632":1}}],["在统计学习框架下",{"2":{"622":1}}],["在文本分类场景中",{"2":{"625":1}}],["在文本分类中",{"2":{"621":1}}],["在文本领域应用广泛",{"2":{"621":1}}],["在朴素贝叶斯的计算过程中",{"2":{"619":1}}],["在各个类中观测计数分别",{"2":{"618":1}}],["在指定的训练样本中",{"2":{"618":2}}],["在观察样本",{"2":{"618":1}}],["在决策树构建完成之后",{"2":{"605":1}}],["在决策树节点分裂的时候",{"2":{"460":1}}],["在id3或c4",{"2":{"604":1}}],["在叶子节点中计算每个类的条件概率",{"2":{"598":1}}],["在所有的负样本中",{"2":{"590":1}}],["在所有的正样本中",{"2":{"590":1}}],["在样本量足够大的时候",{"2":{"571":1}}],["在app",{"2":{"570":1}}],["在adaboost训练过程中",{"2":{"487":1,"488":1}}],["在该点处的二阶导数等于0",{"2":{"551":1}}],["在该点处的二阶导数小于0",{"2":{"551":1}}],["在该点处的二阶导数大于0",{"2":{"551":1}}],["在此过程中",{"2":{"542":1}}],["在求解损失函数的最小值时",{"2":{"540":1}}],["在增量函数是逻辑回归函数的时候",{"2":{"537":1}}],["在默认的函数中是",{"2":{"533":1}}],["在序列标注问题中",{"2":{"527":1}}],["在给定观测集合x的条件下",{"2":{"521":1}}],["在归一化时考虑了数据在全局的分布",{"2":{"520":1}}],["在条件随机场当中",{"2":{"519":1}}],["在目标函数中加入了正则项",{"2":{"513":1}}],["在可扩展性和训练速度上有了巨大的提升",{"2":{"503":1}}],["在高维空间中做运算",{"2":{"635":1}}],["在高维稀疏的情况下这种情况很常见",{"2":{"502":1}}],["在高维文本空间中",{"2":{"422":1}}],["在精度和速度上都有各自的优点",{"2":{"497":1}}],["在回归的使用是使用的k个树的平均",{"2":{"497":1}}],["在进行完一次迭代后",{"2":{"513":1}}],["在进行节点的分裂时",{"2":{"497":2,"505":1,"513":1}}],["在进行embedding的时候可以更好的降低模型的方差",{"2":{"497":1}}],["在进行卷积操作的时候",{"2":{"348":1}}],["在包含x0的某个闭区间",{"2":{"496":1}}],["在gbdt建树方案中",{"2":{"741":1}}],["在gbdt的迭代中",{"2":{"493":1}}],["在gradientboost中",{"2":{"497":1}}],["在gdbt的每一步迭代中",{"2":{"448":1}}],["在框架内可以使用各种方法构建子分类器",{"2":{"487":1}}],["在随机森林中某个特征x的重要性的计算方法如下",{"2":{"483":1}}],["在得到0",{"0":{"482":1}}],["在迭代的每一步构建弱学习器弥补原有模型的不足",{"2":{"480":1}}],["在节点上所有的样本特征中选择一部分样本特征",{"2":{"475":1}}],["在后面查找特征分割点时可以重复使用",{"2":{"505":1}}],["在后面的训练中",{"2":{"472":1}}],["在后面加0",{"2":{"12":1}}],["在剩下梯度小的数据中选取b个",{"2":{"467":1}}],["在分裂次数相同的情况下",{"2":{"466":1}}],["在分类问题中",{"2":{"339":1}}],["在速度上可以提升一倍",{"2":{"465":1}}],["在sklearn中",{"2":{"462":1}}],["在之前学习器做错的样本上投入更多关注",{"2":{"456":1}}],["在性能方面可以匹敌任何先进的机器学习算法",{"2":{"451":1}}],["在传统的gbdt框架当中",{"2":{"449":1}}],["在传统的观点里",{"2":{"109":1}}],["在生成第二个节点时",{"2":{"446":1}}],["在选择第一个节点时",{"2":{"446":1}}],["在同一时间维度下",{"2":{"570":1}}],["在同一个数据分布上",{"2":{"435":1}}],["在同一平台上模型运行延时越长",{"2":{"315":1}}],["在最终分类器中的系数",{"2":{"428":1}}],["在类似",{"2":{"423":1}}],["在蒸馏数据中包含丰富领域术语和知识点",{"2":{"423":1}}],["在特征到结果的映射中加入了一层sigmoid函数",{"2":{"666":1}}],["在特征图中每个点新建若干固定尺寸的anchor",{"2":{"386":1}}],["在特定领域的能力",{"2":{"423":1}}],["在非推理任务上的表现也不如",{"2":{"423":1}}],["在微调时加入原始预训练数据或多样化样本",{"2":{"423":1}}],["在保证一定查找精度的前提下使得查找速度较快",{"2":{"651":1}}],["在保证样本分组不重叠的基础上",{"2":{"573":1}}],["在保证高效率的同时防止过拟合",{"2":{"466":1}}],["在保证不影响其他物体的基础上",{"2":{"403":1}}],["在保持高压缩的同时",{"2":{"423":1}}],["在中文任务上表现不佳",{"2":{"423":1}}],["在中序中找到前序的第一个节点a",{"2":{"90":1}}],["在命名实体识别任务中",{"2":{"423":1}}],["在医疗文本上继续预训练",{"2":{"423":1}}],["在继续预训练时",{"2":{"423":1}}],["在线学习的学习率如何设置",{"2":{"740":1}}],["在线微调或向量归一化强制约束时",{"2":{"423":1}}],["在线只需计算查询向量并快速检索",{"2":{"423":1}}],["在索引中用查询向量检索最相似的照片特征",{"2":{"423":1}}],["在向量相似度检索前对用户输入进行改写",{"2":{"423":1}}],["在提示中加入说明",{"2":{"423":1}}],["在提示词构造后进行语义分析",{"2":{"422":1}}],["在没有推理能力前",{"2":{"422":1}}],["在没有推理模型之前",{"2":{"422":1}}],["在没有其他进程可以执行时",{"2":{"291":1}}],["在计算实例的概率时",{"2":{"618":1}}],["在计算",{"2":{"422":1}}],["在大模型",{"2":{"422":1}}],["在大多数情况下代替行级锁",{"2":{"162":1}}],["在基础网络部分常常会生成比原图小数十倍的特征图",{"2":{"402":1}}],["在基于数据库表的版本解决方案中",{"2":{"133":1}}],["在fm的应用是二阶特征交叉时的表征",{"2":{"738":1}}],["在fpn之前目标检测的大多数方法都是和分类一样",{"2":{"401":1}}],["在feature",{"2":{"320":1}}],["在每次划分特征的时候会遍历所有可能的划分点找到最有的特征分裂点",{"2":{"497":1}}],["在每一段内的映射是不变的",{"2":{"739":1}}],["在每一层都动态构建直方图",{"2":{"514":1}}],["在每一轮建立树之前",{"2":{"446":1}}],["在每一个iou阈值下都有某一类别的ap值",{"2":{"393":1}}],["在每个网格中预测两个bbox这种约束方式减少了对同一目标的多次检测",{"2":{"383":1}}],["在每个单元中计算固定四个坐标位置",{"2":{"369":1}}],["在voc2010及以后",{"2":{"393":1}}],["在voc2010以前",{"2":{"393":1}}],["在value中加入需要的字段",{"2":{"258":1}}],["在一定程度上实现了特征的选择",{"2":{"562":1}}],["在一定程度上",{"2":{"383":1}}],["在一个",{"2":{"784":1}}],["在一个大小为10gb的文件中有一堆整数",{"2":{"763":1}}],["在一个主题建模项目中",{"2":{"422":1}}],["在一个很大很有代表性的模型中",{"2":{"339":1}}],["在一个世世代代都重男轻女的村庄里",{"2":{"276":1}}],["在一个文件里面定义的变量",{"2":{"112":1}}],["在点",{"2":{"369":1}}],["在数学上",{"2":{"369":1}}],["在数据稀疏的情况",{"2":{"730":1}}],["在数据集中找离它最近的点",{"2":{"651":1}}],["在数据库中也没有取到",{"2":{"189":1}}],["在数据修改的时候",{"2":{"174":1}}],["在resize时",{"2":{"368":1}}],["在resnet和inception结构中最后一层都使用了平均池化",{"2":{"339":1}}],["在resnet模块中",{"2":{"320":1}}],["在pooling的过程中需要计算pooling后的结果对应到feature",{"2":{"368":1}}],["在检测速度方面尤为明显",{"2":{"365":1}}],["在检索数据时从联合索引的最左边开始匹�",{"2":{"168":1}}],["在结构上",{"2":{"365":1}}],["在图像和nlp领域这一结构信息尤为重要",{"2":{"355":1}}],["在刚刚开始训练时以很小的学习率进行训练",{"2":{"346":1}}],["在减少维度的同时",{"2":{"339":1}}],["在减少参数维度的贡献上更大一点",{"2":{"339":1}}],["在网络比较深的地方",{"2":{"339":1}}],["在网络中使用bn层",{"2":{"307":1}}],["在反向传播时",{"2":{"338":1}}],["在反向传播过程中",{"2":{"328":1}}],["在0处的次微分集合是",{"2":{"337":1}}],["在loss方面",{"2":{"336":1}}],["在合理的范围之内",{"2":{"333":1}}],["在前向传播和反向传播过程中",{"2":{"328":1}}],["在训练时以一定的概率使神经元失活",{"2":{"566":1}}],["在训练时将训练集和验证集损失分别输出",{"2":{"307":1}}],["在训练数据和未知数据上表现都很差",{"2":{"559":1}}],["在训练数据集t上的指数损失函数最小",{"2":{"430":1}}],["在训练数据集上的分类误差率",{"2":{"428":1}}],["在训练之前",{"2":{"505":1}}],["在训练决策树计算切分点的增益时",{"2":{"497":1}}],["在训练决策树模型的节点的时候",{"2":{"475":1}}],["在训练后",{"2":{"485":1}}],["在训练嵌入模型时",{"2":{"423":1}}],["在训练过程根据链式法则不断迭代更新",{"2":{"314":1}}],["在对称的max",{"2":{"312":1}}],["在卷积神经网络中",{"2":{"312":1}}],["在有多核心的系统上",{"2":{"301":1}}],["在未使用完之前",{"2":{"296":1}}],["在切回来的时候",{"2":{"289":1}}],["在脑门上贴数字",{"2":{"267":1}}],["在这道题中",{"2":{"763":1}}],["在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分",{"2":{"475":1}}],["在这种情况下",{"2":{"459":1}}],["在这种情况下显然max",{"2":{"339":1}}],["在这个过程中",{"2":{"252":1}}],["在这n个数里面找出k个数",{"2":{"34":1}}],["在请求报文中",{"2":{"246":1}}],["在收到确认后再发下一个分组",{"2":{"241":1}}],["在筛选时对设置了过期时间的键值对进行随机删除",{"2":{"200":1}}],["在筛选时会针对设置了过期时间的键值对",{"2":{"200":1}}],["在主从复制的基础上",{"2":{"194":1}}],["在创建新日志时",{"2":{"193":1}}],["在替换之前的文件",{"2":{"192":1}}],["在论文中模型的目标是共同学习低阶和高阶特征交互",{"2":{"733":1}}],["在论文",{"2":{"186":1}}],["在新的redis",{"2":{"185":1}}],["在mapreduce中都是",{"2":{"770":1}}],["在mapreduce的编程模式中",{"2":{"769":1}}],["在master端开启binlog",{"2":{"172":1}}],["在mse的情况下",{"2":{"516":1}}],["在mysql建立联合索引时会遵守最左前缀匹配原则",{"2":{"168":1}}],["在聚簇索引之上创建的索引称之为辅助索引",{"2":{"165":1}}],["在它前面的操作已经全部完�",{"2":{"143":1}}],["在多线程操作情况下",{"2":{"142":1}}],["在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的",{"2":{"140":1}}],["在任何时候都可能被垃圾回收器回收",{"2":{"122":1}}],["在垃圾回收器线程扫描它所管辖的内存区域的过程中",{"2":{"122":1}}],["在垃圾回收后会产生碎片内存",{"2":{"110":1}}],["在负载因子0",{"2":{"120":1}}],["在执行多个中间件中的逻辑时",{"2":{"114":1}}],["在执行了n次遍历之后",{"2":{"74":1}}],["在es6规范中",{"2":{"112":1}}],["在清除前会进行一步整理",{"2":{"110":1}}],["在空间快要占满时将存活对象复制到",{"2":{"110":1}}],["在函数中声明一个变量",{"2":{"110":1}}],["在完成原地修改输入数组后",{"2":{"81":1}}],["在字符串中",{"2":{"77":1}}],["在字串中增加空格来构建一个句子",{"2":{"31":1}}],["在双向链表中删除指定元素",{"0":{"70":1}}],["在面试的过程中",{"2":{"57":1}}],["在面试过程中遇到排序问题",{"2":{"50":1}}],["在右边",{"2":{"48":1}}],["在",{"2":{"15":1,"110":1,"133":1,"135":2,"165":1,"369":1,"422":2,"423":6,"702":1,"705":1,"784":3}}],["在n个物品中挑选若干物品装入背包",{"2":{"4":1}}],["求top",{"2":{"763":1}}],["求每对小文件中相同的url时",{"2":{"747":1}}],["求得的都是测量值",{"2":{"654":1}}],["求得分离超平面",{"2":{"636":1}}],["求得分离超平面和分类决策函数",{"2":{"635":2}}],["求得最优解求得最优解",{"2":{"635":1}}],["求得一个几何间隔最大的分离超平面",{"2":{"635":1}}],["求",{"0":{"699":1},"2":{"635":1}}],["求对α的极大",{"2":{"635":1}}],["求minw",{"2":{"635":2}}],["求解方法",{"2":{"635":1}}],["求解使得该观测序列概率最大的模型",{"2":{"527":1}}],["求解的",{"2":{"280":1}}],["求下列概率值",{"2":{"277":1}}],["求单链表的中间节点",{"0":{"65":1}}],["求所有滑动窗口里的最大值�",{"2":{"47":1}}],["求这两个出现一次的数�",{"2":{"43":1}}],["求出残差",{"2":{"472":3}}],["求出现一次的数�",{"2":{"43":1}}],["求出这个出现一次的数�",{"2":{"43":1}}],["求出岛屿的个",{"2":{"33":1}}],["求出从左上角到右下角的最小路径的",{"2":{"9":1}}],["求可能的最小结果",{"2":{"19":1}}],["求问有多少种方案",{"2":{"15":1}}],["求长度为n",{"2":{"12":1}}],["t2",{"2":{"761":1}}],["t1",{"2":{"761":1}}],["t0",{"2":{"761":1}}],["t的几何间隔为",{"2":{"635":1}}],["t的函数间隔为",{"2":{"635":1}}],["t的样本预测为负",{"2":{"591":1}}],["t的样本预测为正",{"2":{"591":1}}],["t再区间",{"2":{"603":1}}],["t将d分为子集dt−与dt+",{"2":{"603":1}}],["tn",{"2":{"586":1,"591":1}}],["tnode",{"2":{"82":1}}],["tpr作为纵坐标",{"2":{"592":1}}],["tpr和fpr在坐标图上形成一条曲线",{"2":{"591":1}}],["tpr=tptp+fnfpr=fpfp+tn随着阈值t的变化",{"2":{"591":1}}],["tpr=tptp+fn",{"2":{"590":1}}],["tpr",{"2":{"590":4}}],["tp+fp+tn+fn=样例总数",{"2":{"586":1}}],["tp",{"2":{"586":1,"591":1}}],["t∇2f",{"2":{"555":1}}],["t∇f",{"2":{"547":1}}],["t∈di",{"2":{"536":1}}],["t就是",{"2":{"533":1}}],["t≥sj0",{"2":{"532":1}}],["tγ",{"2":{"532":1}}],["t−",{"2":{"532":1}}],["t−1",{"2":{"496":4,"697":5}}],["tδx=−α",{"2":{"547":1}}],["tδx+o",{"2":{"547":2}}],["tδ",{"2":{"532":1}}],["t轮迭",{"2":{"496":1}}],["t个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出",{"2":{"455":1,"475":1}}],["t$是规范化因子",{"2":{"428":1}}],["t+1",{"2":{"428":3}}],["t=1",{"2":{"455":1,"475":1}}],["t=",{"2":{"428":1,"431":1,"635":3}}],["ture",{"2":{"586":1}}],["tuning",{"2":{"423":1}}],["tutorial",{"2":{"203":1}}],["ts对类别型特征进行转化后的标准gbdt算法",{"2":{"449":1}}],["tsdae",{"2":{"423":2}}],["tsetnoc",{"2":{"77":1}}],["tf",{"2":{"422":10}}],["txt$",{"2":{"800":2}}],["txt",{"2":{"796":4}}],["tx∗=",{"2":{"372":1}}],["tx=",{"2":{"372":1}}],["tx=x−xa",{"2":{"367":1}}],["tm",{"2":{"741":1}}],["tmh=h",{"2":{"367":1}}],["tmp",{"2":{"20":3,"35":10,"40":3,"55":7,"58":2,"72":5,"85":12,"86":7,"760":7}}],["ty∗=",{"2":{"372":1}}],["ty∗=y∗−ya",{"2":{"367":1}}],["ty=",{"2":{"372":1}}],["ty=y−ya",{"2":{"367":1}}],["typename",{"2":{"762":1}}],["type=",{"2":{"796":1}}],["type=cover",{"2":{"462":1}}],["type=gain",{"2":{"462":1}}],["type=weight",{"2":{"462":1}}],["typeof",{"2":{"211":10,"223":1}}],["type",{"2":{"111":14}}],["typedef",{"2":{"90":1}}],["title",{"2":{"798":3}}],["title>",{"2":{"796":1}}],["title>defineproperty",{"2":{"796":1}}],["tilde",{"2":{"601":7}}],["tinyzero",{"2":{"423":1}}],["ti−ti∗",{"2":{"372":1}}],["ti∗得尽可能相近",{"2":{"372":1}}],["ti∗",{"2":{"367":1,"372":1}}],["ti",{"2":{"367":2,"372":1}}],["timeout",{"2":{"139":1,"218":1}}],["timeunit",{"2":{"129":1,"139":1}}],["time",{"2":{"26":1,"217":16,"525":1}}],["tcp拥塞控制",{"0":{"243":1}}],["tcp流量控制",{"0":{"242":1}}],["tcp的接收端只允许发送端发送接收端缓冲区能接纳的数据",{"2":{"241":1}}],["tcp如何保证可靠传输",{"0":{"241":1}}],["tcp报文",{"2":{"240":1}}],["tcp和udp的区别",{"0":{"240":1}}],["tcp",{"2":{"235":1,"236":1,"237":1,"240":1,"241":9,"247":1,"253":1}}],["ttl",{"2":{"200":1}}],["tb",{"2":{"163":2}}],["term",{"2":{"690":2}}],["technology",{"2":{"686":1}}],["techniques",{"2":{"686":1}}],["textcnn",{"2":{"689":1}}],["text",{"2":{"423":1,"635":1,"796":1}}],["tencent",{"0":{"409":1,"410":1}}],["tensorflow的区别和选择",{"2":{"334":1}}],["tensorflow",{"2":{"334":2}}],["tensorflow与pytorch编程方式不同",{"2":{"334":2}}],["test",{"0":{"224":2},"2":{"112":3,"224":1,"571":1,"741":1,"800":2}}],["tel",{"2":{"77":1}}],["temperature",{"2":{"422":3}}],["temp=s",{"2":{"77":1}}],["temp=strs",{"2":{"74":1}}],["temp=temp",{"2":{"74":1}}],["template",{"2":{"51":2,"53":2,"762":1,"800":1}}],["temp",{"2":{"32":6,"38":7,"46":3,"53":7,"74":4}}],["t",{"2":{"51":10,"53":8,"59":1,"82":2,"367":1,"428":2,"455":1,"475":1,"496":8,"503":1,"531":4,"532":15,"535":1,"536":6,"547":1,"555":1,"591":2,"602":4,"603":3,"635":16,"660":2,"697":9,"741":1,"762":1}}],["t>",{"2":{"51":3,"53":2,"762":1}}],["twosumplus",{"2":{"40":1}}],["twosum",{"2":{"40":1}}],["two",{"0":{"40":1},"2":{"365":1,"367":1}}],["trie树是一种前缀树",{"2":{"762":1}}],["trie树",{"2":{"754":1,"768":1}}],["truth更接近",{"2":{"372":1}}],["truth",{"2":{"367":2}}],["true",{"2":{"7":1,"36":4,"38":1,"45":1,"61":1,"64":1,"67":1,"68":1,"75":3,"76":3,"78":1,"87":1,"91":2,"92":2,"111":1,"129":1,"136":1,"139":1,"224":1,"586":1,"590":1}}],["trylock",{"2":{"139":1}}],["try",{"2":{"137":1,"139":1}}],["tracholar",{"2":{"591":1}}],["training",{"2":{"519":1}}],["tradeoff角度来讲",{"2":{"497":1}}],["translatez",{"2":{"787":5}}],["translate3d",{"2":{"787":1}}],["translation",{"2":{"690":1}}],["transform",{"2":{"787":6}}],["transformer",{"0":{"704":1,"705":1},"1":{"705":1},"2":{"399":1,"422":3,"423":1,"710":1,"713":1}}],["transaction",{"2":{"26":1}}],["traversal",{"2":{"89":1,"90":2}}],["tree的最近邻查找算法中",{"2":{"651":1}}],["tree是为什么在低维空间中有效而到了高维空间后查找效率就会下降",{"2":{"651":1}}],["tree满足对高维数据的索引",{"2":{"651":1}}],["tree用于对高维数据",{"2":{"651":1}}],["tree在维度较小时",{"2":{"651":1}}],["tree表示使用决策树作为基学习器",{"2":{"497":1}}],["trees",{"2":{"186":1}}],["tree查找",{"2":{"165":1}}],["treenode",{"2":{"84":6,"85":9,"86":3,"87":2,"88":1,"89":1,"90":4,"93":2,"94":3,"762":2}}],["tree",{"0":{"84":1},"1":{"85":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"92":1,"93":1,"94":1,"95":1,"96":1},"2":{"84":1,"89":1,"90":3,"96":2,"497":1,"651":1,"739":1}}],["tool",{"2":{"422":1}}],["token",{"2":{"422":14,"423":1,"690":1,"713":1,"716":1}}],["torch",{"2":{"390":2,"397":2}}],["tostring",{"2":{"83":1}}],["tolower",{"2":{"76":2}}],["to",{"0":{"407":1},"2":{"26":1,"56":1,"81":1,"110":7,"186":1,"368":1,"667":1,"759":1,"800":1}}],["topologicalsort",{"2":{"60":1}}],["top",{"0":{"749":1,"752":1},"2":{"21":2,"54":1,"60":4,"75":3,"85":2,"86":2,"422":2,"730":1,"769":1,"786":1}}],["through",{"0":{"593":1}}],["three",{"2":{"253":1,"312":1}}],["threshold=0",{"2":{"397":1}}],["threshold阈值就删除",{"2":{"397":1}}],["threshold",{"2":{"243":1,"397":1}}],["threadlocal",{"0":{"145":1}}],["threadfactory",{"2":{"129":1}}],["th∗=log⁡",{"2":{"372":1}}],["th∗=h∗",{"2":{"367":1}}],["th=log⁡",{"2":{"372":1}}],["that",{"2":{"90":2}}],["theta$",{"2":{"545":2}}],["theta",{"2":{"545":1,"635":1}}],["the",{"2":{"60":1,"218":2,"253":1,"318":1,"375":1,"497":1,"558":1}}],["there",{"2":{"60":1}}],["then语句构建成了树的形式",{"2":{"597":1}}],["then",{"2":{"11":1,"217":7,"218":5}}],["thisobj",{"2":{"213":2}}],["this",{"2":{"20":2,"111":14,"793":7,"796":1}}],["table>�",{"2":{"774":1}}],["ta=",{"2":{"603":1}}],["tardis",{"2":{"567":1}}],["target捕获事件目标",{"2":{"227":1}}],["target�",{"2":{"40":1}}],["target",{"2":{"15":2,"34":11,"40":9,"41":6,"45":6,"226":1,"796":1}}],["tasks",{"2":{"423":1}}],["task",{"2":{"422":1,"829":1}}],["task的问题",{"2":{"360":1}}],["tanh函数",{"2":{"319":1}}],["take",{"2":{"77":1}}],["tail",{"2":{"64":4}}],["tag",{"2":{"26":1}}],["tag=dynamic",{"2":{"16":1}}],["转而利�",{"2":{"792":1}}],["转而去执行高优先级的任务或者浏览器的动画渲染等",{"2":{"792":1}}],["转化方法",{"2":{"423":1}}],["转化为概率分布",{"2":{"422":1}}],["转化为一维数",{"2":{"10":1}}],["转换为应用程序的依赖图",{"2":{"800":1}}],["转换为模型支持的格式",{"2":{"423":1}}],["转换为word2的最少操作次数",{"2":{"5":1}}],["转置卷积又或是说反卷积",{"2":{"312":1}}],["其根本原因",{"2":{"792":1}}],["其优缺点是什么",{"0":{"787":1}}],["其优势如下",{"2":{"514":1}}],["其取值有以下几种",{"2":{"785":1}}],["其分配到的reduce任务也要重新执行",{"2":{"770":1}}],["其模型表现能力不强",{"2":{"739":1}}],["其模型表达式如下",{"2":{"527":1}}],["其本质都可以看作是语言模型",{"2":{"725":1}}],["其复杂度和设定的负样本数k线性相关",{"2":{"725":1}}],["其次模型的优化目标函数是最小二乘",{"2":{"666":1}}],["其结果都在",{"2":{"660":1}}],["其主要思想为找到空间中的一个更够将所有数据样本划开的超平面",{"2":{"642":1}}],["其主要目的是控制模型复杂度",{"2":{"330":1}}],["其原问题满足slater定理",{"2":{"635":1}}],["其学习算法就是求解凸二次规划的最优化算法",{"2":{"634":1}}],["其学习策略就是间隔最大化",{"2":{"634":1}}],["其还包括核技巧",{"2":{"634":1}}],["其基本模型定义为特征空间上的间隔最大的线性分类器",{"2":{"634":1}}],["其基本思想是",{"2":{"621":1}}],["其它树恰好作为补充",{"2":{"741":1}}],["其它树的预测结果",{"2":{"472":1}}],["其它两个网络给出了错误结果",{"2":{"564":1}}],["其参数值会比较大",{"2":{"562":1}}],["其参数θ按梯度方向更新θi公式如下",{"2":{"545":1}}],["其hessian",{"2":{"552":1}}],["其作用是保证x+δx在x的邻域内",{"2":{"549":1}}],["其作用是保证x+δx在x的",{"2":{"547":1}}],["其目的是增加某些限制来加速运算求解",{"2":{"545":1}}],["其特点",{"2":{"519":1}}],["其决策树都是完全二叉树",{"2":{"497":1}}],["其效率和可扩展性很难满足要求",{"2":{"495":1}}],["其在变量抽样选取的时候",{"2":{"489":1}}],["其相对",{"2":{"464":1}}],["其相似度就越大",{"2":{"382":1}}],["其计算过程分为三步",{"2":{"422":1}}],["其计算复杂度是",{"2":{"422":1}}],["其误差也更大",{"2":{"381":1}}],["其能检测超过9000种类别的物体",{"2":{"378":1}}],["其利用anchor",{"2":{"378":1}}],["其核心思想是在两个方向分别进行一次线性插值",{"2":{"369":1}}],["其余类为另外一类",{"2":{"643":1}}],["其余层采用leak",{"2":{"378":1}}],["其余位置补0",{"2":{"312":1}}],["其余同上",{"2":{"79":1}}],["其传送的运输协议数据单元tpdu是",{"2":{"240":2}}],["其回调�",{"2":{"218":1}}],["其不受外界影响",{"2":{"217":1}}],["其变更才会被其他事务看�",{"2":{"170":1}}],["其实应用多还有就是快速排序中的一次划分很重要",{"2":{"757":1}}],["其实训练收敛完以后",{"2":{"669":1}}],["其实这就是将平时所说的if",{"2":{"597":1}}],["其实很简单",{"2":{"508":1}}],["其实",{"2":{"470":1}}],["其实就是保留全部的不确定性",{"2":{"527":1}}],["其实就是被",{"2":{"428":1}}],["其实就是多尺度的滑动窗口",{"2":{"391":1}}],["其实已经通过k",{"2":{"381":1}}],["其实都是对象",{"2":{"210":1}}],["其实是加载该模块的module",{"2":{"112":1}}],["其实可以根据数据的分布选择对应的分类器",{"2":{"438":1}}],["其实可以",{"2":{"92":1}}],["其实我们知道如果是一个递增序列",{"2":{"25":1}}],["其他的某些外部因素",{"2":{"784":1}}],["其他的作为反例",{"2":{"662":1}}],["其他节点之和master节点通信",{"2":{"770":1}}],["其他",{"2":{"527":1,"703":1}}],["其他worker才能开始分裂",{"2":{"514":1}}],["其他多模态或跨语言任务",{"2":{"423":1}}],["其他检测网络",{"0":{"384":1},"1":{"385":1,"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1,"396":1,"397":1}}],["其他插值方式还有最近邻插值",{"2":{"312":1}}],["其他进程也访问该资源",{"2":{"293":1}}],["其他对象",{"2":{"210":1}}],["其他事务的更新对它就不可见�",{"2":{"170":1}}],["其他几种构造二叉树的方",{"2":{"90":1}}],["其他都出现了三次",{"2":{"43":1}}],["其他都出现了两次",{"2":{"43":1}}],["其他出现两次",{"2":{"43":1}}],["其中一部分的所有数据都比另外一部分的所有数据都要小",{"2":{"757":1}}],["其中用a训练gbdt的时候",{"2":{"741":1}}],["其中也包含部分没用的组合特征",{"2":{"739":1}}],["其中d表示对items进行d个主题划分",{"2":{"730":1}}],["其中u为user特征矩阵",{"2":{"730":1}}],["其中um",{"2":{"730":1}}],["其中uu为user",{"2":{"729":1}}],["其中w指中心词",{"2":{"719":1}}],["其中w是权重",{"2":{"457":1}}],["其中其中x",{"2":{"635":1}}],["其中gain",{"2":{"603":1}}],["其中gbdt中的核心是通过用分类器",{"2":{"497":1}}],["其中对角线对应于",{"2":{"590":1}}],["其中roc曲线的横轴是",{"2":{"590":1}}],["其中β为犯第二类错误的概率",{"2":{"574":1}}],["其中α为拉普拉斯平滑",{"2":{"621":1}}],["其中α为人工设定的接近于的正数",{"2":{"547":1}}],["其中α是人工设置的学习率",{"2":{"555":1}}],["其中隐马",{"2":{"521":1}}],["其中就是期望输出与分类器预测输出的查",{"2":{"497":1}}],["其中的模型可以单独进行训练",{"2":{"453":1}}],["其中a有n个取值",{"2":{"603":1}}],["其中adaboost每一轮通过误差来改变数据的分布",{"2":{"432":1}}],["其中ack报文是用来应答的",{"2":{"239":1}}],["其中bagging方式是降低模型方差",{"2":{"432":1}}],["其中b中的元素bix",{"2":{"46":1}}],["其中",{"2":{"430":1,"496":2,"532":1,"536":1,"555":1,"741":1}}],["其中包括哪些类别的嵌入任务",{"2":{"423":1}}],["其中大",{"2":{"388":1}}],["其中xgboost是对原始版本的gbdt算法的改进",{"2":{"497":1}}],["其中x",{"2":{"372":1}}],["其中μ为所有样本的均值",{"2":{"306":1}}],["其中max是样本数据的最大值",{"2":{"306":1}}],["其中产生01和产生10的概率是相等的",{"2":{"278":1}}],["其中阻塞系数在",{"2":{"131":1}}],["其中有两个值得一提的亮点",{"2":{"378":1}}],["其中有两个出现一次",{"2":{"43":1}}],["其中有一个数字出现了超过1",{"2":{"42":1}}],["其中只有一个数出现了一次",{"2":{"43":1}}],["其中相邻单元指的是水平或者垂直方向相邻",{"2":{"36":1}}],["其中第i个元素是一支股票在第i天的价格",{"2":{"26":1}}],["其元素总和",{"2":{"10":1}}],["其最大子矩阵为",{"2":{"10":1}}],["并进一步选择对应的子树进行检索",{"2":{"762":1}}],["并根据该字母选择对应的子树并转到该子树继续进行检索",{"2":{"762":1}}],["并根据路径参数映射到特定的请求处理器进行处理",{"2":{"235":1}}],["并递归维护下一个当前结点now",{"2":{"756":2}}],["并排序",{"2":{"751":1}}],["并把访问百度的日志中的ip取出来",{"2":{"750":1}}],["并把100词及相应的频率存入文件",{"2":{"749":1}}],["并把这个子矩阵称为最大子矩阵",{"2":{"10":1}}],["并取出现频率最大的100个词",{"2":{"749":1}}],["并与其他之前提到过的模型进行简单的对比",{"2":{"732":1}}],["并舍弃隐层",{"2":{"725":1}}],["并提出了两种训练策略",{"2":{"718":1}}],["并加入队列",{"2":{"651":1}}],["并没有考虑查询路径上一些数据点本身的一些性质",{"2":{"651":1}}],["并采用交叉验证法进行调优",{"2":{"647":1}}],["并计算增益",{"2":{"514":1}}],["并计算他与其他预测框的iou",{"2":{"397":1}}],["并存储为block结构",{"2":{"505":1}}],["并行处理相同key的函数",{"2":{"769":1}}],["并行策略",{"2":{"514":2}}],["并行",{"2":{"501":1,"504":1}}],["并过滤掉出现次数较少的特征值",{"2":{"470":1}}],["并从高到低排序",{"2":{"470":1}}],["并降低了过度拟合的机会",{"2":{"451":1}}],["并用估计的结果对模型进行评分",{"2":{"447":1}}],["并给了你生成所用的完整提示词",{"2":{"423":1}}],["并在生成阶段融合",{"2":{"423":1}}],["并在合适的时机调用不同的智能体",{"2":{"423":1}}],["并保证输出的内容符合国内的大模型安全要求",{"2":{"423":1}}],["并保持智能体的扩展性",{"2":{"423":1}}],["并保留原顺序",{"2":{"66":1}}],["并附上词表",{"2":{"423":1}}],["并通过缩放避免数值过大",{"2":{"422":1}}],["并通过位置编码保留顺序信息",{"2":{"422":1}}],["并通过roi",{"2":{"373":1}}],["并端到端微调",{"2":{"373":1}}],["并同时检测出它们的位置和大小",{"2":{"360":1}}],["并未考虑到平面的结构信息",{"2":{"355":1}}],["并说一下在cnn中如何计算",{"0":{"309":1}}],["并将数据点划分近最近的簇",{"2":{"675":1}}],["并将",{"2":{"512":1}}],["并将访问位置0",{"2":{"299":1}}],["并将处理结果及相应的视图返回给浏览器",{"2":{"235":1}}],["并由init进程对它们完成状态收集工作",{"2":{"294":1}}],["并记录到arp缓存表中",{"2":{"250":1}}],["并记录当前的步数",{"2":{"35":1}}],["并传送给网站",{"2":{"247":1}}],["并返回这个对象的引用�",{"2":{"224":1}}],["并返回删除的元素",{"2":{"220":2}}],["并返回它的索引",{"2":{"82":1}}],["并不能减少计算量",{"2":{"422":1}}],["并不能说明这个模型无效",{"2":{"349":1}}],["并不需要做梯度的计算",{"2":{"338":1}}],["并不会大量消耗cpu资源",{"2":{"202":1}}],["并不是直接写入缓存的",{"2":{"196":1}}],["并不是所有引擎都有�",{"2":{"173":1}}],["并清除其中已过期的key",{"2":{"201":1}}],["并使用高效的操作方式进行操作",{"2":{"202":1}}],["并使用",{"2":{"184":1}}],["并发访问数据库时",{"2":{"166":1}}],["并发编程要解�",{"2":{"140":1}}],["并总结常见的解题模式",{"2":{"106":1}}],["并更新最大深度即可",{"2":{"93":1}}],["并找到第一个相交的",{"2":{"68":1}}],["并且要对所有的运行完成的节点重新分配任务",{"2":{"770":1}}],["并且记录每个桶中元素的格式",{"2":{"763":1}}],["并且记录元素的各种",{"2":{"763":1}}],["并且使得数据集中所有数据到这个超平面的距离最短",{"2":{"642":1}}],["并且使它的萌系数最低",{"2":{"27":1}}],["并且该函数对应着某个映射",{"2":{"635":1}}],["并且该正态分布是受到v",{"2":{"536":1}}],["并且成指数级增长",{"2":{"527":1}}],["并且具有上下文依存关系",{"2":{"527":1}}],["并且假设特",{"2":{"512":1}}],["并且假�",{"2":{"198":1}}],["并且支持并行查找每个特征的分割点",{"2":{"506":1}}],["并且xgboost$还支持自定义损失函数",{"2":{"504":1}}],["并且只用了一阶导数信息",{"2":{"504":1}}],["并且只微调rpn独有的层",{"2":{"373":1}}],["并且是基于树的集成算法",{"2":{"497":1}}],["并且它们的预测能以某种方式结合起来去做出一个总体预测",{"2":{"453":1}}],["并且按照最长匹配优先的规则从前往后一个个切分",{"2":{"422":1}}],["并且提出了一种层次性联合训练方法",{"2":{"378":1}}],["并且可以中断",{"2":{"792":1}}],["并且可以为不同的节假日设置不同的前后窗口值",{"2":{"536":1}}],["并且可以进行在线更新",{"2":{"321":1}}],["并且可以知道他比其他蛋重还是轻",{"2":{"270":1}}],["并且各层通道数会按照8×的倍数来确定",{"2":{"311":1}}],["并且我们可以很明显地知道网络越深",{"2":{"309":1}}],["并且当需要的时候内核也会调度这个进程去运行",{"2":{"301":1}}],["并且由天平第一次左端重",{"2":{"270":1}}],["并且由server层进行记录",{"2":{"172":1}}],["并且比其余蛋轻",{"2":{"270":1}}],["并且比其余蛋重",{"2":{"270":1}}],["并且比起平衡树来说",{"2":{"186":1}}],["并且根据第二次用天平的结果",{"2":{"270":1}}],["并且利用大小来控制发送方的数据发送",{"2":{"242":1}}],["并且原型也是对象",{"2":{"212":1}}],["并且字符串中不会有任何额外的空格",{"2":{"77":1}}],["并且在dist中距离最小的顶点u",{"2":{"59":1}}],["并且将所有访问过的位置记录下",{"2":{"33":1}}],["并且片段要在字典中",{"2":{"31":1}}],["并且所有单词都来自字典",{"2":{"31":1}}],["并且",{"2":{"7":1}}],["r是reduce的个数",{"2":{"770":1}}],["ri",{"2":{"730":1}}],["right|",{"2":{"730":1}}],["right都是同一",{"2":{"89":1}}],["right++",{"2":{"76":2,"77":1}}],["right=0",{"2":{"76":1,"77":1}}],["right",{"2":{"41":1,"56":16,"76":6,"77":2,"84":4,"85":1,"94":5,"536":4,"635":34,"735":1,"756":4,"757":6,"760":10,"785":1}}],["r¯u",{"2":{"729":1}}],["r^",{"2":{"635":1}}],["rho$",{"2":{"601":1}}],["r~v=∑x∈d~vwx∑x∈d~wx",{"2":{"601":1}}],["r=tptp+fn",{"2":{"588":1}}],["r=matrix",{"2":{"11":1}}],["rmse=1n∑i=1n",{"2":{"582":1}}],["rmse",{"0":{"582":1}}],["rmsprop",{"2":{"308":1}}],["rf也是多棵树",{"2":{"741":1}}],["rf不易过拟合",{"2":{"501":1}}],["rf不断的降低模型的方差",{"2":{"501":1}}],["rf对异常值不敏感",{"2":{"501":1}}],["rf最终是多棵树进行多数表决",{"2":{"501":1}}],["rf的树可以并行生成",{"2":{"501":1}}],["rf属于属于bagging思想",{"2":{"501":1}}],["rf可能出现过拟",{"2":{"497":1}}],["rf和gbdt的区",{"0":{"501":1}}],["rf和gbdt的区别",{"2":{"497":1}}],["rf和gbdt能够并行",{"2":{"498":1}}],["rf和gbdt分别有什么表现",{"2":{"497":1}}],["rf采用的是baggging方法",{"2":{"497":1}}],["rf整体是bagging算法的一种",{"2":{"497":1}}],["rf是一个加权平均的模型",{"2":{"497":1}}],["rf分类和回归问题如何预测y值",{"2":{"497":1}}],["rf在以决策树为基学习器构建bagging集成的基础上",{"2":{"492":1}}],["rf",{"2":{"492":1,"497":2}}],["rf模型容易陷入过拟合",{"2":{"485":1}}],["rf实现比较简单",{"2":{"485":1}}],["rf为什么比bagging效率高",{"0":{"481":1}}],["rf与",{"0":{"480":1}}],["rf有两种方法",{"2":{"462":1}}],["rl强化阶段",{"2":{"423":1}}],["rl",{"2":{"423":6}}],["rlhf",{"2":{"423":5}}],["rnn",{"0":{"690":1,"696":1,"698":1},"1":{"697":1,"698":1,"699":1,"700":1},"2":{"422":2,"690":4}}],["rrpn也是基于faster",{"2":{"404":1}}],["rr�",{"2":{"170":1}}],["rbf",{"2":{"640":2}}],["rb",{"2":{"390":2}}],["r2score=1−∑in",{"2":{"583":1}}],["r2=",{"2":{"369":1}}],["r2",{"0":{"583":1},"2":{"369":2,"583":1,"748":4}}],["r10用hash",{"2":{"748":1}}],["r10",{"2":{"748":3}}],["r1如何解决问题",{"2":{"423":1}}],["r1=",{"2":{"369":1}}],["r1",{"2":{"369":2,"423":23,"748":3}}],["rpn中anchor",{"2":{"403":1}}],["rpn中的anchor",{"2":{"367":1}}],["rpn网络得出region",{"2":{"373":1}}],["rpn损失中的回归损失部分输入变量是怎么计算的",{"2":{"367":1}}],["rpn的损失函数",{"2":{"367":1}}],["rpn",{"2":{"366":1,"367":2,"376":1}}],["router",{"0":{"798":1},"2":{"798":1}}],["rotate3d",{"2":{"787":1}}],["row",{"2":{"782":2}}],["ronxin",{"2":{"725":1}}],["roc是以fpr作为横坐标",{"2":{"592":1}}],["roc曲线如下",{"2":{"590":1}}],["roc曲线",{"2":{"590":1}}],["roc全称",{"2":{"590":1}}],["roc",{"0":{"590":1}}],["role",{"2":{"422":1}}],["rope可以自然推广到更长的上下文",{"2":{"422":1}}],["rope编码的是",{"2":{"422":1}}],["rope的优势",{"2":{"422":1}}],["rope",{"2":{"422":3}}],["roialign替换之前faster",{"2":{"375":1}}],["roipooling",{"2":{"368":1}}],["roi",{"0":{"369":1},"2":{"366":4,"367":2,"368":2,"369":5}}],["roihead",{"2":{"362":1}}],["root==null",{"2":{"95":1}}],["root2",{"2":{"91":6}}],["root1",{"2":{"91":6}}],["rootval",{"2":{"90":3}}],["root和root",{"2":{"89":1}}],["root",{"2":{"85":4,"87":10,"88":5,"89":8,"90":1,"91":3,"92":14,"93":8,"94":10,"95":5,"740":1,"756":6}}],["rcnn多个anchor带来的多种尺寸的roi可以算muti",{"2":{"402":1}}],["rcnn的两阶段训练和end",{"0":{"407":1}}],["rcnn的主要贡献就是采用了roi",{"2":{"376":1}}],["rcnn的损失函数是分类",{"2":{"375":1}}],["rcnn的前向计算过程并简述faster",{"0":{"373":1}}],["rcnn主要的贡献在于如下",{"2":{"375":1}}],["rcnn有哪些缺点",{"0":{"374":1}}],["rcnn这个流程",{"0":{"374":1}}],["rcnn",{"0":{"389":1},"2":{"373":1,"385":1}}],["rcnn训练步骤",{"0":{"373":1},"2":{"373":1}}],["rcnn中anchor",{"2":{"378":1}}],["rcnn中的roi",{"2":{"375":1}}],["rcnn中定义的smooth",{"2":{"372":1}}],["rcnn中bbox回归用的是什么公式",{"0":{"372":1}}],["rcnn怎么筛选正负anchor",{"0":{"371":1}}],["rcnn将特征抽取",{"2":{"365":1}}],["rcnn网络架构提出的新的目标检测网络",{"2":{"375":1}}],["rcnn网络是基于faster",{"2":{"375":1}}],["rcnn网络有哪些改进的地方",{"0":{"375":1}}],["rcnn网络中进行分类和回归坐标",{"2":{"373":1}}],["rcnn网络开头",{"2":{"373":2}}],["rcnn网络",{"0":{"364":1,"375":1},"1":{"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1},"2":{"373":1}}],["rcnn等目标检测算法",{"2":{"321":1}}],["rc�",{"2":{"170":1}}],["rules",{"2":{"800":2}}],["ru2",{"2":{"730":4}}],["ru1",{"2":{"730":4}}],["ru",{"2":{"729":2,"730":3}}],["rudyalwayhere",{"2":{"284":1}}],["ru�",{"2":{"170":1}}],["rdb",{"0":{"192":1},"2":{"192":11,"194":2}}],["raw",{"2":{"800":2}}],["rag",{"2":{"423":9}}],["ratio",{"2":{"385":1}}],["ratios",{"2":{"367":1}}],["rate",{"0":{"593":1,"594":1},"2":{"306":3,"507":1,"590":2,"740":5}}],["race",{"2":{"76":1,"217":3}}],["racecar",{"2":{"74":1}}],["ran",{"2":{"652":1}}],["rangle+",{"2":{"635":2}}],["rangle",{"2":{"635":2,"735":1}}],["range",{"2":{"72":1,"533":3,"537":1}}],["ranint",{"2":{"73":1}}],["randomforest",{"0":{"492":1}}],["random",{"2":{"73":1,"200":1,"425":1,"492":1,"519":1,"521":1}}],["randnode",{"2":{"73":1}}],["randint",{"2":{"51":1}}],["randpartition",{"2":{"48":2}}],["ranking",{"2":{"423":1}}],["rank++",{"2":{"22":1,"59":1}}],["rank",{"2":{"22":6,"59":6,"667":1}}],["ra",{"2":{"44":4}}],["re",{"2":{"740":1}}],["rezaei",{"2":{"686":1}}],["reconciler",{"2":{"792":2}}],["reconciliation",{"2":{"792":3}}],["recovery",{"2":{"243":1}}],["recurrent",{"2":{"690":1}}],["receiver",{"2":{"590":1}}],["recall",{"0":{"588":1},"2":{"588":1,"589":2}}],["reinforcement",{"2":{"423":2}}],["retrieval",{"2":{"423":2}}],["retinanet",{"2":{"387":2}}],["retinanet网络的结构可归纳为",{"2":{"387":1}}],["retinanet的作者对one",{"2":{"387":1}}],["return",{"2":{"1":3,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":2,"9":3,"10":2,"11":1,"12":1,"13":2,"14":1,"15":1,"18":1,"19":1,"20":3,"21":1,"22":4,"23":1,"24":1,"25":1,"26":1,"27":4,"31":2,"32":1,"33":5,"34":3,"35":3,"36":9,"37":3,"38":3,"40":3,"41":2,"42":3,"43":2,"44":4,"45":5,"46":1,"47":3,"48":7,"51":3,"53":1,"56":2,"58":3,"59":7,"60":1,"61":2,"64":1,"65":1,"66":2,"67":4,"68":2,"69":6,"70":2,"71":1,"72":1,"73":1,"74":3,"75":4,"76":4,"77":3,"78":4,"79":1,"80":2,"81":1,"82":4,"83":2,"85":4,"86":1,"87":5,"88":2,"89":1,"90":5,"91":4,"92":7,"93":2,"94":4,"95":1,"144":1,"215":2,"217":7,"218":3,"222":2,"223":1,"390":1,"397":1,"757":1,"792":1,"793":2,"796":1}}],["regression",{"0":{"579":1},"1":{"580":1,"581":1,"582":1,"583":1},"2":{"365":1,"372":1,"654":1}}],["region",{"2":{"365":1,"366":7,"368":1,"376":1}}],["regexp",{"2":{"210":1,"211":2}}],["relu一般都是跟在卷积层的后面",{"2":{"394":1}}],["relu",{"2":{"378":1,"394":1,"698":1}}],["relu在负半区的导数为0",{"2":{"350":1}}],["relu的导数计算的更快",{"2":{"350":1}}],["relu比sigmoid的效果好在哪里",{"0":{"350":1}}],["relu可令部分神经元输出为0",{"2":{"328":1}}],["relu相比于sigmoid等激活函数计算量小",{"2":{"328":1}}],["relu函数在0处不可导",{"0":{"337":1}}],["relu函数",{"2":{"319":2}}],["requestidlecallback",{"2":{"792":1}}],["requestanimationframe",{"2":{"792":1}}],["requestldlecallback",{"2":{"792":1}}],["request",{"2":{"245":1}}],["require命令的基本功能是",{"2":{"112":1}}],["require",{"2":{"111":1,"114":1,"800":5}}],["reject",{"2":{"217":8,"218":1}}],["rejected",{"2":{"217":1,"218":1}}],["rejectedexecutionhandler",{"2":{"129":1,"130":1}}],["react16",{"2":{"792":1}}],["react",{"0":{"789":1,"791":1,"792":1,"793":1},"1":{"790":1,"791":1,"792":1,"793":1},"2":{"423":1,"790":4,"792":8}}],["reactor",{"2":{"202":1}}],["readme",{"2":{"804":1}}],["readthedocs",{"2":{"203":1}}],["read",{"2":{"170":3,"202":1,"217":2,"759":1}}],["reduce的个数建议大于节点的个数",{"2":{"770":1}}],["reduce函数",{"2":{"769":1}}],["reduce",{"2":{"220":1,"769":3}}],["redis等",{"2":{"258":1}}],["redis保证缓存与数据库双写时的数据一致性",{"2":{"203":1}}],["redis持久化",{"2":{"203":1}}],["redisbook",{"2":{"203":1}}],["redis提供了丰富的数据类型",{"2":{"202":1}}],["redis是一个kv内存数据库",{"2":{"202":1}}],["redis是一个内存数据库",{"2":{"202":1}}],["redis进程",{"2":{"192":1}}],["redisson",{"0":{"185":1}}],["redis",{"0":{"181":1,"184":1,"185":1,"186":1,"200":1,"201":1,"202":1},"1":{"182":1,"183":1,"184":1,"185":2,"186":1,"187":1,"188":1,"189":1,"190":1,"191":1,"192":1,"193":1,"194":1,"195":1,"196":1,"197":1,"198":1,"199":1,"200":1,"201":1,"202":1,"203":1},"2":{"184":1,"185":7,"186":1,"188":2,"192":7,"202":2,"203":2}}],["redo",{"0":{"171":1,"173":1},"1":{"172":1,"173":1,"174":1},"2":{"173":8,"174":1}}],["replacestate",{"2":{"798":2}}],["repeatable",{"2":{"170":1}}],["representations",{"2":{"690":1}}],["repr",{"2":{"69":2}}],["reentrantlock和synchronized",{"0":{"139":1}}],["reentrantlock类提供了一些高级功能",{"2":{"136":1}}],["reentrantlock",{"0":{"136":1},"1":{"137":1,"138":1,"139":1},"2":{"136":4,"138":1,"139":6}}],["review",{"2":{"686":1}}],["rev",{"2":{"77":4}}],["reversewords",{"2":{"77":2}}],["reverselistrecu",{"2":{"69":3}}],["reverselist",{"2":{"69":2}}],["reverse",{"2":{"64":9,"77":3,"220":1,"782":3}}],["refine",{"2":{"367":1}}],["referenceerror",{"2":{"214":1}}],["ref",{"2":{"56":3}}],["removenthfromend",{"2":{"72":1}}],["remove",{"2":{"19":1,"70":1}}],["removekdigits",{"2":{"19":1}}],["research",{"2":{"423":1}}],["response",{"2":{"423":1}}],["resnet",{"2":{"388":1}}],["resnet50",{"2":{"373":1}}],["rest",{"2":{"217":3}}],["resolve",{"2":{"217":13,"218":3,"800":1}}],["resolved",{"2":{"217":1}}],["res+=",{"2":{"77":1}}],["res+=str",{"2":{"77":2}}],["results",{"2":{"40":3,"217":2}}],["result",{"2":{"22":2,"40":3,"54":2,"59":2,"214":2,"218":4,"222":6,"769":3,"829":1}}],["res",{"2":{"10":1,"11":4,"30":4,"31":4,"34":7,"36":2,"37":8,"43":1,"72":4,"73":2,"77":1,"80":7,"90":4,"94":15,"218":2}}],["res=",{"2":{"77":1}}],["res=sum",{"2":{"10":1}}],["res=int",{"2":{"10":1}}],["r",{"0":{"365":1,"366":2,"367":1,"369":1,"370":1,"410":1},"2":{"10":1,"11":2,"23":7,"41":6,"45":3,"48":6,"52":5,"79":4,"365":1,"366":4,"367":3,"373":4,"378":1,"386":1,"389":4,"401":1,"404":1,"496":1,"601":1,"729":1,"730":8,"756":3,"770":1}}],["988",{"2":{"618":1}}],["98013",{"2":{"303":1}}],["991",{"2":{"618":1}}],["99",{"2":{"618":1}}],["990条样本的f1特征都为0",{"2":{"502":1}}],["90",{"2":{"618":1}}],["9018114",{"2":{"499":1}}],["9309749",{"2":{"595":1}}],["93780308",{"2":{"517":1}}],["95",{"2":{"393":1}}],["9236731",{"2":{"203":1}}],["9",{"0":{"9":1,"26":1,"37":1,"48":1,"72":1,"82":1,"93":1,"148":1,"169":1,"202":1,"243":1,"282":1,"301":1,"312":1,"372":1,"438":1,"461":1,"472":1,"483":1,"509":1,"548":1,"566":1,"605":1,"620":1,"642":1,"662":1,"682":1},"2":{"10":2,"76":1,"83":1,"86":2,"131":1,"277":3,"282":2,"414":1,"496":1,"588":1,"601":3,"651":1}}],["z+r",{"2":{"635":1}}],["z$",{"2":{"635":1}}],["z∣x",{"2":{"521":1}}],["z|x",{"2":{"521":1}}],["zp",{"2":{"521":1}}],["zejkifznyxafgtrrkmaeww",{"2":{"473":1}}],["zerowidthspace",{"2":{"761":2}}],["zero的价值",{"2":{"423":1}}],["zero",{"2":{"305":1,"422":1,"423":11}}],["zm=∑i=1mwmiαm1−em",{"2":{"431":1}}],["zt=∑j=1mwt",{"2":{"428":1}}],["zoom",{"2":{"390":1}}],["zhihu",{"2":{"203":1,"253":1,"414":8,"473":1,"517":1,"538":1,"563":1,"564":1,"567":1,"577":1,"644":2,"725":2}}],["zhuanlan",{"2":{"203":1,"253":1,"414":8,"473":1,"538":1,"564":1,"577":1,"644":2,"725":1}}],["zset",{"2":{"186":1}}],["z型遍",{"2":{"86":1}}],["z",{"2":{"8":2,"9":5,"35":2,"36":4,"74":1,"76":2,"306":1,"521":3,"536":1,"635":3}}],["yfm+ydnn",{"2":{"737":1}}],["yfm=",{"2":{"735":1}}],["y同时发生的概率",{"2":{"613":1}}],["y$同时发生的概率",{"2":{"613":1}}],["y|x1",{"2":{"614":1}}],["y|x",{"2":{"613":3,"627":2,"631":1,"661":1,"668":1}}],["y3",{"2":{"612":1}}],["y=0则表示用户未点击物品",{"2":{"733":1}}],["y=0两式合并得到概率分布表达式",{"2":{"661":1}}],["y=−1|x",{"2":{"668":1}}],["y=1表示用户点击物品",{"2":{"733":1}}],["y=1|x",{"2":{"668":1}}],["y=11−hθ",{"2":{"661":1}}],["y=",{"2":{"612":1}}],["y+1m+",{"2":{"590":1}}],["y¯表示实际值的均",{"2":{"583":1}}],["y表示实际",{"2":{"583":1}}],["yj",{"2":{"545":1,"635":1}}],["yj−hθ",{"2":{"545":2}}],["yt=st+tt+rtyt=st×tt×rtln⁡yt=ln⁡st+ln⁡tt+ln⁡rtfbprophet",{"2":{"531":1}}],["y∣x",{"2":{"519":1,"521":2}}],["y0=start",{"2":{"519":1}}],["y^表示预测",{"2":{"583":1}}],["y^=sigmoid",{"2":{"737":1}}],["y^=",{"2":{"519":1}}],["y^",{"2":{"496":2,"585":3}}],["y^i",{"2":{"496":1}}],["y^it",{"2":{"496":1}}],["yn∗=arg⁡max1⩽j⩽mδn",{"2":{"519":1}}],["yn",{"2":{"431":1,"612":1}}],["yixi",{"2":{"668":1}}],["yi|xi",{"2":{"668":3}}],["yi+1",{"2":{"519":1}}],["yi+1∗",{"2":{"519":1}}],["yi∗=ψi+1",{"2":{"519":1}}],["yi=l",{"2":{"519":2}}],["yi−hθ",{"2":{"656":2}}],["yi−y¯",{"2":{"583":1}}],["yi−y^",{"2":{"583":1}}],["yi−y^i",{"2":{"581":1,"582":1}}],["yi−1=j",{"2":{"519":2}}],["yi−gm",{"2":{"431":1}}],["yi≠gm",{"2":{"430":2}}],["yi≠g",{"2":{"430":2}}],["yi",{"2":{"428":1,"496":3,"519":2,"612":4,"635":5,"654":1}}],["ym",{"2":{"428":1,"455":1,"475":1}}],["yy2",{"2":{"397":2}}],["yy1",{"2":{"397":2}}],["yolo之间的区别是什么",{"0":{"409":1}}],["yolo的预测框是什么值",{"0":{"379":1}}],["yolo9000在识别种类",{"2":{"378":1}}],["yolo",{"2":{"378":1}}],["yolo系列anchor的设计原理",{"0":{"382":1}}],["yolo系列算法是一类典型的one",{"2":{"378":1}}],["yolo系列网络",{"0":{"377":1},"1":{"378":1,"379":1,"380":1,"381":1,"382":1,"383":1}}],["yolov3通过聚类的方式自定义anchor",{"2":{"383":1}}],["yolov3有什么致命问题",{"0":{"383":1}}],["yolov3框是怎么得到的",{"0":{"383":1}}],["yolov3作者发现传统方法在box尺寸比较大的时候",{"2":{"381":1}}],["yolov3总结了自己在yolov2的基础上做的一些尝试性改进",{"2":{"378":1}}],["yolov3",{"2":{"378":1}}],["yolov3复述一遍",{"0":{"378":1}}],["yolov2中如何通过k",{"0":{"380":1}}],["yolov2又叫yolo9000",{"2":{"378":1}}],["yolov2",{"0":{"378":1},"2":{"378":1}}],["yolov1对位置坐标误差",{"2":{"378":1}}],["yolov1的基本思想",{"2":{"378":1}}],["yolov1的核心思想就是利用整张图作为网络的输入",{"2":{"378":1}}],["yolov1到v3的发展历程以及解决的问题",{"0":{"378":1}}],["yolov1",{"0":{"378":1},"2":{"378":1}}],["your",{"2":{"34":1,"94":1}}],["y∗−ya",{"2":{"372":1}}],["y−ya",{"2":{"372":1}}],["y−y1",{"2":{"369":2}}],["y2−y",{"2":{"369":2}}],["y2−y1",{"2":{"369":4}}],["y2",{"2":{"369":2,"397":3,"455":1,"475":1,"612":1}}],["y1=j",{"2":{"519":1}}],["y1",{"2":{"369":3,"397":3,"428":1,"431":2,"455":1,"475":1,"612":1}}],["y＞1",{"2":{"274":1}}],["y取值是x",{"2":{"267":1}}],["yx",{"2":{"253":1,"668":1}}],["yroot",{"2":{"22":6,"59":6}}],["y",{"2":{"8":2,"9":4,"22":5,"40":2,"59":5,"61":4,"267":3,"274":13,"279":3,"369":4,"372":2,"379":1,"496":9,"497":9,"519":6,"521":6,"531":1,"585":3,"590":3,"612":8,"613":3,"614":1,"627":2,"631":2,"635":17,"638":2,"657":1,"661":4}}],["的打包能力",{"2":{"800":1}}],["的功能了�",{"2":{"798":2}}],["的改变添加监听事件",{"2":{"798":1}}],["的具体用法",{"2":{"796":1}}],["的重点是如何知道数据变了",{"2":{"796":1}}],["的变动直接反映在�",{"2":{"795":1}}],["的变化也直接反映在了",{"2":{"795":1}}],["的变化",{"2":{"515":1}}],["的版本使用的算法称为",{"2":{"792":1}}],["的对象进行比较要比针对浏览器",{"2":{"790":1}}],["的对象模�",{"2":{"790":1}}],["的概念",{"0":{"790":1,"792":1}}],["的概率几乎为",{"2":{"703":1}}],["的概率小于百万分之一",{"2":{"120":1}}],["的操作",{"2":{"786":1}}],["的清除浮动",{"2":{"785":1}}],["的宽度由浮动情况和它的包含块决定",{"2":{"784":1}}],["的宽度时",{"2":{"774":1}}],["的元素不是块级盒子的块容器",{"2":{"784":1}}],["的各种属性",{"2":{"782":1}}],["的事件模型",{"0":{"778":1}}],["的内容相关�",{"2":{"776":1}}],["的内容应该与",{"2":{"776":1}}],["的内存淘汰策�",{"0":{"200":1}}],["的内存模�",{"0":{"140":1}}],["的内存空间",{"2":{"110":1}}],["的页脚�",{"2":{"776":1}}],["的页眉�",{"2":{"776":1}}],["的思想",{"2":{"763":1}}],["的思想来解决",{"2":{"755":1}}],["的位置写入文",{"2":{"759":1}}],["的位置及其所属的类别",{"2":{"378":1}}],["的构建代码",{"2":{"756":1}}],["的构建策略",{"2":{"497":1}}],["的过程了",{"2":{"749":1}}],["的过期策�",{"0":{"201":1}}],["的id建一类树",{"2":{"741":1}}],["的偏差",{"2":{"729":1}}],["的平均评分",{"2":{"729":1}}],["的评分",{"2":{"729":1}}],["的缺点进行了优化",{"2":{"716":1}}],["的缺点是",{"2":{"714":1}}],["的缺点包括",{"2":{"711":1}}],["的缺点主要包括",{"2":{"708":1}}],["的缺点在于性能资源的开销和线程管理的问题�",{"2":{"109":1}}],["的每个位置都可以注意到前一层的所有位置",{"2":{"702":1}}],["的更新门",{"2":{"700":1}}],["的三个门调整为两个门",{"2":{"690":1}}],["的历史比",{"2":{"690":1}}],["的输出拼接后展开",{"2":{"689":1}}],["的输出",{"2":{"689":2}}],["的时机",{"0":{"793":1}}],["的时候需要使用的技术",{"2":{"768":1}}],["的时候",{"2":{"657":1,"790":1}}],["的时间复杂度",{"2":{"497":1}}],["的时间复杂度就可以找到对应的数据",{"2":{"202":1}}],["的树结点开始",{"2":{"651":1}}],["的树可以并行生成",{"2":{"501":1}}],["的原理",{"0":{"798":1}}],["的原始问题转换为其对偶问",{"0":{"637":1}}],["的原型链你是如何理解的",{"0":{"212":1}}],["的一个分量满",{"2":{"635":1}}],["的几何间隔为",{"2":{"635":1}}],["的函数间隔为",{"2":{"635":1}}],["的含义是",{"2":{"614":1}}],["的朴",{"2":{"614":1}}],["的中位点ai+ai+12作为候选划分点",{"2":{"603":1}}],["的中间结果",{"2":{"422":1}}],["的代价都是一样的",{"2":{"585":1}}],["的损失",{"2":{"573":1}}],["的用户做实验",{"2":{"573":1}}],["的用法",{"0":{"217":1,"218":1}}],["的点击到达率",{"2":{"593":1}}],["的点",{"2":{"547":1}}],["的梯度负方向更新",{"2":{"545":1}}],["的梯度提升机",{"2":{"464":1}}],["的在此基础上",{"2":{"531":1}}],["的架构",{"2":{"519":1}}],["的并行是在特征粒度上的",{"2":{"513":1}}],["的并发量肯定是要高于多线程同�",{"2":{"109":1}}],["的决策树构建策略",{"2":{"497":1}}],["的高度由",{"2":{"784":1}}],["的高阶无穷小",{"2":{"496":1}}],["的高效缓存和内存带宽",{"2":{"422":1}}],["的优缺点",{"0":{"441":1}}],["的优化差异",{"2":{"422":1}}],["的场景中强化垂直领域能力",{"2":{"423":1}}],["的模型",{"2":{"423":1}}],["的方法",{"2":{"796":2}}],["的方法估计没有出现过的现象的概率",{"2":{"618":1}}],["的方法主要适用于有明确验证机制的任务",{"2":{"423":1}}],["的方向",{"2":{"515":1}}],["的方式替换传统算法中梯度估计方法",{"2":{"448":1}}],["的方式",{"2":{"403":1}}],["的方式来实现文件事件处理器",{"2":{"202":1}}],["的推理能力蒸馏到较小的模型中的",{"2":{"423":1}}],["的上述问题的",{"2":{"423":1}}],["的上下文�",{"2":{"213":1}}],["的训练过程有什么区别",{"2":{"423":1}}],["的分类器",{"2":{"629":1,"630":1}}],["的分布为条件机率",{"2":{"519":1}}],["的分布式锁是如何实现�",{"0":{"184":1},"1":{"185":1}}],["的分块量化通过将模型权重按小块",{"2":{"423":1}}],["的指标",{"2":{"423":1}}],["的理解",{"2":{"423":1}}],["的掩蔽策略相比",{"2":{"422":1}}],["的真实关系",{"2":{"422":1}}],["的矩阵乘法时",{"2":{"422":1}}],["的矩形框",{"2":{"368":1}}],["的非线性变换后",{"2":{"422":1}}],["的词元嵌入空间是否也有类似的属性",{"2":{"422":1}}],["的现象",{"2":{"422":1}}],["的总和",{"2":{"422":1}}],["的卷积操作",{"2":{"388":2}}],["的锚点",{"2":{"371":1}}],["的问题",{"2":{"369":1,"444":1}}],["的问题�",{"2":{"140":1}}],["的特征图上进行",{"2":{"366":1}}],["的特点是",{"2":{"109":1}}],["的预取",{"2":{"366":1,"376":1}}],["的反向传播是怎么实现的",{"2":{"338":1}}],["的基础上",{"2":{"330":1}}],["的基本数据类型",{"0":{"210":1}}],["的缩放系数γ",{"2":{"314":1}}],["的请求",{"2":{"301":1}}],["的接收端会丢弃重复的数据",{"2":{"241":1}}],["的标准",{"2":{"226":2}}],["的写法",{"2":{"218":2}}],["的异常原因抛出",{"2":{"218":1}}],["的直接拦�",{"2":{"189":1}}],["的生命周期",{"0":{"791":1,"797":1}}],["的生命周�",{"0":{"180":1}}],["的生成过程",{"2":{"472":1}}],["的生存时间�",{"2":{"185":1}}],["的剩余生存时间",{"2":{"185":1}}],["的技术就是mysql里经常说到的wal",{"2":{"173":1}}],["的好�",{"2":{"167":1}}],["的好处是",{"2":{"109":1}}],["的索引使用的�",{"2":{"167":1}}],["的本质",{"2":{"165":1}}],["的学生�",{"2":{"163":1}}],["的学生",{"2":{"163":1}}],["的区间内",{"2":{"660":1}}],["的区间",{"2":{"660":1}}],["的区别是什么",{"0":{"226":1}}],["的区别",{"0":{"161":1,"213":1,"218":1,"369":1,"480":1,"700":1},"2":{"422":1}}],["的区�",{"0":{"121":1,"139":1,"157":1}}],["的作�",{"0":{"144":1}}],["的作用域特性",{"2":{"215":1}}],["的作用",{"0":{"141":1},"1":{"142":1,"143":1,"144":1}}],["的实现原�",{"0":{"178":1}}],["的实现涉及到锁的升级",{"2":{"139":1}}],["的实现是一种自旋锁",{"2":{"138":1}}],["的普通用户中无法直接使用",{"2":{"135":1}}],["的值",{"2":{"134":1,"369":1}}],["的值去更新",{"2":{"134":1}}],["的值的时候",{"2":{"134":1}}],["的值等�",{"2":{"134":2}}],["的哈希码主要作用是给散列表快速确定索引的",{"2":{"124":1}}],["的情况下",{"2":{"120":1,"509":1}}],["的洋葱模型",{"0":{"114":1}}],["的执行",{"2":{"109":1,"218":1}}],["的执行环境",{"2":{"109":1}}],["的",{"2":{"109":1,"282":2,"422":3,"423":1,"689":2,"702":1,"710":1,"790":1}}],["的乘积",{"2":{"83":1,"521":1}}],["的字符",{"2":{"81":1}}],["的字符串",{"2":{"75":1}}],["的长度小",{"2":{"83":1}}],["的长度",{"2":{"78":2}}],["的简单方法",{"2":{"74":1}}],["的数组",{"2":{"763":1}}],["的数据集",{"2":{"423":1}}],["的数据库设计模式",{"2":{"258":1}}],["的数量比较小",{"2":{"640":1}}],["的数量很大",{"2":{"640":1}}],["的数量",{"2":{"422":1}}],["的数值",{"2":{"243":1}}],["的数",{"0":{"48":1}}],["的个数",{"2":{"43":1,"80":2}}],["的相似度",{"2":{"32":2,"422":1}}],["的最后一个特征图上进去",{"2":{"366":1}}],["的最大堆的性质",{"2":{"756":1}}],["的最大优势在于其内部可以使用",{"2":{"218":1}}],["的最大长度为",{"2":{"79":1}}],["的最小值",{"2":{"32":1}}],["的最小路径的",{"2":{"9":1}}],["的最值",{"2":{"18":1}}],["的第三类",{"2":{"472":1}}],["的第二类",{"2":{"472":1}}],["的第一类",{"2":{"472":1}}],["的第",{"2":{"8":1}}],["的算",{"2":{"1":1}}],["设为正样本",{"2":{"721":1}}],["设为公平锁",{"2":{"136":1}}],["设每个特征都有一个权重",{"2":{"632":1}}],["设想一个网站上都是",{"2":{"423":1}}],["设计等跨职能协�",{"2":{"838":1}}],["设计与开发",{"2":{"570":1}}],["设计开放式推理模板",{"2":{"423":1}}],["设计自动或半自动评价机制",{"2":{"423":1}}],["设计多任务蒸馏目标",{"2":{"423":1}}],["设计多元化奖励函数",{"2":{"423":1}}],["设计一个分类器",{"2":{"721":1}}],["设计一个主控agent作为",{"2":{"423":1}}],["设计一个算法来找到最大的利润",{"2":{"25":1}}],["设计一个算法来找出最大利润",{"2":{"24":1}}],["设计一个算法",{"2":{"8":1}}],["设计的高效算法",{"2":{"422":1}}],["设群数目为m",{"2":{"348":1}}],["设备管理不同",{"2":{"334":1}}],["设",{"2":{"274":1,"282":1}}],["设置一个master",{"2":{"770":1}}],["设置一个值再次获得锁",{"2":{"184":1}}],["设置一个值",{"2":{"184":1}}],["设置下标从0开",{"2":{"756":1}}],["设置时间t",{"2":{"740":1}}],["设置成负样本",{"2":{"721":1}}],["设置评估分割数据是的最大特征数量",{"2":{"605":1}}],["设置叶子节点的最大数量",{"2":{"605":1}}],["设置每个节点的最小样本数",{"2":{"605":1}}],["设置每个叶子节点的最小样本数",{"2":{"605":1}}],["设置scale",{"2":{"509":1}}],["设置树的最大深度",{"2":{"605":1}}],["设置树的最大深",{"2":{"507":1}}],["设置最小样本权重和的阈",{"2":{"507":1}}],["设置目标函数的增益阈",{"2":{"507":1}}],["设置keep",{"2":{"325":1}}],["设置为一个最大报文段mss的数值",{"2":{"243":1}}],["设置过期时间",{"2":{"185":1}}],["设置超时方法或者将",{"2":{"139":1}}],["设置",{"2":{"110":1,"190":1}}],["设置两个指针slow和fast",{"2":{"68":1}}],["设定为目标类为一类",{"2":{"643":1}}],["设定目标制定方案",{"2":{"570":1}}],["设定默认值与容错机制",{"2":{"423":1}}],["设定多个iou阈值",{"2":{"393":1}}],["设定",{"2":{"7":1}}],["丑数",{"0":{"8":1}}],["8=1",{"2":{"763":1}}],["86556322",{"2":{"686":1}}],["82668141",{"2":{"665":1}}],["8203674",{"2":{"652":1}}],["88638809",{"2":{"664":1}}],["89420421",{"2":{"743":1}}],["89450552",{"2":{"414":1}}],["89315734",{"2":{"652":1}}],["8的空间",{"2":{"514":1}}],["83275299",{"2":{"473":1}}],["83043197",{"2":{"414":1}}],["87885678",{"2":{"473":1}}],["8×a100",{"2":{"423":1}}],["80681100",{"2":{"743":1}}],["80427471",{"2":{"568":1}}],["80833001",{"2":{"473":1}}],["80868385",{"2":{"272":1}}],["80g",{"2":{"423":2}}],["85246432",{"2":{"652":1}}],["85",{"2":{"422":1}}],["8目标是求",{"2":{"282":1}}],["8这9个人分别为a0",{"2":{"268":1}}],["8bb",{"2":{"259":1}}],["8aa619933ebb",{"2":{"203":1}}],["8�",{"0":{"118":1},"1":{"119":1,"120":1}}],["8",{"0":{"8":1,"25":1,"36":1,"47":1,"71":1,"81":1,"92":1,"147":1,"157":1,"168":1,"201":1,"242":1,"281":1,"300":1,"311":1,"371":1,"397":1,"405":1,"413":1,"437":1,"451":1,"460":1,"471":1,"482":1,"508":1,"547":1,"565":1,"604":1,"619":1,"641":1,"661":1,"681":1},"1":{"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1},"2":{"10":2,"83":1,"89":1,"118":1,"131":1,"268":1,"274":2,"280":1,"281":1,"282":1,"388":1,"414":1,"496":1,"587":1,"796":1}}],["fxj",{"2":{"735":1}}],["fxi",{"2":{"735":2}}],["fxixi",{"2":{"735":1}}],["fxixj−∑i=1n∑f=1nvi",{"2":{"735":1}}],["fvi",{"2":{"735":1}}],["fvj",{"2":{"735":1}}],["f×f",{"2":{"695":1}}],["ft",{"2":{"496":3}}],["f33",{"2":{"472":2}}],["f3",{"2":{"472":2}}],["f2xi2",{"2":{"735":2}}],["f22",{"2":{"472":2}}],["f2",{"2":{"472":2}}],["fm层与deep层的输出相拼接",{"2":{"737":1}}],["fm论文中有下述计算",{"2":{"735":1}}],["fm还将特征间的",{"2":{"735":1}}],["fm模型",{"2":{"735":1}}],["fm",{"0":{"735":1},"2":{"434":1,"496":2,"497":2,"738":1}}],["fm−1",{"2":{"430":1,"496":1,"497":7}}],["f1=2∗p∗rp+r",{"2":{"589":1}}],["f1的值为全为1",{"2":{"502":1}}],["f11",{"2":{"472":2}}],["f1",{"0":{"589":1},"2":{"422":2,"472":2}}],["fpr是代价",{"2":{"592":1}}],["fpr=fptn+fp现实使用",{"2":{"590":1}}],["fpr",{"2":{"590":4,"592":1}}],["fp",{"2":{"586":1,"591":1}}],["fps",{"2":{"393":2}}],["fpn网络属于采用了特征金字塔的网络",{"2":{"402":1}}],["fpn网络中采用多尺度feature",{"2":{"402":1}}],["fpn",{"2":{"388":1,"390":1,"399":2}}],["f就是一个像素点的像素值",{"2":{"369":1}}],["f$",{"2":{"369":1}}],["fc",{"0":{"784":1},"2":{"366":1,"784":2}}],["fc全连接网络",{"2":{"314":1,"315":1}}],["few",{"2":{"422":2}}],["feature的组合",{"2":{"446":1}}],["features会降低算法的速度",{"2":{"484":1}}],["features一般能提高模型的性能",{"2":{"484":1}}],["features变多时",{"2":{"446":1}}],["features的不同组合",{"2":{"446":1}}],["features",{"2":{"446":1,"484":2,"739":1}}],["featuremap大小",{"2":{"368":1}}],["feature",{"2":{"311":1,"318":1,"365":1,"464":2,"468":1,"495":1,"640":2,"707":1,"713":1}}],["feedback",{"2":{"423":1}}],["fee",{"2":{"26":6}}],["frac",{"2":{"612":1,"635":3,"730":3}}],["freq",{"2":{"512":1}}],["fr=aladdin",{"2":{"259":1,"595":1}}],["from",{"2":{"110":7,"112":1,"163":1,"423":1}}],["front",{"2":{"32":1,"35":1,"47":4,"60":1,"61":1}}],["funcref",{"2":{"798":2}}],["function",{"0":{"213":2},"2":{"111":1,"112":2,"210":1,"211":4,"213":1,"214":4,"215":2,"217":24,"218":5,"220":6,"222":2,"223":1,"226":1,"330":1,"375":1,"422":1,"511":1,"521":1,"635":2,"758":1,"796":3}}],["funk",{"2":{"730":3,"731":1}}],["fujian",{"2":{"499":1}}],["fusion",{"2":{"318":1}}],["fulfilled",{"2":{"217":1,"218":1}}],["fd",{"2":{"202":3}}],["fsync一次日志文件",{"2":{"193":1}}],["foxmail",{"2":{"766":1}}],["focal",{"2":{"387":1}}],["found",{"2":{"245":1}}],["footer",{"2":{"776":1}}],["footer>",{"2":{"775":1}}],["fool",{"2":{"652":1}}],["foo",{"2":{"112":3}}],["forum",{"2":{"670":1}}],["fornlp",{"2":{"442":1}}],["forest",{"2":{"492":1}}],["forest等算法为代表的",{"2":{"425":1}}],["foreach",{"2":{"111":1,"220":1,"222":1}}],["form>",{"2":{"774":1}}],["former",{"2":{"423":5}}],["format",{"2":{"69":1,"422":1}}],["for=pc",{"2":{"414":1}}],["forbidden",{"2":{"245":1}}],["fork",{"2":{"192":4}}],["for",{"0":{"221":2},"2":{"1":2,"2":2,"3":2,"4":3,"5":4,"6":4,"7":5,"9":4,"10":5,"11":4,"12":1,"13":4,"14":1,"15":3,"18":1,"19":1,"20":1,"21":1,"22":1,"24":1,"25":1,"26":1,"27":1,"29":1,"30":1,"31":3,"32":1,"33":2,"35":3,"36":2,"38":2,"40":5,"42":3,"43":4,"46":2,"47":2,"52":2,"53":1,"58":8,"59":4,"60":5,"61":6,"72":1,"74":1,"75":1,"77":2,"78":3,"79":1,"81":2,"82":2,"83":3,"85":1,"86":1,"89":2,"92":1,"221":4,"223":1,"689":1,"690":1,"756":2,"758":2,"759":3,"769":2}}],["fn0",{"2":{"112":2}}],["fn3",{"2":{"111":2}}],["fn2",{"2":{"111":2}}],["fn",{"2":{"111":5,"112":2,"214":3,"586":1,"591":1}}],["fiber",{"0":{"792":1},"2":{"792":3}}],["field",{"2":{"519":1,"521":1}}],["fi",{"2":{"496":1}}],["fifo",{"2":{"299":1}}],["filter映射为这340亿bit",{"2":{"747":1}}],["filters",{"2":{"689":3}}],["filtering",{"0":{"726":1},"1":{"727":1,"728":1,"729":1,"730":1,"731":1},"2":{"420":1,"727":2}}],["filter",{"2":{"220":1,"689":5,"747":2}}],["filename",{"2":{"800":1}}],["file",{"2":{"173":2,"759":2,"800":1}}],["fine",{"2":{"423":1}}],["finalresult",{"2":{"218":4}}],["final",{"2":{"140":1,"218":2}}],["finally",{"2":{"137":1,"139":1}}],["findbottomleftvalue",{"2":{"93":5}}],["findlca",{"2":{"92":1}}],["findpath",{"2":{"92":5}}],["findkelem",{"2":{"48":1}}],["findmediansortedarrays",{"2":{"44":1}}],["find",{"2":{"22":6,"31":1,"32":1,"35":1,"40":3,"41":1,"58":2,"59":8,"65":1,"74":1,"90":1}}],["fired",{"2":{"111":3}}],["first",{"2":{"82":1,"94":4,"651":1,"800":1}}],["firstuniqchar",{"2":{"82":1}}],["firstmeetnode",{"2":{"68":2}}],["facebook提出提出使用决策树进行特征embedding",{"2":{"739":1}}],["fallback",{"2":{"422":1}}],["false",{"2":{"7":1,"13":1,"36":4,"38":1,"45":2,"61":1,"67":2,"68":1,"75":5,"76":3,"78":1,"87":1,"91":2,"92":2,"111":1,"139":1,"211":2,"224":3,"586":2,"590":1,"798":2}}],["failurecallback",{"2":{"218":2}}],["faster",{"0":{"364":1,"366":1,"367":1,"370":1,"371":1,"372":1,"374":1},"1":{"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1},"2":{"365":2,"366":1,"367":1,"389":1,"402":1}}],["fast先走k",{"2":{"72":1}}],["fast",{"2":{"64":6,"65":8,"68":11,"243":1,"366":1}}],["flex",{"2":{"782":7}}],["flink",{"2":{"767":1}}],["flight",{"2":{"74":1}}],["flash",{"2":{"422":7}}],["flat3",{"2":{"222":2}}],["flat2",{"2":{"222":2}}],["flat",{"2":{"222":3}}],["flag++",{"2":{"88":1}}],["flag",{"2":{"36":16,"67":4,"88":3,"762":1}}],["fl",{"2":{"74":1}}],["flops2=",{"2":{"394":1}}],["flops1=",{"2":{"394":1}}],["flops=hin∗win∗cin",{"2":{"394":1}}],["flops=flops1+flops2",{"2":{"394":1}}],["flops=",{"2":{"394":3}}],["flops会越小",{"2":{"394":1}}],["flops的定义",{"2":{"394":1}}],["flops的计算方式",{"2":{"315":1}}],["flops计算",{"0":{"394":1},"2":{"394":1}}],["flops",{"2":{"315":1,"394":2}}],["flow",{"2":{"74":1}}],["flower",{"2":{"74":1}}],["float",{"2":{"69":1}}],["floydwarshall",{"2":{"58":1}}],["floyd算法是使用动态规划算法",{"2":{"58":1}}],["floyd",{"2":{"58":1}}],["f",{"2":{"7":7,"31":7,"36":1,"369":5,"430":1,"431":1,"457":1,"496":6,"497":2,"532":1,"547":5,"555":1,"568":2,"635":2,"655":1,"679":1}}],["否则要根据高位进行继续分桶",{"2":{"763":1}}],["否则表示这个数字不存在",{"2":{"759":1}}],["否则对应为0",{"2":{"759":1}}],["否则对应1",{"2":{"279":1}}],["否则设置label=0",{"2":{"740":1}}],["否则的话",{"2":{"685":1}}],["否则0",{"2":{"664":1}}],["否则就",{"2":{"759":1}}],["否则就把他的左孩子加入到队列中",{"2":{"651":1}}],["否则就有",{"2":{"61":1}}],["否则加入分裂后的右子树",{"2":{"470":1}}],["否则较小",{"2":{"427":1}}],["否则会导致索引失效而转向全表扫�",{"2":{"169":1}}],["否则会出现错",{"2":{"8":1}}],["否则不能保证每次迭代时函数值下降",{"2":{"549":1}}],["否则不运行",{"2":{"297":1}}],["否则不会执行任何操作",{"2":{"134":1}}],["否则不是",{"2":{"95":1}}],["否则认为是过期数据�",{"2":{"133":1}}],["否则",{"2":{"7":1,"74":1,"266":1}}],["分享面试经验和技巧",{"2":{"849":1}}],["分成多个小问题并行处理",{"2":{"763":1}}],["分治是一种算法思想",{"2":{"769":1}}],["分治",{"2":{"754":1,"768":1,"769":1}}],["分解式为",{"2":{"730":1}}],["分群结果不稳定",{"2":{"676":1}}],["分散程度较大时把这个簇分为两个子簇",{"2":{"676":1}}],["分母p",{"2":{"631":1}}],["分裂对测试集的准确度提升大小",{"2":{"605":1}}],["分裂结点时可以采用多线程并行查找每个特征的最佳分割点",{"2":{"504":1}}],["分段线性函数不是线性的",{"2":{"597":1}}],["分流的数据不会相差太大",{"2":{"575":1}}],["分桶",{"2":{"572":1}}],["分布独立这个假设基本是成立的",{"2":{"625":1}}],["分布公式为",{"2":{"568":2}}],["分布",{"2":{"568":2}}],["分布式假设指的是相同上下文语境的词有似含义",{"2":{"725":1}}],["分布式的通用梯度提升",{"2":{"503":1}}],["分布式扩展",{"2":{"423":1}}],["分布式训练",{"2":{"335":1}}],["分布式",{"2":{"258":1}}],["分布式存储",{"2":{"192":1}}],["分布式锁的最大缺陷�",{"2":{"185":1}}],["分布式锁",{"0":{"185":1}}],["分块并行",{"2":{"506":1}}],["分配给节点进行处理",{"2":{"770":1}}],["分配给它",{"2":{"381":1}}],["分配流量进行测试",{"2":{"570":1}}],["分配如下",{"2":{"423":1}}],["分步流程设计",{"2":{"423":1}}],["分阶段控制质量与连贯性",{"2":{"423":1}}],["分数",{"2":{"422":2}}],["分组查询注意力",{"2":{"422":1}}],["分词规则一样",{"2":{"422":1}}],["分层预测的方法可以提升小目标的检测效果",{"2":{"402":1}}],["分辨率低",{"2":{"401":1}}],["分而治之",{"2":{"362":1}}],["分类特征域一般通过one",{"2":{"734":1}}],["分类决策",{"2":{"646":1}}],["分类决策存在错误率",{"2":{"626":1}}],["分类只需要计算与少数几个支持向量的距离",{"2":{"672":1}}],["分类只需要计算与少数几个支持向量的距",{"2":{"641":1}}],["分类结果非常依赖于参数",{"2":{"640":1}}],["分类结果的混淆矩",{"2":{"586":1}}],["分类效果已经很理想了",{"2":{"640":1}}],["分类的规则是将样本归到后验概率最大的那个",{"2":{"631":1}}],["分类也快",{"2":{"626":1}}],["分类器的判别函数为",{"2":{"631":1}}],["分类器可能会因为失去部分异常值的信息而导致泛化能力下降",{"2":{"629":1}}],["分类器预测错误的比例",{"2":{"590":1}}],["分类器预测正确的比例",{"2":{"590":1}}],["分类器",{"2":{"475":1}}],["分类时针对样本有三类的情况",{"2":{"472":1}}],["分类任务中如何约束输出为限定类别",{"2":{"422":1}}],["分类标签经常变",{"2":{"422":1}}],["分类＋回归网络",{"2":{"387":1}}],["分类＋回归网络retinanet=resnet+fpn+twosub−network",{"2":{"387":1}}],["分类信息以及bbox信息",{"2":{"386":1}}],["分类操作",{"2":{"381":1}}],["分类误差均使用了均方差作为损失函数",{"2":{"378":1}}],["分类",{"0":{"584":1},"1":{"585":1,"586":1,"587":1,"588":1,"589":1,"590":1,"591":1,"592":1,"593":1,"594":1},"2":{"365":1,"423":1,"459":1,"472":1,"578":1}}],["分类问题的时候认为损失函数指数函数",{"2":{"430":1}}],["分类问题",{"2":{"331":1,"497":1,"504":1,"513":1}}],["分类目录",{"0":{"205":1,"261":1,"416":1,"745":1,"802":1,"806":1,"842":1},"1":{"206":1,"207":1,"262":1,"263":1,"264":1,"265":1,"417":1,"418":1,"419":1,"420":1,"421":1,"803":1,"804":1,"843":1}}],["分页和分段的区别",{"0":{"300":1}}],["分隔符为a",{"2":{"220":1}}],["分担服务器负载",{"2":{"194":1}}],["分割样本点的分类器是一个超平面",{"2":{"634":1}}],["分割点查找算",{"2":{"514":1}}],["分割字符",{"0":{"37":1}}],["分割一",{"2":{"7":1}}],["分析思维",{"2":{"816":1}}],["分析并提出假设",{"2":{"570":1}}],["分析用户输入中缺失的关键信息",{"2":{"423":1}}],["分析了一下dw",{"2":{"357":1}}],["分析",{"2":{"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"31":1,"73":1}}],["分别对应了两种原理�",{"2":{"798":1}}],["分别对新老生代采用不同的垃圾回收算法来提高效率",{"2":{"110":1}}],["分别学习语法和语义特征",{"2":{"707":1}}],["分别做不同用途",{"0":{"576":1}}],["分别运行算法看迭代效果",{"2":{"544":1}}],["分别用组成相同相似的群组去随机访问这些版本",{"2":{"570":1}}],["分别用于决定",{"2":{"512":1}}],["分别用a",{"2":{"12":1}}],["分别枚举特征缺省的样本归为左右分支后的增益",{"2":{"508":1}}],["分别如何设置",{"2":{"422":1}}],["分别解释一�",{"0":{"166":1}}],["分别保存了这个行的创建时间",{"2":{"162":1}}],["分别找到a",{"2":{"92":1}}],["分别是�",{"2":{"778":1}}],["分别是bagging和boosting",{"2":{"490":1}}],["分别是每个bin中样本的梯度之和",{"2":{"465":1}}],["分别是depthwise和pointwise",{"2":{"317":1}}],["分别是邻接矩阵和邻接表",{"2":{"57":1}}],["分别是a",{"2":{"6":1}}],["分别选择前一半和后一半",{"2":{"56":1}}],["分别结算",{"2":{"18":1}}],["分别0结尾",{"2":{"12":1}}],["分别表示2",{"2":{"8":1}}],["分别表示插入",{"2":{"5":1}}],["解是唯一的",{"2":{"636":1}}],["解出对偶问题的解α∗=",{"2":{"635":1}}],["解码器架构各有什么优缺点",{"2":{"422":1}}],["解决技术问题的思路和方�",{"2":{"838":1}}],["解决在通过正规方程方法求解θ的过程中出现的xtx不可逆的请况",{"2":{"657":1}}],["解决线性回归出现的过拟合的请况",{"2":{"657":1}}],["解决办法",{"2":{"618":1,"619":1}}],["解决过拟合的根本性方法",{"2":{"561":1}}],["解决决策树泛化能力弱的特点",{"2":{"475":1}}],["解决普通量化信息损失问题",{"2":{"423":1}}],["解决召回阶段排序不准的问题",{"2":{"423":1}}],["解决同义词",{"2":{"423":1}}],["解决",{"2":{"423":1}}],["解决错位",{"2":{"375":1}}],["解决方案�",{"2":{"188":1,"189":1,"190":1}}],["解释什么是局部极小值",{"0":{"554":1}}],["解释多元函数极值判别法则",{"0":{"552":1}}],["解释一元函数极值判别法则",{"0":{"551":1}}],["解释一个什么是gb",{"2":{"497":1}}],["解释一下排序提",{"0":{"449":1}}],["解释原因",{"0":{"357":1}}],["解释",{"2":{"7":2,"36":2,"74":1,"78":3,"93":1,"94":2}}],["解析库进行合法性校验",{"2":{"422":1}}],["解析",{"2":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"32":1,"33":1,"34":1,"35":1,"37":1,"61":1,"72":1,"95":1,"268":1,"269":1,"270":1,"271":1,"274":1,"275":1,"276":1,"277":1,"278":1,"279":1,"280":1,"281":1,"282":1,"283":1}}],["输出数据的结构化",{"2":{"693":1}}],["输出门",{"2":{"690":1}}],["输出单个结果",{"2":{"690":1}}],["输出层的每个节点都只与部分输入层连接",{"2":{"693":1}}],["输出层每个神经元都有6个输入",{"2":{"566":1}}],["输出层使用卷积层替代yolo的全连接层",{"2":{"378":1}}],["输出三棵树对",{"2":{"472":1}}],["输出格式和语言风格",{"2":{"423":1}}],["输出格式要求",{"2":{"422":1}}],["输出为",{"0":{"699":1}}],["输出为最终的强分类器f",{"2":{"455":1,"475":1}}],["输出为对应的答案或摘要",{"2":{"423":1}}],["输出为64",{"2":{"357":3}}],["输出对",{"2":{"423":1}}],["输出中间表示",{"2":{"423":1}}],["输出校验与纠偏",{"2":{"422":1}}],["输出就一定一样",{"2":{"422":1}}],["输出通道统一为",{"2":{"388":1}}],["输出feature",{"2":{"373":1}}],["输出不能改变feature",{"2":{"317":1}}],["输出的尺寸为",{"2":{"695":1}}],["输出的尺寸往往会变小",{"2":{"312":1}}],["输出的feature",{"2":{"315":1,"368":1}}],["输出的是对象",{"2":{"221":2}}],["输出的是数组元素�",{"2":{"221":1}}],["输出的是数组索引值",{"2":{"221":1}}],["输出所有可能的结果",{"2":{"37":1}}],["输出最短序列的长度",{"2":{"35":1}}],["输出将这n个数合并成一个数后消耗的最小能量",{"2":{"21":1}}],["输出它的面",{"2":{"11":1}}],["输出",{"2":{"7":2,"11":1,"36":2,"67":1,"69":1,"74":2,"75":5,"76":2,"77":1,"78":3,"79":2,"81":3,"83":2,"89":1,"94":4,"388":1,"422":2,"431":1,"519":1,"651":1}}],["输入的m个文件直接对应m的map",{"2":{"770":1}}],["输入样本x",{"2":{"739":1}}],["输入映射层并求和得到隐含表征hw=∑u∈c",{"2":{"721":1}}],["输入门",{"2":{"697":1}}],["输入和输出在结构上保持对应关系",{"2":{"693":1}}],["输入实例的k邻近点中",{"2":{"650":1}}],["输入训练",{"2":{"635":1}}],["输入为",{"2":{"472":3}}],["输入为样本集",{"2":{"455":1,"475":1}}],["输入为问题",{"2":{"423":1}}],["输入为64",{"2":{"357":3}}],["输入一样",{"2":{"422":1}}],["输入一张待检测图片",{"2":{"373":1}}],["输入图片的尺寸对检测模型的性能影响相当明显",{"2":{"402":1}}],["输入图像高",{"2":{"382":1}}],["输入图像宽",{"2":{"382":1}}],["输入数据",{"2":{"422":1}}],["输入数据为第三步生成的proposals",{"2":{"373":1}}],["输入数组的",{"2":{"81":3}}],["输入到后面的",{"2":{"367":1}}],["输入输出数据+参数",{"2":{"357":1}}],["输入不存在公共前缀",{"2":{"74":1}}],["输入",{"2":{"7":2,"11":1,"36":2,"67":1,"69":1,"74":2,"75":5,"76":2,"77":1,"78":3,"79":2,"81":3,"83":2,"89":1,"94":4,"422":3,"431":1,"519":1,"651":1,"693":1,"695":1,"699":1}}],["7160330",{"2":{"725":1}}],["71167786",{"2":{"558":1}}],["706466139",{"2":{"725":1}}],["7030601",{"2":{"414":1}}],["7个百分比表示所有功能的覆盖指标",{"2":{"512":1}}],["77587749",{"2":{"499":1}}],["78532619",{"2":{"517":1}}],["78",{"2":{"422":1}}],["79199605",{"2":{"499":1}}],["79802934",{"2":{"414":1}}],["79060495",{"2":{"259":1}}],["7349957",{"2":{"284":1}}],["73662357",{"2":{"284":1}}],["72∗0",{"2":{"282":2}}],["72p",{"2":{"282":1}}],["7439670",{"2":{"272":1}}],["7号瓶子的药混起来给老鼠3吃",{"2":{"269":1}}],["7号瓶子的药混起来给老鼠2吃",{"2":{"269":1}}],["7号瓶子的药混起来给老鼠1吃",{"2":{"269":1}}],["7表示8个瓶子",{"2":{"269":1}}],["75是基于泊松分布",{"2":{"119":1}}],["75",{"0":{"119":1},"2":{"120":1}}],["7的区�",{"0":{"118":1},"1":{"119":1,"120":1}}],["7",{"0":{"7":1,"24":1,"35":1,"46":1,"70":1,"80":1,"91":1,"146":1,"157":1,"167":1,"200":1,"241":1,"280":1,"299":1,"310":1,"370":1,"396":1,"398":1,"412":1,"436":1,"450":1,"459":1,"470":1,"481":1,"507":1,"537":1,"546":1,"564":1,"576":1,"603":1,"618":1,"640":1,"660":1,"680":1},"1":{"399":1,"400":1,"401":1,"402":1,"403":1,"404":1},"2":{"10":1,"66":2,"86":2,"89":1,"118":1,"256":1,"268":1,"270":1,"357":1,"367":1,"371":1,"414":1,"484":1,"496":1,"570":1,"585":1,"651":1,"759":1,"784":1}}],["q=pp+",{"2":{"740":1,"741":1}}],["qwq",{"2":{"423":1}}],["qwen",{"2":{"422":1}}],["qlora",{"2":{"423":2}}],["q9",{"2":{"422":1,"725":1}}],["q8",{"2":{"422":1,"725":1}}],["q7",{"2":{"422":1,"725":1}}],["q60",{"2":{"423":1}}],["q6",{"2":{"422":1,"725":1}}],["q59",{"2":{"423":1}}],["q58",{"2":{"423":1}}],["q57",{"2":{"423":1}}],["q56",{"2":{"423":1}}],["q55",{"2":{"423":1}}],["q54",{"2":{"423":1}}],["q53",{"2":{"423":1}}],["q52",{"2":{"423":1}}],["q51",{"2":{"423":1}}],["q50",{"2":{"423":1}}],["q5",{"2":{"422":1,"725":1}}],["q49",{"2":{"423":1}}],["q48",{"2":{"423":1}}],["q47",{"2":{"423":1}}],["q46",{"2":{"423":1}}],["q45",{"2":{"423":1}}],["q44",{"2":{"423":1}}],["q43",{"2":{"423":1}}],["q42",{"2":{"423":1}}],["q41",{"2":{"423":1}}],["q40",{"2":{"423":1}}],["q4",{"2":{"422":1,"725":1}}],["q39",{"2":{"423":1}}],["q38",{"2":{"423":1}}],["q37",{"2":{"423":1}}],["q36",{"2":{"423":1}}],["q35",{"2":{"423":1}}],["q34",{"2":{"423":1}}],["q33",{"2":{"423":1}}],["q32",{"2":{"423":1}}],["q31",{"2":{"423":1}}],["q30",{"2":{"423":1}}],["q3",{"2":{"422":1,"725":1}}],["q29",{"2":{"423":1}}],["q28",{"2":{"423":1}}],["q27",{"2":{"423":1}}],["q26",{"2":{"423":1}}],["q25",{"2":{"422":1}}],["q24",{"2":{"422":1}}],["q23",{"2":{"422":1}}],["q20",{"2":{"422":1}}],["q2",{"2":{"422":1,"725":1}}],["q22",{"2":{"369":2,"422":1}}],["q21",{"2":{"369":2,"422":1}}],["q21=",{"2":{"369":1}}],["q19",{"2":{"422":1}}],["q18",{"2":{"422":1}}],["q17",{"2":{"422":1}}],["q16",{"2":{"422":1}}],["q15",{"2":{"422":1}}],["q14",{"2":{"422":1}}],["q13",{"2":{"422":1}}],["q10",{"2":{"422":1,"725":1}}],["q1",{"2":{"422":1,"725":1}}],["q12",{"2":{"369":2,"422":1}}],["q12=",{"2":{"369":1}}],["q11",{"2":{"369":2,"422":1,"725":1}}],["q11=",{"2":{"369":1}}],["qm",{"2":{"284":1}}],["qq1195365047",{"2":{"664":1}}],["qq",{"2":{"259":1,"414":4,"473":1,"499":1,"517":1,"556":1}}],["q�",{"0":{"224":1}}],["qsort",{"2":{"22":1,"51":1,"59":1,"757":4}}],["quantization",{"2":{"674":1}}],["ques",{"2":{"658":1}}],["question",{"2":{"203":1,"272":1,"284":1,"517":1,"563":1,"658":1}}],["questions",{"0":{"117":1,"127":1,"151":1,"160":1,"177":1,"183":1,"232":1,"287":1,"363":1,"691":1},"1":{"118":1,"119":1,"120":1,"121":1,"122":1,"123":1,"124":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1,"134":1,"135":1,"136":1,"137":1,"138":1,"139":1,"140":1,"141":1,"142":1,"143":1,"144":1,"145":1,"146":1,"147":1,"148":1,"152":1,"153":1,"154":1,"155":1,"156":1,"157":1,"161":1,"162":1,"163":1,"164":1,"165":1,"166":1,"167":1,"168":1,"169":1,"170":1,"171":1,"172":1,"173":1,"174":1,"178":1,"179":1,"180":1,"184":1,"185":1,"186":1,"187":1,"188":1,"189":1,"190":1,"191":1,"192":1,"193":1,"194":1,"195":1,"196":1,"197":1,"198":1,"199":1,"200":1,"201":1,"202":1,"203":1,"233":1,"234":1,"235":1,"236":1,"237":1,"238":1,"239":1,"240":1,"241":1,"242":1,"243":1,"244":1,"245":1,"246":1,"247":1,"288":1,"289":1,"290":1,"291":1,"292":1,"293":1,"294":1,"295":1,"296":1,"297":1,"298":1,"299":1,"300":1,"301":1,"302":1,"364":1,"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1,"377":1,"378":1,"379":1,"380":1,"381":1,"382":1,"383":1,"384":1,"385":1,"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1,"396":1,"397":1,"398":1,"399":1,"400":1,"401":1,"402":1,"403":1,"404":1,"405":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1,"692":1,"693":1,"694":1,"695":1,"696":1,"697":1,"698":1,"699":1,"700":1,"701":1,"702":1,"703":1,"704":1,"705":1,"706":1,"707":1,"708":1,"709":1,"710":1,"711":1,"712":1,"713":1,"714":1,"715":1,"716":1},"2":{"358":1,"556":1}}],["queries",{"2":{"423":1}}],["query排序",{"0":{"748":1}}],["query",{"2":{"422":3,"702":2,"748":3,"769":1}}],["queen",{"2":{"422":1,"718":1}}],["que",{"2":{"61":6}}],["queue",{"2":{"21":1,"32":1,"35":1,"54":1,"60":1,"61":1,"85":1,"86":1}}],["quicksort",{"2":{"51":3}}],["quot",{"0":{"224":3,"366":2,"824":1,"825":1,"826":2,"827":1},"2":{"7":12,"74":18,"75":10,"76":4,"77":4,"78":14,"79":10,"80":10,"81":74,"82":4,"83":12,"224":2,"239":2,"271":1,"282":4,"334":2,"366":2,"390":3,"422":12,"470":2,"484":2,"590":5,"719":2,"722":2,"755":2,"769":2,"824":5,"825":4,"826":5,"827":6}}],["q",{"0":{"109":1,"110":1,"111":1,"112":1,"114":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1,"217":1,"218":1,"220":1,"221":1,"222":1,"223":1,"226":1,"227":1,"228":1,"229":1,"774":1,"775":1,"776":1,"778":1,"779":1,"782":1,"784":1,"785":1,"786":1,"787":1,"790":1,"791":1,"792":1,"793":1,"795":1,"796":1,"797":1,"798":1,"800":1},"2":{"6":4,"32":6,"35":7,"47":14,"54":4,"60":6,"85":8,"86":8,"358":1,"369":1,"423":5,"496":1}}],["k频率统计开始出发",{"2":{"769":1}}],["k要相对n较小",{"2":{"763":1}}],["klogk",{"2":{"756":2}}],["k的query",{"2":{"769":1}}],["k的最大值",{"2":{"756":1}}],["k的含义",{"2":{"651":2}}],["k问题就没有values",{"2":{"769":1}}],["k问题的伪代码的例子",{"2":{"769":1}}],["k问题抽象出来的",{"2":{"769":1}}],["k问题",{"2":{"756":1,"769":1}}],["k中我们用到了一个数据结构堆",{"2":{"756":1}}],["kn",{"2":{"735":1}}],["knn是分类算",{"2":{"651":1}}],["knn",{"2":{"651":1}}],["knn算法有哪些优点和缺点",{"0":{"649":1}}],["knn算法的核心思想是在一个含未知样本的空间",{"2":{"646":1}}],["knn算法利用训练数据集对特征向量空间进行划分",{"2":{"646":1}}],["knn面试",{"0":{"645":1},"1":{"646":1,"647":1,"648":1,"649":1,"650":1,"651":1,"652":1}}],["knn等构成",{"2":{"453":1}}],["k表示隐向量的维度",{"2":{"735":1}}],["k表示变化",{"2":{"532":1}}],["kyunghyun",{"2":{"690":1}}],["kmean步骤",{"2":{"675":1}}],["kmeans原理详解",{"0":{"675":1}}],["kmeans的原理",{"0":{"382":1}}],["k均值算法",{"2":{"674":1}}],["kd树种距离查找点最近的点以及最近的距离",{"2":{"651":1}}],["kd树",{"2":{"651":1}}],["kd树改",{"2":{"651":1}}],["kd",{"2":{"651":1}}],["k是人工固定好的数字",{"2":{"651":1}}],["k值的选取",{"0":{"677":1}}],["k值的确定",{"2":{"676":1}}],["k值一般取比较小的值",{"2":{"647":1}}],["k值选择",{"2":{"646":1}}],["k1$的概率为0",{"2":{"618":1}}],["k1",{"2":{"618":1,"769":1}}],["k$",{"2":{"601":1}}],["kolmogorov",{"0":{"592":1}}],["koa",{"0":{"114":1},"2":{"114":6}}],["k−x0",{"2":{"555":1}}],["kaur",{"2":{"686":1}}],["kappa",{"2":{"536":3}}],["kaiming初始化",{"2":{"323":1}}],["k个类别都拟合完第一颗树之后才开始拟合第二颗树",{"2":{"497":1}}],["k个数字",{"2":{"756":1}}],["k个数的和",{"0":{"34":1}}],["k个数之和",{"0":{"15":1}}],["k颗树",{"2":{"497":1}}],["k棵树可以并行处理",{"2":{"497":1}}],["k为箱子的个数",{"2":{"465":1}}],["k为卷积核边长",{"2":{"394":1}}],["k矩阵可快速切断目标知识的上下文联系",{"2":{"422":1}}],["k矩阵",{"2":{"422":1}}],["kim",{"2":{"689":1}}],["king",{"2":{"422":1,"718":1}}],["kismetv",{"2":{"203":1}}],["k2",{"2":{"394":1,"769":2}}],["kw",{"2":{"314":1,"315":1,"317":2}}],["kh",{"2":{"314":1,"315":1,"317":2}}],["kp",{"2":{"272":1,"284":1,"658":1}}],["kernel",{"2":{"635":3,"689":1}}],["kernel计算的dw",{"2":{"357":1}}],["keep",{"2":{"397":4}}],["keepalivetime",{"2":{"129":2,"130":1}}],["keyup",{"2":{"796":1}}],["keys",{"2":{"702":1}}],["key值不变",{"2":{"258":1}}],["key=value",{"2":{"228":1}}],["key",{"0":{"201":1},"2":{"163":1,"184":4,"185":8,"189":2,"221":1,"223":3,"422":3,"702":1,"769":5,"770":2}}],["kthpostordernode",{"2":{"88":3}}],["kthsmallest",{"2":{"48":4}}],["ks的计算步骤如下",{"2":{"592":1}}],["ks值是收益最大",{"2":{"592":1}}],["ks值是在模型中用于区分预测正负样本分隔程度的评价指标",{"2":{"592":1}}],["ks曲线的最大值通常为ks值",{"2":{"592":1}}],["ks曲线为tpr",{"2":{"592":1}}],["ks",{"0":{"592":1}}],["ksumii",{"2":{"34":1}}],["ksimilarity",{"2":{"32":1}}],["kruskalmst",{"2":{"22":1,"59":1}}],["kruskal",{"2":{"22":1,"59":1}}],["k=1",{"2":{"532":1}}],["k=9",{"2":{"367":1}}],["k==0",{"2":{"34":1}}],["k==nums",{"2":{"29":1}}],["k=0",{"2":{"10":1,"53":1}}],["k=i",{"2":{"6":1}}],["k+a",{"2":{"532":1}}],["k++",{"2":{"6":1,"10":1,"53":4,"58":1,"78":1,"760":4}}],["k+1",{"2":{"6":2,"29":1,"78":1,"763":1}}],["k",{"0":{"32":1,"673":1,"678":1,"680":1,"681":1,"682":1,"685":1,"749":1,"752":1},"1":{"674":1,"675":1,"676":1,"677":1,"678":1,"679":1,"680":1,"681":1,"682":1,"683":1,"684":1,"685":1,"686":1},"2":{"6":7,"10":3,"15":5,"19":2,"29":3,"30":3,"32":4,"34":10,"36":12,"40":6,"43":2,"47":6,"48":9,"54":1,"56":2,"58":12,"72":2,"78":4,"82":7,"86":4,"88":5,"92":4,"315":2,"367":1,"368":2,"378":1,"381":1,"382":1,"396":7,"422":3,"428":1,"532":1,"601":1,"635":3,"638":1,"643":2,"651":5,"674":1,"675":1,"676":2,"677":1,"678":1,"680":1,"681":1,"686":1,"725":1,"756":2,"760":2,"763":4,"769":2}}],["cdot",{"2":{"730":1,"735":1}}],["cdots",{"2":{"536":2}}],["cf",{"2":{"729":1}}],["c|w",{"2":{"722":2}}],["c|ab",{"2":{"282":2}}],["cbdio",{"2":{"743":1}}],["cbow",{"2":{"725":1}}],["cbow模型",{"0":{"719":1},"1":{"720":1,"721":1}}],["cbbd",{"2":{"79":1}}],["c^",{"2":{"697":1}}],["center",{"2":{"782":2}}],["centered",{"2":{"305":1}}],["cell",{"2":{"690":1}}],["ck",{"2":{"684":2}}],["cj",{"2":{"684":2}}],["ci",{"2":{"684":2}}],["cin∗cout+1",{"2":{"395":1}}],["cin∗k2+1",{"2":{"395":1}}],["cin∗k2",{"2":{"395":1}}],["cin为输入特征图通道数",{"2":{"394":1}}],["cin",{"2":{"314":2,"315":3,"317":3}}],["c2",{"2":{"618":1}}],["c1",{"2":{"618":1}}],["cα",{"2":{"602":1}}],["ctr预估",{"2":{"667":1}}],["ctr=点击次数展示量",{"2":{"593":1}}],["ctr即点击通过",{"2":{"593":1}}],["ctr",{"0":{"593":1},"2":{"546":1,"595":1}}],["ctpn只能检测水平文本",{"2":{"404":1}}],["ctx",{"2":{"114":3}}],["c5",{"2":{"388":3}}],["c4",{"0":{"600":1},"2":{"388":2,"600":5,"604":2,"610":1}}],["cube",{"2":{"787":2}}],["cudnn",{"2":{"357":1}}],["cudnn7",{"2":{"357":1}}],["curse",{"2":{"651":1}}],["curlength++",{"2":{"94":1}}],["curlength",{"2":{"94":5}}],["cur",{"2":{"55":13,"56":7,"67":13,"70":13,"71":7,"73":5,"220":1}}],["currenthashmap",{"0":{"148":1}}],["current",{"2":{"38":2}}],["curmin",{"2":{"14":2}}],["curmax",{"2":{"14":3}}],["cvr=点击量转化量",{"2":{"594":1}}],["cvr即转化率",{"2":{"594":1}}],["cvr",{"0":{"594":1},"2":{"595":1}}],["cv基础",{"2":{"418":1}}],["cv基础知识",{"0":{"304":1},"1":{"305":1,"306":1,"307":1,"308":1,"309":1,"310":1,"311":1,"312":1,"313":1,"314":1,"315":1,"316":1,"317":1,"318":1,"319":1,"320":1,"321":1,"322":1,"323":1,"324":1,"325":1,"326":1,"327":1,"328":1,"329":1,"330":1,"331":1,"332":1,"333":1,"334":1,"335":1,"336":1,"337":1,"338":1,"339":1,"340":1,"341":1,"342":1,"343":1,"344":1,"345":1,"346":1,"347":1,"348":1,"349":1,"350":1,"351":1,"352":1,"353":1,"354":1,"355":1,"356":1,"357":1,"358":1}}],["cv深度学习面试问题记录",{"2":{"358":1}}],["cv计算机机视觉基础",{"2":{"358":1}}],["cv",{"2":{"358":2}}],["cv算法面试题总结",{"2":{"358":1}}],["cv中的卷积操作和数学上的严格定义的卷积的关系",{"0":{"341":1}}],["c¯",{"2":{"282":1}}],["cs224n中提到是为了更方便地求梯度",{"2":{"725":1}}],["cs",{"2":{"442":1}}],["css进阶",{"2":{"803":1}}],["css",{"0":{"780":1,"782":1},"1":{"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1},"2":{"235":1,"784":1,"785":1,"787":3,"803":1}}],["csdn",{"2":{"203":1,"259":1,"272":1,"284":2,"303":1,"414":6,"473":2,"499":2,"517":2,"558":1,"568":1,"644":1,"652":5,"664":1,"665":1,"686":1,"725":1,"743":2,"753":2}}],["createmomo",{"2":{"522":1}}],["creategraph",{"2":{"22":1,"59":1}}],["crf层能够添加一些约束使得预测标签是有效的",{"2":{"521":1}}],["crf模型的输入是每个单词的词向量",{"2":{"521":1}}],["crf模型则统计的是全局概率",{"2":{"520":1}}],["crf算法解析参",{"2":{"522":1}}],["crf算法解析",{"2":{"521":1}}],["crf在处理命名实体识别精度很好",{"2":{"521":1}}],["crf",{"2":{"519":2}}],["crlf",{"2":{"246":2}}],["crash",{"2":{"173":1}}],["cpu会中断当前正在运行的任务",{"2":{"301":1}}],["cpu",{"2":{"109":1,"131":7,"134":1,"143":1,"506":1}}],["cppbool",{"2":{"61":1}}],["cppclass",{"2":{"60":1,"90":1}}],["cppstruct",{"2":{"59":1,"84":1}}],["cppvoid",{"2":{"58":1}}],["cppint",{"2":{"58":1,"59":1}}],["cpptemplate",{"2":{"51":1}}],["cpp",{"2":{"26":1,"85":1,"86":1}}],["c3",{"2":{"81":1,"388":2,"618":1}}],["c>=",{"2":{"76":3}}],["calibration",{"2":{"740":1}}],["calinski",{"2":{"684":1}}],["calling",{"2":{"422":1}}],["call",{"0":{"213":1},"2":{"213":3}}],["capacity",{"2":{"537":1,"560":1,"725":1}}],["caption",{"2":{"423":1}}],["cache缓存命中率低",{"2":{"514":1}}],["cache",{"2":{"506":1}}],["cache命中率优化",{"2":{"464":1}}],["caffe原先的gpu实现group",{"2":{"357":1}}],["cat",{"2":{"470":1}}],["catboost以处理类别特征而闻名",{"2":{"497":1}}],["catboost的优缺点",{"0":{"451":1}}],["catboost的创新点有哪些",{"0":{"445":1}}],["catboost为什么要使用对称树",{"0":{"450":1}}],["catboost有两种提升模式",{"2":{"449":1}}],["catboost主要在第一阶段进行优化",{"2":{"449":1}}],["catboost通过采用排序提升",{"2":{"448":1}}],["catboost如何避免预测偏移",{"0":{"448":1}}],["catboost如何避免梯度偏差",{"0":{"447":1}}],["catboost只考虑一部分combinations",{"2":{"446":1}}],["catboost",{"2":{"445":1,"490":1,"495":2}}],["catboost还解决了梯度偏差以及预测偏移",{"2":{"444":1}}],["catboost是如何处理类别特征的",{"0":{"446":1}}],["catboost是由categorical和boosting组成",{"2":{"444":1}}],["catboost是一种以对称决策",{"2":{"444":1}}],["catboost面试",{"0":{"443":1},"1":{"444":1,"445":1,"446":1,"447":1,"448":1,"449":1,"450":1,"451":1}}],["category",{"2":{"495":1}}],["categorical",{"2":{"464":1}}],["cate",{"2":{"284":1}}],["catch操作跳过一些错误的bad",{"2":{"770":1}}],["catch",{"2":{"217":2,"218":2}}],["cascade",{"2":{"389":1}}],["cas",{"0":{"146":1},"2":{"133":2,"134":3,"135":3,"138":1,"139":1}}],["cas思想",{"0":{"132":1,"134":1},"1":{"133":1,"134":1,"135":1}}],["case3",{"2":{"551":1,"552":1}}],["case2",{"2":{"551":1,"552":1}}],["case1",{"2":{"551":1,"552":1}}],["case",{"2":{"75":6}}],["canvas",{"2":{"776":1}}],["canal",{"2":{"76":1}}],["cand",{"2":{"54":3}}],["cart采用的是不停的二分",{"2":{"604":1}}],["cart是基尼系数",{"2":{"604":1}}],["cart分类树离散值的处理问题",{"2":{"600":1}}],["cart算法",{"0":{"600":1},"2":{"600":1}}],["cart决策树",{"2":{"504":1,"511":1}}],["cart树是二叉树",{"2":{"497":1}}],["cart",{"2":{"472":1,"475":1,"513":2}}],["cart回归树的残差损失",{"2":{"331":1}}],["car",{"2":{"74":1,"76":1}}],["cnn相关",{"0":{"692":1},"1":{"693":1,"694":1,"695":1}}],["cnn系列和ssd本质有啥不一样吗",{"0":{"410":1}}],["cnn类似",{"2":{"386":1}}],["cnn中使用的anchor",{"2":{"378":1}}],["cnn中的运算是不需要翻转卷积核的",{"2":{"341":1}}],["cnn一个单独的检测网络",{"2":{"373":1}}],["cnn之所以叫做",{"2":{"367":1}}],["cnn是如何解决正负样本不平衡的问题",{"0":{"370":1}}],["cnn是经典的two",{"0":{"367":1}}],["cnn是一种两阶段",{"2":{"365":1}}],["cnn网络的原理",{"0":{"365":1}}],["cnn的设计思路",{"2":{"401":1}}],["cnn的fc层",{"2":{"373":1}}],["cnn的输入可以是tensor",{"2":{"355":1}}],["cnn的卷积运算并非数学定义的卷积",{"2":{"341":1}}],["cnn为什么比dnn在图像识别上更好",{"0":{"355":1}}],["cnn模型演变",{"2":{"342":1}}],["cnn详解",{"2":{"313":1}}],["cnn",{"0":{"366":2,"369":1,"689":1,"693":1,"694":1},"2":{"312":1,"315":1,"366":7,"367":2,"373":2,"389":4,"404":1,"689":1,"690":1}}],["cn",{"2":{"203":1,"253":1,"522":1,"671":1}}],["cnblogs",{"2":{"62":1,"96":1,"203":1,"253":2,"272":1,"284":1,"303":1,"499":1,"517":1,"595":1,"652":1,"656":1,"725":2}}],["cnt==1",{"2":{"81":1}}],["cnt=1",{"2":{"81":1}}],["cnt++",{"2":{"60":1,"81":1}}],["cntb",{"2":{"42":6}}],["cnta",{"2":{"42":6}}],["cnt",{"2":{"20":3,"23":3,"33":2,"42":8,"45":3,"60":2,"78":6,"81":1,"82":5}}],["cycle",{"2":{"60":1}}],["cls",{"2":{"423":1}}],["clamp",{"2":{"397":6}}],["classification",{"0":{"584":1},"1":{"585":1,"586":1,"587":1,"588":1,"589":1,"590":1,"591":1,"592":1,"593":1,"594":1},"2":{"365":1,"423":1,"689":1}}],["class",{"2":{"51":3,"53":2,"66":2,"67":2,"69":2,"70":2,"71":2,"72":1,"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1,"144":1,"370":1}}],["classs",{"2":{"20":1}}],["clock",{"2":{"299":1}}],["close",{"2":{"202":1}}],["clip",{"2":{"423":3}}],["clientheight",{"2":{"229":2}}],["clientwidth",{"2":{"229":2}}],["click",{"0":{"593":1},"2":{"226":1}}],["clusters",{"2":{"684":2}}],["clustering",{"0":{"674":1},"2":{"423":1,"686":2}}],["cluster",{"2":{"188":1}}],["clear",{"2":{"38":1,"785":2}}],["cho",{"2":{"690":1}}],["childs",{"2":{"762":1}}],["child",{"2":{"507":1,"792":1}}],["ch",{"2":{"81":1}}],["checkpalindrome",{"2":{"38":2}}],["challenging",{"2":{"719":4,"722":1}}],["change",{"2":{"533":1,"537":1}}],["changepoints",{"2":{"537":1}}],["changepoint",{"2":{"533":8,"537":2}}],["charat",{"2":{"82":5,"83":2}}],["characteristic",{"2":{"590":1}}],["character",{"2":{"82":1}}],["charset=",{"2":{"796":1}}],["chars",{"2":{"81":7}}],["char>",{"2":{"75":1,"81":1}}],["char>>",{"2":{"36":2}}],["char",{"2":{"35":2,"75":1,"76":1,"77":1,"81":1,"82":4}}],["chain",{"2":{"6":1,"519":1,"525":2}}],["ccc",{"2":{"81":1,"214":2}}],["cc",{"2":{"38":1}}],["c++",{"2":{"35":1,"275":1}}],["c=1",{"2":{"532":1}}],["c=512",{"2":{"357":1}}],["c=",{"2":{"35":1}}],["c=matrix",{"2":{"11":1}}],["cmp",{"2":{"20":2,"51":8,"53":6}}],["coordinate",{"2":{"740":1}}],["cookie�",{"2":{"228":1}}],["cookie",{"0":{"228":2},"2":{"228":3,"244":9}}],["cocoleyy",{"2":{"518":1}}],["coco数据集",{"2":{"393":1}}],["cover",{"2":{"512":1}}],["core计算",{"2":{"511":1}}],["corepoolsize",{"2":{"129":2,"130":4}}],["color",{"2":{"786":1}}],["colors",{"2":{"211":2}}],["colsample",{"2":{"507":1}}],["column",{"2":{"497":1,"782":2}}],["collaborative",{"0":{"726":1},"1":{"727":1,"728":1,"729":1,"730":1,"731":1},"2":{"420":1,"727":2}}],["counts",{"2":{"769":1}}],["countstrings",{"2":{"12":1}}],["count",{"2":{"718":1,"748":1,"762":1,"763":5,"793":11}}],["counter++",{"2":{"215":1}}],["counter",{"2":{"215":2}}],["count2+1",{"2":{"80":1}}],["count2",{"2":{"80":5}}],["count2统计",{"2":{"80":1}}],["count1+1",{"2":{"80":1}}],["count1",{"2":{"80":5}}],["count1统计",{"2":{"80":1}}],["cout输出到文件中",{"2":{"748":1}}],["cout分别为输出特征图的高",{"2":{"394":1}}],["cout",{"2":{"58":2,"60":3,"76":1,"85":5,"89":3,"314":2,"315":3,"317":2,"756":1}}],["copy回到原来的数",{"2":{"760":1}}],["copy",{"0":{"272":1},"2":{"53":1,"192":1,"760":1}}],["config",{"2":{"800":2}}],["confidence",{"2":{"386":1}}],["confusion",{"2":{"586":1}}],["connection",{"2":{"318":1}}],["conversion",{"0":{"594":1}}],["conv",{"2":{"373":1}}],["convolutional",{"2":{"689":1}}],["convolution与普通convolution的理论计算复杂度",{"2":{"357":1}}],["convolution需要4秒多",{"2":{"357":1}}],["convolution速度慢",{"2":{"357":1}}],["convolution很糟糕",{"2":{"357":1}}],["convolution",{"0":{"348":1},"2":{"357":1}}],["convolutions",{"2":{"306":1}}],["conv卷积网络",{"2":{"314":1,"315":1}}],["congestion",{"2":{"243":1}}],["concat所有结果",{"2":{"758":1}}],["concat每个通道对应着对应的卷积核",{"2":{"392":1}}],["concat是通道数的增加",{"2":{"392":1}}],["concatenate操作是在inception中首次使用",{"2":{"318":1}}],["concatenate区别是什么",{"0":{"318":1}}],["concat",{"0":{"705":1},"2":{"220":1,"222":1,"705":2}}],["concurrent",{"2":{"133":1,"136":1,"139":1}}],["conditional",{"2":{"519":1}}],["condition",{"2":{"136":1}}],["consistency一致性",{"2":{"258":1}}],["console",{"2":{"111":3,"112":2,"114":6,"211":2,"214":6,"215":3,"217":16,"218":3,"226":1,"793":1}}],["constant",{"2":{"740":1}}],["constrained",{"2":{"423":1}}],["constructor",{"2":{"111":1,"211":8,"212":1,"223":1}}],["const",{"2":{"22":2,"46":1,"51":2,"59":2,"111":5,"114":2,"215":1,"217":3,"218":3,"222":5,"224":2,"229":2,"800":3}}],["content",{"2":{"593":1,"743":1,"782":1}}],["context",{"2":{"422":1}}],["contest",{"2":{"77":1}}],["contact",{"2":{"318":1}}],["containskey",{"2":{"82":1}}],["continue",{"2":{"30":1,"35":1,"40":1,"81":1}}],["code",{"2":{"22":1,"34":1,"59":1,"94":1,"211":7,"499":1}}],["combiner",{"2":{"770":1}}],["combine",{"2":{"203":1}}],["commentbox",{"2":{"644":1}}],["committed",{"2":{"170":1}}],["commonjs规范规定",{"2":{"112":1}}],["commonjs",{"0":{"112":1},"2":{"112":1}}],["computer",{"2":{"686":1,"718":1}}],["compareandswap",{"2":{"139":1}}],["compare",{"2":{"134":1}}],["compact",{"2":{"110":3}}],["compress",{"2":{"81":1}}],["com",{"2":{"16":1,"26":1,"62":1,"85":2,"96":2,"203":7,"253":6,"259":2,"272":2,"284":3,"303":3,"414":16,"442":1,"473":2,"499":2,"517":3,"518":1,"522":1,"538":1,"556":2,"563":1,"564":1,"567":1,"577":1,"595":3,"644":2,"652":1,"656":1,"658":1,"671":1,"725":4,"743":1,"766":1,"798":1}}],["costs",{"2":{"590":1}}],["cost",{"2":{"9":7,"21":3,"661":1}}],["c",{"2":{"6":1,"10":1,"11":2,"35":3,"36":4,"38":2,"43":7,"45":3,"75":2,"76":4,"81":4,"214":2,"220":1,"270":2,"275":5,"282":2,"306":1,"308":1,"312":1,"422":8,"423":2,"532":1,"545":2,"635":2,"697":1,"719":1,"761":2}}],["p>",{"2":{"796":1}}],["p>�",{"2":{"774":1}}],["p是在采样后空间中给出的ctr预估值",{"2":{"740":1}}],["p取不同的值对应不同的距离公式",{"2":{"730":1}}],["pca",{"2":{"684":1}}],["pc端设计出多个版本",{"2":{"570":1}}],["phrase",{"2":{"690":1}}],["php",{"2":{"670":1}}],["phi",{"2":{"635":14}}],["p值为第i",{"2":{"574":1}}],["p表示时间序列的周期",{"2":{"535":1}}],["plugin",{"2":{"800":1}}],["plugins",{"2":{"800":2}}],["plugins�",{"2":{"800":1}}],["plsa",{"2":{"521":2}}],["plain模式是采用内建的ordered",{"2":{"449":1}}],["plan",{"2":{"76":1}}],["ppt",{"2":{"442":1}}],["ppo算法",{"2":{"423":1}}],["ppo",{"2":{"423":4}}],["png",{"2":{"390":1}}],["p7",{"2":{"388":3}}],["p7的作用是什么",{"0":{"388":1}}],["p=tptp+fp",{"2":{"587":1}}],["p=7表示以周为周期",{"2":{"535":1}}],["p=365",{"2":{"535":1}}],["p=",{"2":{"369":1}}],["pinard",{"2":{"517":1,"725":1}}],["pi∗",{"2":{"367":1}}],["pi",{"2":{"367":2}}],["pick",{"2":{"58":1,"59":1}}],["python数据处理",{"2":{"848":1}}],["python编程熟练",{"2":{"845":1}}],["python等",{"2":{"769":1}}],["python1",{"2":{"570":1}}],["python",{"2":{"390":1,"397":1,"845":1,"848":1}}],["pythonclass",{"2":{"64":1}}],["pytorch的索引值为longtensor",{"2":{"397":1}}],["pytorch和tensorflow的特点分别是什么",{"0":{"334":1}}],["pytorch",{"0":{"335":1},"2":{"315":1,"334":3,"335":1}}],["p6",{"0":{"388":1},"2":{"279":1,"388":3}}],["p5～p3",{"2":{"388":1}}],["p5",{"2":{"279":1}}],["p4",{"2":{"279":1}}],["p3完成",{"2":{"217":1}}],["p3",{"2":{"217":2,"279":1}}],["p2完成",{"2":{"217":1}}],["p2",{"2":{"217":2,"279":1,"388":1}}],["p1完成",{"2":{"217":1}}],["p1",{"2":{"217":2,"279":1}}],["perplexity",{"2":{"423":1}}],["per",{"2":{"394":1,"740":3}}],["person",{"2":{"211":2}}],["permute",{"2":{"29":2}}],["pending",{"2":{"217":1}}],["pend",{"2":{"90":2}}],["pstart+1+",{"2":{"90":2}}],["pstart+1",{"2":{"90":1}}],["pstart",{"2":{"90":2}}],["pwke",{"2":{"78":1}}],["pwwkew",{"2":{"78":1}}],["pukey",{"2":{"252":1}}],["pugh",{"2":{"186":1}}],["put",{"2":{"82":2,"246":1}}],["public",{"2":{"74":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":2,"81":1,"82":1,"83":1,"90":1,"94":1,"144":1}}],["pushstate",{"2":{"798":2}}],["push",{"2":{"21":2,"29":1,"30":2,"31":3,"32":2,"34":2,"35":2,"37":4,"38":2,"40":3,"47":4,"54":4,"60":3,"61":3,"75":1,"85":6,"86":6,"89":1,"92":1,"95":1,"111":1,"222":2}}],["pfpath",{"2":{"58":1}}],["p+1",{"2":{"51":1}}],["power",{"2":{"574":1}}],["power=1",{"2":{"573":1}}],["potential",{"2":{"521":1}}],["polynomial",{"2":{"635":1}}],["policy",{"2":{"423":1}}],["pollyfill",{"2":{"792":1}}],["poll",{"2":{"302":1}}],["points",{"2":{"537":1}}],["point",{"2":{"315":1,"394":2,"533":1,"800":1}}],["poivt",{"2":{"51":2}}],["pooling层得到规定大小的feature",{"2":{"373":1}}],["pooling层的作用以及如何进行反向传播",{"0":{"338":1}}],["pooling舍去了近似像素取整数的量化方法",{"2":{"369":1}}],["pooling与roi",{"0":{"369":1}}],["pooling操作中两次量化造成的区域不匹配",{"2":{"369":1}}],["pooling操作",{"2":{"368":1}}],["pooling是怎么做的",{"0":{"368":1}}],["pooling在全局平均池化操作中应用也比较广",{"2":{"339":1}}],["pooling更强调对整体特征信息进行一层下采样",{"2":{"339":1}}],["pooling更合适",{"2":{"339":1}}],["pooling比average",{"2":{"339":1}}],["pooling的过程就是将一个个大小不同的box矩形框",{"2":{"368":1}}],["pooling的主要作用一方面是去掉冗余信息",{"2":{"339":1}}],["pooling的效果更好",{"2":{"339":1}}],["pooling感觉更像是做了特征选择",{"2":{"339":1}}],["pooling都对数据做了下采样",{"2":{"339":1}}],["pooling",{"0":{"339":3},"2":{"313":2,"338":2,"339":1,"366":1,"367":1,"368":1,"374":1,"375":1,"689":2}}],["pooling和average",{"2":{"313":1,"339":1}}],["pooling位置记录最大值的索引位置",{"2":{"312":1}}],["port",{"2":{"114":3}}],["positive",{"2":{"586":2,"590":2}}],["postid=1004244",{"2":{"670":1}}],["post",{"2":{"203":1,"246":1,"670":1}}],["pos+1",{"2":{"48":1}}],["pos",{"2":{"48":6,"509":2}}],["popstate",{"2":{"798":1}}],["pop",{"2":{"21":2,"30":1,"32":1,"34":1,"35":1,"37":3,"47":3,"54":1,"60":1,"61":1,"75":3,"85":2,"86":2,"92":1,"220":1}}],["pa",{"2":{"729":1}}],["padding",{"2":{"689":1,"695":1}}],["paper",{"2":{"686":1,"771":1}}],["paper中default",{"2":{"367":1}}],["pandas",{"2":{"497":1}}],["pang951189",{"2":{"272":1}}],["panpanwelcome",{"2":{"253":1}}],["panama",{"2":{"76":1}}],["patch",{"2":{"423":1}}],["pattern",{"2":{"211":2}}],["path1",{"2":{"92":1}}],["pathb",{"2":{"92":4}}],["patha",{"2":{"92":4}}],["path",{"2":{"58":5,"92":5,"800":7}}],["page",{"2":{"165":1}}],["partition",{"2":{"757":2,"769":1}}],["partial",{"2":{"496":1}}],["part",{"2":{"361":1}}],["parseint",{"2":{"769":1}}],["parse",{"2":{"223":1}}],["params",{"2":{"315":2}}],["param",{"2":{"90":2}}],["paren",{"2":{"75":12}}],["parent",{"2":{"22":9,"59":12,"67":4,"94":3}}],["pass",{"2":{"75":1}}],["palindrome",{"2":{"64":4}}],["pair",{"2":{"40":6,"43":2,"94":1,"423":1}}],["pq",{"2":{"21":8}}],["pred",{"2":{"729":1}}],["precision就低",{"2":{"589":1}}],["precision和recall",{"2":{"589":1}}],["precision",{"0":{"587":1},"2":{"587":1}}],["preference",{"2":{"423":1}}],["prelu",{"2":{"319":1}}],["preorder",{"2":{"90":5}}],["preventdefault",{"2":{"779":1}}],["prev",{"2":{"70":5,"220":1}}],["pre",{"2":{"58":2}}],["premute",{"2":{"29":1}}],["premax",{"2":{"14":5}}],["premin",{"2":{"14":5}}],["prior",{"2":{"385":1,"533":2,"536":1,"537":3}}],["priority",{"2":{"21":1}}],["private",{"2":{"144":2}}],["print",{"2":{"96":1,"798":1}}],["printlevelorder",{"2":{"85":1,"86":1}}],["printpreorder",{"2":{"85":3}}],["printpostorder",{"2":{"85":3}}],["printinorder",{"2":{"85":3}}],["prim",{"2":{"59":1}}],["price",{"2":{"25":1,"26":5}}],["prices",{"2":{"24":5,"25":12,"26":3}}],["prop",{"2":{"796":2}}],["props",{"2":{"793":2}}],["prophet算法使用傅立叶级数来模拟时间序列的周期",{"2":{"535":1}}],["prophet",{"2":{"533":1,"537":1}}],["prophet在逻辑回归的基础上添加了随时间变化的参数",{"2":{"532":1}}],["prophet面试",{"0":{"530":1}}],["proposal阶段",{"2":{"378":1}}],["proposals作为输入数据",{"2":{"373":1}}],["proposal的xywh通常是小数",{"2":{"368":1}}],["proposal",{"2":{"366":7,"373":2,"376":1}}],["proposal提取",{"2":{"365":1}}],["proximal",{"2":{"423":1}}],["prompt",{"2":{"422":5,"423":4}}],["promise",{"0":{"217":1,"218":1},"2":{"217":11,"218":11}}],["pro参数随机让当前层神经元失活",{"2":{"325":1}}],["proto",{"2":{"212":1}}],["prototype",{"2":{"212":5}}],["probabilistic",{"2":{"186":1}}],["problem",{"0":{"31":1},"2":{"16":1}}],["programming",{"2":{"16":2}}],["p",{"2":{"6":7,"31":8,"51":7,"56":10,"62":1,"96":1,"203":4,"217":8,"253":4,"272":1,"278":2,"282":6,"284":2,"303":1,"369":1,"414":8,"422":2,"473":1,"499":2,"517":1,"519":1,"521":4,"538":1,"564":1,"566":2,"574":1,"577":1,"595":1,"601":1,"612":14,"613":10,"614":5,"620":1,"621":3,"627":4,"631":5,"635":1,"644":2,"652":1,"656":1,"661":1,"668":3,"695":1,"721":2,"722":1,"725":3,"730":4,"796":1}}],["6cb8e53d0101oetv",{"2":{"671":1}}],["6d1875160101gy4e",{"2":{"522":1}}],["69m",{"2":{"357":1}}],["6685962",{"2":{"753":1}}],["66",{"2":{"279":1}}],["65",{"2":{"279":1}}],["64mb",{"2":{"770":2}}],["64位",{"2":{"302":1}}],["64",{"2":{"279":1,"357":12,"388":1}}],["6349172",{"2":{"652":1}}],["63560633",{"2":{"517":1}}],["63",{"2":{"279":1}}],["625mb",{"2":{"763":1}}],["62",{"2":{"279":1}}],["61725100",{"2":{"567":1}}],["6140514",{"2":{"517":1}}],["61",{"2":{"279":1}}],["6分别出现一次为事件p",{"2":{"279":1}}],["6出现的概率都不相同",{"2":{"279":1}}],["688377",{"2":{"259":1}}],["6860252224930070536",{"2":{"203":1}}],["6864398",{"2":{"96":1}}],["60",{"2":{"251":1,"390":1}}],["6个字符的变换",{"2":{"35":1}}],["6",{"0":{"6":1,"23":1,"34":1,"45":1,"56":1,"69":1,"79":1,"90":1,"145":1,"157":1,"166":1,"195":1,"240":1,"279":1,"295":1,"309":1,"369":1,"383":1,"390":1,"395":1,"404":1,"411":1,"435":1,"449":1,"458":1,"469":1,"480":1,"506":1,"536":1,"545":1,"563":1,"575":1,"602":1,"617":1,"639":1,"651":1,"659":1,"679":1,"752":1},"1":{"196":1,"197":1,"198":1,"199":1,"296":1,"297":1,"298":1},"2":{"10":1,"40":1,"83":2,"89":1,"95":3,"222":1,"256":1,"268":1,"269":2,"270":1,"279":1,"284":1,"306":1,"414":1,"496":1,"522":1,"570":1,"585":1,"759":1,"784":1}}],["wrap",{"2":{"782":3}}],["write",{"2":{"34":1,"94":1,"173":1,"192":1,"202":1,"217":3,"759":1}}],["w是采样率",{"2":{"740":1}}],["w其中",{"2":{"740":1}}],["w~",{"2":{"721":2}}],["w|c",{"2":{"719":3,"721":1}}],["wf",{"2":{"697":1}}],["wfr=spider",{"2":{"414":1}}],["wu",{"2":{"697":1}}],["wc",{"2":{"697":1}}],["w=∑i=1nαiyixi",{"2":{"635":1}}],["w=32",{"2":{"357":1}}],["wtxi+b",{"2":{"635":4}}],["wt∥w∥xi+b∥w∥",{"2":{"635":1}}],["wt+1",{"2":{"428":4}}],["w^",{"2":{"635":8}}],["w^mieα=",{"2":{"430":1}}],["w^mie−α+∑yi≠gm",{"2":{"430":1}}],["w^mi=exp",{"2":{"430":1}}],["wxj+b",{"2":{"634":1}}],["wxi+b",{"2":{"634":1}}],["w⋅f",{"2":{"519":1}}],["w个样本",{"2":{"502":1}}],["wm+1",{"2":{"431":1}}],["w1",{"2":{"718":1}}],["w1的值",{"2":{"502":1}}],["w1一旦过大",{"2":{"502":1}}],["w1i=1n",{"2":{"431":1}}],["w1i=1m",{"2":{"428":2}}],["w1n",{"2":{"431":1}}],["w1m",{"2":{"428":1}}],["w12",{"2":{"428":1,"431":1}}],["w11",{"2":{"428":1}}],["wk|wk−1",{"2":{"718":1}}],["wk−n+1",{"2":{"718":3}}],["wk−2",{"2":{"718":4}}],["wk−1",{"2":{"718":3}}],["wk",{"2":{"718":2}}],["wkm",{"2":{"428":1}}],["wk2",{"2":{"428":1}}],["wk1",{"2":{"428":1}}],["wke",{"2":{"78":1}}],["w∗=∑i=1nαi∗yiφ",{"2":{"635":1}}],["w∗=∑i=1nαi∗yixi",{"2":{"635":2}}],["w∗=0",{"2":{"635":1}}],["w∗txj+b∗",{"2":{"635":1}}],["w∗txi+b∗",{"2":{"635":4}}],["w∗tx+b∗",{"2":{"635":1}}],["w∗",{"2":{"372":1,"635":5}}],["w",{"2":{"315":3,"317":3,"330":3,"368":1,"372":3,"379":1,"394":1,"635":15,"699":2,"719":4,"721":36,"722":2,"735":2,"741":1}}],["wlwl",{"2":{"303":1}}],["wo",{"2":{"697":1}}],["woman",{"2":{"422":1,"718":2}}],["wolverinn",{"2":{"253":1,"303":1}}],["worker之间需要相互通信",{"2":{"514":1}}],["worker之间相互通信",{"2":{"514":1}}],["workqueue",{"2":{"129":1,"130":2}}],["world",{"2":{"218":1}}],["wordtree",{"2":{"378":1}}],["worddict",{"2":{"31":3}}],["wordbreak",{"2":{"31":1}}],["word",{"0":{"31":1},"2":{"36":14}}],["word2vec原理介绍",{"2":{"725":1}}],["word2vec的缺点",{"2":{"725":1}}],["word2vec与lsa对比",{"2":{"725":1}}],["word2vec模型在nnlm模型上做了哪些改进",{"2":{"725":1}}],["word2vec模型为什么要进行负采样",{"2":{"725":1}}],["word2vec模型为什么要定义两套词向量",{"2":{"725":1}}],["word2vec模型提出了hierarchical",{"2":{"718":1}}],["word2vec模型对其直接进行了求和",{"2":{"718":1}}],["word2vec模型的灵感来源于bengio在2003年提出的nnlm模型",{"2":{"718":1}}],["word2vec是google在2013年提出的一个nlp工具",{"2":{"718":1}}],["word2vec",{"2":{"422":3,"725":2}}],["word2",{"2":{"5":4}}],["word1",{"2":{"5":4}}],["wevi",{"2":{"725":1}}],["welch算法是最大期望算",{"2":{"527":1}}],["welch算法进行参数的学习",{"2":{"527":1}}],["weak",{"2":{"425":1}}],["weixin",{"2":{"414":2,"473":1,"517":1,"556":1,"652":1}}],["weighted",{"2":{"589":1}}],["weight可以",{"2":{"509":1}}],["weight来平衡正样本和负样本的权重",{"2":{"509":1}}],["weight两方面去解决",{"2":{"370":1}}],["weight",{"2":{"22":1,"59":1,"507":1,"740":2}}],["webpack",{"2":{"800":15}}],["webpack�",{"0":{"800":1}}],["webkit",{"2":{"787":2}}],["web服务器利用会话密钥加密与客户端之间的通信",{"2":{"247":1}}],["web服务器利用自己的私钥解密出会话密钥",{"2":{"247":1}}],["web服务器收到客户端请求后",{"2":{"247":1}}],["web",{"2":{"244":1}}],["wd",{"2":{"203":1}}],["wh",{"2":{"390":5}}],["whys",{"2":{"253":1}}],["whered",{"2":{"684":1}}],["where",{"2":{"163":1,"369":2}}],["while",{"2":{"8":1,"19":2,"21":1,"22":1,"23":1,"32":2,"35":1,"41":1,"43":1,"44":1,"45":2,"47":2,"48":3,"49":3,"51":3,"53":3,"55":2,"56":3,"58":3,"59":3,"60":1,"61":1,"64":2,"65":1,"66":2,"67":4,"68":2,"69":1,"70":1,"71":1,"72":1,"73":1,"74":1,"76":3,"77":2,"78":1,"79":2,"81":1,"83":1,"85":2,"86":2,"185":1,"397":1,"757":3,"760":3}}],["wagging",{"2":{"439":1}}],["wa",{"2":{"367":4,"372":4}}],["warmup",{"2":{"346":2}}],["warm",{"2":{"346":1}}],["warshall",{"2":{"58":1}}],["way",{"2":{"253":1}}],["waking",{"2":{"253":1,"303":1}}],["wasabi1234",{"2":{"203":1}}],["watch",{"2":{"185":2}}],["wait时",{"2":{"302":1}}],["wait",{"2":{"139":1}}],["wbzhang233",{"2":{"85":2}}],["wide",{"2":{"738":3}}],["wide部分采用人工特征+lr的形式",{"2":{"738":1}}],["wide部分",{"0":{"735":1}}],["widehat",{"2":{"635":3}}],["width",{"2":{"229":1}}],["wise是在所有叶子节点中选取分裂收益最大的节点进行的",{"2":{"514":1}}],["wise是一种低效的算法",{"2":{"466":1}}],["wise可能会长出比较深的决策树",{"2":{"471":1}}],["wise可以降低更多的误差",{"2":{"466":1}}],["wise之上增加了一个最大深度的限制",{"2":{"466":1}}],["wise相比",{"2":{"466":1}}],["wise的分裂策略",{"2":{"514":2}}],["wise的缺点是",{"2":{"466":1}}],["wise的优点是",{"2":{"466":1}}],["wise的增长策略",{"2":{"466":1}}],["wise的叶子生长策略",{"2":{"464":1}}],["wise",{"0":{"466":1},"2":{"466":1,"471":1,"497":2}}],["wise和",{"0":{"466":1}}],["window",{"2":{"243":1,"798":5}}],["william",{"2":{"186":1}}],["within",{"2":{"684":1}}],["with",{"2":{"26":1,"651":1}}],["wikipedia",{"2":{"0":1,"58":2,"59":2,"60":1,"84":1,"771":1}}],["www",{"2":{"16":2,"26":1,"62":2,"96":4,"203":3,"253":3,"259":1,"272":2,"284":3,"303":2,"414":6,"499":2,"517":2,"563":1,"567":1,"595":1,"652":1,"656":1,"658":1,"666":1,"725":3,"743":1,"798":1}}],["删除b长度的数组",{"2":{"220":1}}],["删除最后一个元素",{"2":{"220":1}}],["删除第一个元素",{"2":{"220":1}}],["删除缓存",{"2":{"197":1}}],["删除缓存更为适合",{"2":{"196":1}}],["删除链表中倒数第k个结点",{"2":{"72":1}}],["删除元素",{"2":{"70":1,"786":1}}],["删除所有含有重复数字的节点",{"0":{"67":1}}],["删除无序链表中的重复项",{"0":{"66":1}}],["删除数字",{"0":{"19":1}}],["删除",{"2":{"5":1,"186":1}}],["删除一个字",{"2":{"5":1}}],["|^p",{"2":{"730":1}}],["|r",{"2":{"730":1}}],["|u|2+|v|2",{"2":{"729":1,"730":1}}],["|v2|",{"2":{"725":1}}],["|w|",{"2":{"635":2}}],["|s",{"2":{"621":4}}],["|dtλ||d|ent",{"2":{"603":1}}],["|im",{"2":{"422":2}}],["|x|",{"2":{"372":1}}],["|最大",{"2":{"18":1}}],["||",{"2":{"13":4,"31":1,"33":3,"34":2,"36":1,"41":1,"48":2,"55":1,"56":1,"75":3,"76":2,"80":1,"83":1,"92":2,"223":1,"229":2}}],["|=",{"2":{"4":1,"43":1}}],["|",{"2":{"4":1,"36":4,"312":1,"331":1,"431":1,"612":6,"730":2}}],["最重要的倒排索引怎么优化",{"2":{"761":1}}],["最坏时间为o",{"2":{"756":1}}],["最鲁棒",{"2":{"636":1}}],["最常用的cart树",{"2":{"490":1}}],["最常用的基分类器是决策树",{"2":{"460":1}}],["最常见的情况",{"2":{"369":1}}],["最好交给算法来处理",{"2":{"446":1}}],["最终每个",{"2":{"689":1}}],["最终收敛到梯度为0",{"2":{"547":1}}],["最终选择增益最大的那个特征的特征",{"2":{"510":1}}],["最终选增益最大的那个特征去做分裂",{"2":{"497":2,"505":1,"513":1}}],["最终产生的惩罚项极其之小",{"2":{"502":1}}],["最终是多棵树进行多数表决",{"2":{"501":1}}],["最终结",{"2":{"501":1}}],["最终结果通过投票产生",{"2":{"662":1}}],["最终结果",{"2":{"394":1}}],["最终集成的泛化性能可通过个体学习器之间的差异度而进一步提升",{"2":{"479":1}}],["最终的结果都是由多棵树一起决定",{"2":{"501":1}}],["最终的",{"2":{"422":1}}],["最终参数量",{"2":{"395":1}}],["最终得到需检测物体的坐标",{"2":{"373":1}}],["最终两个模型在训练过程中",{"2":{"352":1}}],["最终向用户呈现一个完整的页面",{"2":{"235":1}}],["最近一次购买距今的时长",{"2":{"679":1}}],["最近正好做完基于rfm模型的会员分群",{"2":{"679":1}}],["最近transformer在cv领域有了很好的进展",{"2":{"399":1}}],["最近邻插值法",{"2":{"369":1}}],["最近最久未使用置换算法",{"2":{"299":1}}],["最近公共祖先有很多方法",{"2":{"92":1}}],["最近公共祖",{"0":{"92":1}}],["最佳置换算法",{"2":{"299":1}}],["最高老鼠3没死",{"2":{"269":1}}],["最高位为1的4",{"2":{"269":1}}],["最普遍的定义是",{"2":{"258":1}}],["最多有255个桶",{"2":{"763":1}}],["最多有2^32个ip",{"2":{"750":1}}],["最多丢1s数据",{"2":{"193":1}}],["最多能装多满",{"2":{"4":1}}],["最左前缀匹配原则�",{"2":{"168":1}}],["最左前缀匹配规则",{"0":{"168":1}}],["最优路",{"2":{"519":1}}],["最优的缺省方向可以从数据中学到",{"2":{"508":1}}],["最优的方式",{"2":{"6":1}}],["最优",{"2":{"422":1}}],["最优子结构",{"2":{"104":1}}],["最优化问题的经典解法",{"2":{"100":1}}],["最基础的数据结构",{"2":{"99":1}}],["最右边的",{"2":{"93":1}}],["最短路径",{"0":{"58":1},"2":{"57":1}}],["最后归并这几个小文件的排序结果",{"2":{"763":1}}],["最后得到中位数即可",{"2":{"763":1}}],["最后得到的强分类器的分类精度依赖于所有弱分类器",{"2":{"487":1}}],["最后通过一个逻辑回归返回最终的预测结果",{"2":{"737":1}}],["最后通过这些测量数据计算回归到真实值",{"2":{"654":1}}],["最后推导下来逻辑回归其实就是最大熵模型",{"2":{"670":1}}],["最后票数最多的类别被认定为该样本的类",{"2":{"643":1}}],["最后利用贝叶斯定理求解p",{"2":{"627":1}}],["最后再对叶节点编号组合",{"2":{"739":1}}],["最后再对测试集进行预测",{"2":{"458":1}}],["最后再利用期望值和修正概率做出最优决",{"2":{"615":1}}],["最后乘上一个系数ρ",{"2":{"601":1}}],["最后到达叶子节点的过程",{"2":{"597":1}}],["最后根据上述结果对假设做出判断",{"2":{"571":1}}],["最后根据将第一棵树的预测值+权重",{"2":{"472":1}}],["最后评估出最好的版本给予采用",{"2":{"570":1}}],["最后目标函数可表达为由梯度构成",{"2":{"515":1}}],["最后累加加权的预测结果作为输出",{"2":{"486":1}}],["最后使用这a+b个数据计算信息增益",{"2":{"467":1}}],["最后用直方图表示",{"2":{"465":1}}],["最后基于新的训练集进行训练",{"2":{"458":1}}],["最后对所有基模型预测的结果进行线性组合产生最终的预测结果",{"2":{"456":1}}],["最后对分类后的",{"2":{"366":1}}],["最后一层全连接层用线性激活函数",{"2":{"378":1}}],["最后将所有特征图输入到后续的",{"2":{"366":1}}],["最后将所有",{"2":{"366":1}}],["最后",{"2":{"110":1,"268":1,"393":1}}],["最后打印出来map中的值即",{"2":{"89":1}}],["最后剩下的猫的萌系数最小是多少",{"2":{"27":1}}],["最后的概率=a",{"2":{"274":1}}],["最后的猫萌系数是gcd",{"2":{"27":1}}],["最后的",{"0":{"27":1}}],["最后直接返回sell即可",{"2":{"26":1}}],["最小堆呢",{"2":{"756":1}}],["最小样本权重和",{"2":{"507":1}}],["最小化",{"2":{"497":1}}],["最小化非匹配对的相似度",{"2":{"423":2}}],["最小点数",{"2":{"422":1}}],["最小支撑树",{"0":{"22":1,"59":1},"2":{"57":1}}],["最小花费路",{"0":{"9":1}}],["最大的划分点",{"2":{"603":1}}],["最大的好处就在于极大地提高了处理速度",{"2":{"368":1}}],["最大熵hmm模型为什么会产生标注偏置问题",{"2":{"528":1}}],["最大熵这个词听起来很玄妙",{"2":{"527":1}}],["最大熵马尔可夫模型为什么会产生标注偏置问题",{"2":{"527":1}}],["最大熵模型",{"2":{"521":1}}],["最大熵模型在处理中文词性标注表现很好",{"2":{"521":1}}],["最大叶子节点数",{"2":{"484":1}}],["最大限度地保留其通用能力",{"2":{"423":1}}],["最大化真实图文对相似度",{"2":{"423":1}}],["最大线程池大小",{"2":{"129":1}}],["最大连续子序列",{"0":{"18":1}}],["最大正方形面积",{"0":{"11":1}}],["最大子序列的和",{"2":{"10":1}}],["最大矩阵和",{"0":{"10":1}}],["最少需要分割几",{"2":{"7":1}}],["最长连续序列是2",{"2":{"94":1}}],["最长连续序列是3",{"2":{"94":1}}],["最长的连续路径必须是从父亲节点到孩子节点",{"2":{"94":1}}],["最长的子序列长",{"2":{"3":1}}],["最长回文子",{"0":{"79":1}}],["最长子",{"2":{"78":1}}],["最长子序列",{"2":{"3":1}}],["最长公共前缀",{"0":{"74":1},"2":{"763":1}}],["最长公共子序列",{"0":{"2":1}}],["最长整除子",{"0":{"3":1}}],["最长上升子序列问题是在一个无序的给定序列中找到一个尽可能长的由低到高排列的子序列",{"2":{"1":1}}],["最长上升子序列",{"0":{"1":1}}],["4g内存大概可以表示340亿bit",{"2":{"747":1}}],["4个特征和3棵树",{"2":{"512":1}}],["4个人在不同排",{"2":{"275":1}}],["4卡",{"2":{"423":1}}],["49ab87122562",{"2":{"499":1}}],["49",{"0":{"352":1}}],["48小时",{"2":{"423":1}}],["48",{"0":{"351":1}}],["4839031",{"2":{"284":1}}],["475278057",{"2":{"563":1}}],["47",{"0":{"350":1}}],["4^n",{"2":{"280":1}}],["4602",{"2":{"442":1}}],["46",{"0":{"349":1},"2":{"279":1}}],["44915167",{"2":{"652":1}}],["44m",{"2":{"357":2}}],["44",{"0":{"347":1},"2":{"279":1}}],["43827793",{"2":{"644":1}}],["43750248",{"2":{"414":1}}],["43",{"0":{"346":1},"2":{"279":1}}],["42109740",{"2":{"414":1}}],["42g",{"2":{"357":1}}],["42",{"0":{"345":1},"2":{"279":1}}],["4字节",{"2":{"251":1}}],["4xx状态码",{"2":{"245":1}}],["4kwue8ml",{"2":{"556":1}}],["4k",{"2":{"244":1}}],["4�",{"2":{"139":1}}],["4次位运算+5次异或运�",{"2":{"118":1}}],["45192775",{"2":{"753":1}}],["45",{"0":{"348":1},"2":{"83":1,"279":1}}],["456",{"2":{"83":1}}],["41",{"0":{"68":1,"344":1},"2":{"279":1}}],["4096",{"2":{"422":1}}],["404",{"2":{"245":1}}],["403",{"2":{"245":1}}],["401",{"2":{"245":1}}],["400",{"2":{"245":1}}],["40x20",{"2":{"6":1}}],["40",{"0":{"343":1},"2":{"6":3}}],["4",{"0":{"4":1,"21":1,"32":1,"43":1,"54":1,"61":1,"67":1,"77":1,"88":1,"123":1,"140":1,"155":1,"164":1,"191":1,"225":1,"236":1,"252":1,"258":1,"270":1,"277":1,"293":1,"307":1,"381":1,"388":1,"393":1,"402":1,"409":1,"433":1,"447":1,"456":1,"467":1,"478":1,"504":1,"520":1,"534":1,"543":1,"561":1,"573":1,"600":1,"615":1,"637":1,"649":1,"657":1,"677":1,"750":1,"783":1},"1":{"192":1,"193":1,"226":1,"227":1,"228":1,"229":1,"237":1,"784":1,"785":1,"786":1,"787":1},"2":{"10":3,"11":1,"40":3,"41":2,"67":2,"75":1,"82":1,"83":4,"89":1,"91":2,"94":4,"95":4,"211":2,"222":1,"252":1,"255":1,"256":1,"268":1,"274":3,"275":2,"277":1,"279":1,"280":3,"390":2,"397":2,"414":1,"423":1,"496":1,"522":1,"529":1,"570":1,"583":1,"601":2,"730":3,"759":1,"782":1,"784":1,"785":1,"786":1,"833":1,"834":1,"835":1,"836":1}}],["each",{"2":{"769":2}}],["early",{"2":{"325":1,"561":1}}],["estimators",{"2":{"484":1}}],["es6",{"0":{"112":1},"2":{"112":1}}],["efb",{"0":{"468":1},"2":{"464":1,"468":1,"495":1}}],["effective",{"2":{"275":1}}],["eα−e−α",{"2":{"430":1}}],["eαt",{"2":{"428":1}}],["e−αt",{"2":{"428":1}}],["et=p",{"2":{"428":1}}],["e^",{"2":{"306":1}}],["echo",{"2":{"303":1}}],["epoll",{"2":{"302":1}}],["ernie2",{"2":{"716":1}}],["ernie对bert进行了哪些优化",{"0":{"716":1}}],["ernie",{"0":{"715":1},"1":{"716":1}}],["erroob2−erroob1",{"2":{"483":1}}],["error反映的是整个模型的准确度",{"2":{"622":1}}],["error=bias",{"2":{"622":1}}],["error",{"2":{"210":1,"218":2,"580":1,"581":1,"585":1,"682":1}}],["eraseoverlapintervals",{"2":{"20":1}}],["erase",{"2":{"19":2,"35":1,"40":1}}],["encoder",{"2":{"690":1,"702":5,"713":1}}],["entry",{"2":{"800":4}}],["entropy如何反向求导",{"0":{"344":1}}],["ent",{"2":{"601":2,"603":1}}],["ensemble",{"2":{"425":1}}],["engineering",{"2":{"423":1}}],["en",{"2":{"203":1,"796":1}}],["end训练的不一样",{"0":{"407":1}}],["end的形式训练目标检测系统",{"2":{"368":1}}],["endlv",{"2":{"77":2}}],["endlv=ii+1",{"2":{"77":1}}],["endlv=ii",{"2":{"77":1}}],["endlv=0",{"2":{"77":1}}],["endl",{"2":{"58":1,"60":1,"76":1}}],["end",{"2":{"19":1,"20":7,"23":1,"30":1,"31":1,"32":1,"35":4,"40":3,"51":7,"53":5,"54":3,"58":2,"59":2,"60":2,"61":4,"69":4,"78":5,"89":2,"90":2,"635":1,"782":2}}],["every",{"2":{"220":1}}],["everysec",{"2":{"193":1}}],["event",{"2":{"226":2,"779":1}}],["events",{"0":{"536":1},"2":{"111":9}}],["eventemitter",{"2":{"111":14}}],["eventemitter�",{"0":{"111":1}}],["ehcache",{"2":{"188":1}}],["equals",{"0":{"123":1},"2":{"123":1,"124":2}}],["em>",{"2":{"775":1}}],["em>�",{"2":{"774":1}}],["embed",{"2":{"689":2}}],["embedding内容是共享的",{"2":{"738":1}}],["embedding内容是否共享",{"2":{"738":1}}],["embedding向量作为fm的输入",{"2":{"735":1}}],["embedding结构如下",{"2":{"734":1}}],["embedding",{"2":{"422":1,"423":2,"689":1,"705":2}}],["email",{"0":{"524":1},"2":{"518":1}}],["emi=",{"2":{"431":1}}],["emitintemediate",{"2":{"769":1}}],["emit",{"2":{"111":6,"769":1}}],["em=∑i=1nwmiemi",{"2":{"431":1}}],["em=∑i=1nw^mii",{"2":{"430":1}}],["em=max|yi−gm",{"2":{"431":1}}],["empty",{"2":{"33":2,"35":1,"36":1,"47":3,"60":1,"61":1,"70":1,"75":4,"85":2,"86":2}}],["edocteel",{"2":{"77":1}}],["edge",{"2":{"22":14,"59":14}}],["ekat",{"2":{"77":1}}],["exclusive",{"2":{"464":1,"468":1,"495":1}}],["extraction",{"2":{"365":1}}],["expand",{"2":{"390":6}}],["exponential",{"2":{"319":1}}],["export",{"2":{"112":1}}],["exports�",{"2":{"112":1}}],["exports属性�",{"2":{"112":1}}],["exports",{"2":{"111":1,"112":2,"800":1}}],["expire",{"2":{"184":1}}],["explain",{"2":{"164":1}}],["expected",{"2":{"94":2}}],["exists",{"2":{"60":1}}],["exist",{"2":{"36":1}}],["example",{"2":{"3":1,"6":1,"7":1,"10":1,"11":1,"798":1}}],["e++",{"2":{"22":1,"59":1}}],["e",{"2":{"22":6,"36":4,"59":6,"61":2,"761":1,"766":1,"796":2}}],["elmo的缺点",{"0":{"708":1}}],["elmo",{"0":{"706":1},"1":{"707":1},"2":{"708":1}}],["elasticnet在我们发现用lasso回归太过",{"2":{"657":1}}],["elasticnet",{"2":{"657":1}}],["elu",{"2":{"319":1,"698":1}}],["else判定规则",{"2":{"597":1}}],["else",{"2":{"5":1,"9":1,"10":1,"11":2,"18":1,"20":2,"22":2,"23":1,"36":1,"38":1,"40":2,"41":4,"42":6,"43":1,"44":4,"45":4,"48":2,"51":1,"53":1,"55":1,"56":1,"59":2,"64":1,"65":1,"66":1,"67":3,"69":1,"70":2,"71":1,"75":3,"76":1,"78":1,"82":1,"86":1,"94":2,"111":1,"222":1,"223":1,"397":1,"757":1,"760":1}}],["element�",{"0":{"773":1},"1":{"774":1,"775":1,"776":1}}],["element",{"2":{"3":1}}],["5年的职业发展方向",{"2":{"810":1}}],["5∗106",{"2":{"763":2}}],["5亿个整数",{"2":{"751":2}}],["5亿个整数中找出不重复的整数",{"2":{"751":1}}],["5882",{"2":{"689":1}}],["5看成是负样本",{"2":{"659":1}}],["5可以看成是正样本",{"2":{"659":1}}],["57947723",{"2":{"644":1}}],["5为什么使用信息增益比来选择特征",{"2":{"610":1}}],["5不同",{"2":{"604":1}}],["5是信息增益比",{"2":{"604":1}}],["5相同",{"2":{"604":1}}],["5中采用的策略",{"2":{"603":1}}],["5由于使用了熵模型",{"2":{"600":1}}],["5只能用于分类",{"2":{"600":1}}],["5生成的是多叉树",{"2":{"600":1}}],["5在id3算法上面的改进",{"2":{"600":1}}],["5算法",{"0":{"600":1}}],["5个结果取均值或者多数取胜的投票策略去决定最终结果",{"2":{"564":1}}],["5个和2个观察值的叶节",{"2":{"512":1}}],["5万样本",{"2":{"423":1}}],["5天",{"2":{"423":1}}],["5x2",{"2":{"367":1,"372":1}}],["5xx状态码",{"2":{"245":1}}],["5=3637",{"2":{"282":1}}],["5+0",{"2":{"282":1}}],["55",{"2":{"279":1}}],["53",{"0":{"356":1},"2":{"279":1,"378":1}}],["53f0b27dc7e1",{"2":{"203":1}}],["52535694",{"2":{"652":1}}],["52330017",{"2":{"538":1}}],["52",{"0":{"355":1},"2":{"279":1}}],["51121582",{"2":{"652":1}}],["515113",{"2":{"414":1}}],["51680715",{"2":{"414":1}}],["51227754",{"2":{"644":1}}],["5122",{"2":{"367":1}}],["51201278",{"2":{"303":1}}],["51",{"0":{"354":1},"2":{"279":1}}],["51zhy",{"2":{"253":1}}],["56382372",{"2":{"725":1}}],["569536833",{"2":{"517":1}}],["56",{"2":{"279":1}}],["5678放在天平的右端",{"2":{"270":1}}],["56088",{"2":{"83":1}}],["54709759",{"2":{"414":1}}],["54",{"0":{"357":1},"2":{"259":1,"279":1}}],["5000",{"2":{"749":1}}],["500",{"2":{"358":1,"556":1}}],["500服务器内部错误",{"2":{"245":1}}],["50",{"0":{"353":1},"2":{"282":1}}],["501服务不可用",{"2":{"245":1}}],["5920953",{"2":{"62":1}}],["5�",{"2":{"40":1}}],["5的属于0分类",{"2":{"660":1}}],["5的属于1分类",{"2":{"660":1}}],["5的归为0分类",{"2":{"660":1}}],["5的归为1分类",{"2":{"660":1}}],["5的一颗子树中",{"2":{"604":1}}],["5的不足",{"2":{"600":1}}],["5的卷积核有相同的感知野",{"2":{"347":1}}],["5的家庭",{"2":{"276":1}}],["5的家庭一胎生男就停止生育",{"2":{"276":1}}],["5的第0",{"2":{"83":1}}],["5的倍数进行构造",{"2":{"8":1}}],["5的对应的数",{"2":{"8":1}}],["5进行组合",{"2":{"8":1}}],["5",{"0":{"5":1,"22":1,"33":1,"44":1,"55":1,"68":1,"78":1,"89":1,"124":1,"141":1,"156":1,"165":1,"194":1,"238":1,"271":1,"278":1,"294":1,"308":1,"368":1,"382":1,"389":1,"394":1,"403":1,"410":1,"434":1,"448":1,"457":1,"468":1,"479":1,"505":1,"521":1,"535":1,"544":1,"562":1,"574":1,"601":1,"616":1,"638":1,"650":1,"658":1,"678":1,"751":1},"1":{"142":1,"143":1,"144":1,"239":1},"2":{"3":2,"8":1,"10":1,"40":1,"41":2,"66":3,"67":2,"69":1,"75":1,"83":7,"94":3,"95":3,"139":1,"222":1,"252":1,"256":1,"268":1,"269":2,"270":1,"275":5,"276":1,"279":1,"282":1,"367":1,"372":1,"378":1,"393":1,"397":1,"414":1,"423":1,"496":1,"512":1,"522":1,"566":1,"570":1,"583":1,"659":1,"660":1,"763":1,"784":1,"786":1,"787":3}}],["使",{"2":{"763":1}}],["使类别内的数据相似度较大而类别间的数据相似度较小",{"2":{"674":1}}],["使新期望为0",{"2":{"544":1}}],["使算法更加保守",{"2":{"507":1}}],["使他不至于过大",{"2":{"502":1}}],["使学习出来的模型更加简单",{"2":{"497":1,"513":1}}],["使公式",{"2":{"497":1}}],["使随机森林算法在样本层面失去了随机性",{"2":{"478":1}}],["使每一颗树拟合的细节不同",{"2":{"477":1}}],["使偏差减小",{"2":{"432":1}}],["使fm",{"2":{"430":1}}],["使推理过程连贯且可信",{"2":{"423":1}}],["使负例更贴近当前模型难区分样本",{"2":{"423":1}}],["使向量更准确地表达用户真实意图",{"2":{"423":1}}],["使模型能同时捕捉序列中不同维度的依赖关系",{"2":{"422":1}}],["使模型更准确",{"2":{"305":1}}],["使微调后的框更ground",{"2":{"372":1}}],["使判决函数更具有判决性",{"2":{"347":1}}],["使输入数据变成一维向量",{"2":{"339":1}}],["使下降方向越准确",{"2":{"333":1}}],["使的每次训练都有一批神经元不参与模型训练",{"2":{"307":1}}],["使不同量纲的特征处于同一数值量级",{"2":{"305":1}}],["使网络传输减少",{"2":{"247":1}}],["使基于无状态的",{"2":{"244":1}}],["使拥塞窗口缓慢地线性增大",{"2":{"243":1}}],["使其更鲁棒",{"2":{"770":1}}],["使其更好的应用到我们的业务上",{"2":{"769":1}}],["使其在公司内部更好的应用",{"2":{"769":1}}],["使其在新的特征空间中线性可分",{"2":{"635":1}}],["使其输出风格更简洁",{"2":{"423":1}}],["使其能同时回答故事梗概和故事细节",{"2":{"423":1}}],["使其能够生成所有可能的并且有效的括号组合",{"2":{"80":1}}],["使其按线性规律缓慢增大",{"2":{"243":1}}],["使里面的函数能够访问到外面函数的变量",{"2":{"215":1}}],["使程序异常终止�",{"2":{"122":1}}],["使字符串由仅一个字符或两个字符组成",{"2":{"37":1}}],["使它的萌系数最小",{"2":{"27":1}}],["使两个子数组和的差的绝对值|sum",{"2":{"18":1}}],["使用5路归并",{"2":{"763":1}}],["使用归并排序的思想进行排序",{"2":{"763":1}}],["使用提示",{"2":{"759":1}}],["使用gbdt建两类树",{"2":{"741":1}}],["使用由于lr是线性模型",{"2":{"739":1}}],["使用协同过滤算法之前",{"2":{"731":1}}],["使用词频count",{"2":{"718":1}}],["使用词表检索后重写",{"2":{"423":1}}],["使用双向语言模型建模",{"2":{"707":1}}],["使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值",{"2":{"369":1}}],["使用高斯分布概率密度来计算类的条件概率密度",{"2":{"621":1}}],["使用公式",{"2":{"603":1}}],["使用基尼系数来代替信息增益比",{"2":{"600":1}}],["使用基于学习算法的决策树",{"2":{"464":1}}],["使用信息增益比",{"2":{"600":1}}],["使用信息增益比时",{"2":{"599":1}}],["使用信息增益时",{"2":{"599":1}}],["使用acc与error作为衡量指标时",{"2":{"585":1}}],["使用非线性模型",{"2":{"560":1}}],["使用非线性函数log",{"2":{"306":1}}],["使用该增量则有",{"2":{"547":1}}],["使用前向和后向算法求解",{"2":{"527":1}}],["使用前i",{"2":{"497":1}}],["使用残差拟合只是考虑到损失函数为平方损失的特殊情况",{"2":{"515":1}}],["使用线性分类器",{"2":{"513":1}}],["使用叶子结点的数目和叶子结点权重的l2模的平方",{"2":{"507":1}}],["使用缓存预取的方法",{"2":{"506":1}}],["使用二阶可以使损失函数更加准确",{"2":{"497":1}}],["使用二分查找可以得到o",{"2":{"1":1}}],["使用的时候",{"2":{"730":1}}],["使用的cart树",{"2":{"497":1}}],["使用的个k个树的投票策略",{"2":{"497":1}}],["使用的流量控制协议是可变大小的滑动窗口协议",{"2":{"241":1}}],["使用了前向分布算法",{"2":{"493":1}}],["使用了更高效的内存访问模式",{"2":{"422":1}}],["使用相应的oob",{"2":{"483":1}}],["使用相对位置",{"2":{"48":1}}],["使用可变重要性图表中的前n个特征",{"2":{"459":1}}],["使用正则化技术",{"2":{"459":1}}],["使用正则或解析器判断输出是否合法",{"2":{"422":1}}],["使用模型估计样本的梯度",{"2":{"447":1}}],["使用模板化结构如",{"2":{"422":1}}],["使用数据的不同排列",{"2":{"446":1}}],["使用权值分布",{"2":{"428":1}}],["使用强模型构建合成数据集或者加入噪音样本",{"2":{"423":1}}],["使用熵正则化增加策略探索",{"2":{"423":1}}],["使用kl散度约束限制新策略与原始模型差异",{"2":{"423":1}}],["使用kruskal算法",{"2":{"22":1}}],["使用跨语言对齐任务",{"2":{"423":1}}],["使用中文文本做领域小规模继续预训练",{"2":{"423":1}}],["使用子词级别标签体系",{"2":{"423":1}}],["使用较小学习率",{"2":{"423":1}}],["使用预训练的视觉模型",{"2":{"423":1}}],["使用弱多模态模型对图像+文本输入进行理解",{"2":{"423":1}}],["使用一定重叠率的滑窗分块",{"2":{"423":1}}],["使用函数调用",{"2":{"422":1}}],["使用上下文分离机制",{"2":{"422":1}}],["使用指令封闭结构",{"2":{"422":1}}],["使用llm做",{"2":{"422":1}}],["使用fpn",{"2":{"403":1}}],["使用过度采样",{"2":{"403":1}}],["使用多种分辨率的图像送到网络中识别",{"2":{"402":1}}],["使用微调的模型来预测原图经过上采样的图像",{"2":{"401":1}}],["使用顶层的特征来进行处理",{"2":{"401":1}}],["使用更低的特征图做检测",{"2":{"385":1}}],["使用batch",{"2":{"378":1}}],["使用bfs进行变换",{"2":{"35":1}}],["使用新的loss",{"2":{"375":1}}],["使用softnms代替nms",{"2":{"374":1}}],["使用sql语句查询想要的一切",{"2":{"258":1}}],["使用early",{"2":{"354":1}}],["使用1×1卷积核增加通道的数量",{"2":{"320":1}}],["使用1",{"2":{"317":1}}],["使用合适的模型",{"2":{"307":1}}],["使用方便",{"2":{"258":1}}],["使用方法",{"0":{"136":1,"137":1},"1":{"137":1,"138":1,"139":1}}],["使用流量控制和拥塞控制",{"2":{"240":1}}],["使用解构和递归实现",{"2":{"222":1}}],["使用返回值为函数的函数",{"2":{"215":1}}],["使用场景�",{"2":{"172":1}}],["使用任何存储引擎的mysql数据库都会记录binlog日志",{"2":{"172":1}}],["使用短索引",{"2":{"169":1}}],["使用这个关键字可以得到哪些信息�",{"0":{"164":1}}],["使用这个s表示当前可能满足的最大和",{"2":{"18":1}}],["使用",{"2":{"162":1,"167":1,"184":1,"200":2,"211":1,"228":1,"422":4,"423":1,"472":1,"689":2,"710":1,"713":1,"787":1,"793":1}}],["使用释放更加灵�",{"2":{"139":1}}],["使用cas线程是不会被阻塞的",{"2":{"134":1}}],["使用require",{"2":{"112":1}}],["使用r表示目前可以表示的右边界",{"2":{"23":1}}],["使用import和export可以使js文件模块化�",{"2":{"112":1}}],["使用空间叫",{"2":{"110":1}}],["使用深度优先搜索dfs",{"2":{"93":1}}],["使用原地算法将其压缩",{"2":{"81":1}}],["使用两个",{"2":{"699":1}}],["使用两个指针扫描",{"2":{"72":1}}],["使用两个指针fast和slow",{"2":{"72":1}}],["使用两次同一�",{"2":{"40":1}}],["使用dist表示从mstset集合某个点到u的最小距离为inf",{"2":{"59":1}}],["使用u更新dist距离",{"2":{"59":1}}],["使用u更新距离",{"2":{"58":1,"59":1}}],["使用u作为中间顶点",{"2":{"58":1}}],["使用vector",{"2":{"58":1,"59":1}}],["使用快重传可以使整个网络的吞吐量提高约20",{"2":{"243":1}}],["使用快慢指针",{"2":{"56":1}}],["使用快排的一次划�",{"2":{"48":1}}],["使用最大堆",{"2":{"54":1}}],["使用2",{"2":{"8":1}}],["使得我们可以对浏览器历史记录栈进行修改�",{"2":{"798":1}}],["使得a",{"2":{"756":1}}],["使得arri",{"2":{"40":1}}],["使得高频词离根节点距离更近",{"2":{"725":1}}],["使得误差平方和最小",{"2":{"656":1}}],["使得样本在这个特征空间内线性可",{"2":{"638":1}}],["使得所有属于d0的点",{"2":{"634":1}}],["使得朴素贝叶斯获得的结果向该特征所希望的方向进行了偏移",{"2":{"624":1}}],["使得他们的偏差较小",{"2":{"622":1}}],["使得机器将部分噪音认为是特征从而扰乱了预设的分类规则",{"2":{"559":1}}],["使得该邻域内的所有点即所有满足",{"2":{"554":1}}],["使得随机梯度下降并不是每次迭代都向着整体最优化方向",{"2":{"545":1}}],["使得看起来就拟合残差合情合理",{"2":{"515":1}}],["使得学习出来的模型更加不容易过拟合",{"2":{"504":1}}],["使得模型更加鲁棒",{"2":{"492":1}}],["使得模型的解偏向于范数较小的",{"2":{"330":1}}],["使得$d",{"2":{"428":1}}],["使得主题表示更精准",{"2":{"422":1}}],["使得测试时bbox经过w运算后可以得到一个较好的平移量",{"2":{"372":1}}],["使得综合性能有较大提高",{"2":{"365":1}}],["使得激活函数的输入值落在激活函数对输入比较敏感的区域",{"2":{"351":1}}],["使得网络熟悉数据",{"2":{"346":1}}],["使得网络更稀疏",{"2":{"307":1}}],["使得目标函数或损失函数达到最小",{"2":{"340":1}}],["使得两个类别间的相对比例是显著的",{"2":{"336":1}}],["使得神经网络需要更长的时间才能收敛甚至无法收敛",{"2":{"323":1}}],["使得有效的信息流继续向后传递",{"2":{"318":1}}],["使得后面的卷积核能够学到更加全局的信息",{"2":{"313":1}}],["使得01出现的概率都是1",{"2":{"279":1}}],["使得它产生0和1的概率均为1",{"2":{"278":1}}],["使得核心线程有效时间",{"2":{"129":1}}],["使得图中任意一对顶点u和v",{"2":{"60":1}}],["使得范围",{"2":{"23":1}}],["使得这k个数的和等于目标数字",{"2":{"34":1}}],["使得这",{"2":{"15":1}}],["使得这个子矩阵内的所有元素之和最大",{"2":{"10":1}}],["使得里面的值全部为true",{"2":{"11":1}}],["使得每个子串都是回文",{"2":{"7":1}}],["使得序列中每一个较小的数都能整除较大的",{"2":{"3":1}}],["找兄弟节点",{"2":{"792":1}}],["找父节点",{"2":{"792":1}}],["找第一个子节点",{"2":{"792":1}}],["找key",{"2":{"752":1}}],["找一个映射",{"2":{"635":1}}],["找",{"2":{"79":1}}],["找出那个频率最大的ip",{"2":{"750":1}}],["找出每个小文件出现频率最大的ip",{"2":{"750":1}}],["找出最佳分裂点",{"2":{"470":1}}],["找出最长的子序",{"2":{"3":1}}],["找出毒药",{"0":{"269":1}}],["找出a和b的最近公共祖",{"2":{"92":1}}],["找出第k小的数�",{"2":{"48":1}}],["找出从start到end的最短转换序列",{"2":{"35":1}}],["找出两个不重叠的子数组a和b",{"2":{"18":1}}],["找出两个",{"2":{"18":1}}],["找出一个序列中乘积最大的连续子序列",{"2":{"14":1}}],["找出只含素因",{"2":{"8":1}}],["找到某个单词在文档中出现的地方",{"2":{"763":1}}],["找到第m个数字",{"2":{"763":1}}],["找到第一个不满足递增的数字删除",{"2":{"19":1}}],["找到左右孩子的最大",{"2":{"756":1}}],["找到使目标函数向全局最优值提升的参数",{"2":{"628":1}}],["找到基尼系数最小的组合",{"2":{"604":1}}],["找到分裂增益最大的一个叶子",{"2":{"466":1}}],["找到正确的对",{"2":{"423":1}}],["找到就绪的文件描述符",{"2":{"302":1}}],["找到等概率事件",{"2":{"278":1}}],["找到服务器",{"2":{"252":1}}],["找到这棵树最中最后一行中最左边的",{"2":{"93":1}}],["找到这两个数组合并排序后的中位数�",{"2":{"44":1}}],["找到其前序遍历的第k个结",{"2":{"88":1}}],["找到它的第一个不重复的字符",{"2":{"82":1}}],["找到链表的倒数第k个节",{"2":{"72":1}}],["找到最长连续序列路径的长度",{"2":{"94":1}}],["找到最长连续路径的长度",{"2":{"94":1}}],["找到最长公共前缀",{"2":{"74":1}}],["找到最长公共子序列",{"2":{"2":1}}],["找到最大顶点值",{"2":{"61":1}}],["找到插入的位置",{"2":{"55":1}}],["找到a和b",{"2":{"43":1}}],["找到所有可能的下标组合�",{"2":{"40":1}}],["找到一种数组与链表相结合的存储方法称为邻接表",{"2":{"57":1}}],["找到一组下标",{"2":{"40":1}}],["找到一个等概率事件",{"2":{"279":1}}],["找到一个主元素",{"2":{"42":1}}],["找到一个单词划",{"2":{"31":1}}],["找到一个具有最大和的子数组",{"2":{"18":1}}],["找到一个最大的正方形",{"2":{"11":1}}],["找到需要移除的最小区间数",{"2":{"20":1}}],["找到有效的方式把这些数相乘到一",{"2":{"6":1}}],["给属性提�",{"2":{"796":2}}],["给调用reduce函数的节点使用",{"2":{"769":1}}],["给大数据面试带来了很多困扰点",{"2":{"765":1}}],["给两种锚点分配一个正标签",{"2":{"371":1}}],["给第二次机会",{"2":{"299":1}}],["给你一根铅笔",{"2":{"274":1}}],["给你一个文件",{"2":{"763":1}}],["给你一个不均匀的骰子",{"2":{"279":1}}],["给你一个二叉树",{"2":{"95":1}}],["给你一个二维矩阵",{"2":{"11":1}}],["给你一个单链表",{"2":{"73":1}}],["给你一个数组",{"2":{"49":1}}],["给你一个数组arr",{"2":{"40":1}}],["给你一个无序数组",{"2":{"48":1}}],["给你一个每一行每一列都有序的二维数组",{"2":{"45":1}}],["给你一个证书数组",{"2":{"42":1}}],["给你一个n只猫",{"2":{"27":1}}],["给你一个矩阵序",{"2":{"6":1}}],["给客户端发一个警告",{"2":{"252":1}}],["给发送的每一个包进行编号",{"2":{"241":1}}],["给每一个缓存数据增加相应的缓存标记",{"2":{"188":1}}],["给个二叉",{"2":{"88":1}}],["给",{"2":{"80":1}}],["给一棵二叉树",{"2":{"94":1}}],["给一个字符串",{"2":{"37":1}}],["给一个布尔类型的二维数组",{"2":{"33":1}}],["给一字串s和单词的字典dict",{"2":{"31":1}}],["给出n个单词组成的熟词表",{"2":{"763":1}}],["给出n个数",{"2":{"21":1}}],["给出lr的损失函数",{"0":{"668":1}}],["给出一种解法",{"2":{"266":1}}],["给出一个二叉树",{"2":{"87":1}}],["给出一个二维的字母板和一个单词",{"2":{"36":1}}],["给出一个正整数数组nums和一个整数n",{"2":{"23":1}}],["给出二叉树的前序和中序遍",{"2":{"90":1}}],["给出二叉树的层次遍历",{"2":{"85":1}}],["给出",{"2":{"80":1}}],["给出三个字符",{"2":{"13":1}}],["给出两个单词",{"2":{"35":1}}],["给出两个单词word1和word2",{"2":{"5":1}}],["给出两个字符串",{"2":{"2":1}}],["给定n个互不相同的仅由一个单词构成的英文名",{"2":{"763":1}}],["给定n个不同的正整数",{"2":{"34":1}}],["给定a",{"2":{"747":1}}],["给定文本序列",{"2":{"690":3}}],["给定单个字符",{"2":{"690":1}}],["给定单个",{"2":{"690":1}}],["给定的各个样本数据分别属于两个类之一",{"2":{"634":1}}],["给定的观察值则为随机变",{"2":{"519":1}}],["给定划分特征",{"2":{"601":1}}],["给定m+个正例和m−个反",{"2":{"590":1}}],["给定初始训练数据",{"2":{"456":1}}],["给定两个节点a和b",{"2":{"92":1}}],["给定两个以字符串形式表示的非负整",{"2":{"83":1}}],["给定两个有序数组",{"2":{"44":1}}],["给定两个字母异位",{"2":{"32":1}}],["给定一棵二叉树",{"2":{"93":1,"94":1}}],["给定一组字符",{"2":{"81":1}}],["给定一些区间",{"2":{"20":1}}],["给定一个点",{"2":{"651":1}}],["给定一个超平面$",{"2":{"635":2}}],["给定一个样本数量为m的数据集",{"2":{"428":1}}],["给定一个字符串",{"2":{"76":1,"77":1,"78":1,"79":1,"82":1}}],["给定一个字符串s",{"2":{"38":1}}],["给定一个只包括",{"2":{"75":1}}],["给定一个链表",{"2":{"68":1}}],["给定一个排序链表",{"0":{"67":1}}],["给定一个无序的链表",{"2":{"66":1}}],["给定一个target",{"2":{"45":1}}],["给定一个目标值进行搜索",{"2":{"41":1}}],["给定一个可能具有重复数字的列表",{"2":{"30":1}}],["给定一个数字列表",{"2":{"29":1}}],["给定一个数组array和滑动的大小k",{"2":{"47":1}}],["给定一个数组a0",{"2":{"46":1}}],["给定一个数组",{"2":{"26":1}}],["给定一个以字符串表示的非负整数",{"2":{"19":1}}],["给定一个整数数组",{"2":{"18":3}}],["给定一个由整数组成二维矩阵",{"2":{"10":1}}],["给定一个矩",{"2":{"9":1}}],["给定一个n个正整数的数",{"2":{"3":1}}],["给定",{"2":{"15":1,"695":1}}],["给定字符",{"2":{"7":1}}],["3分钟的自我介绍框�",{"2":{"809":1}}],["3d",{"2":{"787":2}}],["3n",{"2":{"699":2}}],["3nn",{"2":{"699":1}}],["3nm",{"2":{"699":1}}],["3n+1个非负数",{"2":{"43":1}}],["3步骤直到簇中心坐标不再改变",{"2":{"675":1}}],["3个特征值对应的无缺失a特征的样本个数为2",{"2":{"601":1}}],["3x3",{"2":{"388":3}}],["3xx状态码",{"2":{"245":1}}],["3检测",{"2":{"385":1}}],["3=9",{"2":{"357":1}}],["3k个",{"2":{"357":2}}],["3的训练实例没有参与第k棵树的生成",{"2":{"483":1}}],["3的卷积核比一个较大尺寸的卷积核有更多层的非线性函数",{"2":{"347":1}}],["3的卷积核串联和5",{"2":{"347":1}}],["3的空洞卷积",{"2":{"306":1}}],["3卷积核的优势是什么",{"0":{"347":1}}],["39",{"0":{"342":1}}],["38200980",{"2":{"564":1}}],["38",{"0":{"341":1}}],["3750170",{"2":{"743":1}}],["37969519",{"2":{"725":1}}],["37096933",{"2":{"563":1}}],["37",{"0":{"340":1}}],["3长度的直尺",{"2":{"271":1}}],["33638791",{"2":{"414":1}}],["33",{"0":{"336":1},"2":{"217":1,"279":1}}],["33333",{"2":{"111":2}}],["346198300",{"2":{"414":2}}],["349807581",{"2":{"414":1}}],["34732244",{"2":{"253":1}}],["34",{"0":{"337":1},"2":{"211":2,"279":1}}],["36",{"0":{"339":1}}],["366972218",{"2":{"203":1}}],["360952172",{"2":{"414":1}}],["360",{"2":{"44":1,"54":1}}],["3�",{"2":{"139":1}}],["35",{"0":{"338":1},"2":{"81":1,"279":2}}],["31",{"0":{"334":1},"2":{"73":1,"279":1}}],["32保存特征值",{"2":{"514":1}}],["32来存储索",{"2":{"514":1}}],["32b",{"2":{"423":1}}],["32位机默认是1024",{"2":{"302":1}}],["32",{"0":{"335":1},"2":{"43":1,"279":1,"388":1}}],["30是1",{"2":{"664":1}}],["30作为一个区间",{"2":{"664":1}}],["30+",{"2":{"358":1}}],["302暂时重定向",{"2":{"245":1}}],["301",{"2":{"245":1}}],["3000",{"2":{"114":2,"217":1}}],["30x10",{"2":{"6":1}}],["30",{"0":{"333":1},"2":{"6":4,"469":2}}],["3",{"0":{"3":1,"20":1,"31":1,"42":1,"53":1,"60":1,"66":1,"76":1,"87":1,"122":1,"136":1,"154":1,"163":1,"180":1,"187":1,"219":1,"235":1,"251":1,"257":1,"269":1,"276":1,"290":1,"367":1,"380":1,"384":1,"387":1,"392":1,"401":1,"408":1,"429":1,"430":1,"431":1,"432":2,"433":1,"434":1,"435":1,"436":1,"437":1,"438":1,"439":1,"440":1,"441":1,"446":1,"455":1,"466":1,"477":1,"503":1,"533":1,"542":1,"560":1,"572":1,"599":1,"614":1,"636":1,"648":1,"656":1,"676":1,"722":1,"723":1,"724":1,"749":1,"780":1},"1":{"137":1,"138":1,"139":1,"188":1,"189":1,"190":1,"220":1,"221":1,"222":1,"223":1,"224":1,"291":1,"292":1,"385":1,"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1,"396":1,"397":1,"430":1,"431":1,"432":1,"433":1,"434":1,"435":1,"436":1,"437":1,"438":1,"439":1,"440":1,"441":1,"723":1,"724":1,"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1},"2":{"3":2,"8":4,"40":6,"41":2,"42":2,"43":1,"66":2,"67":2,"75":1,"78":5,"80":1,"81":2,"83":4,"86":2,"89":1,"90":3,"91":4,"94":12,"95":2,"111":1,"114":2,"211":4,"215":2,"222":2,"243":1,"252":1,"255":1,"256":1,"268":1,"269":2,"270":1,"275":1,"277":16,"279":4,"280":2,"282":1,"357":17,"367":3,"368":2,"369":1,"371":1,"385":1,"388":1,"390":2,"393":1,"397":2,"414":1,"422":1,"423":2,"472":2,"496":1,"497":2,"519":1,"522":1,"529":1,"544":1,"545":1,"555":1,"570":1,"582":1,"601":2,"612":2,"651":1,"654":1,"699":1,"730":4,"759":1,"778":1,"782":1,"784":3,"785":1,"786":1,"834":1}}],["svd相对于svd有哪些优势",{"2":{"731":1}}],["svd",{"2":{"729":1,"730":4,"731":1}}],["svm能做的lr有的做不了",{"2":{"672":1}}],["svm能做",{"2":{"672":1}}],["svm采用的是hinge",{"2":{"672":1}}],["svm采用的是合页损失函数",{"2":{"641":1}}],["svm如何处理多分类问题",{"0":{"643":1}}],["svm是一种二类分类模型",{"2":{"642":1}}],["svm是非参数模型",{"2":{"641":1,"672":1}}],["svm转化为对偶问题后",{"2":{"641":1,"672":1}}],["svm基本思想",{"2":{"635":1}}],["svm的处理方法是只考虑support",{"2":{"672":1}}],["svm的处理方法是只考虑支持向量点",{"2":{"641":1}}],["svm的原理是什么",{"0":{"642":1}}],["svm的效果和支持向量点有关",{"2":{"639":1}}],["svm的直观目的就是找到最小函数距离的样本点",{"2":{"634":1}}],["svm的要求",{"2":{"634":1}}],["svm直观解释",{"0":{"634":1}}],["svm面试题",{"0":{"633":1},"1":{"634":1,"635":1,"636":1,"637":1,"638":1,"639":1,"640":1,"641":1,"642":1,"643":1,"644":1}}],["svm",{"0":{"636":1,"637":1,"638":1,"640":1},"2":{"366":1,"453":1,"634":2,"639":1,"640":3}}],["svm支持向量机",{"2":{"331":1}}],["ssbk−1sswn−k",{"2":{"684":1}}],["ssb",{"2":{"684":1}}],["sswk",{"2":{"684":1}}],["ssw",{"2":{"684":1}}],["sse",{"2":{"682":1}}],["ssd对小目标的检测效果一般",{"2":{"385":1}}],["ssd主要缺点",{"2":{"385":1}}],["ssd有什么致命缺点",{"2":{"385":1}}],["ssd的优点是运行速度超过yolo",{"2":{"385":1}}],["ssd的核心是对固定设置的default",{"2":{"385":1}}],["ssd网络的特点是对不同尺度下的feature",{"2":{"385":1}}],["s可以把它看成是一个概率值",{"2":{"659":1}}],["s值",{"2":{"592":1}}],["sdg",{"2":{"545":1}}],["sj−m−∑ℓ",{"2":{"532":1}}],["sklearn中的adaboost接口给出的是使用决策树作为基分类器",{"2":{"438":1}}],["skip",{"0":{"722":1},"1":{"723":1,"724":1},"2":{"186":1,"725":1}}],["skiplist",{"2":{"186":1,"203":1}}],["sft",{"2":{"423":6}}],["sfcs",{"2":{"36":1}}],["sqrt",{"2":{"730":3}}],["square",{"2":{"740":1}}],["squares",{"2":{"684":2}}],["squared",{"2":{"581":1,"682":1}}],["squeeze",{"2":{"397":1}}],["sql基础",{"2":{"264":1}}],["sql",{"0":{"163":1,"164":1},"2":{"163":4,"258":1}}],["s表复数",{"2":{"394":1}}],["s小写",{"2":{"394":1}}],["smirnov",{"0":{"592":1}}],["smooth",{"2":{"372":1}}],["smoothl1",{"2":{"372":1}}],["smooththl1",{"2":{"367":1}}],["smote",{"2":{"336":1}}],["smss",{"2":{"243":1}}],["shuffle操作的hash函数真的很重要",{"2":{"770":1}}],["shuffle就是打乱数据",{"2":{"769":1}}],["shuffle",{"2":{"769":1}}],["shufflenet等",{"2":{"320":1}}],["shenxiaolin",{"2":{"595":1}}],["short",{"2":{"690":2}}],["show",{"2":{"593":1,"796":2}}],["shot",{"2":{"422":3,"423":1}}],["shrinkage",{"2":{"507":1,"513":1}}],["shift",{"2":{"220":1}}],["sandwichnlp",{"2":{"725":1}}],["samples",{"2":{"484":3}}],["sampling通过随机负采样来提升运算效率",{"2":{"725":1}}],["sampling对比",{"2":{"725":1}}],["sampling两种策略进行优化",{"2":{"718":1}}],["sampling",{"0":{"721":1,"724":1},"2":{"312":1,"422":1,"464":1,"495":1,"725":3}}],["safe",{"2":{"173":1}}],["sgd的区别在于",{"2":{"546":1}}],["sgd",{"2":{"308":1,"546":2}}],["science",{"2":{"686":1}}],["scutan90",{"2":{"556":1}}],["schema",{"2":{"422":1}}],["scale3d",{"2":{"787":1}}],["scale",{"2":{"509":1,"533":3,"536":1,"537":3}}],["scale思想的应用",{"2":{"402":1}}],["scales",{"2":{"367":1,"372":2}}],["scavenge",{"2":{"110":2}}],["score越大",{"2":{"583":1}}],["scores",{"2":{"397":2}}],["scores维度为",{"2":{"397":1}}],["score",{"0":{"583":1,"589":1},"2":{"306":1,"422":1,"583":1,"589":1}}],["script>",{"2":{"796":2}}],["scr中需要将页面在链表中移动",{"2":{"299":1}}],["scr",{"2":{"299":1}}],["s=",{"2":{"274":1}}],["s=1",{"2":{"274":1}}],["s=target",{"2":{"15":1}}],["syn报文是用来同步的",{"2":{"239":1}}],["syn",{"2":{"237":1}}],["synchronized",{"0":{"136":1},"1":{"137":1,"138":1,"139":1},"2":{"136":4,"139":6,"140":5,"144":1}}],["symbol",{"2":{"210":1}}],["slope太小",{"2":{"663":1}}],["slot",{"2":{"422":1}}],["slow就是倒数第k个节",{"2":{"72":1}}],["slow",{"2":{"65":4,"68":7,"243":1}}],["slice",{"2":{"220":1}}],["slave",{"2":{"185":2,"194":2}}],["slave端重放binlog从而达到主从数据一�",{"2":{"172":1}}],["swin",{"2":{"399":1}}],["sweep",{"2":{"110":3}}],["swap",{"2":{"29":2,"32":1,"44":1,"48":2,"49":1,"51":3,"52":2,"77":1,"134":1,"756":2,"757":2}}],["sb",{"2":{"83":3}}],["sn",{"2":{"74":6}}],["span>�",{"2":{"774":1}}],["spark",{"2":{"767":1}}],["sparsity",{"2":{"725":1}}],["sping",{"0":{"178":1}}],["spring",{"0":{"175":1,"179":1},"1":{"176":1,"177":1,"178":1,"179":1,"180":1}}],["splice",{"2":{"111":1,"220":1}}],["splits",{"2":{"769":1}}],["splitstring",{"2":{"37":1}}],["split",{"2":{"56":2,"484":3}}],["sptset",{"2":{"58":11,"59":1}}],["situation",{"2":{"829":1}}],["sibling",{"2":{"792":1}}],["sina",{"2":{"522":1,"671":1}}],["singleton",{"2":{"144":6}}],["singlenumberpp",{"2":{"43":1}}],["singlenumberp",{"2":{"43":1}}],["singlenumber",{"2":{"43":1}}],["side",{"2":{"464":1,"495":1}}],["sigma",{"2":{"730":1}}],["sigmoid也让逻辑回归的损失函数成为凸函数",{"2":{"670":1}}],["sigmoid是连续光滑的",{"2":{"670":1}}],["sigmoid",{"2":{"394":1,"532":1}}],["sigmoid的导数只有在0的附近时有较好的激活性",{"2":{"350":1}}],["sigmoid函数取值范围为",{"2":{"660":1}}],["sigmoid函数的形式",{"2":{"532":1}}],["sigmoid函数存在饱和区",{"2":{"328":1}}],["sigmoid函数",{"2":{"319":1}}],["sign",{"2":{"635":4}}],["sigio",{"2":{"302":1}}],["simhash",{"2":{"754":1,"768":1}}],["simjaccard",{"2":{"730":1}}],["sim",{"2":{"729":1,"730":3}}],["simple",{"2":{"558":1}}],["simain",{"2":{"271":1}}],["similarity",{"2":{"730":1}}],["similar",{"0":{"32":1}}],["si",{"2":{"74":2}}],["size的设置一定要合适",{"2":{"403":1}}],["size和长宽比",{"2":{"385":1}}],["size对训练效果的影响",{"2":{"333":1}}],["size设置每个binlog文件的大小�",{"2":{"173":1}}],["sizeof",{"2":{"1":1,"4":1,"10":1,"22":2,"59":2}}],["size",{"0":{"695":1},"2":{"1":2,"2":6,"4":1,"5":8,"9":2,"11":4,"13":9,"14":1,"15":1,"18":1,"19":2,"20":1,"21":2,"23":1,"24":1,"25":1,"27":2,"29":2,"30":1,"31":3,"32":2,"33":4,"34":1,"35":4,"36":8,"37":3,"40":2,"41":1,"44":6,"45":6,"46":3,"47":1,"49":1,"54":3,"58":4,"59":3,"60":1,"61":2,"74":4,"76":1,"77":6,"78":4,"79":1,"81":2,"82":4,"85":1,"86":1,"92":2,"333":3,"385":1,"390":2,"423":1,"689":6}}],["seo",{"2":{"775":1}}],["sepp",{"2":{"690":1}}],["seq",{"2":{"689":1}}],["seasonality",{"2":{"537":1}}],["searchmatrixp",{"2":{"45":1}}],["searchmatrix",{"2":{"45":1}}],["search",{"0":{"28":1},"1":{"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1},"2":{"365":1,"366":2,"376":1}}],["semi",{"2":{"521":1}}],["sentence",{"2":{"423":1,"689":1}}],["section",{"2":{"776":3}}],["section>",{"2":{"775":1}}],["sections数量与输出的维度相同",{"2":{"368":1}}],["second的缩写",{"2":{"394":1}}],["second",{"2":{"94":4}}],["segmentfault",{"2":{"253":1}}],["services",{"2":{"258":1}}],["server服务器返回ip地址给本地服务器",{"2":{"249":1}}],["server服务器",{"2":{"249":1}}],["serializable�",{"2":{"170":1}}],["session",{"2":{"244":10}}],["session与cookie",{"0":{"244":1}}],["selective",{"2":{"365":1,"366":2}}],["select函数返回后",{"2":{"302":1}}],["selectanalyze",{"2":{"284":1}}],["select",{"2":{"163":1,"272":1,"302":1}}],["self",{"2":{"64":1,"66":4,"67":5,"68":1,"69":12,"70":11,"71":4,"72":1,"73":1,"390":1,"397":1,"702":1}}],["sellold",{"2":{"26":2}}],["sell",{"2":{"26":9}}],["setter",{"2":{"796":2}}],["settimeout",{"2":{"217":7}}],["setstate",{"0":{"793":1},"2":{"792":1,"793":5}}],["set中",{"2":{"747":2}}],["setfit",{"2":{"423":2}}],["setnc",{"2":{"184":1}}],["set",{"2":{"31":1,"32":1,"35":1,"58":2,"59":2,"796":3}}],["source",{"2":{"776":1}}],["sourcegraph",{"2":{"203":1}}],["so|is",{"2":{"722":1}}],["so|nlp",{"2":{"722":1}}],["so",{"2":{"719":8,"722":1}}],["sofmax",{"2":{"725":1}}],["sofasofa",{"2":{"670":1}}],["softmax的模型使用huffman树代替了传统的线性神经网络",{"2":{"721":1}}],["softmax与negative",{"2":{"718":1}}],["softmax损失",{"2":{"423":1}}],["softmax",{"0":{"720":1,"723":1},"2":{"422":4,"423":1,"472":2,"703":2,"725":5}}],["softmax+cross",{"0":{"344":1}}],["sogou",{"2":{"567":1}}],["social",{"2":{"258":1}}],["some",{"2":{"220":1}}],["solve",{"2":{"27":1}}],["solution2",{"2":{"69":1}}],["solution",{"2":{"26":1,"64":1,"66":1,"67":1,"68":1,"69":1,"71":1,"72":1,"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1,"90":1,"94":1,"96":1}}],["sorted",{"2":{"55":9}}],["sort",{"0":{"50":1},"1":{"51":1,"52":1,"53":1,"54":1,"55":1,"56":1},"2":{"3":1,"20":1,"23":1,"30":1,"220":1,"397":1,"758":2,"759":1,"760":3,"769":1}}],["support",{"2":{"634":1}}],["suppression就需要执行n次",{"2":{"397":1}}],["suppression一次处理一个类别",{"2":{"397":1}}],["suppression",{"0":{"397":1}}],["supervised",{"2":{"423":1}}],["sunflower627",{"2":{"284":1}}],["subsampling",{"2":{"497":1}}],["subscribe",{"2":{"111":4}}],["substr",{"2":{"31":2,"37":3,"74":1,"77":2}}],["subsets",{"2":{"22":23,"59":23}}],["subset",{"2":{"22":6,"59":6}}],["sub",{"2":{"30":6}}],["sum还是avg",{"2":{"394":1}}],["sum>res",{"2":{"10":1}}],["sum=0",{"2":{"10":1}}],["sum=maxsum",{"2":{"10":1}}],["sum=ma",{"2":{"10":2}}],["sum",{"0":{"40":1},"2":{"10":2,"18":1,"25":3,"635":7,"682":1,"684":2,"725":1,"730":3,"735":2,"763":3}}],["src",{"2":{"22":2,"58":2,"59":5,"800":1}}],["style",{"2":{"786":1}}],["style=",{"2":{"390":1}}],["sts",{"2":{"423":1}}],["stsb",{"2":{"423":2}}],["stoppropagation",{"2":{"779":1}}],["stopping",{"2":{"325":1,"354":1,"561":1}}],["stock",{"2":{"26":1}}],["student",{"2":{"163":2}}],["star法则",{"0":{"829":1}}],["start|",{"2":{"422":2}}],["start=ii+1",{"2":{"77":1}}],["start=0",{"2":{"77":1}}],["start+end",{"2":{"53":1}}],["start+1",{"2":{"51":1,"53":1,"78":1}}],["start>=end",{"2":{"51":1,"53":1}}],["start和end",{"2":{"35":1}}],["start",{"2":{"20":4,"32":2,"35":3,"51":7,"53":5,"61":5,"77":4,"78":4,"243":1,"782":2}}],["statistical",{"2":{"527":1,"690":1}}],["static",{"2":{"51":1,"88":1,"144":2}}],["stateobject",{"2":{"798":3}}],["state",{"2":{"497":1,"793":8}}],["stage的异同",{"0":{"406":1}}],["stage的含义",{"0":{"367":1}}],["stage和one",{"0":{"406":1}}],["stage方法中的iou阈值",{"2":{"401":1}}],["stage方法相比",{"2":{"378":1}}],["stage检测器准确率不高的问题原因进行探究",{"2":{"387":1}}],["stage目标检测算法",{"2":{"378":1}}],["stage",{"0":{"367":1},"2":{"365":1,"367":1,"378":1}}],["standardization",{"2":{"305":1}}],["sta",{"2":{"85":7,"86":5}}],["stacking中的",{"2":{"503":1}}],["stacking常见的使用方式",{"2":{"458":1}}],["stacking",{"2":{"458":1}}],["stacking三种",{"2":{"454":1}}],["stack",{"2":{"75":1,"85":1,"86":1,"792":1}}],["step3",{"2":{"759":1}}],["step为一个有限数字来帮助收敛",{"2":{"509":1}}],["step解答",{"2":{"423":1}}],["step+1",{"2":{"32":1}}],["step",{"2":{"32":5,"422":3,"423":4,"759":2}}],["stretch",{"2":{"782":1}}],["strong>",{"2":{"775":1}}],["strong>�",{"2":{"774":1}}],["stride",{"2":{"388":3,"695":1}}],["stride=2",{"2":{"388":2}}],["stringify",{"2":{"223":1}}],["stringbuffer",{"0":{"121":1},"2":{"121":1}}],["stringbuilder",{"0":{"121":1},"2":{"83":2,"121":1}}],["stringfoo",{"2":{"112":1}}],["strings",{"0":{"32":1}}],["string>>",{"2":{"37":3}}],["string>",{"2":{"31":2,"32":1,"35":2,"37":2,"38":3,"74":1,"80":4}}],["string",{"0":{"121":1,"224":1},"2":{"2":2,"5":2,"7":1,"13":3,"19":2,"31":3,"32":5,"35":3,"36":2,"37":2,"38":3,"74":2,"75":1,"76":1,"77":8,"78":2,"79":3,"80":3,"81":1,"82":2,"83":3,"121":1,"210":2,"211":2,"224":3,"769":3}}],["strs",{"2":{"74":4}}],["str",{"2":{"32":8,"38":9,"77":1}}],["structured",{"2":{"519":1}}],["structure",{"2":{"62":1,"96":1}}],["struct",{"2":{"22":18,"32":1,"55":2,"59":17,"82":1,"85":5,"86":1,"88":1,"91":3,"95":1,"762":2}}],["s>=a",{"2":{"15":1}}],["s3",{"2":{"13":9,"74":1}}],["s2",{"2":{"13":11,"74":1}}],["s1",{"2":{"13":11,"74":8,"79":2}}],["s",{"2":{"7":11,"10":6,"15":6,"18":6,"31":7,"32":5,"36":2,"37":15,"38":5,"61":2,"75":2,"76":7,"77":24,"78":6,"79":8,"82":19,"414":2,"473":1,"517":1,"522":1,"535":1,"556":1,"635":1,"651":1,"660":1,"671":1,"695":1}}],["+m对应的是中位数的下标",{"2":{"763":1}}],["+η∑u∈pos",{"2":{"721":1}}],["+ηαmgm",{"2":{"434":1}}],["+v→",{"2":{"718":1}}],["+variance$",{"2":{"622":1}}],["+γf∗c",{"2":{"697":1}}],["+θnxn=θtx其中θ",{"2":{"655":1}}],["+θnxn损失函数为",{"2":{"545":1}}],["+bo",{"2":{"697":1}}],["+bf",{"2":{"697":1}}],["+bu",{"2":{"697":1}}],["+bc",{"2":{"697":1}}],["+b^",{"2":{"635":3}}],["+b",{"2":{"635":1}}],["+bnsin⁡",{"2":{"535":1}}],["+∇2f",{"2":{"555":2}}],["+∇f",{"2":{"555":1}}],["+o",{"2":{"555":1}}],["+ϵt",{"2":{"531":1}}],["+h",{"2":{"531":1}}],["+∑j1=1d∑j2=j1+1d",{"2":{"735":1}}],["+∑u∈neg",{"2":{"721":1}}],["+∑i=1nαis",{"2":{"635":1}}],["+∑i=1nαi",{"2":{"635":1}}],["+∑i=1tω",{"2":{"496":1}}],["+∑k∑i=1nμksk",{"2":{"519":1}}],["+w⋅fi",{"2":{"519":2}}],["+∂l",{"2":{"497":2}}],["+λ",{"2":{"729":1,"730":1}}],["+λt求上式最小化的参数",{"2":{"496":1}}],["+λt+12∑i=1tωj2",{"2":{"496":1}}],["+λt+12∑j=1tωj2",{"2":{"496":2}}],["+λ1nreg∑ipi∗lreg",{"2":{"367":1}}],["+gift",{"2":{"496":1}}],["+graph",{"2":{"58":2}}],["+constant",{"2":{"496":1}}],["+ω",{"2":{"496":3}}],["+βmb",{"2":{"496":2,"497":1}}],["+e−α∑i=1nw^mi将已经求得的gm∗",{"2":{"430":1}}],["+αg",{"2":{"430":1}}],["+αmgm",{"2":{"430":1}}],["+ft",{"2":{"496":1}}],["+focallossretinanet由backbone网络和两个子任务网络组成",{"2":{"387":1}}],["+foo",{"2":{"112":1}}],["+f",{"2":{"369":3,"496":4}}],["+y−y1y2−y1f",{"2":{"369":1}}],["+x−x1x2−x1f",{"2":{"369":2}}],["++cnt",{"2":{"33":1}}],["++itr",{"2":{"89":1}}],["++it",{"2":{"89":1}}],["++i",{"2":{"33":1,"38":1,"51":2,"79":1,"83":1,"757":3}}],["++j",{"2":{"31":1,"33":1}}],["++v",{"2":{"22":1,"59":1}}],["++",{"2":{"18":1,"19":1,"20":2,"21":1,"23":1,"24":1,"27":1,"31":1,"32":2,"35":1,"36":3,"40":4,"42":7,"43":6,"45":3,"46":1,"47":2,"49":2,"54":4,"56":1,"58":5,"59":3,"60":1,"61":1,"78":4,"82":1,"85":1,"86":2}}],["+=",{"2":{"15":2,"18":1,"21":1,"23":1,"25":1,"31":1,"43":1,"73":1,"83":2,"769":1}}],["+=a",{"2":{"10":1}}],["+s",{"2":{"10":1,"531":1}}],["+a|t|ht",{"2":{"602":1}}],["+areas",{"2":{"397":1}}],["+a",{"2":{"9":1}}],["+p",{"2":{"6":1}}],["+dp",{"2":{"6":1}}],["+",{"2":{"2":1,"5":1,"6":4,"7":10,"9":3,"11":2,"12":3,"13":3,"19":1,"21":2,"25":1,"26":2,"30":1,"31":1,"32":1,"37":1,"38":1,"40":1,"41":3,"44":8,"45":2,"52":1,"58":5,"61":2,"77":1,"82":2,"94":10,"188":1,"217":6,"218":2,"274":4,"282":1,"317":1,"357":3,"395":1,"422":4,"423":1,"495":1,"512":2,"547":1,"603":1,"632":2,"635":1,"657":2,"661":1,"670":1,"721":2,"756":3,"760":2,"793":4}}],["+12",{"2":{"555":1}}],["+12hift2",{"2":{"496":4}}],["+1n",{"2":{"496":1}}],["+1",{"0":{"668":1},"2":{"1":2,"2":3,"3":2,"5":3,"87":1,"131":1,"428":2,"635":1,"668":1,"730":1,"735":1}}],["bfc",{"0":{"784":1},"2":{"784":5}}],["bfs的应用场景",{"2":{"104":1}}],["bfs",{"2":{"28":1,"100":1}}],["b0",{"2":{"747":1}}],["b999",{"2":{"747":2}}],["b文件共同的url",{"2":{"747":1}}],["b两个文件",{"2":{"747":1}}],["b分成训练",{"2":{"741":1}}],["b用来训练lr",{"2":{"741":1}}],["b都有评价的items集合",{"2":{"729":1}}],["b^",{"2":{"635":5}}],["b∗=yj−∑i=1nαi∗yi",{"2":{"635":2}}],["b∗",{"2":{"635":6}}],["bmaxαi≥0l",{"2":{"635":1}}],["bθα",{"2":{"635":2}}],["bγ^∥w∥s",{"2":{"635":1}}],["bγs",{"2":{"635":1}}],["bdg",{"2":{"545":1}}],["b特征的原始取值为区间",{"2":{"469":1}}],["by树",{"2":{"507":1}}],["by",{"2":{"423":1,"730":2}}],["bl",{"2":{"635":3}}],["blip",{"2":{"423":2}}],["block结构支持并行化",{"2":{"511":1}}],["block按列进行解压缩",{"2":{"506":1}}],["block预先放入内存",{"2":{"506":1}}],["block",{"2":{"422":1,"423":1,"506":1,"784":1}}],["blob",{"2":{"203":1}}],["blog",{"2":{"203":1,"259":1,"272":1,"284":2,"303":1,"414":6,"473":2,"499":2,"517":2,"522":2,"558":1,"568":1,"644":1,"652":5,"664":1,"665":1,"671":2,"686":1,"725":1,"743":2,"753":2}}],["b40pdgb7o95jmpmeiicbuq",{"2":{"414":1}}],["bp",{"2":{"340":1}}],["bgd",{"2":{"308":1,"546":2}}],["bn和dropout单独使用都能减少过拟合并加速训练速度",{"2":{"567":1}}],["bn和dropout共同使用时会出现的问题",{"0":{"567":1}}],["bn",{"2":{"307":1,"314":1}}],["b|c¯",{"2":{"282":1}}],["b|c",{"2":{"282":2}}],["b是2和4",{"2":{"267":1}}],["b说他也知道了",{"2":{"267":1}}],["b就可以直接知道自己的是2",{"2":{"267":1}}],["b就会离开",{"2":{"27":1}}],["b看到x后",{"2":{"267":1}}],["b头上的数字是y",{"2":{"267":1}}],["b头上的字是多少",{"2":{"267":1}}],["b却比a更早更新了缓存",{"2":{"196":1}}],["b返回的条目比较少",{"2":{"168":1}}],["b树",{"2":{"167":1,"754":1,"768":1}}],["b+",{"2":{"167":4}}],["b所有祖",{"2":{"92":1}}],["bi=1|ui|∑u∈ui",{"2":{"730":1}}],["bi为item",{"2":{"729":1}}],["bigdata",{"2":{"743":1}}],["big",{"2":{"658":1}}],["bigint�",{"2":{"210":1}}],["biginteger",{"2":{"83":1}}],["bi",{"2":{"521":2,"522":1,"708":1}}],["bias反映的是模型在样本上的输出与真实值之间的误差",{"2":{"622":1}}],["bias",{"2":{"422":1,"558":1,"699":1}}],["bins",{"2":{"497":1}}],["bin",{"2":{"471":1,"651":2}}],["binlog适用于主从复制和数据恢复",{"2":{"173":1}}],["binlog日志",{"2":{"173":1}}],["binlog是server层实现的",{"2":{"173":1}}],["binlog是mysql的逻辑日志",{"2":{"172":1}}],["binlog可通过配置参数max",{"2":{"173":1}}],["binlog用于记录数据库执行的写入性操�",{"2":{"172":1}}],["binlog",{"0":{"171":1,"172":1},"1":{"172":1,"173":1,"174":1},"2":{"173":3}}],["binary",{"0":{"84":1},"1":{"85":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"92":1,"93":1,"94":1,"95":1,"96":1},"2":{"84":1,"89":1,"96":2}}],["bit",{"2":{"759":3}}],["bitmap",{"2":{"189":2,"751":1}}],["bitmul",{"2":{"83":4}}],["bits",{"2":{"43":3}}],["b2",{"2":{"81":1}}],["bbf的算",{"2":{"651":1}}],["bbf",{"2":{"651":1}}],["bboxes",{"2":{"397":5}}],["bboxes维度为",{"2":{"397":1}}],["bbox的iou高的那个最为最后的检测框",{"2":{"378":1}}],["bbox",{"2":{"366":1,"389":2}}],["bbb",{"2":{"214":2}}],["bbbbbbbbbbbb",{"2":{"81":1}}],["bbbbb",{"2":{"78":1}}],["bb",{"2":{"79":1,"81":1}}],["baseline",{"2":{"782":1}}],["based同理",{"2":{"727":1}}],["based",{"2":{"361":1,"464":1,"495":1,"651":1,"707":1,"710":1,"713":3,"727":3,"729":1}}],["ball",{"2":{"684":1}}],["balanced",{"2":{"186":1,"370":1}}],["baum",{"2":{"527":1}}],["bayesian",{"2":{"521":1,"614":1}}],["bagging在选择划分属性时要对每棵树是对所有特征进行考察",{"2":{"481":1}}],["bagging使用的是确定型决策树",{"2":{"481":1}}],["bagging的主要好处是集成后的分类器的方差",{"2":{"461":1}}],["bagging算法把数据集分成重复随机取样形成的子集",{"2":{"459":1}}],["bagging",{"2":{"455":1,"503":1}}],["bagging相当于bagging与单分类器的折中",{"2":{"439":1}}],["bagging相比bagging会降低误差",{"2":{"439":1}}],["bagging将bagging作为adaboost的基学习器",{"0":{"439":1}}],["bath",{"2":{"333":1}}],["batch的提前过拟合现象",{"2":{"346":1}}],["batch",{"0":{"351":1},"2":{"307":1,"333":2,"367":1,"545":1,"546":3,"689":1,"698":1}}],["baijiahao",{"2":{"414":1}}],["baidu",{"2":{"259":1,"414":1,"595":2}}],["baike",{"2":{"259":1,"595":2}}],["bad",{"2":{"245":1,"592":1}}],["baddream",{"2":{"217":2}}],["bar+",{"2":{"112":1}}],["bab",{"2":{"79":1}}],["babad",{"2":{"79":1}}],["background",{"2":{"786":1}}],["backbone网络负责计算feature",{"2":{"387":1}}],["backbone用于特征提取",{"2":{"362":1}}],["backbone",{"2":{"362":1}}],["back",{"2":{"29":1,"30":3,"31":3,"34":3,"37":7,"38":2,"40":3,"47":8,"54":2,"60":1,"61":1,"86":2,"89":1,"92":2,"95":1}}],["backpack",{"2":{"4":1}}],["bundle",{"2":{"800":2}}],["bundles",{"2":{"800":1}}],["bundling",{"2":{"464":1,"468":1,"495":1}}],["buckets",{"2":{"758":4,"763":1}}],["bucket",{"2":{"758":1}}],["bu=1|iu|∑i∈iu",{"2":{"730":1}}],["bu为user",{"2":{"729":1}}],["buffer",{"2":{"173":2}}],["buildtree",{"2":{"90":1}}],["buildtreerecur",{"2":{"90":4}}],["buildmaxheap",{"2":{"52":2,"756":2}}],["buy",{"2":{"26":5}}],["both",{"2":{"785":1}}],["boldsymbol",{"2":{"536":1}}],["boosted",{"2":{"739":1}}],["boost就是通过每次迭代的时候构建一个沿梯度下降最快的方向的学习器",{"2":{"480":1}}],["boosting思想",{"2":{"505":1}}],["boosting思想的数学表达式是什么",{"0":{"457":1}}],["boosting$思想",{"2":{"501":1}}],["boosting算法",{"2":{"497":1}}],["boosting算法的优化",{"2":{"449":1}}],["boosting不是一种串行的结构",{"2":{"497":2,"513":1}}],["boosting",{"2":{"454":1,"456":1,"464":1,"495":1,"497":1,"503":1}}],["boosting是主要是通过降低模型的偏差来降低模型的误差",{"2":{"432":1}}],["boosting和bagging之间的区别",{"0":{"432":1}}],["boolean",{"2":{"139":1,"210":2,"211":2}}],["bool",{"2":{"13":1,"20":1,"36":3,"45":1,"51":3,"53":2,"75":1,"76":2,"87":1,"91":2,"92":1}}],["bool>",{"2":{"7":1}}],["bool>>",{"2":{"7":1,"11":1}}],["bought",{"2":{"730":2}}],["bounding",{"2":{"365":1,"378":1}}],["bouding",{"2":{"360":1}}],["box2",{"2":{"390":8}}],["box2维度为",{"2":{"390":1}}],["box1",{"2":{"390":8}}],["box个数相关",{"2":{"385":1}}],["box进行分类和边框回归的操作",{"2":{"385":1}}],["box有不同的大小和横纵比例",{"2":{"385":1}}],["box类完全一样",{"2":{"381":1}}],["box类与之前所属的anchor",{"2":{"381":1}}],["box其所属的anchor",{"2":{"381":1}}],["box新的尺寸",{"2":{"381":1}}],["box中的那些bounding",{"2":{"381":1}}],["box属于它",{"2":{"381":1}}],["box都有哪些bounding",{"2":{"381":1}}],["box更新",{"2":{"381":1}}],["box对于每个anchor",{"2":{"381":2}}],["box与每个anchor",{"2":{"381":1}}],["box与anchor",{"2":{"367":2}}],["box坐标提取出来",{"2":{"381":1}}],["boxes精确度",{"2":{"381":1}}],["boxes中随机选取k个值作为k个anchor",{"2":{"381":1}}],["boxes过程详解",{"0":{"381":1}}],["boxes的width和height都是相对于整张图片的比例",{"2":{"382":1}}],["boxes的width和height即可",{"2":{"380":1}}],["boxes的初始值",{"2":{"381":1}}],["boxes的宽高数据",{"2":{"381":1}}],["boxes的位置被每个栅格固定",{"2":{"380":1}}],["boxes",{"0":{"380":1}}],["box的基础大小和形状不能直接通过学习获得",{"2":{"385":1}}],["box的大小",{"2":{"383":1}}],["box的分类已经不再更新",{"2":{"381":1}}],["box的宽高的中值大小",{"2":{"381":1}}],["box的误差为",{"2":{"381":1}}],["box的误差dn∗k",{"2":{"381":1}}],["box的iou值",{"2":{"381":1}}],["box的思想",{"2":{"378":1}}],["box的位置和所属的类别",{"2":{"378":1}}],["box将分类与目标定位的回归问题结合起来",{"2":{"378":1}}],["box尺寸的选择主要有三种方式",{"2":{"367":1}}],["box是怎么选取的",{"2":{"367":1}}],["box之间的转化关系",{"2":{"367":2}}],["box",{"2":{"360":1,"365":1,"367":5,"372":2,"378":1,"381":4,"385":4,"784":3}}],["body>",{"2":{"796":2}}],["body",{"2":{"229":2}}],["bom",{"0":{"225":1},"1":{"226":1,"227":1,"228":1,"229":1}}],["board",{"2":{"36":21}}],["break",{"0":{"31":1},"2":{"32":1,"40":1,"41":1,"43":1,"44":1,"49":1,"51":1,"70":1,"75":3,"78":1,"397":2,"757":1}}],["beis和david",{"2":{"651":1}}],["bengio发现",{"2":{"718":1}}],["benefits",{"2":{"590":1}}],["benchmark",{"2":{"423":1}}],["bert缺点",{"0":{"714":1}}],["bertopic",{"2":{"422":1}}],["bert",{"0":{"712":1},"1":{"713":1,"714":1},"2":{"422":5,"423":5,"714":1,"716":1}}],["bert类",{"2":{"422":1}}],["between",{"2":{"318":1,"684":1}}],["bean",{"0":{"180":1}}],["best",{"2":{"26":1,"558":1,"651":2}}],["begin",{"2":{"19":3,"20":1,"23":1,"30":1,"54":1,"60":2,"69":4,"89":2,"90":2,"635":1}}],["b1∥w∥s",{"2":{"635":1}}],["b12∥w∥2s",{"2":{"635":1}}],["b12",{"2":{"81":1}}],["b1",{"2":{"22":2,"59":2,"747":2}}],["b合并",{"2":{"21":1}}],["bcc",{"2":{"38":1}}],["bc",{"2":{"6":1}}],["b",{"2":{"2":5,"5":2,"6":1,"7":1,"12":7,"18":1,"20":2,"21":3,"22":2,"27":4,"32":10,"36":2,"38":2,"43":4,"44":11,"51":2,"59":2,"78":1,"81":16,"92":8,"134":3,"163":1,"167":3,"213":5,"214":2,"220":3,"250":1,"267":2,"270":2,"280":1,"306":1,"308":1,"312":1,"313":1,"422":2,"423":4,"496":3,"545":3,"571":1,"635":16,"660":1,"699":1,"729":1,"741":1,"761":2}}],["2年的职业发展计划",{"2":{"810":1}}],["2位的正整数",{"2":{"763":1}}],["2向前维护每一个节点的性质",{"2":{"756":1}}],["2bit",{"2":{"751":1}}],["2g左右的机器",{"2":{"748":1}}],["2−∑i=1nvi",{"2":{"735":1}}],["2阶",{"2":{"735":1}}],["2皮尔森系数跟修正的余弦相似度几乎一致",{"2":{"730":1}}],["2适用于定量情况",{"2":{"730":1}}],["2∑i∈pu1",{"2":{"730":1}}],["2∑i∈pu2",{"2":{"730":1}}],["2∑i∈ihi+λ",{"2":{"496":1}}],["2∑i∈irhi+λ−",{"2":{"496":1}}],["2∑i∈ilhi+λ+",{"2":{"496":1}}],["2∑i∈ijhi+λ+γt根据公式",{"2":{"496":1}}],["2个二分类任务",{"2":{"662":1}}],["2个3",{"2":{"347":1}}],["2是为了方便计算",{"2":{"656":1}}],["2找到合适的参数",{"2":{"656":1}}],["2由于mse与我们的目标变量的量纲不一致",{"2":{"581":1}}],["2的效果",{"2":{"567":1}}],["2的空洞卷积",{"2":{"306":1}}],["2其中共有m个样本点",{"2":{"656":1}}],["2其中",{"2":{"545":1,"729":1}}],["2πntp",{"2":{"535":2}}],["2l",{"2":{"496":1}}],["2+λ",{"2":{"657":1}}],["2+λ∑j=1n|θj|",{"2":{"657":1}}],["2+λ∑j=1nθj2",{"2":{"657":1}}],["2+",{"2":{"496":1}}],["2em2",{"2":{"431":1}}],["2卡",{"2":{"423":2}}],["2∗cin−1",{"2":{"394":1}}],["2∗cin",{"2":{"394":2}}],["2∗cin∗k2",{"2":{"394":1}}],["2∗cin∗k2−1",{"2":{"394":1}}],["2∗k2",{"2":{"394":1}}],["2914",{"2":{"658":1}}],["29",{"0":{"332":1}}],["28",{"0":{"331":1}}],["267852",{"2":{"414":1}}],["26种神经网络激活函数可视化",{"2":{"319":1}}],["26",{"0":{"329":1},"2":{"279":1,"591":1}}],["26000",{"2":{"6":1}}],["24小时",{"2":{"423":2}}],["24小时后",{"2":{"269":1}}],["24502469",{"2":{"414":1}}],["245668",{"2":{"414":1}}],["24",{"0":{"327":1},"2":{"279":1}}],["238556",{"2":{"414":1}}],["23",{"0":{"326":1,"482":1},"2":{"279":1,"658":1}}],["234",{"0":{"64":1}}],["21",{"0":{"324":1,"632":1},"2":{"279":1,"414":1,"497":1}}],["27",{"0":{"330":1},"2":{"277":4,"743":1}}],["2=7",{"2":{"269":1}}],["2=6",{"2":{"269":1}}],["2=5",{"2":{"269":1}}],["2=4",{"2":{"269":1}}],["2=3",{"2":{"269":1}}],["2=2",{"2":{"269":1}}],["2=1m∑j=0mcost",{"2":{"545":1}}],["2=1",{"2":{"269":1}}],["2=0",{"2":{"269":1}}],["2cto",{"2":{"259":1}}],["2xx状态码",{"2":{"245":1}}],["22σi2μij",{"2":{"620":1}}],["22σ2",{"2":{"568":1}}],["22238533",{"2":{"499":1}}],["22222499",{"2":{"259":1}}],["22222",{"2":{"111":2}}],["22个神经网络训练技巧",{"2":{"310":1}}],["22",{"0":{"325":1},"2":{"217":1,"279":1,"369":1}}],["2^",{"2":{"519":1}}],["2^53",{"2":{"210":1}}],["2^n",{"2":{"26":1}}],["2�",{"2":{"139":1}}],["250px",{"2":{"787":6}}],["250532",{"2":{"414":1}}],["25mb",{"2":{"763":1}}],["25表示以年为周期",{"2":{"535":1}}],["25二胎生男则停止生育",{"2":{"276":1}}],["25",{"0":{"328":1},"2":{"110":2,"279":1,"533":1}}],["2562",{"2":{"367":1}}],["256了",{"2":{"357":1}}],["256=2",{"2":{"357":3}}],["256=590k",{"2":{"357":1}}],["256",{"2":{"78":2,"82":3,"357":11,"388":2}}],["2n+2个数",{"2":{"43":1}}],["2n+1个数",{"2":{"43":1}}],["2以及",{"2":{"23":1}}],["20215345",{"2":{"595":1}}],["2020",{"0":{"378":1,"383":1,"396":1,"397":1,"404":1,"409":1,"410":1,"412":1,"413":1},"2":{"385":1}}],["20小时",{"2":{"423":1}}],["2048",{"2":{"302":1,"422":1}}],["20个阿里巴巴b2b技术部的员工被安排为4排",{"2":{"275":1}}],["2013",{"2":{"686":1}}],["2017",{"2":{"495":1}}],["201710",{"2":{"259":1}}],["2018",{"0":{"365":3,"368":1,"378":1,"383":1,"385":1,"396":1,"397":1},"2":{"367":1,"591":1}}],["2010",{"2":{"361":1}}],["2015",{"2":{"307":1,"743":1}}],["2016",{"2":{"307":1}}],["2014年",{"2":{"360":2}}],["2014",{"2":{"303":1,"690":1}}],["2019",{"0":{"369":1,"374":1,"383":1,"385":1,"389":1,"390":3,"397":2,"399":1,"406":1,"407":1,"408":1,"411":1},"2":{"203":1}}],["2008",{"2":{"361":1}}],["2005",{"2":{"361":1}}],["2001",{"2":{"361":1}}],["200",{"2":{"245":1}}],["2000",{"2":{"217":5,"366":2}}],["20x30",{"2":{"6":1}}],["20能被整除10",{"2":{"3":1}}],["20",{"0":{"323":1,"631":1},"2":{"3":2,"6":3,"86":2,"251":1,"275":2,"414":1,"469":1,"497":2,"664":1}}],["2",{"0":{"2":1,"19":1,"30":1,"41":1,"52":1,"59":1,"65":1,"75":1,"86":1,"120":1,"121":1,"132":1,"153":1,"162":1,"179":1,"186":1,"216":1,"234":1,"250":1,"256":1,"268":1,"275":1,"289":1,"306":1,"366":1,"377":1,"379":1,"386":1,"391":1,"400":1,"407":1,"426":1,"427":1,"428":2,"431":1,"445":1,"454":1,"465":1,"476":1,"502":1,"532":1,"541":1,"559":1,"571":1,"598":1,"613":1,"635":1,"647":1,"655":1,"675":1,"719":1,"720":1,"721":2,"724":1,"725":1,"748":1,"777":1},"1":{"133":1,"134":1,"135":1,"217":1,"218":1,"378":1,"379":1,"380":1,"381":1,"382":1,"383":1,"427":1,"428":1,"720":1,"721":1,"778":1,"779":1},"2":{"7":3,"8":1,"10":5,"23":2,"27":1,"35":1,"36":6,"37":3,"40":4,"41":3,"42":2,"44":6,"45":1,"46":1,"49":2,"52":3,"53":1,"56":2,"60":1,"67":3,"73":2,"74":1,"75":1,"76":1,"78":2,"79":1,"81":4,"82":2,"83":7,"86":2,"90":3,"91":4,"92":1,"94":17,"95":6,"110":1,"111":1,"114":5,"131":1,"196":1,"211":2,"215":2,"217":1,"243":2,"252":1,"255":1,"256":1,"268":1,"270":2,"274":10,"275":1,"277":5,"278":1,"279":6,"280":8,"281":1,"282":1,"303":1,"357":4,"367":3,"368":3,"369":3,"381":1,"388":2,"390":17,"393":3,"397":2,"402":1,"414":1,"422":1,"423":3,"428":3,"431":3,"455":1,"472":1,"475":1,"496":2,"512":1,"519":5,"522":1,"529":1,"544":1,"545":1,"555":3,"570":1,"581":1,"582":1,"583":2,"601":1,"612":2,"635":24,"643":2,"651":1,"654":1,"657":2,"682":1,"730":17,"732":1,"735":2,"738":1,"741":1,"756":6,"759":2,"760":1,"761":3,"763":1,"778":1,"784":3,"785":1,"786":1,"796":1,"830":1,"833":1,"834":1,"835":1}}],["mvvm",{"0":{"795":1}}],["mvcc",{"0":{"162":1},"2":{"162":5,"174":1}}],["m和r的设置会对master的监督有一定的影响",{"2":{"770":1}}],["m的内存空间",{"2":{"763":1}}],["m是树的数量",{"2":{"741":1}}],["mu和方和方",{"2":{"620":1}}],["mul",{"2":{"83":8}}],["multiboosting由于集合了bagging",{"2":{"439":1}}],["multiboosting算法将adaboost作为bagging的基学习器",{"0":{"439":1}}],["multibosoting先减低模型的偏差再减低模型的方差",{"2":{"439":1}}],["multiply",{"2":{"46":1,"83":1}}],["multmerge",{"2":{"54":1}}],["m个特个特",{"2":{"612":1}}],["m个通道",{"2":{"348":1}}],["ms",{"2":{"787":1}}],["mse表示均方误差",{"2":{"583":1}}],["mse=1n∑i=1n",{"2":{"581":1}}],["mse",{"0":{"581":1},"2":{"656":1}}],["mstset",{"2":{"59":8}}],["m为样本个数",{"2":{"545":1}}],["m+a",{"2":{"532":1}}],["m+1",{"2":{"4":1,"9":1}}],["m=0",{"2":{"532":1}}],["m$次这个词的场景",{"2":{"621":1}}],["m$",{"2":{"532":1}}],["mδn",{"2":{"519":1}}],["m终止",{"2":{"519":1}}],["mψi",{"2":{"519":1}}],["m递推",{"2":{"519":1}}],["mteb涵盖的嵌入任务类别主要包括",{"2":{"423":1}}],["mteb",{"2":{"423":2}}],["mnr",{"2":{"423":3}}],["mlm+nsp",{"2":{"713":1}}],["mlm",{"2":{"422":2,"713":1}}],["mqa",{"2":{"422":2}}],["mha",{"2":{"422":2}}],["mportance",{"2":{"462":1}}],["mp",{"2":{"414":1,"473":1,"517":1,"556":1}}],["m4",{"2":{"388":4}}],["md",{"2":{"203":1}}],["moz",{"2":{"787":1}}],["momentum",{"2":{"308":1}}],["mongodb",{"2":{"258":1}}],["monitorexit",{"2":{"140":1}}],["monitorenter",{"2":{"140":1}}],["monitorenter与monitorexit",{"2":{"139":1}}],["monitor",{"2":{"139":1}}],["model初始化fast",{"2":{"373":1}}],["model初始化rpn再次进行训练",{"2":{"373":1}}],["model初始化",{"2":{"373":1}}],["model",{"2":{"140":1,"361":1,"527":1,"614":1,"710":1,"713":2,"718":1,"740":1}}],["module变量代表当前模块�",{"2":{"112":1}}],["module",{"2":{"111":1,"112":1,"800":3}}],["my",{"2":{"800":2}}],["mycar",{"2":{"211":2}}],["mycomp",{"2":{"22":2,"59":2}}],["mylock",{"2":{"185":1}}],["mysql每执行一条dml语句",{"2":{"173":1}}],["mysql�",{"0":{"166":1}}],["mysql8",{"2":{"163":1}}],["mysqlselect",{"2":{"163":1}}],["mysql",{"0":{"163":1},"2":{"167":1,"168":1,"188":1,"258":1}}],["mysql的引擎了解吗",{"0":{"161":1}}],["myisam",{"0":{"161":1},"2":{"161":1}}],["myeventemitter",{"2":{"111":1}}],["mb",{"2":{"44":12}}],["mikolov提出了两种改进思路来绕过sigmoid归一化这一操作",{"2":{"719":1}}],["mikolov对nnlm模型进行了以下几个部分的修改",{"2":{"718":1}}],["mikolov发现",{"2":{"718":1}}],["mixture",{"2":{"674":1}}],["mixup",{"2":{"345":1}}],["milvus",{"2":{"423":1}}],["misalignment",{"2":{"375":1}}],["mis",{"2":{"369":1}}],["middle",{"2":{"65":1}}],["mid+1",{"2":{"53":1,"757":1,"760":2}}],["mid",{"2":{"41":9,"45":6,"53":4,"757":2,"760":6}}],["minuv∑",{"2":{"729":1}}],["minb∑",{"2":{"729":1}}],["minα12∑i=1n∑j=1nαiαjyiyj",{"2":{"635":2}}],["minw",{"2":{"635":3}}],["mini=1mminj=i+1md",{"2":{"684":1}}],["mini",{"2":{"545":1,"546":2}}],["mining",{"2":{"423":1}}],["mininum",{"2":{"58":1,"59":1}}],["min=0",{"2":{"397":2}}],["min=y1",{"2":{"397":1}}],["min=x1",{"2":{"397":1}}],["min是样本数据的最小值",{"2":{"306":1}}],["minas",{"2":{"42":1}}],["minp",{"2":{"24":4}}],["minpatches",{"2":{"23":1}}],["mincost",{"2":{"9":1}}],["mincut",{"2":{"7":1}}],["minv",{"2":{"8":5}}],["mindistance",{"2":{"5":1,"58":2,"59":2}}],["min",{"2":{"5":3,"6":1,"7":2,"8":4,"9":3,"10":1,"11":2,"14":2,"24":1,"40":1,"44":1,"58":3,"59":3,"306":4,"390":1,"484":3,"507":1,"635":3}}],["messagechannel",{"2":{"792":1}}],["meaning",{"2":{"725":1}}],["mean",{"2":{"580":1,"581":1,"589":1}}],["means中空聚类的处理",{"0":{"685":1}}],["means中比较常用的距离度量是欧几里得距离和余弦相似度",{"2":{"681":1}}],["means的第三步我们可以看出",{"2":{"682":1}}],["means不适用哪些数据",{"0":{"680":1}}],["means之前要将数据点在各维度上归一化",{"0":{"679":1}}],["means陷入局部最优解",{"2":{"678":1}}],["means选择的初始点不同获得的最终分类结果也可能不同",{"2":{"678":1}}],["means++",{"2":{"676":1}}],["means是否会一直陷入选择质心的循环停不下来",{"0":{"682":1}}],["means是一种常见的聚类算法",{"2":{"675":1}}],["means是聚类算",{"2":{"651":1}}],["means面试题",{"0":{"673":1},"1":{"674":1,"675":1,"676":1,"677":1,"678":1,"679":1,"680":1,"681":1,"682":1,"683":1,"684":1,"685":1,"686":1}}],["means与knn有什么区",{"2":{"651":1}}],["means",{"0":{"681":1},"2":{"422":2,"651":1,"674":1,"679":1,"680":1}}],["means代表类簇内数据对象的均值",{"2":{"396":1}}],["means算法中初始点的选择对最终结果的影响",{"0":{"678":1}}],["means算法中的k代表类簇个数",{"2":{"396":1}}],["means算法要求事先知道数据集能分为几群",{"2":{"677":1}}],["means算法优缺点分析",{"2":{"396":1}}],["means算法通常采用欧氏距离来计算数据对象间的距离",{"2":{"396":1}}],["means算法又称为k",{"2":{"396":1}}],["means算法原理",{"2":{"396":1}}],["means算法是一种基于划分的聚类算法",{"2":{"396":1}}],["means算法是一种聚类算法",{"2":{"396":1}}],["means算法是很典型的基于距离的聚类算法",{"2":{"382":1}}],["means算法计算出anchor",{"2":{"381":1}}],["means原理",{"0":{"382":1}}],["means计算出anchor",{"2":{"380":1}}],["means得到anchor",{"0":{"380":1}}],["means聚类效果进行评估",{"0":{"684":1}}],["means聚类获得anchor",{"0":{"381":1}}],["means聚类来选择锚的个数和形状",{"2":{"378":1}}],["means聚类",{"2":{"367":1}}],["meta",{"2":{"796":1}}],["metric主要用来评测机器学习模型的好坏程",{"2":{"578":1}}],["methods",{"2":{"312":1}}],["me",{"2":{"253":1,"666":1}}],["memm容易陷入局部最优",{"2":{"520":1}}],["memm模型是对转移概率和表现概率建立联合概率",{"2":{"520":1}}],["memm和crf模型的比",{"0":{"520":1}}],["memory",{"2":{"140":1,"423":1,"690":2,"702":1}}],["memset",{"2":{"1":1,"4":1,"10":1}}],["mergetwolists",{"2":{"71":1}}],["mergesort",{"2":{"56":3}}],["mergesortutil",{"2":{"53":4}}],["merge",{"2":{"53":2,"56":3,"760":5}}],["mergenumber",{"2":{"21":1}}],["median",{"2":{"44":7,"676":1}}],["m5",{"2":{"8":3,"388":2}}],["m3~m5",{"2":{"388":1}}],["m3",{"2":{"8":3,"388":3}}],["m2",{"2":{"8":3}}],["mail",{"2":{"766":1}}],["main",{"2":{"112":1,"670":1}}],["mainb",{"2":{"42":5}}],["maina",{"2":{"42":5}}],["mainelemp",{"2":{"42":1}}],["mainelem",{"2":{"42":5}}],["margin",{"2":{"634":2,"784":1}}],["markov",{"2":{"521":1,"525":2}}],["mark",{"2":{"110":6}}],["machine",{"2":{"591":1,"634":1,"690":1}}],["mae=1n∑i=1n|yi−y^i|mae虽能较好衡量回归模型的好坏",{"2":{"580":1}}],["mae",{"0":{"580":1}}],["massive",{"2":{"423":1}}],["mask",{"0":{"369":1},"2":{"375":3,"376":1,"422":1,"702":1,"716":1}}],["master会监控所有节点的运行状态",{"2":{"770":1}}],["master会重新分配那些已经完成的节点任务",{"2":{"770":1}}],["master会将此过程中的写命令写入缓存",{"2":{"194":1}}],["master监控所有节点的信息",{"2":{"770":1}}],["master负责调度和通信",{"2":{"770":1}}],["master",{"2":{"185":5,"194":1}}],["mathrm",{"2":{"635":1,"654":3}}],["math",{"2":{"210":1}}],["matrix",{"2":{"11":6,"45":12,"586":1}}],["matrixchainorder",{"2":{"6":1}}],["magic",{"2":{"111":3}}],["mann",{"2":{"686":1}}],["many",{"2":{"470":1}}],["man",{"2":{"76":1,"422":1,"718":3}}],["madian",{"2":{"44":1}}],["make",{"2":{"40":2,"43":1}}],["map生成的中间文件要根据key进行排序",{"2":{"770":1}}],["map任务运行时候尽可能的读取本地或者当前局域内的文件",{"2":{"770":1}}],["map和reduce之间有时候需要加合并",{"2":{"770":1}}],["map和reduce个数如何设置",{"2":{"770":1}}],["map和reduce",{"2":{"769":1}}],["mapreduce模式下我们需要关注的问题如下",{"2":{"770":1}}],["mapreduce模式这么流行",{"2":{"769":1}}],["mapreduce框架帮我们处理好了并行计算",{"2":{"769":1}}],["mapreduce认为第一个分隔符之前的字段是key",{"2":{"769":1}}],["mapreduce支持的数据格式",{"2":{"769":1}}],["mapreduce组成",{"2":{"769":1}}],["mapreduce最早是由google公司研究提出的一种面向大规模数据处理的并行计算模型和方法",{"2":{"769":1}}],["mapreduce是一种编程模式",{"2":{"769":1}}],["mapreduce",{"2":{"754":1,"768":1,"769":1,"771":2,"804":1}}],["mapreduce还没有使用",{"2":{"752":1}}],["map进行频率统计",{"2":{"750":1}}],["map进行reuse",{"2":{"368":1}}],["map等",{"2":{"749":1}}],["map等直接来统计每个query出现的次数",{"2":{"748":1}}],["map即一次图像输入完成",{"2":{"402":1}}],["map分层融合",{"2":{"402":1}}],["map分别输入到rpn和fast",{"2":{"373":1}}],["map一起组成的",{"2":{"402":1}}],["map融合来提高小目标检测的精度和召回",{"2":{"400":1}}],["map值即",{"2":{"393":1}}],["map就是所有类别ap值的平均",{"2":{"393":2}}],["map计算方法",{"2":{"393":1}}],["map定义及相关概念",{"2":{"393":1}}],["map特征融合方式",{"0":{"392":1}}],["map做卷积操作",{"2":{"385":1}}],["map中每一个空间位置都设置一组default",{"2":{"385":1}}],["map中的每一个点都设置一些default",{"2":{"385":1}}],["map送入fast",{"2":{"373":1}}],["map提取特征",{"2":{"373":1}}],["map上所占的范围",{"2":{"368":1}}],["maps大小",{"2":{"368":1}}],["maps的大小不取决于roi和卷积feature",{"2":{"368":1}}],["maps",{"2":{"368":1}}],["map对应位置",{"2":{"368":1}}],["map尺度",{"2":{"320":1}}],["map尺度不变的情况下",{"2":{"320":1}}],["map在通道上直接拼接",{"2":{"318":1}}],["map相同位置点的值直接相加",{"2":{"318":1}}],["map的特征信息",{"2":{"339":1}}],["map的hw相同",{"2":{"318":1}}],["map的通道数",{"2":{"317":1}}],["map的尺寸比输入更大",{"2":{"312":1}}],["map的分辨率越小",{"2":{"311":1}}],["map间隔填充0",{"2":{"312":1}}],["map达到最大",{"2":{"311":1}}],["map",{"2":{"40":3,"82":6,"89":2,"220":1,"222":1,"315":1,"318":2,"373":1,"386":3,"387":1,"393":1,"748":1,"769":3}}],["malloc",{"2":{"22":1,"59":1}}],["ma",{"2":{"10":8,"44":15}}],["maxθl",{"2":{"719":1,"721":1,"722":1}}],["maxk=1mdiam",{"2":{"684":1}}],["maxα−12∑i=1n∑j=1nαiαjyiyj",{"2":{"635":1}}],["maxw",{"2":{"635":3}}],["maxy",{"2":{"519":1}}],["max=y2",{"2":{"397":1}}],["max=x2",{"2":{"397":1}}],["max=0",{"2":{"78":1}}],["maximum",{"0":{"397":1},"2":{"397":2}}],["maximumpoolsize",{"2":{"129":1,"130":2}}],["maxout函数",{"2":{"319":1}}],["max标准化",{"2":{"306":1}}],["maxmumpoolsize+workqueue",{"2":{"129":1}}],["maxmatrixsum",{"2":{"10":1}}],["max+1",{"2":{"79":1}}],["maxheapfy",{"2":{"52":4,"756":4}}],["maxsildingwindow",{"2":{"47":1}}],["maxsubarray",{"2":{"18":1}}],["maxsubsquare",{"2":{"11":1}}],["maxsum",{"2":{"10":1}}],["maxprofit",{"2":{"24":1,"25":1,"26":1}}],["maxproduct",{"2":{"14":1}}],["max",{"0":{"339":1},"2":{"1":4,"2":3,"3":3,"6":1,"11":1,"14":3,"18":1,"24":1,"26":3,"40":1,"44":1,"58":3,"59":2,"61":2,"78":4,"79":5,"87":1,"94":5,"95":5,"306":1,"312":1,"339":1,"385":1,"390":1,"484":3,"612":1,"635":1,"689":1}}],["m",{"0":{"699":1},"2":{"4":5,"6":1,"9":5,"10":6,"11":2,"33":2,"45":4,"61":3,"390":17,"428":3,"431":1,"472":1,"497":2,"519":1,"545":1,"686":1,"730":4,"795":2}}],["0时",{"2":{"635":1}}],["0$",{"2":{"635":1}}],["0组",{"2":{"592":1}}],["05",{"2":{"574":1}}],["05为步长",{"2":{"393":1}}],["0个",{"2":{"512":1}}],["0个样本",{"2":{"502":1}}],["0个正样本1",{"2":{"502":1}}],["0里的group",{"2":{"357":1}}],["0及之后直接支持group",{"2":{"357":1}}],["0值不可微",{"2":{"337":1}}],["0均值标准化",{"2":{"306":1}}],["0908",{"2":{"303":1}}],["03",{"2":{"303":1}}],["00路归",{"2":{"763":1}}],["00个数组中找到最大的k个元素",{"2":{"763":1}}],["00个有",{"2":{"763":1}}],["00表示不存在",{"2":{"751":1}}],["00的训练误差后",{"0":{"482":1}}],["00",{"2":{"278":1,"651":1}}],["001",{"2":{"269":1,"618":1}}],["000",{"2":{"269":1}}],["0=nan",{"2":{"210":1}}],["07",{"2":{"203":1}}],["02∗0",{"2":{"282":1}}],["02根据实际情况",{"2":{"282":1}}],["02",{"2":{"203":1}}],["01变10",{"2":{"751":1}}],["01表示出现一次",{"2":{"751":1}}],["01说明分群合理",{"2":{"684":1}}],["011",{"2":{"269":1,"618":1}}],["0101",{"2":{"279":1}}],["010",{"2":{"269":1}}],["01",{"2":{"203":1,"278":1,"591":1,"618":1}}],["0秒",{"2":{"189":1}}],["0秒检查一下",{"2":{"185":1}}],["08",{"2":{"83":1,"743":1}}],["06",{"0":{"69":1}}],["0",{"2":{"1":4,"2":1,"3":5,"4":2,"5":5,"6":1,"7":6,"9":13,"10":7,"11":25,"12":2,"13":7,"14":1,"15":4,"18":5,"19":5,"20":3,"21":2,"22":5,"23":2,"24":2,"25":1,"26":2,"27":6,"29":1,"30":1,"31":5,"32":3,"33":11,"34":5,"36":17,"37":1,"38":1,"40":6,"41":2,"42":7,"43":14,"44":8,"45":9,"46":3,"47":2,"48":3,"49":2,"52":1,"54":4,"56":1,"58":9,"59":9,"60":5,"61":2,"71":1,"72":2,"73":2,"74":4,"76":1,"77":2,"78":6,"79":2,"80":2,"82":9,"83":17,"85":1,"86":2,"87":1,"88":1,"89":1,"92":1,"93":2,"94":8,"95":1,"110":1,"131":2,"163":1,"215":1,"217":1,"268":1,"269":1,"274":3,"282":1,"283":1,"306":1,"323":1,"337":1,"367":2,"372":1,"390":10,"393":6,"397":5,"422":2,"430":1,"469":3,"472":4,"509":1,"533":1,"536":1,"585":1,"586":4,"587":1,"588":1,"590":2,"602":1,"618":1,"634":2,"635":4,"651":1,"655":1,"659":1,"660":3,"670":1,"703":2,"716":1,"718":1,"739":3,"756":4,"757":1,"759":4,"760":2,"761":3,"762":1,"769":1,"787":8}}],["x4999",{"2":{"749":1}}],["xym4869",{"2":{"656":1}}],["x都是列向量",{"2":{"655":1}}],["x^",{"2":{"635":1}}],["x$的样本方",{"2":{"620":1}}],["x与事与事",{"2":{"613":1}}],["x发生之后",{"2":{"613":1}}],["x发生之前",{"2":{"613":1}}],["x|y",{"2":{"613":3,"620":1,"627":1,"631":3}}],["x|yi",{"2":{"612":2}}],["x对于每个分类目标来说都一样",{"2":{"612":1}}],["xk+1=xk−αhk−1gk直至收敛到驻点处",{"2":{"555":1}}],["xk+1=xk−α∇f",{"2":{"547":1}}],["xk",{"2":{"547":2}}],["xj1⋅xj2其中w∈rd",{"2":{"735":1}}],["xj则有",{"2":{"634":1}}],["xj",{"2":{"545":1,"635":7}}],["x3",{"2":{"545":1}}],["x3c",{"2":{"1":4,"2":2,"3":2,"4":2,"5":4,"6":5,"7":8,"8":1,"9":9,"10":6,"11":9,"12":1,"13":4,"14":2,"15":1,"18":2,"19":2,"20":4,"21":5,"22":3,"23":4,"24":2,"25":2,"26":1,"27":2,"29":4,"30":5,"31":6,"32":3,"33":8,"34":12,"35":5,"36":13,"37":8,"38":7,"40":18,"41":4,"42":3,"43":8,"44":7,"45":7,"46":4,"47":9,"48":6,"49":3,"51":6,"52":2,"53":7,"54":14,"55":1,"56":1,"58":37,"59":16,"60":18,"61":9,"71":1,"74":2,"75":1,"76":12,"77":4,"78":4,"79":5,"80":4,"81":3,"82":8,"83":4,"85":23,"86":5,"88":1,"89":12,"90":3,"92":4,"93":1,"94":1,"95":2,"390":1,"397":1,"756":7,"757":4,"758":1,"759":2,"760":6,"762":1,"774":4,"775":14,"796":17}}],["x−μ",{"2":{"568":1}}],["x−m",{"2":{"532":1}}],["x−x∗",{"2":{"554":1}}],["x−x0",{"2":{"496":4,"555":5}}],["x−xa",{"2":{"372":1}}],["x−x1",{"2":{"369":2}}],["x=x0−h−1g在泰勒公式中忽略了高阶项将函数做了近似",{"2":{"555":1}}],["x=x0−",{"2":{"555":1}}],["x=",{"2":{"519":1,"612":1}}],["x+b^",{"2":{"635":1}}],["x+1m−",{"2":{"590":1}}],["x+δx",{"2":{"496":1,"547":4}}],["x+y=1",{"2":{"274":1}}],["x0j",{"2":{"545":6}}],["x0",{"2":{"496":4,"545":1,"547":1,"555":10,"749":1}}],["xgb中的数据并行也是水平切分",{"2":{"514":1}}],["xgb每个worker节点中仅有部分的列数据",{"2":{"514":1}}],["xgb用block结构的一个缺点是取梯度的时候",{"2":{"514":1}}],["xgb无法直接输入类别型变量因此需要事先对类别型变量进行编码",{"2":{"514":1}}],["xgb使用特征预排序算法",{"2":{"514":1}}],["xgb对每一层所有节点做无差别分裂",{"2":{"514":1}}],["xgb采用level",{"2":{"514":1}}],["xgb",{"2":{"497":1,"514":1}}],["xgb之所以使用二阶梯度信息",{"2":{"497":1}}],["xgb为什么使用二阶梯度信息",{"2":{"497":1}}],["xgb如何在计算特征时加速的",{"2":{"497":1}}],["xgb可以说是工程上的最佳实践模型",{"2":{"494":1}}],["xgb主要有三种计算方法",{"2":{"462":1}}],["xgboost和lightgbm的区别",{"0":{"514":1}}],["xgboost使用二阶泰勒展开的目的和优势",{"0":{"516":1}}],["xgboost使用",{"2":{"510":1}}],["xgboost使用按层生长",{"2":{"497":1}}],["xgboost模型的一个优点就是允许特征存在缺失值",{"2":{"508":1}}],["xgboost如何评价特征的重要性",{"0":{"512":1}}],["xgboost如何选择最佳分裂点",{"0":{"510":1}}],["xgboost如何处理不平衡数据",{"0":{"509":1}}],["xgboost如何处理缺失值",{"0":{"508":1}}],["xgboost如何进行参数更新",{"2":{"498":1}}],["xgboost中如何处理过拟合的情况",{"0":{"507":1}}],["xgboost本质上仍然采本质上仍然采",{"2":{"505":1}}],["xgboost本身不具备自动处理类别特征的能力",{"2":{"497":1}}],["xgboost为什么快",{"0":{"506":1}}],["xgboost为什么可以并行训",{"0":{"505":1}}],["xgboost为什么使用二阶梯度信",{"2":{"498":1}}],["xgboost$还提出了一种可并行的近似算法",{"2":{"513":1}}],["xgboost$在训练之前",{"2":{"513":1}}],["xgboost$",{"2":{"507":1,"513":3}}],["xgboost$预先将每个特征按特征值排好序",{"2":{"504":1}}],["xgboost$可以自动学习出它的默认分裂方向",{"2":{"504":1}}],["xgboost$支持列采样",{"2":{"504":1}}],["xgboost$的目标函数加了正则项",{"2":{"504":1}}],["xgboost对损失函数做了二阶泰勒展开",{"2":{"504":1}}],["xgboost相当于带相当于带l1",{"2":{"504":1}}],["xgboost相对gbdt做了哪些改进",{"2":{"497":1}}],["xgboost与gbdt有什么不",{"0":{"504":1}}],["xgboost是以mse为基础推导出来的",{"2":{"516":1}}],["xgboost是根据gain来做重要性判断的",{"2":{"512":1}}],["xgboost是一种集成学习算法",{"2":{"503":1}}],["xgboost是大规模",{"2":{"503":1}}],["xgboost是gbdt的改进或者说是梯度提升树的一种",{"2":{"494":1}}],["xgboost面试",{"0":{"500":1},"1":{"501":1,"502":1,"503":1,"504":1,"505":1,"506":1,"507":1,"508":1,"509":1,"510":1,"511":1,"512":1,"513":1,"514":1,"515":1,"516":1,"517":1}}],["xgboost里现在也提供了这一选项",{"2":{"497":1}}],["xgboost在构建树的节点过程中只考虑非缺失值的数据遍历",{"2":{"508":1}}],["xgboost在训练之前",{"2":{"497":2,"505":1}}],["xgboost在代价函数里加入了正则项",{"2":{"497":1}}],["xgboost的目标函数展开就是一阶项+二阶项的形式",{"2":{"516":1}}],["xgboost的目标公",{"2":{"496":1}}],["xgboost的优缺",{"0":{"513":1}}],["xgboost的scalable性如何体现",{"0":{"511":1}}],["xgboost的基分类器不仅支的基分类器不仅支",{"2":{"504":1}}],["xgboost的并行是在特征粒度上的",{"2":{"497":2,"505":1,"513":1}}],["xgboost也是一次迭代完才能进行下一次迭代的",{"2":{"497":2,"505":1,"513":1}}],["xgboost工具支持并行",{"2":{"497":2,"513":1}}],["xgboost工具支持自定义代价函数",{"2":{"497":1}}],["xgboost可以自动学习出它的分裂方向",{"2":{"497":1}}],["xgboost借鉴了随机森林的做法",{"2":{"497":1}}],["xgboost则对代价函数进行了二阶泰勒展开",{"2":{"497":1}}],["xgboost还支持线性分类器",{"2":{"497":1}}],["xgboost损失函数的泰勒二阶展开",{"2":{"496":1}}],["xgboost",{"0":{"494":1},"2":{"456":1,"464":1,"466":1,"473":1,"490":1,"497":1,"503":1,"513":6}}],["xnj",{"2":{"545":6}}],["xn",{"2":{"431":1}}],["xiongweinie",{"2":{"766":1}}],["xixi=12",{"2":{"735":1}}],["xixj−12∑i=1n",{"2":{"735":1}}],["xixj=12∑i=1n∑j=1n",{"2":{"735":1}}],["xi|yk",{"2":{"621":1}}],["xi|yj",{"2":{"619":3}}],["xi−μj",{"2":{"620":1}}],["xi=xi|y=yj",{"2":{"620":1}}],["xij−xi¯",{"2":{"682":1}}],["xij",{"2":{"545":1}}],["xijc",{"2":{"545":1}}],["xijb",{"2":{"545":1}}],["xi",{"2":{"428":6,"430":10,"431":4,"496":11,"547":1,"634":1,"635":10,"654":1,"656":2}}],["xm",{"2":{"428":1,"455":1,"475":1}}],["xx2",{"2":{"397":2}}],["xx1",{"2":{"397":2}}],["xxx",{"2":{"112":1,"793":2}}],["x∗",{"2":{"554":2}}],["x∗分别是预测box",{"2":{"372":1}}],["x∗−xa",{"2":{"372":1}}],["x2|y",{"2":{"614":1}}],["x2−x",{"2":{"369":2}}],["x2−x1",{"2":{"369":4}}],["x2",{"2":{"369":1,"397":3,"455":1,"475":1,"547":1,"614":2}}],["x26",{"2":{"1":1,"2":2,"5":2,"7":2,"11":1,"13":7,"14":1,"18":1,"19":5,"20":1,"21":1,"23":3,"24":1,"25":1,"26":1,"27":1,"29":2,"30":5,"31":4,"32":4,"33":2,"34":5,"35":3,"36":22,"37":3,"38":3,"40":2,"41":1,"43":3,"44":10,"45":2,"46":1,"47":6,"48":4,"49":5,"51":4,"52":5,"53":2,"54":5,"55":3,"56":4,"58":11,"59":7,"61":4,"74":1,"75":1,"76":10,"77":2,"79":8,"80":2,"81":3,"82":2,"83":2,"87":2,"89":1,"90":2,"91":8,"92":7,"93":2,"94":2,"95":2,"756":4,"757":4,"760":2}}],["x1|y",{"2":{"614":1}}],["x1j",{"2":{"545":6}}],["x1",{"2":{"369":2,"397":3,"428":1,"455":1,"472":1,"545":1,"547":1,"614":1,"749":1}}],["x一定是depth深度的最左节点",{"2":{"93":1}}],["xavier初始化",{"2":{"323":1}}],["xa",{"2":{"46":1,"372":1}}],["xai",{"2":{"46":1}}],["xor",{"2":{"43":1}}],["xroot",{"2":{"22":7,"59":7}}],["x",{"2":{"8":2,"9":4,"22":5,"40":2,"48":2,"59":5,"66":2,"67":2,"69":2,"73":2,"215":4,"222":4,"267":3,"274":12,"279":3,"306":8,"315":1,"367":1,"368":1,"369":6,"372":3,"379":1,"390":2,"423":1,"428":6,"430":9,"431":4,"434":3,"455":2,"457":2,"472":23,"475":3,"496":17,"497":20,"519":11,"521":5,"532":2,"547":13,"554":2,"555":3,"568":2,"590":3,"612":11,"613":3,"618":1,"620":2,"627":1,"631":3,"635":30,"638":2,"654":1,"655":2,"656":1,"657":4,"661":9,"668":3,"682":1,"684":2,"697":4,"735":4,"749":1,"792":1}}],["lp−norms",{"2":{"730":1}}],["lvq",{"2":{"674":1}}],["lwr",{"2":{"657":1}}],["lhanchao",{"2":{"652":1}}],["luoshixian099",{"2":{"644":1}}],["lua",{"2":{"185":1}}],["ldots",{"2":{"635":7,"654":1}}],["lda等模型都是先对联合概率分布进行建模",{"2":{"521":1}}],["lda等",{"2":{"521":1}}],["lsa是基于共现矩阵构建词向量",{"2":{"725":1}}],["lstm网络",{"2":{"527":1}}],["lstm",{"0":{"697":1,"700":1},"2":{"521":2,"522":1,"690":2,"697":1,"698":1,"700":2,"707":1,"710":1}}],["lsplit=12",{"2":{"496":1}}],["l=1",{"2":{"519":2}}],["l=2",{"2":{"6":1}}],["lgb中先对数据水平切分",{"2":{"514":1}}],["lgb中对每个特征都有一个直方图",{"2":{"514":1}}],["lgb特征并行的前提是每个worker留有一份完整的数据集",{"2":{"514":1}}],["lgb是基于直方图分裂特征的",{"2":{"514":1}}],["lgb可以直接处理类别型变量",{"2":{"514":1}}],["lgb还可以使用直方图做差加速",{"2":{"514":1}}],["lgb使用基于直方图的切分点算法",{"2":{"514":1}}],["lgb采用leaf",{"2":{"514":1}}],["lgb和xgb",{"2":{"497":1}}],["lgb相对xgb做了哪些改进",{"2":{"497":1}}],["l^",{"2":{"496":1}}],["llama",{"2":{"423":2}}],["llm",{"2":{"423":1}}],["lr能做的",{"2":{"672":1}}],["lr如何进行并行计算",{"0":{"671":1}}],["lr为什么使用sigmoid函数",{"0":{"670":1}}],["lr的权重个数",{"2":{"741":1}}],["lr的权重个数和gbdt的什么有关",{"2":{"741":1}}],["lr的可解释性强",{"2":{"663":1}}],["lr的效果一般会",{"2":{"502":1}}],["lr和svm有什么不同吗",{"0":{"672":1}}],["lr和svm都可以处理分类问题",{"2":{"641":1,"672":1}}],["lr和svm的联系与区别",{"0":{"641":1}}],["lr是参数模型",{"2":{"641":1,"672":1}}],["lr是判别模",{"2":{"627":1}}],["lr是线性模型",{"2":{"502":1}}],["lr$时有效",{"2":{"509":1}}],["lr$回归",{"2":{"504":1}}],["lr",{"0":{"627":1,"739":1},"2":{"420":1,"502":2,"511":1,"627":1}}],["lreg",{"2":{"372":1}}],["lru算法题",{"2":{"299":1}}],["lru",{"2":{"200":5,"299":1}}],["ln",{"2":{"307":2}}],["lfu",{"2":{"200":2}}],["lca",{"2":{"92":3}}],["lcp",{"2":{"74":7}}],["lcs",{"2":{"2":2}}],["l2等等",{"2":{"641":1,"672":1}}],["l2范数损失",{"2":{"581":1}}],["l2范数更容易产生分散的权重",{"2":{"330":1}}],["l2先验趋向零周围",{"2":{"568":1}}],["l2正则",{"2":{"564":1}}],["l2正则限制参数变化",{"2":{"423":1}}],["l2正则化项",{"2":{"504":1}}],["l2正则化",{"2":{"307":1,"325":1,"330":1}}],["l2",{"0":{"568":1},"2":{"71":8,"330":1,"568":1,"657":1}}],["l1范数损失",{"2":{"580":1}}],["l1范数更容易产生稀疏的权重",{"2":{"330":1}}],["l1先验趋向零本身",{"2":{"568":1}}],["l1函数",{"2":{"372":1}}],["l1正则与l2正则的特点是什么",{"2":{"330":1}}],["l1正则化和l2正则化有什么区别",{"0":{"330":1}}],["l1正则化",{"2":{"325":1,"568":1,"657":1}}],["l1",{"0":{"568":1},"2":{"71":8,"307":1,"330":1,"372":1,"568":1}}],["ly",{"2":{"62":1}}],["loader",{"2":{"800":6}}],["loader�",{"2":{"800":1}}],["loss变小但是正则变大",{"2":{"515":1}}],["loss来解决类别不平衡问题",{"2":{"387":1}}],["loss和focal",{"2":{"370":1}}],["loss等loss进行控制不平衡样本",{"2":{"336":1}}],["loss",{"2":{"330":1,"370":1,"378":1,"387":2,"399":1,"672":1,"708":1}}],["location",{"2":{"798":1}}],["localhost",{"2":{"114":2}}],["locks",{"2":{"139":1}}],["lockinterruptibly",{"2":{"136":1,"139":1}}],["lock",{"2":{"136":1,"137":1,"139":1,"143":2}}],["logk",{"2":{"756":2}}],["log⁡n",{"2":{"725":1}}],["log⁡p",{"2":{"722":1}}],["log⁡",{"2":{"721":1}}],["log⁡σ",{"2":{"721":1}}],["log⁡∏i=1np",{"2":{"619":1}}],["logistic回归",{"2":{"632":1}}],["logits",{"2":{"422":1}}],["log时",{"2":{"193":1}}],["log适用于崩溃恢�",{"2":{"173":1}}],["log是innodb引擎层实现的",{"2":{"173":1}}],["log的大小是固定的�",{"2":{"173":1}}],["logging",{"2":{"173":1}}],["log包括两部分",{"2":{"173":1}}],["logn",{"2":{"120":1,"756":2}}],["log",{"0":{"171":2,"173":1,"174":1},"1":{"172":2,"173":2,"174":2},"2":{"111":3,"112":3,"114":6,"173":6,"174":7,"211":3,"214":6,"215":3,"217":16,"218":3,"226":1,"661":2,"793":1}}],["loveleetcode",{"2":{"82":1}}],["lo>=0",{"2":{"79":2}}],["lo",{"2":{"79":16}}],["lowe提出了一种改进算法kd",{"2":{"651":1}}],["low",{"2":{"45":4}}],["longtensor",{"2":{"397":1}}],["longestconsecutive2",{"2":{"94":1}}],["longestconsecutiveutil",{"2":{"94":3}}],["longestcommonprefix",{"2":{"74":1}}],["longestpalindrome",{"2":{"79":1}}],["long",{"2":{"23":2,"139":1,"527":1,"690":2}}],["leq",{"2":{"635":2}}],["leakrelu",{"2":{"698":1}}],["leaky",{"2":{"319":1}}],["leaf",{"2":{"466":3,"471":1,"484":2,"497":1,"514":1}}],["learner",{"2":{"425":2}}],["learning",{"2":{"423":2,"425":1,"591":1,"651":1,"674":1,"690":1,"740":5}}],["learnable",{"2":{"423":1}}],["level+1",{"2":{"95":2}}],["level",{"0":{"466":1},"2":{"95":8,"466":1,"497":1,"784":2}}],["leetcode",{"2":{"77":1,"82":1}}],["let",{"2":{"77":1,"111":2,"112":2,"215":1,"217":4,"223":2,"796":1}}],["letter",{"2":{"76":3}}],["left+1",{"2":{"757":1}}],["left|r",{"2":{"730":1}}],["leftview",{"2":{"95":4}}],["left是下一",{"2":{"89":1}}],["left=s",{"2":{"76":1,"77":1}}],["left",{"2":{"41":1,"56":16,"76":8,"77":3,"84":4,"85":1,"94":5,"96":1,"536":4,"635":34,"735":1,"756":4,"757":6,"760":9,"785":1,"786":1}}],["len++",{"2":{"81":2}}],["len=0",{"2":{"81":1}}],["lenb",{"2":{"44":5}}],["lena",{"2":{"44":6}}],["len",{"2":{"38":8,"79":2,"81":2,"85":2,"86":2}}],["lengthoflongestsubstring2",{"2":{"78":1}}],["lengthoflongestsubstring",{"2":{"78":1}}],["length",{"2":{"6":1,"7":1,"13":2,"31":1,"35":4,"38":2,"82":2,"83":4}}],["layer",{"2":{"702":1}}],["layers提取整张图片的特征",{"2":{"373":1}}],["lasso回归",{"2":{"657":1}}],["lastindexof",{"2":{"220":1}}],["lambda",{"2":{"618":2}}],["laplace",{"2":{"568":2}}],["label>",{"2":{"774":1}}],["label的均值",{"2":{"470":1}}],["label",{"2":{"422":1,"502":1,"703":2}}],["lab",{"0":{"383":1,"409":1,"410":1,"413":1},"2":{"385":1}}],["latest",{"2":{"203":1}}],["la",{"2":{"44":4}}],["ladderlength",{"2":{"35":1}}],["lang=",{"2":{"796":1}}],["langle",{"2":{"635":4,"735":1}}],["language",{"2":{"527":1,"718":1}}],["lang",{"2":{"26":1}}],["largesubset",{"2":{"3":1}}],["light",{"2":{"464":1}}],["lightgbm中则需要指定类别特征名称",{"2":{"497":1}}],["lightgbm中对离散特征实行的是many",{"2":{"470":1}}],["lightgbm则是使用按叶子生长",{"2":{"497":1}}],["lightgbm和catboost都是目前经典的sota",{"2":{"497":1}}],["lightgbm里默认的训练决策树时使用直方图算法",{"2":{"497":1}}],["lightgbm提供一种数据类型的封装相对numpy",{"2":{"497":1}}],["lightgbm如何处理类别特征",{"2":{"473":1}}],["lightgbm在leaf",{"2":{"471":1}}],["lightgbm的优缺点",{"0":{"471":1}}],["lightgbm的efb算法将这个问题转化为图着色的问题来求解",{"2":{"468":1}}],["lightgbm是基于偏差的算法",{"2":{"471":1}}],["lightgbm是怎么支持类别特征",{"0":{"470":1}}],["lightgbm是一个梯度",{"2":{"464":1}}],["lightgbm采用leaf",{"2":{"466":1}}],["lightgbm面试题",{"0":{"463":1},"1":{"464":1,"465":1,"466":1,"467":1,"468":1,"469":1,"470":1,"471":1,"472":1,"473":1}}],["lightgbm",{"0":{"445":1,"495":1},"2":{"464":2,"473":2,"490":1,"497":1}}],["li",{"2":{"227":1}}],["liuxiao214",{"2":{"414":1}}],["liu",{"2":{"203":1}}],["like",{"2":{"169":1}}],["lib",{"2":{"112":2}}],["lines",{"2":{"770":1}}],["line",{"2":{"769":2,"784":4}}],["linear",{"2":{"319":1,"635":1,"654":1}}],["linux中的grep命令",{"2":{"769":1}}],["linux基础",{"2":{"767":1}}],["linux",{"2":{"303":1}}],["linuxidc",{"2":{"303":1}}],["linjcai",{"2":{"272":1}}],["linklist",{"0":{"63":1},"1":{"64":1,"65":1,"66":1,"67":1,"68":1,"69":1,"70":1,"71":1,"72":1,"73":1}}],["lintcode",{"2":{"16":1}}],["lists",{"2":{"186":1,"769":1}}],["listen",{"2":{"114":1}}],["listnode",{"2":{"66":3,"67":3,"69":2,"72":1}}],["list",{"2":{"51":15,"53":12,"60":4,"80":3,"90":2,"769":3}}],["lis",{"2":{"1":1}}],["l+1",{"2":{"6":1,"48":4}}],["l++",{"2":{"6":1}}],["l",{"2":{"6":4,"41":6,"48":6,"52":5,"367":1,"496":6,"497":2,"519":2,"536":2,"635":3,"661":1,"668":2,"682":1,"756":5}}],["lt",{"0":{"365":1,"368":1,"369":1,"374":1,"378":1,"383":1,"385":1,"389":1,"390":1,"396":1,"397":2,"399":1,"404":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1},"2":{"1":1,"7":1,"15":1,"18":1,"34":2,"58":2,"81":2,"89":1,"189":1,"274":8,"279":1,"367":2,"372":1,"385":1,"390":2,"422":2,"519":4,"532":2,"545":2,"591":1,"634":1,"635":2,"638":1,"697":14,"763":3,"776":12}}],["这中间的省略号",{"2":{"769":1}}],["这棵树的每个结点的所有儿子很显然地按照其字母大小排序",{"2":{"763":1}}],["这棵树如图所示",{"2":{"94":1}}],["这棵树如图所",{"2":{"94":1}}],["这10个文件归并排序",{"2":{"748":1}}],["这应该也是用gbdt的原因",{"2":{"741":1}}],["这次",{"2":{"722":1}}],["这次实验就作废",{"2":{"279":1}}],["这么做的好处是最直观",{"2":{"684":1}}],["这么做确保读请求结束",{"2":{"199":1}}],["这让整个逻辑回归都有理可据",{"2":{"670":1}}],["这k个数据点",{"2":{"651":1}}],["这使它成为实质上的非线性分类器",{"2":{"634":1}}],["这大概是朴素贝叶斯应用最多的地方了",{"2":{"625":1}}],["这大大限制了id3的用途",{"2":{"600":1}}],["这和完形填空颇有点异曲同工之妙",{"2":{"719":1}}],["这和",{"2":{"604":1}}],["这四类样本的比例各不相同",{"2":{"591":1}}],["这将分裂簇并降低聚类的总see",{"2":{"685":1}}],["这将消除当前对总平方误差影响最大的点",{"2":{"685":1}}],["这将导致非连续的内存访问",{"2":{"514":1}}],["这将针对所",{"2":{"512":1}}],["这未必完全是对的",{"2":{"484":1}}],["这32个bin中最优划分的阈值的左边或者右边所有的bin容器就是一个many集合",{"2":{"470":1}}],["这b个数据乘以权重1−ab",{"2":{"467":1}}],["这意味着",{"2":{"459":1}}],["这意味着我们读写数据都是在内存中完成",{"2":{"202":1}}],["这也证明了wide",{"2":{"732":1}}],["这也就要求样本线性可分",{"2":{"634":1}}],["这也就是为什么在高维稀疏特征的时候",{"2":{"502":1}}],["这也是很好的性质",{"2":{"670":1}}],["这也是我们常说的过拟合",{"2":{"502":1}}],["这也是xgboost异于传统gbdt的一个特性",{"2":{"497":1,"513":1}}],["这也是xgboost优于传统gbdt的一个特性",{"2":{"497":1,"513":1}}],["这也使得模型变得更加具有通用性",{"2":{"451":1}}],["这也意味着小目标被检测出的概率变小",{"2":{"403":1}}],["这导致估计梯度在特征空间的任何域中的分布与该域中梯度的真实分布相比发生了偏移",{"2":{"447":1}}],["这在显存或内存上有较高开销",{"2":{"422":1}}],["这显然是对最终的图像的分类是有益的",{"2":{"392":1}}],["这部分称为base",{"2":{"386":1}}],["这可以提高定位的准确率",{"2":{"383":1}}],["这些盒子会通过不同的方式进行对齐",{"2":{"784":1}}],["这些元素让页面的内容结构化",{"2":{"775":1}}],["这些概率值可以快速的根据增量数据进行更新",{"2":{"623":1}}],["这些规则是我们通过经验总结出来的",{"2":{"597":1}}],["这些特征在其它的神经元的随机子集中也存在",{"2":{"564":1}}],["这些约束便是从训练数据的过程中学习得到的",{"2":{"521":1}}],["这些样本利用单个学习算法生成一组模型",{"2":{"459":1}}],["这些default",{"2":{"385":1}}],["这些都是可学习的参数",{"2":{"314":1}}],["这些请求会调用内核中可以调度i",{"2":{"301":1}}],["这些操作都在内存中进行",{"2":{"202":1}}],["这段共享内存由一个进程创建",{"2":{"293":1}}],["这道题是正确的是事件c",{"2":{"282":1}}],["这条曲线就是roc曲线",{"2":{"591":1}}],["这条数据就加入分裂后的左子树",{"2":{"470":1}}],["这条法律颁布之后的若干年村子的男女比例将会多少",{"2":{"276":1}}],["这条路径是指",{"2":{"94":1}}],["这时",{"2":{"636":1}}],["这时分母也要记得加上n",{"2":{"618":1}}],["这时候我们就通过object",{"2":{"796":1}}],["这时候会取到原来的state",{"2":{"793":1}}],["这时候可以用manova计算",{"2":{"684":1}}],["这时候考虑使用密度聚类",{"2":{"680":1}}],["这时候选用线性核",{"2":{"640":1}}],["这时候就要用梯度啦",{"2":{"515":1}}],["这时候一阶导数是y",{"2":{"470":1}}],["这时候两个网络还没有共享卷积层",{"2":{"373":1}}],["这时使用随机梯度下降法能够加快梯度的计算",{"2":{"321":1}}],["这时深度指的是module的个数",{"2":{"311":1}}],["这时即使把处理机分配给进程也无法运行",{"2":{"291":1}}],["这时就排除了1",{"2":{"274":1}}],["这时天平会出现3种情况",{"2":{"270":1}}],["这时也可以�",{"2":{"189":1}}],["这两种回归均通过在损失函数中引入正则化项来达到目的",{"2":{"657":1}}],["这两步和原来一样",{"2":{"199":2}}],["这两个损失函数的目的都是增加对分类影响较大的数据点的权重",{"2":{"641":1,"672":1}}],["这两个过程都是分开的",{"2":{"327":1}}],["这两个列",{"2":{"162":1}}],["这两个字节码",{"2":{"140":1}}],["这就称为回流",{"2":{"786":1}}],["这就完成了堆排序",{"2":{"756":1}}],["这就出现了所有的外排序",{"2":{"755":1}}],["这就出现请求a更新缓存应该比请求b更新缓存早才对",{"2":{"196":1}}],["这就达到了分类的目的",{"2":{"660":1}}],["这就意味着需要回溯判断的树分支就会更多",{"2":{"651":1}}],["这就容易造成在较小的区间里预测值产生较大的波动",{"2":{"562":1}}],["这就使得最终集成得泛化性能可通过个体学习器之间差异度得增加而进一步提升",{"2":{"492":1}}],["这就导致了脏数据",{"2":{"196":1}}],["这就是为什么mapreduce在业界流行",{"2":{"769":1}}],["这就是划分",{"2":{"763":1}}],["这就是上述问题的抽象",{"2":{"763":1}}],["这就是我们最长用到的归并排序",{"2":{"760":1}}],["这就是回归的由来",{"2":{"654":1}}],["这就是均方误差",{"2":{"580":1}}],["这就是无向图的联通块问题",{"2":{"33":1}}],["这就是贪心的思想",{"2":{"17":1}}],["这�",{"2":{"173":1}}],["这相当�",{"2":{"136":1}}],["这一策略要求同一标签数据不能排列在一起",{"2":{"446":1}}],["这一中间层结构",{"2":{"423":1}}],["这一经典算法的优势",{"2":{"200":1}}],["这一点很重要",{"2":{"85":1,"86":1}}],["这一个的都步数一",{"2":{"35":1}}],["这样又得到了5000个文件",{"2":{"749":1}}],["这样得到了10个排好序的文件",{"2":{"748":1}}],["这样新生成的文件每个的大小大约也1g",{"2":{"748":1}}],["这样处理后",{"2":{"747":1}}],["这样每个文件大概是200k左右",{"2":{"749":1}}],["这样每个小文件的大约为300m",{"2":{"747":1}}],["这样每经过一个传输轮次",{"2":{"243":1}}],["这样对每一个测试样本就得到了不一样的权重向量",{"2":{"657":1}}],["这样会影响最后的分类",{"2":{"650":1}}],["这样当有一个新的样本要来的时候",{"2":{"643":1}}],["这样针对k个类可以训练出k个分类器",{"2":{"643":1}}],["这样使得求解的难度大大降低",{"2":{"638":1}}],["这样超平面的两个参数",{"2":{"635":1}}],["这样w∗就求出来",{"2":{"635":1}}],["这样一直重复检索",{"2":{"651":1}}],["这样一来",{"2":{"591":1}}],["这样一周时间的实验给公司造成10",{"2":{"573":1}}],["这样损失未免有点大",{"2":{"573":1}}],["这样权值的更新不再依赖于有固定关系的隐含节点的共同作用",{"2":{"564":1}}],["这样做的优点在于可预测最终模型的变化趋势",{"2":{"546":1}}],["这样做会降低系统性能",{"2":{"297":1}}],["这样也就解决了memm中的标记偏置问题",{"2":{"520":1}}],["这样也导致脏数据",{"2":{"198":1}}],["这样在样本特征维度很高的时候",{"2":{"485":1}}],["这样在有限资源下",{"2":{"423":1}}],["这样需要绑定的特征就是在图着色问题中要涂上同一种颜色的那些点",{"2":{"468":1}}],["这样造成的结果是",{"2":{"440":1}}],["这样的超平面有无穷多个",{"2":{"642":1}}],["这样的好处就是可以进一步将用户打散",{"2":{"572":1}}],["这样的不稳定学习器更适合作为基分类器",{"2":{"460":1}}],["这样的方式",{"2":{"439":1}}],["这样的话x可以取两个值y+1",{"2":{"267":1}}],["这样的话",{"2":{"184":1,"635":1,"739":1}}],["这样的话猫b的萌系数就会减去猫a的萌系数",{"2":{"27":1}}],["这样主题关键词更具区分性",{"2":{"422":1}}],["这样可提高proposal的准确率",{"2":{"403":1}}],["这样可以保证更好的并行计算",{"2":{"770":1}}],["这样可以忽略掉分母",{"2":{"631":1}}],["这样可以避免保存整个注意力矩阵",{"2":{"422":1}}],["这样可以从不同大小的方框得到固定大小的相应的feature",{"2":{"368":1}}],["这样可以防止攻击用户反复用同一个id暴力攻击",{"2":{"189":1}}],["这样可以确保事务读取的行",{"2":{"162":1}}],["这样可以提高系统的并发量",{"2":{"133":1}}],["这样可以大大减少使�",{"2":{"124":1}}],["这样基本不增加计算量",{"2":{"374":1}}],["这样有利于gpu的并行计算",{"2":{"311":1}}],["这样不会阻塞请求了",{"2":{"199":1}}],["这样就一定会+2�",{"2":{"793":1}}],["这样就可以避免梯度消失问题",{"2":{"703":1}}],["这样就增加的模型的复杂度来更好的拟合非线性数据",{"2":{"657":1}}],["这样就造成了下溢出",{"2":{"619":1}}],["这样就能找到应该属于的类别了",{"2":{"612":1}}],["这样就不会出现超时",{"2":{"243":1}}],["这样就出现脏数据了",{"2":{"198":1}}],["这样就避免了再建单列索引",{"2":{"168":1}}],["这样即当不同机子上的请求打过来的时候能够保证某一时刻只能有一个请求去消费资源",{"2":{"184":1}}],["这样能够节省大量索引空�",{"2":{"169":1}}],["这样空闲的内存都是连续的",{"2":{"110":1}}],["这样",{"2":{"110":1,"244":1,"373":1,"730":1,"748":1}}],["这样我们就可以单独都对每一位进行相乘计算把结果存入相应的index",{"2":{"83":1}}],["这种情况只会+1",{"2":{"793":1}}],["这种情况怎么处理",{"0":{"404":1}}],["这种编程模式很简单",{"2":{"769":1}}],["这种思想可以转为位图排序",{"2":{"759":1}}],["这种函数是一个或多个称为回归系数的模型参数的线性组合",{"2":{"654":1}}],["这种综合起来取平均的策略通常可以有效防止过拟合问题",{"2":{"564":1}}],["这种较大的波动也反映了在这个区间里的导数很大",{"2":{"562":1}}],["这种对比学习目标确保模型既能",{"2":{"423":1}}],["这种差异如何帮助改进主题表示的质量",{"2":{"422":1}}],["这种预训练方式如何帮助模型在下游的文本分类任务中获得更好的性能",{"2":{"422":1}}],["这种均值是一种对类簇中心的描述",{"2":{"396":1}}],["这种中断是一种需要内核为正在运行的进程去做一些事情",{"2":{"301":1}}],["这种进程称之为僵尸进程",{"2":{"294":1}}],["这种方法效率是比较高的",{"2":{"763":1}}],["这种方法迭代速度就很慢",{"2":{"545":1}}],["这种方法让模型学会理解整个句子的意思",{"2":{"422":1}}],["这种方法后面研究工作用的不多",{"2":{"370":1}}],["这种方法理论上可行",{"2":{"279":1}}],["这种方式通过缩小搜索空间的方式优化协同过滤算法",{"2":{"730":1}}],["这种方式能提升系统响应效率",{"2":{"423":1}}],["这种方式称为轮询",{"2":{"302":1}}],["这种方式非常适合�",{"2":{"192":1}}],["这种题目没有什么好的方法",{"2":{"266":1}}],["这种锁的",{"2":{"185":1}}],["这种结构存在对存储空间的极大浪费",{"2":{"57":1}}],["这种子序列不一定是连续的或者唯一",{"2":{"1":1}}],["这是",{"2":{"792":1}}],["这是主要的功能",{"2":{"769":1}}],["这是协同过滤中最大的问题",{"2":{"730":1}}],["这是最简单的基于user的协同过滤算法",{"2":{"727":1}}],["这是最短路",{"2":{"92":1}}],["这是大模型所没有的",{"2":{"703":1}}],["这是hard",{"2":{"634":1}}],["这是因为huffman树对于高频词会赋予更短的编码",{"2":{"725":1}}],["这是因为",{"2":{"573":1}}],["这是因为越到深层",{"2":{"311":1}}],["这是用为什么gbdt会比rf慢的主要原因之一",{"2":{"497":1}}],["这是为什么",{"2":{"422":1}}],["这是拓扑排序的一种应用",{"2":{"61":1}}],["这是一个等比数列",{"2":{"280":1}}],["这是一个端到端的检验和",{"2":{"241":1}}],["这是一个随机化算法的一",{"2":{"73":1}}],["这是一个有序的链表",{"2":{"55":1}}],["这是一个bfs的问",{"2":{"32":1}}],["这是面试中最常见的问题",{"2":{"51":1}}],["这篇文章并不介绍排序",{"2":{"50":1}}],["这个就可以解决复杂任务长时间霸占主线程导致渲染延迟�",{"2":{"792":1}}],["这个就没有办法了",{"2":{"607":1}}],["这个规则只能影响使用清除的元素本身",{"2":{"785":1}}],["这个设置和集群的个数和经验有很大关系",{"2":{"770":1}}],["这个问题",{"2":{"763":1}}],["这个数据结构是根据属性值来确定记录的位置",{"2":{"761":1}}],["这个数就是主元素",{"2":{"42":1}}],["这个也是sigmoid的功劳",{"2":{"670":1}}],["这个在进行复杂核函数计算时优势很明显",{"2":{"641":1,"672":1}}],["这个在机器学习算法里面用的很普遍",{"2":{"560":1}}],["这个结合加入松弛变量的情况再讲",{"2":{"635":1}}],["这个结构就被成为原型链�",{"2":{"212":1}}],["这个假设现实中基本上不存在",{"2":{"614":1}}],["这个假设在现实世界中是很不真实的",{"2":{"614":1}}],["这个可以是基于历史数据统计",{"2":{"613":1}}],["这个可以通过调节样本权重来改善",{"2":{"607":1}}],["这个可以通过集成学习之类的方法解决",{"2":{"607":1}}],["这个可以参考最长上升子序列",{"2":{"3":1}}],["这个技术也是c4",{"2":{"603":1}}],["这个组合",{"2":{"590":1}}],["这个指标影响的",{"2":{"536":1}}],["这个特殊情况跟cart拟合残差一模一样",{"2":{"515":1}}],["这个特性决定了索引组织表中数据也是索引的一部分",{"2":{"165":1}}],["这个直方图算法使得worker间的通信成本降低一倍",{"2":{"514":1}}],["这个bin可以说就是转换后的特",{"2":{"514":1}}],["这个block结构也使得并行成为了可能",{"2":{"497":2,"505":1,"513":1}}],["这个时候xgboost相当于带l1和l2正则化项的逻辑斯蒂回归",{"2":{"497":1}}],["这个要求每轮迭代的时候",{"2":{"497":1}}],["这个值越大越",{"2":{"496":1}}],["这个值限制了决策树的增长",{"2":{"484":1}}],["这个值限制了叶子节点最少的样本数",{"2":{"484":1}}],["这个过程是贪心算法",{"2":{"422":1}}],["这个过程中一�",{"2":{"185":1}}],["这个计算方式是对每层的feature",{"2":{"385":1}}],["这个网络真的好吗",{"0":{"413":1}}],["这个网络相比于faster",{"0":{"375":1}}],["这个网络能正常训练嘛",{"0":{"322":1}}],["这个偏差会影响检测或者分割的准确度",{"2":{"368":1}}],["这个区域的每一个神经元都是有参与前向传播了的",{"2":{"338":1}}],["这个操作可以融合之前的特征",{"2":{"318":1}}],["这个使图像由小分辨率映射到大分辨率的操作",{"2":{"312":1}}],["这个满足要求吗",{"2":{"279":1}}],["这个函数的任意返回值会作为第一个参数传给下一项�",{"2":{"220":1}}],["这个速度是非常快的",{"2":{"202":1}}],["这个异步删除缓存可以加上重试机制",{"2":{"199":1}}],["这个1秒应该看你的业务场景",{"2":{"199":1}}],["这个请求处理完之后",{"2":{"184":1}}],["这个变量是一个对象",{"2":{"112":1}}],["这个",{"2":{"110":1,"212":1,"792":1}}],["这个阈值的原因是当这次",{"2":{"110":1}}],["这个不变",{"2":{"35":1}}],["这里里面的两个思想",{"2":{"763":1}}],["这里是连接不是归并",{"2":{"758":1}}],["这里留给读者计",{"2":{"756":1}}],["这里计算时间复杂度的时候",{"2":{"756":1}}],["这里就先介绍一下这个数据结构的性质",{"2":{"756":1}}],["这里就不给出",{"2":{"1":1}}],["这里给出几个需求",{"2":{"755":1}}],["这里给出最好理解一个方",{"2":{"92":1}}],["这里使用不同的",{"2":{"689":1}}],["这里使用滚动变量表示dp",{"2":{"14":1}}],["这里涉及了几个概念",{"2":{"634":1}}],["这里的桶是文件表示",{"2":{"763":1}}],["这里的软标签就是缩放的",{"2":{"703":1}}],["这里的距离即数据点到簇中心的距离",{"2":{"675":1}}],["这里的x和y分别对应tpr和fpr",{"2":{"591":1}}],["这里的残差就是当前模型的负梯度",{"2":{"497":1}}],["这里我们对分治进行抽象",{"2":{"769":1}}],["这里我们使",{"2":{"763":1}}],["这里我们基于海量数据的考虑重新思考排序",{"2":{"755":1}}],["这里我们只介绍主要的模型",{"2":{"690":1}}],["这里我们可以算出一个最小样本量",{"2":{"573":1}}],["这里我们需要找到从root到a的路",{"2":{"92":1}}],["这里",{"2":{"532":1}}],["这里可以分成两个读取文件",{"2":{"763":1}}],["这里可以回忆一下rnn",{"2":{"527":1}}],["这里可以借鉴和最大的子序",{"2":{"14":1}}],["这里为什么不是label的均值呢",{"2":{"470":1}}],["这里不考虑bias为准",{"2":{"395":1}}],["这里假设卷积层的输出为hout∗wout∗cout因为relu函数的计算只涉及到一个判断",{"2":{"394":1}}],["这里又分为全局池化和一般池化两种情况",{"2":{"394":1}}],["这里仅谈一下网络的参数量对其的影响",{"2":{"394":1}}],["这里只考虑空间位置",{"2":{"385":1}}],["这里只给出第二种方法的代",{"2":{"95":1}}],["这里表示所有bounding",{"2":{"381":1}}],["这里参照github上作者qqwweee那个yolov3项目",{"2":{"381":1}}],["这里主要针对最近几年发展比较快的基于深度学习的目标检测算法",{"2":{"362":1}}],["这里存储的并不是实际的时间值",{"2":{"162":1}}],["这里同样给出高频而且有代表性的10道题目",{"2":{"84":1}}],["这里先不做详细解",{"2":{"73":1}}],["npm",{"2":{"800":1}}],["n表示items特征矩阵",{"2":{"730":1}}],["n表示样本",{"2":{"583":1}}],["n=",{"2":{"730":1}}],["n=1−msevarr2score又称决定系数",{"2":{"583":1}}],["n×n",{"2":{"695":1}}],["n−1",{"2":{"662":1}}],["n−2",{"2":{"519":1}}],["nγ=γ^∥w∥",{"2":{"635":1}}],["nt",{"2":{"740":1}}],["nt表示具体某个叶节点的样本数",{"2":{"602":1}}],["nthuglynumber",{"2":{"8":1}}],["n∑in",{"2":{"583":1}}],["nlp|is",{"2":{"719":1,"722":1}}],["nlp",{"2":{"689":1,"719":4,"722":1}}],["nlp问题会涉及哦",{"2":{"527":1}}],["nlp汉语自然语言处理原理与实",{"2":{"522":1}}],["nlogn",{"2":{"756":1}}],["nlog",{"2":{"1":1}}],["n^",{"2":{"519":1}}],["n的高阶无穷小",{"2":{"496":1}}],["nnlm",{"2":{"725":2}}],["nnlm在进行sigmoid归一化时需要遍历整个词汇表",{"2":{"718":1}}],["nnlm在利用上文词预测目标词时",{"2":{"718":1}}],["nnlm模型的瓶颈在sigmoid归一化上",{"2":{"719":1}}],["nnlm模型的训练速度非常慢",{"2":{"718":1}}],["nnlm模型可以被拆分成两个步骤",{"2":{"718":1}}],["nn+nm+n",{"2":{"699":1}}],["nn",{"2":{"458":1}}],["nms算法",{"2":{"397":1}}],["nms为非极大值抑制",{"2":{"397":1}}],["nms实现细节",{"0":{"397":1}}],["nms",{"0":{"397":1},"2":{"397":3}}],["n只老鼠可以最多检验2^n个瓶子",{"2":{"269":1}}],["nav",{"2":{"776":1}}],["nav>",{"2":{"775":1}}],["naive",{"2":{"614":2}}],["nag",{"2":{"308":1}}],["native",{"2":{"211":7}}],["name",{"2":{"211":2,"214":5,"223":1,"249":1}}],["name=",{"2":{"163":1}}],["nan",{"2":{"210":2,"211":1}}],["n2",{"2":{"83":3,"92":1}}],["n1+n2+2",{"2":{"83":1}}],["n1",{"2":{"83":3,"92":1}}],["n+2p−fs+1",{"2":{"695":2}}],["n+256",{"2":{"82":1}}],["n+rn",{"2":{"496":1}}],["n+1",{"2":{"9":1,"496":1}}],["nucdy",{"2":{"652":1}}],["null",{"2":{"48":1,"55":4,"56":10,"85":4,"87":2,"88":1,"90":1,"91":2,"92":1,"94":1,"144":2,"186":1,"189":1,"210":2,"211":1,"223":1}}],["numel",{"2":{"397":4}}],["num2",{"2":{"83":10}}],["num1的第i",{"2":{"83":1}}],["num1",{"2":{"83":10}}],["number",{"2":{"76":3,"210":2,"211":3}}],["numbers",{"2":{"21":3}}],["numislands",{"2":{"33":1}}],["num",{"2":{"19":13,"470":1,"689":3}}],["nums",{"2":{"1":5,"14":9,"18":4,"23":8,"29":9,"30":10,"47":9}}],["noise",{"2":{"558":1}}],["no进行特征选择",{"2":{"497":1}}],["nonzero",{"2":{"397":1}}],["non",{"0":{"397":1},"2":{"397":2}}],["none",{"2":{"64":1,"65":1,"66":2,"67":8,"69":4,"70":7,"71":4,"72":1,"73":1,"484":1,"785":1,"786":1}}],["normalization可以从model中去掉dropout",{"2":{"378":1}}],["normalization的作用",{"0":{"351":1}}],["normalization",{"2":{"305":1,"307":1,"698":1}}],["no",{"2":{"193":1}}],["notify",{"2":{"139":1}}],["not",{"2":{"34":1,"69":1,"214":1,"245":1,"258":1}}],["nodes",{"2":{"484":1}}],["node为每个模块提供一个exports变量",{"2":{"112":1}}],["nodejs",{"0":{"107":1,"108":1,"109":1,"113":1},"1":{"108":1,"109":2,"110":2,"111":2,"112":2,"113":1,"114":2},"2":{"109":1,"207":1}}],["node>",{"2":{"32":1}}],["node",{"2":{"32":6,"55":9,"56":14,"65":1,"70":1,"71":2,"85":18,"86":3,"88":1,"89":2,"91":3,"92":2,"94":9,"95":1,"109":2,"112":1}}],["nowrap",{"2":{"782":1}}],["now=r",{"2":{"756":1}}],["now=l",{"2":{"756":1}}],["nowcoder",{"2":{"414":6}}],["now+s",{"2":{"31":1}}],["now",{"2":{"31":3,"34":8,"37":13,"52":9,"756":6}}],["nerual",{"2":{"718":1}}],["neural",{"2":{"689":1}}],["neighbor",{"2":{"651":1}}],["nears",{"2":{"651":1}}],["nearest",{"2":{"368":1}}],["negative",{"0":{"721":1,"724":1},"2":{"423":1,"586":2,"725":4}}],["neck进行高低层特征的传递与融合",{"2":{"362":1}}],["neck",{"2":{"362":1}}],["netword",{"2":{"521":1}}],["networks",{"2":{"689":1}}],["network",{"2":{"386":1,"718":1}}],["networking",{"2":{"258":1}}],["net",{"2":{"203":1,"253":1,"259":1,"272":1,"284":2,"303":1,"399":1,"414":6,"473":2,"499":2,"517":2,"558":1,"568":1,"644":1,"652":5,"664":1,"665":1,"686":1,"725":1,"743":2,"753":2}}],["nextres",{"2":{"218":3}}],["next为空",{"2":{"68":1}}],["next",{"2":{"22":4,"55":3,"59":4,"64":9,"65":5,"66":6,"67":20,"68":6,"69":10,"70":8,"71":11,"72":8,"73":2,"114":8}}],["newvalue",{"2":{"796":3}}],["newresult",{"2":{"218":1}}],["new",{"0":{"224":2},"2":{"22":2,"53":1,"59":2,"67":7,"80":2,"82":1,"83":2,"90":1,"110":1,"111":1,"114":1,"144":1,"211":2,"217":7,"224":4,"760":1,"800":1}}],["n",{"0":{"699":1},"2":{"1":1,"3":4,"6":7,"7":10,"8":3,"9":5,"10":3,"11":1,"12":6,"15":3,"18":1,"23":6,"27":1,"31":4,"33":2,"34":1,"40":5,"42":6,"43":7,"45":6,"46":2,"48":3,"52":6,"54":4,"56":3,"60":1,"61":10,"80":11,"89":2,"93":1,"120":1,"307":1,"390":17,"397":8,"422":2,"423":1,"431":2,"483":1,"484":1,"496":4,"519":1,"527":1,"533":3,"537":1,"545":1,"612":2,"635":30,"649":1,"654":1,"662":1,"686":1,"689":1,"730":5,"756":9,"757":1,"759":2,"763":1}}],["dl>�",{"2":{"774":1}}],["dlinkedlist",{"2":{"70":1}}],["d为用户特征矩阵",{"2":{"730":1}}],["dvd",{"2":{"730":1}}],["d指语料库",{"2":{"719":1}}],["dk",{"2":{"703":2}}],["ddydavie",{"2":{"665":1}}],["d树",{"2":{"648":1}}],["d0和d1是n维欧氏空间中的两个点集",{"2":{"634":1}}],["dtλ",{"2":{"603":1}}],["dt+",{"2":{"603":1}}],["dt−",{"2":{"603":1}}],["dt是指decision",{"2":{"497":1}}],["d~v",{"2":{"601":1}}],["d~",{"2":{"601":3}}],["d^v$",{"2":{"601":1}}],["d$中在特征$a$上取值为$a",{"2":{"601":1}}],["d$中属于第$k$类的样本子集",{"2":{"601":1}}],["d$",{"2":{"601":1}}],["dx",{"2":{"591":1}}],["d=",{"2":{"455":1,"475":1}}],["d=1−iou",{"2":{"381":1}}],["daily",{"2":{"850":1}}],["dart树",{"2":{"497":1}}],["darknet",{"2":{"378":1}}],["date",{"2":{"210":1,"211":3}}],["datawhale",{"2":{"850":1}}],["datawhalechina",{"2":{"850":1}}],["data�",{"2":{"796":1}}],["database",{"2":{"259":1}}],["datastruct",{"2":{"203":1}}],["data",{"2":{"55":1,"62":1,"84":4,"93":7,"96":1,"217":12,"223":7,"497":2,"796":4}}],["dw卷积",{"2":{"357":1}}],["dnn",{"2":{"738":1}}],["dnn的梯度更新方式",{"2":{"356":1}}],["dnn的梯度是如何更新的",{"0":{"356":1}}],["dnn的输入是向量形式",{"2":{"355":1}}],["dns的具体过程",{"0":{"249":1}}],["dns",{"2":{"235":3}}],["dropout如何平衡训练和测试时的差异呢",{"0":{"566":1}}],["dropout在训练时采用",{"2":{"565":1}}],["dropout在训练和测试时都需要吗",{"0":{"565":1}}],["dropout类似于性别在生物进化中的角色",{"2":{"564":1}}],["dropout掉不同的隐藏神经元就类似在训练不同的网络",{"2":{"564":1}}],["dropout为什么有助于防止过拟合",{"0":{"564":1}}],["dropout为什么能解决过拟合",{"0":{"332":1}}],["dropout",{"2":{"307":1,"325":1,"561":1,"566":1}}],["draveness",{"2":{"253":1}}],["dunns",{"2":{"684":1}}],["durability持久性",{"2":{"258":1}}],["dump",{"2":{"192":1}}],["dummy",{"2":{"69":4}}],["dbscan",{"2":{"422":2,"674":1}}],["db2等",{"2":{"258":1}}],["db",{"2":{"203":1}}],["d+1",{"2":{"89":1}}],["dirname",{"2":{"800":1}}],["direction",{"2":{"782":1}}],["direct",{"2":{"423":1}}],["directory找到数据行",{"2":{"165":1}}],["directed",{"2":{"60":1}}],["div>",{"2":{"796":1}}],["div>�",{"2":{"774":1}}],["div",{"2":{"785":1,"796":1}}],["diam",{"2":{"684":1}}],["diagonal",{"2":{"89":1}}],["diagorder",{"2":{"89":1}}],["diagorderutil",{"2":{"89":4}}],["diagvec",{"2":{"89":8}}],["dimension",{"2":{"651":1}}],["display",{"2":{"786":1}}],["displaystyle",{"2":{"735":1}}],["discrete",{"2":{"525":1}}],["discuss",{"2":{"414":6}}],["distance",{"2":{"58":1,"59":1,"527":1}}],["dist",{"2":{"58":31,"59":10,"800":2}}],["difference",{"2":{"318":1}}],["dilated",{"2":{"306":1}}],["dilation",{"2":{"306":1}}],["dijstra",{"2":{"58":1,"59":1}}],["dijkstra",{"2":{"58":1}}],["dict",{"2":{"35":4}}],["dependency",{"2":{"527":1}}],["depthwise",{"0":{"357":1}}],["depth+1",{"2":{"93":2}}],["depth",{"2":{"93":10,"484":1,"507":1}}],["delta",{"2":{"509":1}}],["deleteduplicates",{"2":{"66":1,"67":2}}],["delete",{"2":{"53":1,"174":1,"184":1}}],["dense",{"2":{"423":1}}],["densehead",{"2":{"362":1}}],["detection的开山之作",{"2":{"378":1}}],["detector",{"2":{"361":2}}],["details",{"2":{"203":1,"259":1,"272":1,"284":2,"303":1,"414":6,"473":2,"499":2,"517":2,"558":1,"568":1,"644":1,"652":5,"664":1,"665":1,"686":1,"725":1,"743":2,"753":2}}],["deep模型",{"2":{"738":1}}],["deep模型的改进",{"2":{"732":1}}],["deep与deepfm的区别",{"2":{"738":1}}],["deep部分是一个前向传播的神经网络",{"2":{"736":1}}],["deep部分",{"0":{"736":1}}],["deep不同的是",{"2":{"734":1}}],["deep这种模型架构的有效性",{"2":{"732":1}}],["deeplearn",{"2":{"666":1}}],["deeplearning",{"2":{"358":1,"556":1}}],["deep",{"2":{"423":1,"738":1}}],["deepseek蒸馏r1推理能力的方法",{"2":{"423":1}}],["deepseek",{"2":{"423":8}}],["deepfm的wide部分与deep部分分别是什么",{"2":{"738":1}}],["deepfm的模型结构非常简单",{"2":{"733":1}}],["deepfm模型的wide部分就直接使用了fm",{"2":{"735":1}}],["deepfm模型是将wide部分替换为了fm模型",{"2":{"732":1}}],["deepfm模型是2017年由哈工大与华为联合提出的模型",{"2":{"732":1}}],["deepfm中的wide部分与deep部分共享了输入特征",{"2":{"734":1}}],["deepfm是一种端到端的模型",{"2":{"732":1}}],["deepfm",{"0":{"732":1},"1":{"733":1,"734":1,"735":1,"736":1,"737":1,"738":1},"2":{"420":1}}],["deepcopy",{"2":{"223":2}}],["descriptor",{"2":{"796":3}}],["descending=true",{"2":{"397":1}}],["design",{"2":{"253":1}}],["dest",{"2":{"22":2,"59":2}}],["decoder",{"2":{"690":1,"702":3,"710":1}}],["decoding",{"2":{"423":1,"519":1}}],["decision",{"2":{"497":1,"739":1}}],["dec",{"2":{"94":3}}],["defineproperty",{"2":{"796":4}}],["defined",{"2":{"214":1}}],["deformable",{"2":{"361":1}}],["default",{"2":{"75":1}}],["def",{"2":{"64":1,"65":1,"66":2,"67":3,"68":1,"69":5,"70":3,"71":2,"72":1,"73":1,"390":1,"397":1}}],["degree",{"2":{"60":4}}],["deque",{"2":{"47":1}}],["doctype",{"2":{"796":1}}],["documentelement",{"2":{"229":2}}],["document",{"2":{"228":1,"229":4,"776":2,"796":3}}],["dots",{"2":{"601":1,"612":1}}],["downsamples",{"2":{"382":2}}],["dom2",{"2":{"226":1}}],["dom0",{"2":{"226":1}}],["dom",{"0":{"225":1,"790":1},"1":{"226":1,"227":1,"228":1,"229":1},"2":{"226":1,"787":1,"790":10,"792":2}}],["dosomething",{"2":{"218":1}}],["dofinalthing",{"2":{"218":2}}],["donext",{"2":{"218":2}}],["dog这样的特征",{"2":{"446":1}}],["dog看门狗",{"2":{"185":1}}],["dog",{"2":{"74":1,"185":1}}],["doesn",{"2":{"59":1}}],["do",{"2":{"44":1}}],["double",{"2":{"44":2}}],["dfs",{"2":{"30":2,"31":3,"33":6,"34":7,"36":6,"37":8,"100":1,"104":1}}],["dfs的相关的题目",{"2":{"28":1}}],["dynamic",{"2":{"16":1}}],["d",{"2":{"1":1,"6":2,"36":2,"58":3,"59":3,"61":6,"89":3,"214":2,"381":3,"428":3,"431":1,"536":2,"545":1,"601":2,"603":5,"721":9,"735":2,"758":2,"759":2,"761":2}}],["dpo",{"2":{"423":4}}],["dpm",{"2":{"361":1}}],["dp转化",{"2":{"13":1}}],["dp+n",{"2":{"3":1}}],["dp",{"0":{"0":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1},"2":{"1":13,"2":14,"3":10,"4":12,"5":17,"6":11,"7":4,"8":7,"9":16,"11":15,"13":20,"15":8}}],["a>�",{"2":{"774":1}}],["a0",{"2":{"747":1}}],["a999",{"2":{"747":2}}],["a用来训练gbdt",{"2":{"741":1}}],["agnes",{"2":{"674":1}}],["age",{"2":{"211":2}}],["age=",{"2":{"163":1}}],["a3对应的样本",{"2":{"604":1}}],["a3和a1",{"2":{"604":1}}],["a3和a5是夫妇",{"2":{"268":1}}],["a3",{"2":{"601":2,"604":3,"612":1}}],["akenseren",{"2":{"568":1}}],["aj|yi",{"2":{"612":3}}],["aj",{"2":{"532":2}}],["a4v9n",{"2":{"517":1}}],["a4和甲是夫妇",{"2":{"268":1}}],["a特征的原始取值为区间",{"2":{"469":1}}],["a与b差距越大特征i越重要",{"2":{"462":1}}],["am",{"2":{"612":1}}],["am∗=12log1−emem其中em是分类误差率",{"2":{"430":1}}],["amp",{"0":{"575":1},"2":{"188":1,"414":2,"635":2,"684":1,"732":2,"734":1,"738":2,"756":2}}],["audio",{"2":{"776":2}}],["auc=∫t=∞−∞y",{"2":{"591":1}}],["auc",{"0":{"591":1},"2":{"591":1}}],["author",{"0":{"524":1},"2":{"518":1}}],["auto",{"2":{"19":1,"89":2,"94":2,"782":1}}],["augmented",{"2":{"423":1}}],["ai+ai+12|1≤i≤n−1",{"2":{"603":1}}],["ai+1",{"2":{"603":2}}],["ai算法",{"0":{"415":1},"1":{"416":1,"417":1,"418":1,"419":1,"420":1,"421":1},"2":{"845":1,"848":1}}],["ai",{"0":{"409":1,"410":1},"2":{"422":2,"423":3,"603":2}}],["aw1",{"2":{"473":1}}],["awesome",{"2":{"358":1}}],["await",{"0":{"218":1},"2":{"114":2,"218":11}}],["attention",{"0":{"701":1,"702":1},"1":{"702":1,"703":1},"2":{"422":7,"702":3}}],["attention机制的作用",{"0":{"353":1}}],["atomic",{"2":{"135":1,"784":1}}],["atomic下的原子变量类就是使用了乐观锁的一种实现方�",{"2":{"133":1}}],["average",{"0":{"339":1},"2":{"338":1,"339":2,"689":1}}],["afkjgouj",{"2":{"284":1}}],["a|c",{"2":{"282":3}}],["a＞x",{"2":{"274":1}}],["a=1",{"2":{"274":1}}],["a7必须和除了a0和自己配偶以外的所有人握手",{"2":{"268":1}}],["a8和a0是夫妇",{"2":{"268":1}}],["a8",{"2":{"268":1}}],["a才可能知道自己是3",{"2":{"267":1}}],["a是3",{"2":{"267":1}}],["a是否为数�",{"2":{"220":1}}],["a确定自己是3",{"2":{"267":1}}],["a说我知道了",{"2":{"267":1}}],["a看到b头上的y",{"2":{"267":1}}],["aof开启后",{"2":{"193":1}}],["aof日志一般比rdb快照更大",{"2":{"193":1}}],["aof的备份策�",{"2":{"193":1}}],["aof的出现是为了弥补rdb备份的不足",{"2":{"193":1}}],["aof持久化是以日志的形式记录记录每一个增删操作然后追加到文件中",{"2":{"193":1}}],["aof",{"0":{"193":1},"2":{"192":1}}],["aop",{"0":{"178":1}}],["ahead",{"2":{"173":1}}],["action",{"2":{"829":1}}],["acc与error平等对待每个类别",{"2":{"585":1}}],["acc",{"2":{"585":1}}],["accept",{"2":{"202":1}}],["ack",{"2":{"237":1,"242":1}}],["acid分别是atomic原子性",{"2":{"258":1}}],["acid",{"0":{"166":1}}],["acyclic",{"2":{"60":1}}],["api�",{"0":{"220":1}}],["api",{"0":{"225":1},"1":{"226":1,"227":1,"228":1,"229":1},"2":{"137":1,"139":1,"220":2,"422":1,"792":3}}],["app种类",{"2":{"732":1}}],["app种类与时间戳",{"2":{"732":1}}],["app",{"2":{"114":5,"796":1}}],["apply",{"0":{"213":1},"2":{"111":1,"213":2}}],["appendsync",{"2":{"193":1}}],["appendfsync",{"2":{"193":2}}],["append",{"2":{"83":1,"193":1,"397":2,"758":1}}],["a�",{"2":{"134":1}}],["aside",{"2":{"776":2}}],["aside>",{"2":{"775":1}}],["assign",{"2":{"793":1}}],["assistant",{"2":{"422":1}}],["asstring",{"2":{"769":1}}],["assert",{"2":{"756":2}}],["as",{"2":{"532":1}}],["aspect",{"2":{"367":1,"385":1}}],["ascii",{"2":{"244":1}}],["async",{"0":{"218":1},"2":{"114":3,"218":8}}],["ash",{"2":{"62":1}}],["areas",{"2":{"397":2}}],["area2",{"2":{"390":3}}],["area1+area2",{"2":{"390":1}}],["area1",{"2":{"390":3}}],["art",{"2":{"497":1,"567":1}}],["art的效果",{"2":{"375":1}}],["article>",{"2":{"775":1}}],["article",{"2":{"203":1,"259":1,"272":1,"284":3,"303":1,"414":6,"473":2,"499":2,"517":2,"558":1,"568":1,"644":1,"652":5,"664":1,"665":1,"686":1,"725":1,"743":2,"753":2,"776":3}}],["arq协议",{"2":{"241":1}}],["arp进程在本局域网上广播发送一个arp请求分组",{"2":{"250":1}}],["arp高速缓存中查看有无主机b的ip地址",{"2":{"250":1}}],["arp协议的工作原理和流程",{"0":{"250":1}}],["arp查询",{"2":{"235":1}}],["arp",{"2":{"235":2}}],["arg⁡maxyp",{"2":{"631":1}}],["argmin",{"2":{"497":1}}],["argn",{"2":{"213":1}}],["arg2",{"2":{"213":1}}],["arg1",{"2":{"213":1}}],["argarray",{"2":{"213":1}}],["args2",{"2":{"213":1}}],["args1",{"2":{"213":1}}],["args",{"2":{"111":11}}],["arguments",{"2":{"111":1,"210":1,"213":1}}],["arr3",{"2":{"222":1}}],["array等数据对象而言节省了内存的使用",{"2":{"497":1}}],["array",{"0":{"220":1},"2":{"210":1,"211":3,"220":7,"222":2,"223":1,"757":13,"758":2,"760":12}}],["arraylist",{"2":{"80":1}}],["array�",{"0":{"39":1},"1":{"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1}}],["arr2",{"2":{"46":6,"222":1}}],["arr1",{"2":{"46":6,"222":1}}],["arr",{"2":{"3":1,"34":1,"40":17,"41":7,"42":12,"43":9,"48":16,"49":4,"222":8,"760":1}}],["a和b之间的距",{"2":{"92":1}}],["a2三种情况",{"2":{"604":1}}],["a2和a1",{"2":{"604":1}}],["a2和a6是夫妇",{"2":{"268":1}}],["a2c4ede32d11",{"2":{"253":1}}],["a2",{"2":{"81":1,"601":2,"603":1,"612":1}}],["abtest的时候怎么分组才最合理呢",{"0":{"576":1}}],["abtest我们需要知道当前用户是处于对照组还是实验组",{"2":{"575":1}}],["abtest背后的理论支撑是什么",{"0":{"571":1}}],["abtest就是为了测试和验证模型项目的效果",{"2":{"570":1}}],["ab测试面试题",{"0":{"569":1},"1":{"570":1,"571":1,"572":1,"573":1,"574":1,"575":1,"576":1,"577":1}}],["ab|c¯",{"2":{"282":1}}],["ab|c",{"2":{"282":4}}],["absolute",{"2":{"580":1}}],["abs",{"2":{"87":1}}],["aba",{"0":{"146":1},"2":{"79":1}}],["abc",{"2":{"78":1,"224":3}}],["abcabcbb",{"2":{"78":1}}],["abcced",{"2":{"36":1}}],["abce",{"2":{"36":1}}],["alpha^",{"2":{"635":2}}],["alpha",{"2":{"602":1,"635":21}}],["aligned",{"2":{"635":2}}],["align以及加了一个mask分支",{"2":{"376":1}}],["align中双线性插值计算像素值的具体方法",{"2":{"369":1}}],["alignment",{"2":{"369":1}}],["align很好地解决了roi",{"2":{"369":1}}],["align相比roi",{"2":{"369":1}}],["align的思路很简单",{"2":{"369":1}}],["align",{"0":{"369":1},"2":{"369":1,"782":1}}],["always",{"2":{"193":1}}],["alternative",{"2":{"186":1}}],["allkeys",{"2":{"200":1}}],["all",{"2":{"59":1,"217":3,"759":1}}],["algorithms",{"0":{"674":1},"2":{"62":1}}],["algorithm",{"2":{"59":2,"358":1}}],["ad",{"2":{"741":1}}],["adaboost中所有的树加权投票来决定因变量的预测值",{"2":{"489":1}}],["adaboost后面树的训练",{"2":{"489":1}}],["adaboost是基于boosting的算法",{"2":{"489":1}}],["adaboost是前向分步加法算法的特例",{"2":{"430":1}}],["adaboost和随机森林算法的异同点",{"0":{"489":1}}],["adaboost和gbdt都是通过减低偏差提高模型精度",{"2":{"436":1}}],["adaboost和gbdt之间的区别",{"0":{"436":1}}],["adaboost对噪声敏感吗",{"0":{"488":1}}],["adaboost对同一个训练样本集训练不同的弱分类器",{"2":{"487":1}}],["adaboost依赖于弱分类器",{"2":{"487":1}}],["adaboost会使得难于分类样本的权值呈指数增长",{"2":{"487":1,"488":1}}],["adaboost可以根据弱分类器的反馈",{"2":{"487":1}}],["adaboost都能显著的提高学习精度",{"2":{"487":1}}],["adaboost提供一种框架",{"2":{"487":1}}],["adaboost每一个根据前m",{"2":{"436":1}}],["adaboost的优点和缺点",{"0":{"487":1}}],["adaboost的迭代次数",{"0":{"437":1}}],["adaboost的m个基学习器是有顺序关系的",{"2":{"435":1}}],["adaboost的最终分类器是",{"2":{"430":1}}],["adaboost使用m个基学习器和加权平均使用m个学习器之间有什么不同",{"0":{"435":1}}],["adaboost算法不需要预先知道弱分类器的错误率上限",{"2":{"487":1}}],["adaboost算法不需要弱分类器的先验知识",{"2":{"487":1}}],["adaboost算法流程",{"2":{"486":1}}],["adaboost算法利用同一种基分类器",{"2":{"486":1}}],["adaboost算法中基学习器是否很重要",{"0":{"438":1}}],["adaboost算法如何加入正则项",{"0":{"434":1}}],["adaboost算法每一次都会降低整体的误差",{"2":{"433":1}}],["adaboost也能够应用到回归问题",{"2":{"431":1}}],["adaboost能否做回归问题",{"0":{"431":1}}],["adaboost分类模型的学习器的权重系数α怎么计算的",{"0":{"430":1}}],["adaboost等算法为代表的",{"2":{"425":1}}],["adaboost",{"0":{"424":1,"426":1,"427":1,"428":1,"441":1},"1":{"425":1,"426":1,"427":2,"428":2,"429":1,"430":1,"431":1,"432":1,"433":1,"434":1,"435":1,"436":1,"437":1,"438":1,"439":1,"440":1,"441":1,"442":1},"2":{"439":1,"440":2,"456":1}}],["adagrad",{"2":{"308":1}}],["adam",{"2":{"308":1}}],["add等价于concat之后对应通道共享同一个卷积核",{"2":{"392":1}}],["add是描述图像的特征下的信息量增多了",{"2":{"392":1}}],["add是特征图相加",{"2":{"392":1}}],["addition是在resnet中提出",{"2":{"318":1}}],["addition和concatenate分支操作统称为shortcut",{"2":{"318":1}}],["addeventlistener",{"0":{"226":1},"2":{"796":1,"798":2}}],["add",{"0":{"705":1},"2":{"80":1,"215":2,"318":1,"388":2,"705":1}}],["addstrings",{"2":{"38":2}}],["adj",{"2":{"60":6}}],["adee",{"2":{"36":1}}],["an",{"2":{"603":1}}],["ancos⁡",{"2":{"535":1}}],["anchors",{"2":{"402":1}}],["anchor设置的意义",{"0":{"391":1}}],["anchor高",{"2":{"382":1}}],["anchor宽",{"2":{"382":1}}],["anchor距离如何度量",{"0":{"382":1}}],["anchor的设计方式仍然使用聚类",{"2":{"378":1}}],["anchor",{"2":{"367":1,"372":1,"378":1,"381":1}}],["and",{"0":{"536":1},"2":{"26":1,"62":1,"64":2,"65":1,"67":2,"68":1,"71":1,"134":1,"163":1,"318":2,"367":1,"495":1,"686":1,"719":5,"722":1,"730":1}}],["answer",{"2":{"517":1,"563":1,"725":1}}],["anshuai",{"2":{"473":1}}],["ans+",{"2":{"80":1}}],["ans1+",{"2":{"80":1}}],["ans1",{"2":{"80":1}}],["ans=m",{"2":{"4":1}}],["ans",{"2":{"1":4,"4":4,"14":5,"15":3,"18":4,"24":4,"27":4,"29":4,"32":3,"43":5,"47":5,"73":1,"78":4,"80":3,"82":2,"86":4,"93":14,"95":5}}],["a1和a7只能是夫妇",{"2":{"268":1}}],["a1和a7是夫妇",{"2":{"268":1}}],["a1",{"2":{"22":2,"59":2,"268":1,"532":1,"603":1,"612":1,"747":2}}],["aaa",{"2":{"214":2}}],["aa",{"2":{"7":1,"81":1}}],["aab",{"2":{"7":2}}],["a+n",{"2":{"3":1}}],["a",{"2":{"1":1,"2":6,"3":6,"4":5,"5":2,"6":1,"7":2,"10":1,"12":9,"15":3,"18":1,"20":2,"21":3,"22":2,"27":8,"32":6,"34":8,"35":2,"36":3,"43":8,"44":11,"49":2,"51":2,"52":16,"59":2,"60":1,"74":1,"76":6,"81":8,"90":5,"92":7,"134":2,"163":4,"186":1,"213":5,"220":9,"253":1,"267":2,"270":2,"274":2,"280":4,"306":1,"308":1,"312":1,"313":1,"358":1,"422":1,"423":3,"496":3,"532":1,"545":4,"571":1,"601":5,"603":4,"612":1,"686":1,"697":5,"725":7,"741":3,"756":19,"761":3,"769":2,"793":1}}],["i>�",{"2":{"774":1}}],["i>j",{"2":{"757":1}}],["i>=2",{"2":{"756":1}}],["i>=1",{"2":{"756":1}}],["i>=",{"2":{"46":1}}],["i是特征i所有实例的前t次的总和",{"2":{"740":1}}],["i是特征数据",{"2":{"654":1}}],["i其中",{"2":{"740":1}}],["i其中zm是规范化因子",{"2":{"431":1}}],["i的特征",{"2":{"729":1}}],["i−bu−μ",{"2":{"730":1}}],["i−μ",{"2":{"730":1}}],["i−r",{"2":{"730":4}}],["i−r¯u2",{"2":{"730":2}}],["i−r¯u1",{"2":{"730":2}}],["i−uuvi",{"2":{"729":1,"730":1}}],["i−1",{"2":{"276":1}}],["i$的样本均值估",{"2":{"620":1}}],["i$的类条件概率等于",{"2":{"620":1}}],["i个样本个样本",{"2":{"583":1}}],["i个字符串的时候",{"2":{"74":1}}],["i表示",{"2":{"583":1}}],["iztexp⁡",{"2":{"428":1}}],["izt×",{"2":{"428":1}}],["i⋯",{"2":{"428":1}}],["img>�",{"2":{"774":1}}],["impurity",{"2":{"484":1}}],["importance",{"2":{"462":2}}],["import",{"2":{"82":1,"112":1}}],["images",{"2":{"271":1,"390":1}}],["ip统计",{"0":{"750":1}}],["ipc",{"2":{"293":1}}],["ipv6",{"2":{"251":1}}],["ipv6有40",{"2":{"251":1}}],["ipv6协议的数据包需要1280个字节",{"2":{"251":1}}],["ipv6协议具有128位",{"2":{"251":1}}],["ipv6地址是以十六进制表示的二进制数",{"2":{"251":1}}],["ipv4",{"2":{"251":1}}],["ipv4根据提供的",{"2":{"251":1}}],["ipv4协议的数据包需要576个字节",{"2":{"251":1}}],["ipv4协议具有32位",{"2":{"251":1}}],["ipv4地址是以小数表示的二进制数",{"2":{"251":1}}],["ipv4和ipv6的区别",{"0":{"251":1}}],["ip",{"2":{"250":1,"251":2}}],["ip链接建立起来后",{"2":{"235":1}}],["iexp⁡",{"2":{"428":1}}],["ie8",{"2":{"226":1}}],["iend",{"2":{"90":4}}],["id类树",{"2":{"741":1}}],["id类特征在ctr预估中是非常重要的特征",{"2":{"741":1}}],["id建一类树",{"2":{"741":1}}],["id建gbdt树",{"2":{"741":1}}],["id作为feature进行建树不可行",{"2":{"741":1}}],["id3",{"2":{"600":1,"604":1}}],["id3算法没有考虑过拟合的问题",{"2":{"600":1}}],["id3算法没有考虑连续特征",{"2":{"600":1}}],["id3算法对于缺失值的情况没有做考虑",{"2":{"600":1}}],["id3算法采用信息增益大的特征优先建立决策树的节点",{"2":{"600":1}}],["id3算法",{"0":{"600":1}}],["idf",{"2":{"422":10}}],["idx+1",{"2":{"397":1}}],["idx",{"2":{"397":2}}],["id=1622412414004300046",{"2":{"414":1}}],["id=",{"2":{"163":1,"796":3}}],["id",{"2":{"162":2,"185":3,"189":2,"272":1,"284":1,"658":2}}],["iou计算",{"2":{"390":1}}],["iou误差",{"2":{"378":1}}],["iou比率低于0",{"2":{"371":1}}],["iou的锚点",{"2":{"371":1}}],["iou",{"2":{"367":2,"371":1,"378":3,"389":2,"390":5,"397":3,"399":1}}],["io模型",{"0":{"302":1}}],["ioc",{"0":{"178":1}}],["io",{"0":{"109":2},"2":{"109":12,"131":2,"167":1,"202":1,"203":2,"522":1,"591":1,"670":1,"725":1}}],["ii=0",{"2":{"77":1}}],["ii=1",{"2":{"74":1}}],["ii++",{"2":{"74":1,"77":1}}],["ii",{"2":{"74":2,"77":3,"371":1,"574":1}}],["itplus",{"2":{"725":1}}],["ityouknow",{"2":{"253":1}}],["iterroot+1",{"2":{"90":1}}],["iterroot",{"2":{"90":4}}],["iter",{"2":{"90":6}}],["iterative",{"0":{"439":1},"2":{"439":1}}],["iterativepreorder",{"2":{"85":1}}],["iterator>",{"2":{"54":1}}],["iterator",{"2":{"40":1,"54":1,"60":2,"90":1,"769":1}}],["items作为列",{"2":{"730":1}}],["items",{"2":{"730":1,"782":1}}],["item",{"2":{"70":8,"71":5,"220":5,"222":4,"259":1,"397":2,"595":2,"727":2,"729":2}}],["itr++",{"2":{"60":2}}],["itr",{"2":{"60":9,"89":3}}],["it",{"2":{"19":5,"40":3,"54":11,"89":4}}],["i5++",{"2":{"8":1}}],["i5",{"2":{"8":3}}],["i3++",{"2":{"8":1}}],["i3",{"2":{"8":3}}],["i2其中",{"2":{"740":1}}],["i2++",{"2":{"8":1}}],["i2",{"2":{"8":3}}],["is|nlp",{"2":{"719":1,"722":1}}],["isodata",{"2":{"676":1}}],["isolation隔离性",{"2":{"258":1}}],["isarray",{"2":{"220":1,"222":2}}],["isture",{"2":{"203":1}}],["istart",{"2":{"90":6}}],["issymmetric",{"2":{"91":1}}],["ismirror",{"2":{"91":4}}],["isbalanced",{"2":{"87":3}}],["isvalid",{"2":{"75":1}}],["iscyclicgraph",{"2":{"61":1}}],["isinterleave",{"2":{"13":1}}],["ispalindrome",{"2":{"64":1,"76":1}}],["ispalin",{"2":{"7":6}}],["is",{"2":{"6":1,"64":4,"66":1,"67":1,"70":1,"76":3,"214":1,"719":5,"722":1}}],["i+2",{"2":{"37":1}}],["i+j+1",{"2":{"83":3}}],["i+j",{"2":{"13":5,"83":2}}],["i+l",{"2":{"6":1}}],["i+1",{"2":{"3":1,"12":2,"18":1,"19":1,"25":3,"33":1,"34":4,"36":4,"37":2,"38":2,"46":1,"78":2,"81":2,"758":1,"763":1}}],["i++",{"2":{"1":1,"2":1,"3":1,"4":1,"5":3,"6":2,"7":2,"8":1,"9":2,"10":3,"11":2,"12":1,"13":3,"14":1,"15":1,"22":1,"23":1,"25":1,"29":1,"30":1,"35":1,"38":1,"40":1,"48":2,"53":3,"58":1,"59":1,"60":2,"61":3,"77":1,"81":2,"82":5,"83":1,"92":1,"759":2,"760":2}}],["i=n",{"2":{"756":2}}],["i=n−1",{"2":{"519":1}}],["i=α",{"2":{"740":1}}],["i=αt",{"2":{"740":1}}],["i=αnt",{"2":{"740":2}}],["i=αβ+∑j=1t▽j",{"2":{"740":1}}],["i=wmizmαm1−em",{"2":{"431":1}}],["i=wt",{"2":{"428":1}}],["i=start",{"2":{"53":2}}],["i=l+1",{"2":{"48":1}}],["i=",{"2":{"30":1,"496":1}}],["i=k",{"2":{"29":1}}],["i=2",{"2":{"8":1}}],["i=1",{"2":{"2":1,"5":3,"6":2,"10":2,"14":1,"25":1,"79":1,"428":2,"431":2,"635":22}}],["i=0",{"2":{"1":1,"4":1,"10":1,"15":1,"35":1,"38":1,"60":1,"78":1,"81":1}}],["inline",{"2":{"784":3}}],["innodb",{"0":{"161":1},"2":{"161":1,"162":2,"165":5,"167":2}}],["innerhtml",{"2":{"796":1}}],["inner�",{"2":{"214":1}}],["innervar",{"2":{"214":5}}],["inner",{"2":{"66":9,"67":9,"214":2}}],["instruction",{"2":{"422":1}}],["instanceof",{"2":{"211":4}}],["instance==null",{"2":{"144":2}}],["instance",{"2":{"144":5,"212":2}}],["insertsort",{"2":{"55":1}}],["insertlinked",{"2":{"55":2}}],["insert",{"2":{"32":1,"58":1,"59":1,"174":1}}],["inc",{"2":{"94":3}}],["include",{"2":{"59":1}}],["inorder",{"2":{"90":5}}],["inference",{"2":{"519":1}}],["information",{"2":{"423":1}}],["infinity",{"2":{"210":1,"222":1}}],["inf",{"2":{"69":1}}],["inpre",{"2":{"66":4,"67":4}}],["input>",{"2":{"774":1}}],["input与embedding层",{"0":{"734":1},"1":{"735":1,"736":1}}],["input",{"2":{"3":1,"6":1,"38":1,"95":2,"422":2,"739":1,"796":3}}],["init",{"2":{"66":1,"67":1,"69":1,"70":2,"71":1}}],["indexof",{"2":{"111":1,"220":1}}],["index",{"2":{"38":3,"41":3,"54":5,"82":12,"83":1,"111":3,"203":2,"220":6,"684":1,"756":9,"757":4,"758":3,"798":1,"800":1}}],["interface提供�",{"2":{"798":1}}],["interesting|is",{"2":{"722":1}}],["interesting",{"2":{"719":7,"722":1}}],["inter",{"2":{"390":3,"397":3}}],["interviews",{"2":{"358":1}}],["interview",{"2":{"203":1,"358":1,"850":1}}],["intervals",{"2":{"20":7}}],["interval>",{"2":{"20":1}}],["interval",{"2":{"20":5}}],["internal",{"2":{"203":1}}],["interrupt",{"2":{"139":1}}],["integers",{"2":{"90":2}}],["integer>",{"2":{"82":1}}],["int>>",{"2":{"9":1,"11":1,"21":1,"30":1,"33":2,"34":3,"36":2,"40":1,"58":2,"59":1,"61":1,"89":1}}],["int>",{"2":{"1":1,"4":1,"11":1,"14":1,"18":1,"21":2,"23":1,"24":1,"25":1,"26":1,"27":1,"29":2,"30":2,"31":2,"34":4,"36":1,"40":7,"41":1,"43":1,"44":2,"45":2,"46":3,"47":4,"49":1,"54":7,"58":10,"59":5,"60":7,"61":4,"86":3,"89":1,"90":3,"92":2,"94":1,"95":1}}],["int",{"2":{"1":4,"2":4,"3":6,"4":6,"5":6,"6":6,"7":8,"8":13,"9":9,"10":16,"11":4,"12":4,"13":6,"14":5,"15":6,"18":3,"19":2,"20":6,"21":6,"22":19,"23":4,"24":4,"25":3,"26":5,"27":6,"29":2,"30":2,"31":3,"32":6,"33":7,"34":5,"35":5,"36":5,"37":1,"38":5,"40":20,"41":6,"42":13,"43":19,"44":3,"45":9,"46":3,"47":3,"48":16,"49":1,"51":8,"52":10,"53":7,"54":4,"55":1,"56":2,"58":19,"59":29,"60":7,"61":9,"73":1,"74":1,"76":1,"77":7,"78":8,"79":4,"80":4,"81":5,"82":8,"83":8,"84":2,"85":2,"86":3,"87":1,"88":2,"89":3,"90":1,"92":5,"93":6,"94":8,"95":2,"756":10,"757":1,"760":1,"762":2,"769":1}}],["in",{"0":{"221":1},"2":{"1":1,"3":1,"6":1,"60":5,"72":1,"221":2,"223":1,"307":2,"536":2,"635":2,"730":3,"758":2,"759":1,"769":2}}],["ifc",{"0":{"784":1},"2":{"784":2}}],["ifgt",{"2":{"428":2}}],["if|x|",{"2":{"367":1}}],["if",{"2":{"1":3,"2":3,"3":2,"4":1,"5":1,"6":1,"7":2,"8":3,"9":1,"10":3,"11":2,"13":5,"18":2,"19":1,"20":2,"22":4,"23":1,"25":1,"27":2,"29":1,"30":1,"31":4,"32":3,"33":5,"34":3,"35":4,"36":11,"37":3,"38":4,"40":4,"41":5,"42":8,"43":2,"44":8,"45":6,"47":3,"48":5,"49":1,"51":2,"52":3,"53":2,"55":1,"56":4,"58":5,"59":7,"60":3,"61":3,"64":1,"65":1,"66":2,"67":5,"68":1,"69":3,"70":4,"71":3,"73":1,"74":2,"75":3,"76":2,"77":3,"78":4,"79":2,"80":3,"81":1,"82":2,"83":1,"85":9,"86":5,"87":3,"88":3,"89":1,"90":1,"91":2,"92":5,"93":3,"94":5,"95":2,"111":5,"144":2,"222":1,"223":1,"372":1,"397":2,"532":1,"756":3,"757":2,"759":1,"760":2}}],["i",{"2":{"1":10,"2":16,"3":7,"4":6,"5":22,"6":17,"7":31,"8":1,"9":20,"10":11,"11":21,"12":12,"13":30,"14":7,"15":4,"18":8,"19":6,"20":5,"21":4,"22":7,"23":3,"24":5,"25":10,"27":4,"29":3,"30":6,"31":16,"32":7,"33":13,"34":7,"35":1,"36":20,"37":7,"38":5,"40":28,"42":16,"43":18,"45":5,"46":9,"47":11,"48":5,"49":8,"51":5,"52":14,"53":6,"54":17,"58":31,"59":18,"60":6,"61":15,"72":1,"73":3,"77":7,"78":6,"79":4,"81":4,"82":26,"83":9,"85":3,"86":3,"92":7,"202":2,"276":1,"301":2,"302":7,"367":1,"371":1,"381":3,"397":11,"431":1,"496":2,"519":2,"545":1,"612":4,"635":30,"654":1,"657":11,"661":8,"729":10,"730":8,"735":1,"740":1,"756":18,"757":5,"758":3,"759":7,"760":4,"763":2}}],["=u",{"2":{"730":1}}],["=ru1⋅ru2|ru1|2|ru2|2=∑i∈pu1",{"2":{"730":1}}],["=r",{"2":{"729":1}}],["=v",{"2":{"721":1}}],["=θu+η",{"2":{"721":1}}],["=θ0x0+θ1x1+θ2x2",{"2":{"655":1}}],["=θ0x0+θ1x1+",{"2":{"545":1}}],["=d",{"2":{"721":1}}],["=∏w∈d∏c∈c",{"2":{"722":1}}],["=∏w∈dp",{"2":{"719":1}}],["=∏i=1m11+e−yiwxi对上式取对数及负值",{"2":{"668":1}}],["=∏i=1mhω",{"2":{"668":1}}],["=∏i=1mp",{"2":{"668":1}}],["=∏i=1m",{"2":{"661":1}}],["=γo∗c",{"2":{"697":1}}],["=γu∗c^",{"2":{"697":1}}],["=tanh⁡",{"2":{"697":1}}],["=temp",{"2":{"77":1}}],["=heapsize",{"2":{"756":2}}],["=hω",{"2":{"668":2}}],["=hθ",{"2":{"661":1}}],["=exp⁡",{"2":{"635":1}}],["=end",{"2":{"53":3}}],["=x^",{"2":{"635":1}}],["=y",{"2":{"635":3}}],["=yi",{"2":{"428":1}}],["=ρ×",{"2":{"601":1}}],["=ρ×gain",{"2":{"601":1}}],["=z",{"2":{"536":1}}],["=g",{"2":{"531":1}}],["=−log⁡∏i=1mp",{"2":{"668":1}}],["=−lnl",{"2":{"661":1}}],["=−12∑i=1n∑j=1nαiαjyiyj",{"2":{"635":1}}],["=−12∑j=1t",{"2":{"496":1}}],["=−∑i=1mlog⁡11+e−yiwxi=∑i=1mlog⁡",{"2":{"668":1}}],["=−∑i=1mlog⁡p",{"2":{"668":1}}],["=−∑i=1m",{"2":{"661":1}}],["=−∑i=1nαi∗yi=0",{"2":{"635":1}}],["=−∑i=1nαiyi=0",{"2":{"635":1}}],["=−∑kntkntlog⁡ntknt其中|t|代表叶节点个数",{"2":{"602":1}}],["=−∑k=1|y|p~klog2⁡p~k",{"2":{"601":1}}],["=−∂l",{"2":{"497":1}}],["=f",{"2":{"496":2,"547":1,"555":1}}],["=fm−1",{"2":{"430":1,"434":1,"496":2}}],["=∑t=1l−1i^j2i",{"2":{"741":1}}],["=∑t=1|t|ntht",{"2":{"602":1}}],["=∑w∈d∑c∈c",{"2":{"722":1}}],["=∑w∈d∑u∈pos",{"2":{"721":1}}],["=∑w∈d",{"2":{"721":1}}],["=∑w∈dlog⁡∏u∈pos",{"2":{"721":1}}],["=∑w∈dlog⁡∏u∈dp",{"2":{"721":1}}],["=∑w∈dlog⁡p",{"2":{"719":1,"721":1}}],["=∑n=1n",{"2":{"535":1}}],["=∑zp",{"2":{"521":2}}],["=∑j=1t",{"2":{"496":2}}],["=∑m=1mgm∗",{"2":{"431":1}}],["=∑m−1mαmgm",{"2":{"430":1}}],["=∑yi=gm",{"2":{"430":1}}],["=∑i=1k∑j∈ci",{"2":{"682":1}}],["=∑i=1n",{"2":{"496":3}}],["=∑i=1nlog⁡p",{"2":{"619":1}}],["=∑i=1nl",{"2":{"496":2}}],["=∑i=1mwtii",{"2":{"428":1}}],["=∑i=1m",{"2":{"276":1}}],["=∑i∈pu1",{"2":{"730":1}}],["=∑i∈",{"2":{"372":1}}],["=w∗−∑i=1nαi∗yixi=0",{"2":{"635":2}}],["=w−∑i=1nαiyixi=0",{"2":{"635":1}}],["=w⋅f1",{"2":{"519":1}}],["=w0+∑m=1mwmϕm",{"2":{"457":1}}],["=w11",{"2":{"431":1}}],["=wt",{"2":{"428":1}}],["=word2",{"2":{"5":2}}],["=word1",{"2":{"5":2}}],["=p",{"2":{"282":3,"521":1,"612":1,"613":1,"614":1,"621":1,"631":1}}],["=8",{"2":{"277":1}}],["=6",{"2":{"277":1}}],["=2",{"2":{"267":4}}],["=>",{"2":{"111":4,"114":3,"222":2,"793":2}}],["=>>",{"2":{"43":1}}],["=c",{"2":{"532":2}}],["=ch",{"2":{"81":1}}],["=chars",{"2":{"81":1}}],["=cmp",{"2":{"51":2,"53":2}}],["=log⁡",{"2":{"668":1}}],["=l",{"2":{"496":1,"497":3}}],["=len",{"2":{"79":2}}],["=lcp",{"2":{"74":1}}],["=items",{"2":{"730":1}}],["=i",{"2":{"51":1,"79":1}}],["=0=",{"2":{"721":1}}],["=0f",{"2":{"635":1}}],["=0知道知道",{"2":{"635":1}}],["=0$显然不是原问题的解",{"2":{"635":1}}],["=0$",{"2":{"635":1}}],["=0解这个线性方程组可以得到",{"2":{"555":1}}],["=0对于一般的函数",{"2":{"555":1}}],["=0",{"2":{"27":1,"189":1,"282":4,"635":6}}],["=mid",{"2":{"53":2}}],["=minx∈ci",{"2":{"684":1}}],["=minw",{"2":{"635":1}}],["=min∂l",{"2":{"497":1}}],["=min",{"2":{"11":1}}],["=maxx",{"2":{"684":1}}],["=maxαi≥0minw",{"2":{"635":1}}],["=max⏟t∈ta",{"2":{"603":1}}],["=max⏟t∈tagain",{"2":{"603":1}}],["=max1",{"2":{"519":2}}],["=ma",{"2":{"10":1}}],["=sign",{"2":{"428":1,"635":1}}],["=s",{"2":{"10":2,"77":1}}],["=nyk1+αnyk+αn",{"2":{"621":1}}],["=none",{"2":{"71":1}}],["=n",{"2":{"8":1}}],["=j",{"2":{"6":1,"735":1}}],["=11−σ",{"2":{"721":1}}],["=11+e",{"2":{"660":1}}],["=11+e−t函数中t无论取什么值",{"2":{"660":1}}],["=1−h",{"2":{"668":1}}],["=1−hω",{"2":{"668":1}}],["=1−acc",{"2":{"585":1}}],["=1−不可解释性变异整体变异=1−msevar=r2",{"2":{"583":1}}],["=1n∑i=1nyi=yi^",{"2":{"585":1}}],["=1ncls∑ilcls",{"2":{"367":1}}],["=12∑f=1k",{"2":{"735":2}}],["=12∑i=1mw",{"2":{"657":1}}],["=12∑im",{"2":{"657":1}}],["=12m∑i=1m",{"2":{"656":1,"657":3}}],["=12m∑j=0m",{"2":{"545":1}}],["=12∥w∥2+∑i=1nαi",{"2":{"635":1}}],["=12πσij2e",{"2":{"620":1}}],["=12πσexp⁡",{"2":{"568":1}}],["=12λe−|x−μ|λgaussian",{"2":{"568":1}}],["=1m∑j=0m",{"2":{"545":2}}],["=1zexp⁡",{"2":{"519":1}}],["=1",{"2":{"4":2,"11":1,"267":3,"276":2,"277":3,"280":1,"532":1,"654":1,"735":1}}],["=b",{"2":{"2":1}}],["=arg⁡max1⩽j⩽m",{"2":{"519":1}}],["=argminα",{"2":{"430":1}}],["=a",{"2":{"2":1}}],["===",{"2":{"223":3,"224":2}}],["==�",{"0":{"123":1}}],["==chars",{"2":{"81":1}}],["==s",{"2":{"78":1,"79":2}}],["==sptset",{"2":{"58":1}}],["==0",{"2":{"74":1}}],["==mstset",{"2":{"59":1}}],["==1",{"2":{"4":1}}],["==b",{"2":{"2":1}}],["==",{"2":{"1":1,"2":1,"3":2,"5":2,"7":2,"8":3,"11":1,"13":6,"19":2,"27":3,"30":1,"31":2,"32":4,"34":2,"35":3,"36":8,"37":2,"38":1,"40":3,"41":2,"42":7,"44":5,"45":4,"47":1,"48":2,"49":2,"54":1,"55":1,"56":2,"58":1,"59":1,"60":2,"64":1,"66":1,"67":5,"68":1,"70":3,"73":1,"74":1,"77":3,"80":2,"82":5,"83":1,"85":4,"86":2,"87":2,"88":2,"90":1,"91":3,"92":2,"94":4,"123":2,"224":2,"279":1,"397":2,"759":1}}],["=",{"2":{"1":6,"2":6,"3":7,"4":1,"5":8,"6":7,"7":15,"8":9,"9":15,"11":11,"12":7,"13":18,"14":8,"15":5,"18":5,"19":6,"20":7,"21":4,"22":25,"23":7,"24":5,"25":2,"26":6,"27":3,"30":1,"31":6,"32":7,"33":6,"34":2,"35":8,"36":11,"37":1,"38":8,"40":17,"41":9,"42":16,"43":17,"44":12,"45":15,"46":7,"47":5,"48":2,"49":2,"51":5,"52":10,"53":7,"54":11,"55":14,"56":28,"58":27,"59":38,"60":8,"61":10,"64":8,"65":4,"66":10,"67":32,"68":9,"69":8,"70":12,"71":16,"72":8,"73":8,"74":1,"75":3,"76":4,"77":2,"78":12,"79":10,"80":3,"81":2,"82":15,"83":13,"85":4,"86":4,"88":2,"89":4,"90":5,"92":3,"93":4,"94":11,"95":1,"111":12,"112":4,"114":3,"144":2,"212":1,"214":6,"215":3,"217":11,"218":3,"222":6,"223":3,"224":4,"226":1,"229":2,"274":4,"277":1,"280":2,"282":1,"306":6,"315":2,"357":1,"367":1,"369":1,"372":1,"378":1,"390":13,"393":1,"395":1,"397":18,"428":3,"472":3,"495":1,"512":1,"532":2,"533":1,"536":3,"537":3,"547":1,"612":1,"635":9,"638":1,"655":1,"661":1,"721":2,"730":3,"751":1,"756":7,"757":4,"758":1,"759":5,"760":13,"761":3,"763":2,"769":1,"770":1,"793":1,"795":2,"796":4,"800":7}}],["j^j2",{"2":{"741":1}}],["j^j2=1m∑m=1mj^j2",{"2":{"741":1}}],["jeffrey",{"2":{"651":1}}],["j出现的概出现的概",{"2":{"612":1}}],["j为参数个数",{"2":{"545":1}}],["jδℓk+∑ℓ≤jδℓ",{"2":{"532":1}}],["jγℓ",{"2":{"532":1}}],["jaccard",{"2":{"730":1}}],["jamexfx",{"2":{"517":1}}],["jasonwang",{"2":{"473":1}}],["javascript深度理解",{"2":{"847":1}}],["javascriptobject",{"2":{"796":1}}],["javascriptevent",{"2":{"779":1}}],["javascriptdocument",{"2":{"226":1}}],["javascriptdosomething",{"2":{"218":1}}],["javascriptpush",{"2":{"220":1}}],["javascriptthis",{"2":{"793":1}}],["javascripttry",{"2":{"218":1}}],["javascripttypeof",{"2":{"211":1}}],["javascriptname",{"2":{"214":1}}],["javascriptvar",{"2":{"214":1}}],["javascriptfunction",{"2":{"213":1,"214":1,"217":1}}],["javascript",{"0":{"208":1,"209":1,"216":1,"219":1},"1":{"209":1,"210":2,"211":2,"212":2,"213":2,"214":2,"215":2,"216":1,"217":2,"218":2,"219":1,"220":2,"221":2,"222":2,"223":2,"224":2,"225":1,"226":1,"227":1,"228":1,"229":1},"2":{"211":2,"223":1,"229":1,"790":1,"800":1,"847":1}}],["javascript基础",{"2":{"207":1}}],["javascriptconsole",{"2":{"211":1}}],["javascriptconst",{"2":{"111":1,"114":1,"215":1,"222":1,"224":2,"800":3}}],["javascriptclass",{"2":{"111":1}}],["java基础",{"2":{"206":1,"767":1}}],["javaclass",{"2":{"144":1}}],["java乐观锁机�",{"0":{"133":1}}],["java乐观锁机制",{"0":{"132":1},"1":{"133":1,"134":1,"135":1}}],["java并发",{"0":{"125":1},"1":{"126":1,"127":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1,"134":1,"135":1,"136":1,"137":1,"138":1,"139":1,"140":1,"141":1,"142":1,"143":1,"144":1,"145":1,"146":1,"147":1,"148":1}}],["java",{"0":{"115":1,"140":1},"1":{"116":1,"117":1,"118":1,"119":1,"120":1,"121":1,"122":1,"123":1,"124":1},"2":{"82":1,"133":2,"135":2,"136":1,"139":2,"140":11,"203":2,"769":1,"846":2}}],["jpg",{"2":{"271":1}}],["journal",{"2":{"686":1}}],["jones",{"2":{"361":1}}],["join",{"2":{"220":1}}],["john",{"2":{"211":4}}],["jianshu",{"2":{"203":2,"253":1,"499":1}}],["jiuzhang",{"2":{"26":1,"96":1}}],["justify",{"2":{"782":1}}],["junshen1314",{"2":{"652":1}}],["july",{"2":{"652":1,"753":1}}],["july的博客",{"2":{"442":1}}],["julyedu",{"2":{"272":1,"284":1,"658":1}}],["juejin",{"2":{"203":1}}],["judge",{"2":{"78":2}}],["jmm",{"2":{"140":2}}],["jdk1",{"2":{"139":1}}],["jvm",{"0":{"149":1,"152":1,"157":1},"1":{"150":1,"151":1,"152":1,"153":1,"154":1,"155":1,"156":1,"157":1},"2":{"122":1,"139":1}}],["jsp",{"2":{"253":1}}],["js进行解析",{"2":{"235":1}}],["jsonl",{"2":{"423":1}}],["json",{"2":{"223":2,"422":5}}],["js文件",{"2":{"112":1}}],["js",{"0":{"210":1,"211":1,"212":1,"213":1,"214":1,"215":1,"217":1,"218":1,"228":2,"229":1},"2":{"109":2,"112":1,"215":1,"228":1,"790":1,"792":2,"800":2}}],["j的路径小于dist",{"2":{"58":1}}],["j的最短距离",{"2":{"58":1}}],["j+1",{"2":{"33":1,"36":4}}],["j++",{"2":{"1":1,"2":1,"3":1,"5":1,"7":2,"9":2,"10":1,"11":2,"13":1,"35":1,"53":2,"58":1,"77":1,"78":1,"760":2}}],["j>start",{"2":{"51":1}}],["j>l",{"2":{"48":1}}],["j>0",{"2":{"15":1}}],["j>=a",{"2":{"4":1}}],["j=r",{"2":{"48":1}}],["j=k",{"2":{"15":1}}],["j=i",{"2":{"10":1}}],["j=minuv∑",{"2":{"730":1}}],["j=mid+1",{"2":{"53":1}}],["j=m",{"2":{"4":1}}],["j=1",{"2":{"2":1,"5":1,"519":1,"635":1}}],["j=0",{"2":{"1":1,"35":1,"77":1}}],["j",{"2":{"1":8,"2":16,"3":10,"4":5,"5":16,"6":13,"7":13,"9":20,"10":2,"11":21,"13":18,"15":6,"31":9,"32":7,"33":13,"35":5,"36":19,"40":7,"43":5,"45":6,"48":8,"49":8,"51":9,"53":3,"58":20,"73":2,"77":8,"78":7,"83":4,"519":7,"545":2,"635":6,"656":1,"657":5,"661":1,"686":2,"729":3,"730":1,"735":5,"757":8,"760":4}}],["1内联块状元素同时具备内联元素",{"2":{"774":1}}],["1内联元素",{"2":{"774":1}}],["1位串来表示",{"2":{"759":1}}],["1位表示一个老鼠",{"2":{"269":1}}],["1维护堆中每个节点的最大堆性质",{"2":{"756":1}}],["1g",{"2":{"763":1}}],["1g内存",{"2":{"751":1}}],["1g左右的内存支持10w左右的连接数",{"2":{"302":1}}],["1阶",{"2":{"735":1}}],["1间的一种回归模型",{"2":{"666":1}}],["1$",{"2":{"655":1}}],["1lambda",{"2":{"618":1}}],["1≤v≤v",{"2":{"601":1}}],["1≤k≤|y|",{"2":{"601":1}}],["1p+1r",{"2":{"589":1}}],["1f1=12⋅",{"2":{"589":1}}],["1−p",{"2":{"740":1,"741":1}}],["1−d",{"2":{"721":5}}],["1−σ",{"2":{"721":6}}],["1−y",{"2":{"661":3}}],["1−yi",{"2":{"635":6}}],["1−hθ",{"2":{"661":3}}],["1−ρ",{"2":{"657":1}}],["1−k+∑ℓ",{"2":{"532":1}}],["1−0",{"2":{"282":2}}],["1+exp⁡",{"2":{"532":1}}],["1+e−yiwxi",{"2":{"668":2}}],["1+e−k",{"2":{"532":1}}],["1+e−x",{"2":{"532":1}}],["1^",{"2":{"519":1}}],["1次迭代的预测值",{"2":{"497":2,"505":1}}],["1次位运算+1次异或运�",{"2":{"118":1}}],["1的负梯度作为残差",{"2":{"497":1}}],["1的梯度作为当前残差进行拟合",{"2":{"497":1}}],["1的卷积核进行传统的卷积运算",{"2":{"317":1}}],["1树的残差",{"2":{"497":1}}],["1日",{"2":{"495":1}}],["1个单词的影响",{"2":{"527":1}}],["1个的学习剩下的label的偏差",{"2":{"436":1}}],["1个模型的误差更新当前数据集的权重",{"2":{"436":1}}],["1个学习器得到的误差更新数据分布",{"2":{"435":1}}],["1个边",{"2":{"59":1}}],["1张卡运行策略模型更新",{"2":{"423":1}}],["1张卡处理环境模拟",{"2":{"423":1}}],["1组k",{"2":{"422":1}}],["1组成的二进制串中",{"2":{"12":1}}],["1∗1∗cin",{"2":{"395":1}}],["1卷积",{"2":{"394":1,"395":1}}],["1共11个点时的precision最大值",{"2":{"393":1}}],["1|x|−0",{"2":{"367":1,"372":1}}],["1997",{"2":{"690":1}}],["1998年",{"2":{"360":1}}],["19",{"0":{"322":1,"630":1,"672":1},"2":{"414":1,"497":2}}],["1×1卷积核理解",{"2":{"320":1}}],["1×1卷积核可以在保持feature",{"2":{"320":1}}],["165406531",{"2":{"577":1}}],["16=133k",{"2":{"357":1}}],["16=9",{"2":{"357":1}}],["16=2",{"2":{"357":1}}],["16",{"0":{"319":1,"515":1,"555":1,"627":1,"669":1},"2":{"279":1,"357":6,"388":1,"414":1,"496":1,"593":1,"770":1,"792":1}}],["16字节",{"2":{"251":1}}],["1=1",{"2":{"267":1}}],["1=nan�",{"2":{"210":1}}],["1和y+1的其中的一个",{"2":{"267":1}}],["1和y+1",{"2":{"267":1}}],["1和x+1",{"2":{"267":1}}],["1788",{"2":{"666":1}}],["17$个观测值",{"2":{"512":1}}],["17",{"0":{"320":1,"516":1,"628":1,"670":1},"2":{"210":1,"414":1,"496":2,"594":1}}],["181413",{"2":{"414":1}}],["18",{"0":{"321":1,"629":1,"671":1},"2":{"163":1,"414":1,"496":1}}],["1x1",{"2":{"388":1}}],["1x",{"2":{"46":1}}],["1�",{"2":{"41":1,"110":3,"139":1}}],["1408",{"2":{"689":1}}],["14",{"0":{"14":1,"317":1,"488":1,"513":1,"553":1,"625":1,"667":1},"2":{"89":1,"211":2,"279":1,"414":1,"496":1,"591":1}}],["13",{"0":{"13":1,"247":1,"316":1,"376":1,"487":1,"552":1,"609":1,"624":1,"666":1},"2":{"89":1,"279":1,"414":2,"496":1,"590":1}}],["120deg",{"2":{"787":1}}],["12∥w∥2",{"2":{"635":1}}],["128维的sift特征",{"2":{"651":1}}],["128",{"2":{"388":1}}],["1282",{"2":{"367":1}}],["12583965",{"2":{"253":1}}],["12apply",{"2":{"213":1}}],["123如果不想对元素用",{"2":{"787":1}}],["123addeventlistener",{"2":{"226":1}}],["1234将朴素贝叶斯中的所有概率计",{"2":{"618":1}}],["1234则有",{"2":{"586":1}}],["1234作用域链",{"2":{"214":1}}],["12345�",{"2":{"224":1}}],["12345",{"2":{"114":1,"224":1,"229":1}}],["1234563",{"2":{"800":1}}],["123456建成最大堆之后",{"2":{"756":1}}],["123456解析",{"2":{"267":1}}],["123456",{"2":{"84":1,"782":1}}],["1234567但是",{"2":{"787":1}}],["12345672",{"2":{"782":1}}],["123456782",{"2":{"800":1}}],["12345678一个简单的响应式数据的例子�",{"2":{"796":1}}],["12345678",{"2":{"218":1,"800":1}}],["12345678910history",{"2":{"798":1}}],["12345678910使用",{"2":{"211":1}}],["1234567891011async",{"2":{"218":1}}],["1234567891011",{"2":{"88":1}}],["12345678910111213扩展",{"2":{"94":1}}],["12345678910111213cpp",{"2":{"91":1}}],["1234567891011121314commonjs",{"2":{"112":1}}],["1234567891011121314",{"2":{"23":1,"29":1,"68":1,"144":1}}],["123456789101112131415",{"2":{"4":1,"14":1,"19":1,"91":1,"759":1,"798":1}}],["123456789101112131415161718",{"2":{"72":1,"89":1,"214":1}}],["1234567891011121314151617181920基于上面的这个维护的性质",{"2":{"756":1}}],["123456789101112131415161718192021",{"2":{"66":1,"220":1}}],["12345678910111213141516171819202122",{"2":{"34":1,"71":1,"81":1,"90":1,"92":1}}],["123456789101112131415161718192021222324访问",{"2":{"114":1}}],["123456789101112131415161718192021222324class",{"2":{"94":1}}],["123456789101112131415161718192021222324",{"2":{"80":1}}],["12345678910111213141516171819202122232425快速排序在海量数据处理的过程中",{"2":{"757":1}}],["12345678910111213141516171819202122232425",{"2":{"33":1,"76":1,"222":1,"760":1}}],["123456789101112131415161718192021222324252627282930void",{"2":{"94":1}}],["123456789101112131415161718192021222324252627282930",{"2":{"58":1,"796":1}}],["12345678910111213141516171819202122232425262728293031",{"2":{"48":1,"53":1}}],["12345678910111213141516171819202122232425262728293031323334",{"2":{"59":1}}],["12345678910111213141516171819202122232425262728293031323334353637",{"2":{"55":1,"70":1}}],["12345678910111213141516171819202122232425262728293031323334353637383940",{"2":{"60":1,"78":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041424344使用�",{"2":{"111":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041424344",{"2":{"61":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445",{"2":{"43":1}}],["12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758",{"2":{"82":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465",{"2":{"85":1}}],["12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697",{"2":{"217":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869",{"2":{"56":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263",{"2":{"22":1,"59":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354",{"2":{"67":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748",{"2":{"40":1,"42":1,"77":1,"83":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041",{"2":{"45":1}}],["123456789101112131415161718192021222324252627282930313233343536373839",{"2":{"36":1,"86":1}}],["1234567891011121314151617181920212223242526272829303132333435",{"2":{"32":1,"44":1,"51":1,"52":1,"69":1}}],["123456789101112131415161718192021222324252627282930313233",{"2":{"35":1,"54":1}}],["1234567891011121314151617181920212223242526272829303132",{"2":{"31":1,"58":1,"75":1,"397":1}}],["1234567891011121314151617181920212223242526272829",{"2":{"38":1,"79":1}}],["12345678910111213141516171819202122232425262728",{"2":{"10":1,"111":1}}],["123456789101112131415161718192021222324252627",{"2":{"9":1,"47":1,"390":1}}],["1234567891011121314151617181920212223242526",{"2":{"7":1,"13":1,"37":1}}],["1234567891011121314151617181920212223",{"2":{"8":1,"11":1,"20":1,"94":1}}],["1234567891011121314151617181920",{"2":{"41":1}}],["12345678910111213141516171819bool",{"2":{"36":1}}],["12345678910111213141516171819",{"2":{"6":1,"95":1}}],["1234567891011121314151617",{"2":{"5":1,"793":1}}],["12345678910111213141516",{"2":{"1":1,"21":1,"46":1,"64":1,"74":1,"112":1,"223":1,"775":1}}],["12345678910111213",{"2":{"3":1,"15":1,"27":1,"30":1,"73":1,"93":1}}],["123456789101112",{"2":{"2":1,"87":1,"215":1,"758":1}}],["12345678910",{"2":{"49":1,"95":1}}],["123456789",{"2":{"12":1,"18":1,"24":1,"25":1,"26":1,"756":1,"782":1}}],["1234567函数作用域",{"2":{"214":1}}],["1234567使用",{"2":{"211":1}}],["1234567",{"2":{"65":1,"570":1,"762":1,"782":1}}],["1234",{"2":{"89":1}}],["123的第1",{"2":{"83":1}}],["123",{"2":{"83":2,"112":1,"211":1}}],["126",{"2":{"81":1}}],["12class",{"2":{"68":1,"69":1}}],["12bool",{"2":{"38":1}}],["12",{"0":{"12":1,"246":1,"315":1,"375":1,"441":1,"486":1,"512":1,"551":1,"608":1,"623":1,"665":1,"685":1},"2":{"276":1,"279":1,"414":1,"423":1,"496":1,"590":1,"779":1}}],["11无意义",{"2":{"751":1}}],["11596848",{"2":{"725":1}}],["11309134",{"2":{"656":1}}],["116656242",{"2":{"414":1}}],["11号蛋",{"2":{"270":1}}],["11这3个蛋中",{"2":{"270":1}}],["111011001",{"2":{"759":1}}],["111",{"2":{"269":1}}],["11111",{"2":{"111":1}}],["110",{"2":{"269":1}}],["1190000020610336",{"2":{"253":1}}],["11",{"0":{"11":1,"95":1,"171":1,"245":1,"314":1,"374":1,"440":1,"485":1,"511":1,"550":1,"568":1,"607":1,"622":1,"664":1,"684":1},"1":{"172":1,"173":1,"174":1},"2":{"217":1,"270":2,"278":1,"279":1,"414":1,"496":1,"589":1,"618":1}}],["15",{"0":{"15":1,"318":1,"489":1,"514":1,"554":1,"626":1,"668":1},"2":{"3":1,"86":2,"279":1,"414":1,"496":1,"591":1,"792":3}}],["107",{"2":{"763":2}}],["10^7",{"2":{"763":1}}],["10保持不变",{"2":{"751":1}}],["10表示多次",{"2":{"751":1}}],["10的结果将query写入到另外10个文件",{"2":{"748":1}}],["10653699",{"2":{"595":1}}],["10时",{"2":{"509":1}}],["10万样本",{"2":{"423":1}}],["105121529",{"2":{"414":1}}],["105740704",{"2":{"414":1}}],["105912701",{"2":{"414":1}}],["10m",{"2":{"357":1}}],["10293057",{"2":{"303":1}}],["10映射为1",{"2":{"278":1}}],["1003=0",{"2":{"618":3}}],["100",{"2":{"269":1,"422":1}}],["1000",{"2":{"15":2,"31":1,"79":1,"81":1,"217":1,"422":2,"423":1,"747":1}}],["1000000",{"2":{"18":1}}],["100000",{"2":{"8":1}}],["103728",{"2":{"259":1}}],["10856177",{"2":{"253":1}}],["108052428",{"2":{"203":1}}],["101+fpn用作特征提取网络",{"2":{"375":1}}],["101",{"2":{"10":4,"269":1}}],["10x30",{"2":{"6":1}}],["10能被5整除",{"2":{"3":1}}],["10",{"0":{"10":1,"27":1,"38":1,"49":1,"73":1,"83":1,"94":1,"170":1,"244":1,"283":1,"302":1,"313":1,"373":1,"439":1,"462":1,"484":1,"510":1,"549":1,"567":1,"606":1,"621":1,"643":1,"663":1,"683":1},"2":{"3":2,"6":4,"83":3,"89":1,"270":4,"278":1,"414":1,"469":2,"496":1,"512":1,"536":1,"589":1,"758":2,"759":1}}],["1",{"0":{"1":1,"18":1,"29":1,"40":1,"51":1,"58":1,"64":1,"74":1,"85":1,"118":2,"119":1,"128":1,"152":1,"157":2,"161":1,"178":1,"184":1,"209":1,"233":1,"249":1,"255":1,"267":1,"274":1,"288":1,"305":1,"364":1,"365":1,"378":1,"385":1,"399":1,"406":1,"425":1,"427":1,"430":1,"444":1,"453":1,"464":1,"475":1,"501":1,"519":1,"531":1,"540":1,"558":1,"570":1,"597":1,"612":1,"634":1,"646":1,"654":1,"668":1,"674":1,"717":1,"718":2,"719":1,"720":2,"721":1,"722":1,"723":2,"724":1,"747":1,"773":1,"781":1,"831":1},"1":{"119":2,"120":2,"129":1,"130":1,"131":1,"185":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1,"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1,"718":1,"719":1,"720":2,"721":2,"722":1,"723":2,"724":2,"774":1,"775":1,"776":1,"782":1},"2":{"1":5,"2":11,"3":2,"5":19,"6":7,"7":16,"8":3,"9":14,"10":7,"11":24,"12":7,"13":26,"15":3,"18":1,"19":1,"20":2,"21":1,"22":1,"23":4,"24":1,"25":3,"27":3,"29":1,"30":2,"31":2,"32":1,"33":3,"34":2,"35":1,"36":13,"37":4,"40":3,"41":8,"42":7,"43":4,"44":10,"45":4,"46":7,"47":1,"48":4,"49":3,"51":2,"52":5,"56":2,"58":1,"59":3,"61":4,"66":1,"67":3,"69":1,"73":1,"74":2,"75":1,"76":2,"77":7,"78":3,"79":2,"81":4,"82":10,"83":11,"86":2,"89":1,"90":3,"91":2,"92":3,"93":1,"94":17,"95":7,"110":1,"111":2,"114":5,"118":2,"131":1,"163":2,"167":1,"185":1,"196":1,"202":1,"210":1,"211":2,"215":2,"217":5,"222":1,"243":1,"252":1,"253":1,"255":1,"256":1,"267":1,"268":2,"270":2,"272":1,"274":18,"275":6,"276":2,"277":12,"278":1,"279":6,"280":10,"281":1,"282":1,"283":1,"306":2,"317":2,"320":1,"337":1,"367":5,"368":3,"369":1,"370":1,"381":1,"390":8,"393":3,"397":12,"402":1,"414":1,"422":3,"423":2,"428":2,"431":1,"472":3,"496":4,"497":2,"503":1,"519":2,"522":1,"529":1,"532":1,"536":4,"544":1,"545":2,"555":2,"556":1,"566":1,"574":1,"580":1,"585":1,"586":4,"587":1,"588":1,"601":3,"612":2,"618":1,"635":9,"651":1,"659":1,"660":3,"668":1,"670":1,"703":1,"718":1,"730":14,"732":1,"735":3,"738":1,"739":2,"741":1,"756":9,"757":3,"758":1,"759":4,"760":2,"761":2,"762":2,"763":5,"769":1,"774":1,"778":1,"782":1,"784":3,"785":1,"786":1,"793":5,"796":1,"800":1}}]],"serializationVersion":2}';export{t as default};
